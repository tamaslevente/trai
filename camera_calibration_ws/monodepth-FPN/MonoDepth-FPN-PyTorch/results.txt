#bs=1 epochs =10#
#################
[epoch  0][iter    0] loss: 102.1421 RMSElog: 10.2142 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   10] loss: 96.3584 RMSElog: 9.6358 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   20] loss: 104.1300 RMSElog: 10.4130 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   30] loss: 105.0377 RMSElog: 10.5038 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   40] loss: 101.4625 RMSElog: 10.1463 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   50] loss: 101.8135 RMSElog: 10.1814 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   60] loss: 100.5578 RMSElog: 10.0558 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   70] loss: 105.2577 RMSElog: 10.5258 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   80] loss: 99.1979 RMSElog: 9.9198 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   90] loss: 101.8199 RMSElog: 10.1820 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  100] loss: 99.9605 RMSElog: 9.9961 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  110] loss: 97.8561 RMSElog: 9.7856 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  120] loss: 97.0205 RMSElog: 9.7020 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  130] loss: 98.7426 RMSElog: 9.8743 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  140] loss: 93.4997 RMSElog: 9.3500 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  150] loss: 99.7364 RMSElog: 9.9736 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  160] loss: 92.8675 RMSElog: 9.2868 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  170] loss: 98.7566 RMSElog: 9.8757 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  180] loss: 99.8795 RMSElog: 9.9879 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  190] loss: 98.3744 RMSElog: 9.8374 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  200] loss: 100.5708 RMSElog: 10.0571 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  210] loss: 97.9316 RMSElog: 9.7932 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  220] loss: 102.7599 RMSElog: 10.2760 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  230] loss: 97.3038 RMSElog: 9.7304 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  240] loss: 99.2101 RMSElog: 9.9210 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  250] loss: 93.4858 RMSElog: 9.3486 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  260] loss: 100.2585 RMSElog: 10.0258 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  270] loss: 93.0985 RMSElog: 9.3098 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  280] loss: 99.4858 RMSElog: 9.9486 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  290] loss: 95.2008 RMSElog: 9.5201 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  300] loss: 96.6946 RMSElog: 9.6695 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  310] loss: 98.7955 RMSElog: 9.8795 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  320] loss: 98.5869 RMSElog: 9.8587 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  330] loss: 97.7763 RMSElog: 9.7776 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  340] loss: 101.1741 RMSElog: 10.1174 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  350] loss: 102.2461 RMSElog: 10.2246 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  360] loss: 91.8394 RMSElog: 9.1839 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  370] loss: 98.1989 RMSElog: 9.8199 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  380] loss: 101.8889 RMSElog: 10.1889 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  390] loss: 96.6095 RMSElog: 9.6610 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  400] loss: 97.7234 RMSElog: 9.7723 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  410] loss: 99.2947 RMSElog: 9.9295 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  420] loss: 97.4834 RMSElog: 9.7483 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  430] loss: 101.1590 RMSElog: 10.1159 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  440] loss: 101.0272 RMSElog: 10.1027 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  450] loss: 100.3411 RMSElog: 10.0341 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  460] loss: 97.1710 RMSElog: 9.7171 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  470] loss: 100.6386 RMSElog: 10.0639 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  480] loss: 98.2169 RMSElog: 9.8217 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  490] loss: 97.0805 RMSElog: 9.7080 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  500] loss: 101.8557 RMSElog: 10.1856 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  510] loss: 98.2158 RMSElog: 9.8216 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  520] loss: 97.9008 RMSElog: 9.7901 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  530] loss: 100.0756 RMSElog: 10.0076 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  540] loss: 96.3880 RMSElog: 9.6388 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  550] loss: 99.6100 RMSElog: 9.9610 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  560] loss: 101.5150 RMSElog: 10.1515 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  570] loss: 96.7024 RMSElog: 9.6702 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  580] loss: 101.7094 RMSElog: 10.1709 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  590] loss: 102.5575 RMSElog: 10.2558 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter    0] loss: 100.5090 RMSElog: 10.0509 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   10] loss: 100.2923 RMSElog: 10.0292 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   20] loss: 102.5085 RMSElog: 10.2509 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   30] loss: 101.3287 RMSElog: 10.1329 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   40] loss: 101.6553 RMSElog: 10.1655 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   50] loss: 99.3804 RMSElog: 9.9380 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   60] loss: 100.4031 RMSElog: 10.0403 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   70] loss: 100.6337 RMSElog: 10.0634 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   80] loss: 101.7533 RMSElog: 10.1753 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   90] loss: 103.5933 RMSElog: 10.3593 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  100] loss: 99.4352 RMSElog: 9.9435 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  110] loss: 100.6191 RMSElog: 10.0619 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  120] loss: 99.5148 RMSElog: 9.9515 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  130] loss: 105.0238 RMSElog: 10.5024 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  140] loss: 99.7965 RMSElog: 9.9796 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  150] loss: 102.6984 RMSElog: 10.2698 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  160] loss: 98.7715 RMSElog: 9.8771 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  170] loss: 101.0798 RMSElog: 10.1080 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  180] loss: 102.7606 RMSElog: 10.2761 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  190] loss: 98.3694 RMSElog: 9.8369 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  200] loss: 99.9074 RMSElog: 9.9907 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  210] loss: 101.0709 RMSElog: 10.1071 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  220] loss: 97.5017 RMSElog: 9.7502 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  230] loss: 101.4707 RMSElog: 10.1471 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  240] loss: 99.0244 RMSElog: 9.9024 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  250] loss: 102.6012 RMSElog: 10.2601 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  260] loss: 99.5738 RMSElog: 9.9574 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  270] loss: 99.1009 RMSElog: 9.9101 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  280] loss: 99.9587 RMSElog: 9.9959 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  290] loss: 101.8856 RMSElog: 10.1886 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  300] loss: 99.8862 RMSElog: 9.9886 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  310] loss: 98.2803 RMSElog: 9.8280 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  320] loss: 99.2914 RMSElog: 9.9291 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  330] loss: 98.0161 RMSElog: 9.8016 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  340] loss: 97.7657 RMSElog: 9.7766 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  350] loss: 101.2011 RMSElog: 10.1201 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  360] loss: 98.9546 RMSElog: 9.8955 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  370] loss: 99.0484 RMSElog: 9.9048 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  380] loss: 97.2485 RMSElog: 9.7248 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  390] loss: 97.6532 RMSElog: 9.7653 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  400] loss: 96.1403 RMSElog: 9.6140 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  410] loss: 99.6342 RMSElog: 9.9634 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  420] loss: 99.1566 RMSElog: 9.9157 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  430] loss: 97.2715 RMSElog: 9.7271 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  440] loss: 98.8290 RMSElog: 9.8829 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  450] loss: 100.5371 RMSElog: 10.0537 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  460] loss: 99.8478 RMSElog: 9.9848 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  470] loss: 97.4681 RMSElog: 9.7468 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  480] loss: 101.8611 RMSElog: 10.1861 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  490] loss: 98.2878 RMSElog: 9.8288 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  500] loss: 101.2390 RMSElog: 10.1239 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  510] loss: 96.3522 RMSElog: 9.6352 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  520] loss: 100.1657 RMSElog: 10.0166 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  530] loss: 99.1563 RMSElog: 9.9156 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  540] loss: 101.1949 RMSElog: 10.1195 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  550] loss: 97.3790 RMSElog: 9.7379 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  560] loss: 102.8131 RMSElog: 10.2813 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  570] loss: 99.7468 RMSElog: 9.9747 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  580] loss: 95.9734 RMSElog: 9.5973 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  590] loss: 99.0568 RMSElog: 9.9057 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter    0] loss: 99.1787 RMSElog: 9.9179 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   10] loss: 104.0516 RMSElog: 10.4052 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   20] loss: 102.2149 RMSElog: 10.2215 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   30] loss: 96.3605 RMSElog: 9.6360 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   40] loss: 102.7560 RMSElog: 10.2756 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   50] loss: 104.3340 RMSElog: 10.4334 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   60] loss: 97.2722 RMSElog: 9.7272 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   70] loss: 97.4476 RMSElog: 9.7448 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   80] loss: 100.8418 RMSElog: 10.0842 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   90] loss: 103.9722 RMSElog: 10.3972 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  100] loss: 101.8656 RMSElog: 10.1866 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  110] loss: 100.9193 RMSElog: 10.0919 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  120] loss: 99.4392 RMSElog: 9.9439 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  130] loss: 98.7344 RMSElog: 9.8734 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  140] loss: 99.3294 RMSElog: 9.9329 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  150] loss: 99.3518 RMSElog: 9.9352 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  160] loss: 96.9428 RMSElog: 9.6943 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  170] loss: 102.2683 RMSElog: 10.2268 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  180] loss: 101.3649 RMSElog: 10.1365 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  190] loss: 101.0437 RMSElog: 10.1044 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  200] loss: 102.1660 RMSElog: 10.2166 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  210] loss: 92.4589 RMSElog: 9.2459 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  220] loss: 98.2720 RMSElog: 9.8272 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  230] loss: 96.5457 RMSElog: 9.6546 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  240] loss: 97.3902 RMSElog: 9.7390 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  250] loss: 102.0426 RMSElog: 10.2043 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  260] loss: 100.1281 RMSElog: 10.0128 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  270] loss: 96.8970 RMSElog: 9.6897 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  280] loss: 100.2199 RMSElog: 10.0220 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  290] loss: 96.7864 RMSElog: 9.6786 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  300] loss: 96.8515 RMSElog: 9.6852 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  310] loss: 95.8229 RMSElog: 9.5823 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  320] loss: 99.8591 RMSElog: 9.9859 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  330] loss: 97.8472 RMSElog: 9.7847 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  340] loss: 101.3932 RMSElog: 10.1393 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  350] loss: 100.6269 RMSElog: 10.0627 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  360] loss: 96.1386 RMSElog: 9.6139 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  370] loss: 91.6469 RMSElog: 9.1647 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  380] loss: 102.3405 RMSElog: 10.2340 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  390] loss: 97.4674 RMSElog: 9.7467 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  400] loss: 98.4685 RMSElog: 9.8468 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  410] loss: 101.7356 RMSElog: 10.1736 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  420] loss: 91.7421 RMSElog: 9.1742 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  430] loss: 96.4265 RMSElog: 9.6426 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  440] loss: 97.4832 RMSElog: 9.7483 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  450] loss: 100.1030 RMSElog: 10.0103 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  460] loss: 101.5312 RMSElog: 10.1531 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  470] loss: 96.9678 RMSElog: 9.6968 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  480] loss: 101.8908 RMSElog: 10.1891 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  490] loss: 99.2180 RMSElog: 9.9218 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  500] loss: 97.0612 RMSElog: 9.7061 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  510] loss: 98.2056 RMSElog: 9.8206 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  520] loss: 97.3096 RMSElog: 9.7310 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  530] loss: 98.8531 RMSElog: 9.8853 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  540] loss: 101.5333 RMSElog: 10.1533 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  550] loss: 95.2373 RMSElog: 9.5237 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  560] loss: 98.0236 RMSElog: 9.8024 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  570] loss: 102.2773 RMSElog: 10.2277 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  580] loss: 97.0092 RMSElog: 9.7009 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  590] loss: 102.8699 RMSElog: 10.2870 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter    0] loss: 92.3709 RMSElog: 9.2371 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   10] loss: 96.6144 RMSElog: 9.6614 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   20] loss: 99.1571 RMSElog: 9.9157 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   30] loss: 99.3604 RMSElog: 9.9360 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   40] loss: 101.8034 RMSElog: 10.1803 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   50] loss: 101.3601 RMSElog: 10.1360 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   60] loss: 98.0963 RMSElog: 9.8096 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   70] loss: 96.4959 RMSElog: 9.6496 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   80] loss: 96.5002 RMSElog: 9.6500 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   90] loss: 98.6832 RMSElog: 9.8683 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  100] loss: 100.8598 RMSElog: 10.0860 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  110] loss: 91.4366 RMSElog: 9.1437 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  120] loss: 101.0208 RMSElog: 10.1021 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  130] loss: 98.7139 RMSElog: 9.8714 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  140] loss: 103.6537 RMSElog: 10.3654 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  150] loss: 96.8231 RMSElog: 9.6823 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  160] loss: 95.2558 RMSElog: 9.5256 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  170] loss: 97.8300 RMSElog: 9.7830 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  180] loss: 97.0577 RMSElog: 9.7058 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  190] loss: 100.6576 RMSElog: 10.0658 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  200] loss: 99.5950 RMSElog: 9.9595 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  210] loss: 100.4435 RMSElog: 10.0444 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  220] loss: 97.6109 RMSElog: 9.7611 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  230] loss: 99.9337 RMSElog: 9.9934 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  240] loss: 98.7297 RMSElog: 9.8730 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  250] loss: 99.3110 RMSElog: 9.9311 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  260] loss: 101.4295 RMSElog: 10.1429 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  270] loss: 100.2532 RMSElog: 10.0253 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  280] loss: 96.6303 RMSElog: 9.6630 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  290] loss: 98.6449 RMSElog: 9.8645 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  300] loss: 98.9759 RMSElog: 9.8976 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  310] loss: 96.3693 RMSElog: 9.6369 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  320] loss: 96.1703 RMSElog: 9.6170 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  330] loss: 97.1042 RMSElog: 9.7104 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  340] loss: 95.7028 RMSElog: 9.5703 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  350] loss: 94.6251 RMSElog: 9.4625 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  360] loss: 93.9232 RMSElog: 9.3923 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  370] loss: 92.6488 RMSElog: 9.2649 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  380] loss: 92.8952 RMSElog: 9.2895 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  390] loss: 88.9606 RMSElog: 8.8961 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  400] loss: 91.1640 RMSElog: 9.1164 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  410] loss: 93.1509 RMSElog: 9.3151 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  420] loss: 92.9060 RMSElog: 9.2906 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  430] loss: 94.7969 RMSElog: 9.4797 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  440] loss: 88.1078 RMSElog: 8.8108 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  450] loss: 92.7157 RMSElog: 9.2716 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  460] loss: 91.5506 RMSElog: 9.1551 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  470] loss: 87.1415 RMSElog: 8.7142 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  480] loss: 93.5750 RMSElog: 9.3575 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  490] loss: 94.4056 RMSElog: 9.4406 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  500] loss: 88.1006 RMSElog: 8.8101 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  510] loss: 91.8658 RMSElog: 9.1866 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  520] loss: 91.1690 RMSElog: 9.1169 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  530] loss: 91.3387 RMSElog: 9.1339 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  540] loss: 92.6735 RMSElog: 9.2673 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  550] loss: 91.2723 RMSElog: 9.1272 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  560] loss: 88.9476 RMSElog: 8.8948 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  570] loss: 87.0694 RMSElog: 8.7069 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  580] loss: 88.5292 RMSElog: 8.8529 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  590] loss: 91.2549 RMSElog: 9.1255 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter    0] loss: 90.0797 RMSElog: 9.0080 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   10] loss: 89.4799 RMSElog: 8.9480 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   20] loss: 91.9332 RMSElog: 9.1933 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   30] loss: 90.5235 RMSElog: 9.0524 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   40] loss: 89.8740 RMSElog: 8.9874 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   50] loss: 85.6950 RMSElog: 8.5695 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   60] loss: 90.3671 RMSElog: 9.0367 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   70] loss: 89.2255 RMSElog: 8.9226 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   80] loss: 92.5477 RMSElog: 9.2548 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   90] loss: 90.0457 RMSElog: 9.0046 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  100] loss: 87.4792 RMSElog: 8.7479 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  110] loss: 85.4520 RMSElog: 8.5452 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  120] loss: 92.7508 RMSElog: 9.2751 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  130] loss: 87.3126 RMSElog: 8.7313 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  140] loss: 88.9372 RMSElog: 8.8937 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  150] loss: 90.1298 RMSElog: 9.0130 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  160] loss: 84.7207 RMSElog: 8.4721 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  170] loss: 88.7673 RMSElog: 8.8767 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  180] loss: 89.4053 RMSElog: 8.9405 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  190] loss: 87.3518 RMSElog: 8.7352 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  200] loss: 92.3858 RMSElog: 9.2386 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  210] loss: 90.7151 RMSElog: 9.0715 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  220] loss: 88.3685 RMSElog: 8.8369 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  230] loss: 88.4568 RMSElog: 8.8457 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  240] loss: 89.9225 RMSElog: 8.9922 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  250] loss: 85.8093 RMSElog: 8.5809 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  260] loss: 87.4048 RMSElog: 8.7405 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  270] loss: 86.2579 RMSElog: 8.6258 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  280] loss: 89.5657 RMSElog: 8.9566 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  290] loss: 89.5245 RMSElog: 8.9525 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  300] loss: 86.9326 RMSElog: 8.6933 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  310] loss: 86.3346 RMSElog: 8.6335 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  320] loss: 91.8873 RMSElog: 9.1887 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  330] loss: 89.5144 RMSElog: 8.9514 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  340] loss: 87.9131 RMSElog: 8.7913 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  350] loss: 89.5166 RMSElog: 8.9517 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  360] loss: 90.1156 RMSElog: 9.0116 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  370] loss: 87.7917 RMSElog: 8.7792 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  380] loss: 88.2038 RMSElog: 8.8204 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  390] loss: 85.3098 RMSElog: 8.5310 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  400] loss: 94.7720 RMSElog: 9.4772 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  410] loss: 86.0613 RMSElog: 8.6061 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  420] loss: 89.9756 RMSElog: 8.9976 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  430] loss: 88.2651 RMSElog: 8.8265 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  440] loss: 84.7308 RMSElog: 8.4731 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  450] loss: 90.3827 RMSElog: 9.0383 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  460] loss: 90.0400 RMSElog: 9.0040 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  470] loss: 89.9435 RMSElog: 8.9943 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  480] loss: 87.8253 RMSElog: 8.7825 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  490] loss: 88.1923 RMSElog: 8.8192 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  500] loss: 90.1905 RMSElog: 9.0191 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  510] loss: 86.9910 RMSElog: 8.6991 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  520] loss: 87.5684 RMSElog: 8.7568 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  530] loss: 89.6922 RMSElog: 8.9692 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  540] loss: 83.7076 RMSElog: 8.3708 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  550] loss: 84.5805 RMSElog: 8.4580 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  560] loss: 89.3384 RMSElog: 8.9338 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  570] loss: 85.8901 RMSElog: 8.5890 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  580] loss: 86.5720 RMSElog: 8.6572 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  590] loss: 86.8443 RMSElog: 8.6844 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  4][iter    0] loss: 112832.0469 RMSElog: 8.6062 grad_loss: 11274.5986 normal_loss: 0.0000
[epoch  4][iter   10] loss: 174979.6562 RMSElog: 8.8228 grad_loss: 17489.1426 normal_loss: 0.0000
[epoch  4][iter   20] loss: 114803.6016 RMSElog: 8.5750 grad_loss: 11471.7852 normal_loss: 0.0000
[epoch  4][iter   30] loss: 174354.0312 RMSElog: 9.1117 grad_loss: 17426.2910 normal_loss: 0.0000
[epoch  4][iter   40] loss: 114132.6172 RMSElog: 8.6990 grad_loss: 11404.5625 normal_loss: 0.0000
[epoch  4][iter   50] loss: 127050.1094 RMSElog: 8.8402 grad_loss: 12696.1709 normal_loss: 0.0000
[epoch  4][iter   60] loss: 198011.0156 RMSElog: 8.9762 grad_loss: 19792.1250 normal_loss: 0.0000
[epoch  4][iter   70] loss: 143416.2656 RMSElog: 8.5652 grad_loss: 14333.0605 normal_loss: 0.0000
[epoch  4][iter   80] loss: 176932.5156 RMSElog: 9.0789 grad_loss: 17684.1738 normal_loss: 0.0000
[epoch  4][iter   90] loss: 145367.5000 RMSElog: 8.9006 grad_loss: 14527.8496 normal_loss: 0.0000
[epoch  4][iter  100] loss: 157787.1562 RMSElog: 8.7949 grad_loss: 15769.9209 normal_loss: 0.0000
[epoch  4][iter  110] loss: 128297.2500 RMSElog: 8.6898 grad_loss: 12821.0352 normal_loss: 0.0000
[epoch  4][iter  120] loss: 213391.3125 RMSElog: 9.0535 grad_loss: 21330.0781 normal_loss: 0.0000
[epoch  4][iter  130] loss: 185878.8750 RMSElog: 8.8579 grad_loss: 18579.0293 normal_loss: 0.0000
[epoch  4][iter  140] loss: 166470.7500 RMSElog: 8.8950 grad_loss: 16638.1797 normal_loss: 0.0000
[epoch  4][iter  150] loss: 115639.4922 RMSElog: 8.5447 grad_loss: 11555.4043 normal_loss: 0.0000
[epoch  4][iter  160] loss: 141144.4688 RMSElog: 8.4747 grad_loss: 14105.9717 normal_loss: 0.0000
[epoch  4][iter  170] loss: 141205.1719 RMSElog: 8.8459 grad_loss: 14111.6709 normal_loss: 0.0000
[epoch  4][iter  180] loss: 123271.8359 RMSElog: 8.8046 grad_loss: 12318.3789 normal_loss: 0.0000
[epoch  4][iter  190] loss: 172661.9375 RMSElog: 8.9609 grad_loss: 17257.2324 normal_loss: 0.0000
[epoch  4][iter  200] loss: 160644.2812 RMSElog: 8.9320 grad_loss: 16055.4971 normal_loss: 0.0000
[epoch  4][iter  210] loss: 141420.7656 RMSElog: 8.7386 grad_loss: 14133.3379 normal_loss: 0.0000
[epoch  4][iter  220] loss: 143818.2344 RMSElog: 8.8507 grad_loss: 14372.9727 normal_loss: 0.0000
[epoch  4][iter  230] loss: 203536.2812 RMSElog: 8.8077 grad_loss: 20344.8203 normal_loss: 0.0000
[epoch  4][iter  240] loss: 146190.5000 RMSElog: 8.7688 grad_loss: 14610.2812 normal_loss: 0.0000
[epoch  4][iter  250] loss: 208744.0469 RMSElog: 8.8531 grad_loss: 20865.5508 normal_loss: 0.0000
[epoch  4][iter  260] loss: 176194.6250 RMSElog: 9.0510 grad_loss: 17610.4121 normal_loss: 0.0000
[epoch  4][iter  270] loss: 231672.5938 RMSElog: 9.1850 grad_loss: 23158.0742 normal_loss: 0.0000
[epoch  4][iter  280] loss: 196894.3438 RMSElog: 8.9988 grad_loss: 19680.4355 normal_loss: 0.0000
[epoch  4][iter  290] loss: 161261.6406 RMSElog: 8.8117 grad_loss: 16117.3525 normal_loss: 0.0000
[epoch  4][iter  300] loss: 182291.2812 RMSElog: 9.0114 grad_loss: 18220.1172 normal_loss: 0.0000
[epoch  4][iter  310] loss: 110207.5391 RMSElog: 8.2751 grad_loss: 11012.4785 normal_loss: 0.0000
[epoch  4][iter  320] loss: 103930.4219 RMSElog: 8.4112 grad_loss: 10384.6309 normal_loss: 0.0000
[epoch  4][iter  330] loss: 217888.1250 RMSElog: 8.9597 grad_loss: 21779.8535 normal_loss: 0.0000
[epoch  4][iter  340] loss: 102205.1172 RMSElog: 8.7475 grad_loss: 10211.7646 normal_loss: 0.0000
[epoch  4][iter  350] loss: 105714.1406 RMSElog: 8.2520 grad_loss: 10563.1621 normal_loss: 0.0000
[epoch  4][iter  360] loss: 116047.8281 RMSElog: 8.3903 grad_loss: 11596.3926 normal_loss: 0.0000
[epoch  4][iter  370] loss: 158902.4531 RMSElog: 8.8299 grad_loss: 15881.4150 normal_loss: 0.0000
[epoch  4][iter  380] loss: 206375.4531 RMSElog: 9.0571 grad_loss: 20628.4883 normal_loss: 0.0000
[epoch  4][iter  390] loss: 143508.7344 RMSElog: 8.5245 grad_loss: 14342.3486 normal_loss: 0.0000
[epoch  4][iter  400] loss: 120717.9609 RMSElog: 8.3390 grad_loss: 12063.4570 normal_loss: 0.0000
[epoch  4][iter  410] loss: 149362.0625 RMSElog: 8.7833 grad_loss: 14927.4229 normal_loss: 0.0000
[epoch  4][iter  420] loss: 109234.0781 RMSElog: 8.4019 grad_loss: 10915.0059 normal_loss: 0.0000
[epoch  4][iter  430] loss: 139039.5156 RMSElog: 8.6627 grad_loss: 13895.2891 normal_loss: 0.0000
[epoch  4][iter  440] loss: 198267.6250 RMSElog: 8.8907 grad_loss: 19817.8711 normal_loss: 0.0000
[epoch  4][iter  450] loss: 167708.9375 RMSElog: 9.0305 grad_loss: 16761.8633 normal_loss: 0.0000
[epoch  4][iter  460] loss: 232956.2188 RMSElog: 9.0031 grad_loss: 23286.6172 normal_loss: 0.0000
[epoch  4][iter  470] loss: 174607.0156 RMSElog: 8.8944 grad_loss: 17451.8066 normal_loss: 0.0000
[epoch  4][iter  480] loss: 179878.8750 RMSElog: 8.8451 grad_loss: 17979.0410 normal_loss: 0.0000
[epoch  4][iter  490] loss: 151345.0312 RMSElog: 8.6972 grad_loss: 15125.8066 normal_loss: 0.0000
[epoch  4][iter  500] loss: 167771.5625 RMSElog: 8.8815 grad_loss: 16768.2754 normal_loss: 0.0000
[epoch  4][iter  510] loss: 156232.3281 RMSElog: 8.8516 grad_loss: 15614.3809 normal_loss: 0.0000
[epoch  4][iter  520] loss: 148030.6094 RMSElog: 8.7013 grad_loss: 14794.3594 normal_loss: 0.0000
[epoch  4][iter  530] loss: 144634.5000 RMSElog: 8.8454 grad_loss: 14454.6045 normal_loss: 0.0000
[epoch  4][iter  540] loss: 105767.5391 RMSElog: 8.3471 grad_loss: 10568.4072 normal_loss: 0.0000
[epoch  4][iter  550] loss: 110575.5000 RMSElog: 8.3469 grad_loss: 11049.2031 normal_loss: 0.0000
[epoch  4][iter  560] loss: 214465.9062 RMSElog: 8.9711 grad_loss: 21437.6191 normal_loss: 0.0000
[epoch  4][iter  570] loss: 170667.7500 RMSElog: 8.9259 grad_loss: 17057.8496 normal_loss: 0.0000
[epoch  4][iter  580] loss: 123068.4453 RMSElog: 8.3733 grad_loss: 12298.4717 normal_loss: 0.0000
[epoch  4][iter  590] loss: 168522.7500 RMSElog: 8.7287 grad_loss: 16843.5469 normal_loss: 0.0000
[epoch  5][iter    0] loss: 221063.8125 RMSElog: 9.1051 grad_loss: 22097.2754 normal_loss: 0.0000
[epoch  5][iter   10] loss: 114290.2500 RMSElog: 8.5231 grad_loss: 11420.5020 normal_loss: 0.0000
[epoch  5][iter   20] loss: 115508.4297 RMSElog: 8.4094 grad_loss: 11542.4336 normal_loss: 0.0000
[epoch  5][iter   30] loss: 137237.8594 RMSElog: 8.9763 grad_loss: 13714.8096 normal_loss: 0.0000
[epoch  5][iter   40] loss: 189480.7812 RMSElog: 8.9724 grad_loss: 18939.1055 normal_loss: 0.0000
[epoch  5][iter   50] loss: 138035.0312 RMSElog: 8.5328 grad_loss: 13794.9697 normal_loss: 0.0000
[epoch  5][iter   60] loss: 170034.4375 RMSElog: 8.8197 grad_loss: 16994.6230 normal_loss: 0.0000
[epoch  5][iter   70] loss: 144963.4688 RMSElog: 8.8026 grad_loss: 14487.5439 normal_loss: 0.0000
[epoch  5][iter   80] loss: 176194.0781 RMSElog: 9.0201 grad_loss: 17610.3887 normal_loss: 0.0000
[epoch  5][iter   90] loss: 180401.4688 RMSElog: 8.9593 grad_loss: 18031.1875 normal_loss: 0.0000
[epoch  5][iter  100] loss: 100723.2891 RMSElog: 8.6550 grad_loss: 10063.6738 normal_loss: 0.0000
[epoch  5][iter  110] loss: 139073.3594 RMSElog: 8.6922 grad_loss: 13898.6436 normal_loss: 0.0000
[epoch  5][iter  120] loss: 122306.4219 RMSElog: 8.6095 grad_loss: 12222.0332 normal_loss: 0.0000
[epoch  5][iter  130] loss: 193952.2812 RMSElog: 9.0456 grad_loss: 19386.1836 normal_loss: 0.0000
[epoch  5][iter  140] loss: 195645.0938 RMSElog: 8.7978 grad_loss: 19555.7129 normal_loss: 0.0000
[epoch  5][iter  150] loss: 160570.0312 RMSElog: 8.8218 grad_loss: 16048.1826 normal_loss: 0.0000
[epoch  5][iter  160] loss: 191946.1719 RMSElog: 8.8862 grad_loss: 19185.7305 normal_loss: 0.0000
[epoch  5][iter  170] loss: 187210.1406 RMSElog: 8.8264 grad_loss: 18712.1875 normal_loss: 0.0000
[epoch  5][iter  180] loss: 163763.0938 RMSElog: 8.7752 grad_loss: 16367.5342 normal_loss: 0.0000
[epoch  5][iter  190] loss: 141419.6250 RMSElog: 8.6829 grad_loss: 14133.2793 normal_loss: 0.0000
[epoch  5][iter  200] loss: 100087.8906 RMSElog: 8.3704 grad_loss: 10000.4189 normal_loss: 0.0000
[epoch  5][iter  210] loss: 196650.5625 RMSElog: 8.7403 grad_loss: 19656.3164 normal_loss: 0.0000
[epoch  5][iter  220] loss: 119445.3125 RMSElog: 8.4024 grad_loss: 11936.1289 normal_loss: 0.0000
[epoch  5][iter  230] loss: 155457.9844 RMSElog: 8.9716 grad_loss: 15536.8262 normal_loss: 0.0000
[epoch  5][iter  240] loss: 165429.9219 RMSElog: 8.9614 grad_loss: 16534.0312 normal_loss: 0.0000
[epoch  5][iter  250] loss: 181440.1250 RMSElog: 8.9028 grad_loss: 18135.1094 normal_loss: 0.0000
[epoch  5][iter  260] loss: 185748.2656 RMSElog: 8.9046 grad_loss: 18565.9219 normal_loss: 0.0000
[epoch  5][iter  270] loss: 104428.3438 RMSElog: 8.4470 grad_loss: 10434.3867 normal_loss: 0.0000
[epoch  5][iter  280] loss: 153074.3125 RMSElog: 8.6072 grad_loss: 15298.8242 normal_loss: 0.0000
[epoch  5][iter  290] loss: 179276.3750 RMSElog: 8.7467 grad_loss: 17918.8906 normal_loss: 0.0000
[epoch  5][iter  300] loss: 190911.2500 RMSElog: 9.0574 grad_loss: 19082.0684 normal_loss: 0.0000
[epoch  5][iter  310] loss: 137230.5312 RMSElog: 8.9996 grad_loss: 13714.0527 normal_loss: 0.0000
[epoch  5][iter  320] loss: 162811.9375 RMSElog: 8.8806 grad_loss: 16272.3135 normal_loss: 0.0000
[epoch  5][iter  330] loss: 152514.9375 RMSElog: 8.7245 grad_loss: 15242.7686 normal_loss: 0.0000
[epoch  5][iter  340] loss: 148766.8750 RMSElog: 8.7756 grad_loss: 14867.9121 normal_loss: 0.0000
[epoch  5][iter  350] loss: 217147.2500 RMSElog: 8.9224 grad_loss: 21705.8027 normal_loss: 0.0000
[epoch  5][iter  360] loss: 189557.6875 RMSElog: 8.8243 grad_loss: 18946.9453 normal_loss: 0.0000
[epoch  5][iter  370] loss: 176931.3125 RMSElog: 9.0319 grad_loss: 17684.0996 normal_loss: 0.0000
[epoch  5][iter  380] loss: 133261.0781 RMSElog: 8.6235 grad_loss: 13317.4844 normal_loss: 0.0000
[epoch  5][iter  390] loss: 140912.3125 RMSElog: 8.4603 grad_loss: 14082.7715 normal_loss: 0.0000
[epoch  5][iter  400] loss: 196409.1875 RMSElog: 8.7731 grad_loss: 19632.1445 normal_loss: 0.0000
[epoch  5][iter  410] loss: 117668.4375 RMSElog: 8.4300 grad_loss: 11758.4141 normal_loss: 0.0000
[epoch  5][iter  420] loss: 154284.0938 RMSElog: 8.6662 grad_loss: 15419.7441 normal_loss: 0.0000
[epoch  5][iter  430] loss: 172732.6719 RMSElog: 8.9840 grad_loss: 17264.2832 normal_loss: 0.0000
[epoch  5][iter  440] loss: 182543.2500 RMSElog: 8.9871 grad_loss: 18245.3379 normal_loss: 0.0000
[epoch  5][iter  450] loss: 177172.7188 RMSElog: 9.1305 grad_loss: 17708.1406 normal_loss: 0.0000
[epoch  5][iter  460] loss: 161608.2969 RMSElog: 8.9154 grad_loss: 16151.9150 normal_loss: 0.0000
[epoch  5][iter  470] loss: 125668.4297 RMSElog: 8.3968 grad_loss: 12558.4463 normal_loss: 0.0000
[epoch  5][iter  480] loss: 162692.7969 RMSElog: 8.9497 grad_loss: 16260.3301 normal_loss: 0.0000
[epoch  5][iter  490] loss: 102204.9141 RMSElog: 8.7506 grad_loss: 10211.7402 normal_loss: 0.0000
[epoch  5][iter  500] loss: 204622.8125 RMSElog: 8.9180 grad_loss: 20453.3633 normal_loss: 0.0000
[epoch  5][iter  510] loss: 195749.6875 RMSElog: 8.8476 grad_loss: 19566.1211 normal_loss: 0.0000
[epoch  5][iter  520] loss: 135443.6406 RMSElog: 8.9267 grad_loss: 13535.4375 normal_loss: 0.0000
[epoch  5][iter  530] loss: 148216.3125 RMSElog: 8.8068 grad_loss: 14812.8242 normal_loss: 0.0000
[epoch  5][iter  540] loss: 175271.5625 RMSElog: 8.7938 grad_loss: 17518.3633 normal_loss: 0.0000
[epoch  5][iter  550] loss: 178446.2344 RMSElog: 8.9093 grad_loss: 17835.7129 normal_loss: 0.0000
[epoch  5][iter  560] loss: 150271.4219 RMSElog: 8.6706 grad_loss: 15018.4707 normal_loss: 0.0000
[epoch  5][iter  570] loss: 108392.3359 RMSElog: 8.6125 grad_loss: 10830.6211 normal_loss: 0.0000
[epoch  5][iter  580] loss: 172723.9688 RMSElog: 8.9409 grad_loss: 17263.4551 normal_loss: 0.0000
[epoch  5][iter  590] loss: 188475.6250 RMSElog: 8.9266 grad_loss: 18838.6367 normal_loss: 0.0000
[epoch  6][iter    0] loss: 115709.8828 RMSElog: 8.1998 grad_loss: 11562.7881 normal_loss: 0.0000
[epoch  6][iter   10] loss: 130500.6953 RMSElog: 8.5758 grad_loss: 13041.4932 normal_loss: 0.0000
[epoch  6][iter   20] loss: 159399.4531 RMSElog: 8.6966 grad_loss: 15931.2490 normal_loss: 0.0000
[epoch  6][iter   30] loss: 177172.4688 RMSElog: 9.1248 grad_loss: 17708.1211 normal_loss: 0.0000
[epoch  6][iter   40] loss: 104060.3750 RMSElog: 8.5137 grad_loss: 10397.5234 normal_loss: 0.0000
[epoch  6][iter   50] loss: 211611.9062 RMSElog: 8.8879 grad_loss: 21152.3027 normal_loss: 0.0000
[epoch  6][iter   60] loss: 108801.7109 RMSElog: 8.1826 grad_loss: 10871.9883 normal_loss: 0.0000
[epoch  6][iter   70] loss: 103918.6797 RMSElog: 8.1512 grad_loss: 10383.7168 normal_loss: 0.0000
[epoch  6][iter   80] loss: 174983.2500 RMSElog: 8.7793 grad_loss: 17489.5449 normal_loss: 0.0000
[epoch  6][iter   90] loss: 120740.8906 RMSElog: 8.4930 grad_loss: 12065.5957 normal_loss: 0.0000
[epoch  6][iter  100] loss: 135180.9531 RMSElog: 8.4637 grad_loss: 13509.6309 normal_loss: 0.0000
[epoch  6][iter  110] loss: 141143.6719 RMSElog: 8.4481 grad_loss: 14105.9189 normal_loss: 0.0000
[epoch  6][iter  120] loss: 121161.1328 RMSElog: 8.7490 grad_loss: 12107.3643 normal_loss: 0.0000
[epoch  6][iter  130] loss: 158901.5000 RMSElog: 8.7879 grad_loss: 15881.3613 normal_loss: 0.0000
[epoch  6][iter  140] loss: 154832.5469 RMSElog: 8.7975 grad_loss: 15474.4570 normal_loss: 0.0000
[epoch  6][iter  150] loss: 132017.0938 RMSElog: 8.8390 grad_loss: 13192.8701 normal_loss: 0.0000
[epoch  6][iter  160] loss: 121809.8594 RMSElog: 8.2894 grad_loss: 12172.6973 normal_loss: 0.0000
[epoch  6][iter  170] loss: 121842.3125 RMSElog: 8.5494 grad_loss: 12175.6816 normal_loss: 0.0000
[epoch  6][iter  180] loss: 204622.5000 RMSElog: 8.8904 grad_loss: 20453.3594 normal_loss: 0.0000
[epoch  6][iter  190] loss: 140029.5938 RMSElog: 8.6495 grad_loss: 13994.3105 normal_loss: 0.0000
[epoch  6][iter  200] loss: 212211.1562 RMSElog: 8.9053 grad_loss: 21212.2109 normal_loss: 0.0000
[epoch  6][iter  210] loss: 189556.3906 RMSElog: 8.7670 grad_loss: 18946.8711 normal_loss: 0.0000
[epoch  6][iter  220] loss: 166047.4219 RMSElog: 8.7559 grad_loss: 16595.9863 normal_loss: 0.0000
[epoch  6][iter  230] loss: 106151.7969 RMSElog: 8.0710 grad_loss: 10607.1084 normal_loss: 0.0000
[epoch  6][iter  240] loss: 223848.7656 RMSElog: 9.0977 grad_loss: 22375.7793 normal_loss: 0.0000
[epoch  6][iter  250] loss: 100722.6875 RMSElog: 8.6375 grad_loss: 10063.6309 normal_loss: 0.0000
[epoch  6][iter  260] loss: 115506.8750 RMSElog: 8.3193 grad_loss: 11542.3682 normal_loss: 0.0000
[epoch  6][iter  270] loss: 170033.2656 RMSElog: 8.7637 grad_loss: 16994.5625 normal_loss: 0.0000
[epoch  6][iter  280] loss: 152567.7656 RMSElog: 8.5820 grad_loss: 15248.1943 normal_loss: 0.0000
[epoch  6][iter  290] loss: 125668.2891 RMSElog: 8.3906 grad_loss: 12558.4385 normal_loss: 0.0000
[epoch  6][iter  300] loss: 114480.6562 RMSElog: 8.2610 grad_loss: 11439.8047 normal_loss: 0.0000
[epoch  6][iter  310] loss: 162349.0312 RMSElog: 8.8281 grad_loss: 16226.0742 normal_loss: 0.0000
[epoch  6][iter  320] loss: 161260.1719 RMSElog: 8.7361 grad_loss: 16117.2812 normal_loss: 0.0000
[epoch  6][iter  330] loss: 105597.9219 RMSElog: 8.3555 grad_loss: 10551.4365 normal_loss: 0.0000
[epoch  6][iter  340] loss: 206374.7188 RMSElog: 9.0253 grad_loss: 20628.4473 normal_loss: 0.0000
[epoch  6][iter  350] loss: 195749.3750 RMSElog: 8.8239 grad_loss: 19566.1133 normal_loss: 0.0000
[epoch  6][iter  360] loss: 107451.9141 RMSElog: 8.2584 grad_loss: 10736.9326 normal_loss: 0.0000
[epoch  6][iter  370] loss: 159800.1719 RMSElog: 8.8047 grad_loss: 15971.2129 normal_loss: 0.0000
[epoch  6][iter  380] loss: 161059.2812 RMSElog: 8.8623 grad_loss: 16097.0664 normal_loss: 0.0000
[epoch  6][iter  390] loss: 149107.7031 RMSElog: 8.7872 grad_loss: 14901.9834 normal_loss: 0.0000
[epoch  6][iter  400] loss: 160764.9062 RMSElog: 8.7613 grad_loss: 16067.7285 normal_loss: 0.0000
[epoch  6][iter  410] loss: 152536.7656 RMSElog: 8.6487 grad_loss: 15245.0283 normal_loss: 0.0000
[epoch  6][iter  420] loss: 178570.3906 RMSElog: 8.8889 grad_loss: 17848.1504 normal_loss: 0.0000
[epoch  6][iter  430] loss: 167320.5312 RMSElog: 8.7806 grad_loss: 16723.2715 normal_loss: 0.0000
[epoch  6][iter  440] loss: 167930.9219 RMSElog: 8.6526 grad_loss: 16784.4395 normal_loss: 0.0000
[epoch  6][iter  450] loss: 215515.9531 RMSElog: 9.1246 grad_loss: 21542.4707 normal_loss: 0.0000
[epoch  6][iter  460] loss: 160026.8438 RMSElog: 8.7720 grad_loss: 15993.9121 normal_loss: 0.0000
[epoch  6][iter  470] loss: 178445.7969 RMSElog: 8.8793 grad_loss: 17835.7012 normal_loss: 0.0000
[epoch  6][iter  480] loss: 157401.8438 RMSElog: 8.8871 grad_loss: 15731.2979 normal_loss: 0.0000
[epoch  6][iter  490] loss: 143878.5156 RMSElog: 8.7154 grad_loss: 14379.1357 normal_loss: 0.0000
[epoch  6][iter  500] loss: 182453.8281 RMSElog: 8.9647 grad_loss: 18236.4180 normal_loss: 0.0000
[epoch  6][iter  510] loss: 174738.8281 RMSElog: 8.7643 grad_loss: 17465.1191 normal_loss: 0.0000
[epoch  6][iter  520] loss: 136480.0312 RMSElog: 8.6790 grad_loss: 13639.3242 normal_loss: 0.0000
[epoch  6][iter  530] loss: 133440.9531 RMSElog: 8.5991 grad_loss: 13335.4961 normal_loss: 0.0000
[epoch  6][iter  540] loss: 114356.5547 RMSElog: 8.5958 grad_loss: 11427.0596 normal_loss: 0.0000
[epoch  6][iter  550] loss: 140912.2812 RMSElog: 8.4466 grad_loss: 14082.7812 normal_loss: 0.0000
[epoch  6][iter  560] loss: 151697.8281 RMSElog: 8.7606 grad_loss: 15161.0215 normal_loss: 0.0000
[epoch  6][iter  570] loss: 172660.6875 RMSElog: 8.9192 grad_loss: 17257.1484 normal_loss: 0.0000
[epoch  6][iter  580] loss: 143436.0625 RMSElog: 8.6456 grad_loss: 14334.9609 normal_loss: 0.0000
[epoch  6][iter  590] loss: 213389.5469 RMSElog: 8.9758 grad_loss: 21329.9785 normal_loss: 0.0000
[epoch  7][iter    0] loss: 133020.1719 RMSElog: 8.6490 grad_loss: 13293.3672 normal_loss: 0.0000
[epoch  7][iter   10] loss: 175974.6875 RMSElog: 9.1671 grad_loss: 17588.3008 normal_loss: 0.0000
[epoch  7][iter   20] loss: 152514.3594 RMSElog: 8.6908 grad_loss: 15242.7461 normal_loss: 0.0000
[epoch  7][iter   30] loss: 160856.6250 RMSElog: 8.8403 grad_loss: 16076.8223 normal_loss: 0.0000
[epoch  7][iter   40] loss: 100952.7344 RMSElog: 8.1731 grad_loss: 10087.1006 normal_loss: 0.0000
[epoch  7][iter   50] loss: 158901.3906 RMSElog: 8.7829 grad_loss: 15881.3564 normal_loss: 0.0000
[epoch  7][iter   60] loss: 104413.8672 RMSElog: 8.2792 grad_loss: 10433.1074 normal_loss: 0.0000
[epoch  7][iter   70] loss: 142669.7969 RMSElog: 8.6338 grad_loss: 14258.3457 normal_loss: 0.0000
[epoch  7][iter   80] loss: 146757.5000 RMSElog: 8.7599 grad_loss: 14666.9902 normal_loss: 0.0000
[epoch  7][iter   90] loss: 153568.7031 RMSElog: 8.6537 grad_loss: 15348.2168 normal_loss: 0.0000
[epoch  7][iter  100] loss: 132016.2188 RMSElog: 8.7821 grad_loss: 13192.8398 normal_loss: 0.0000
[epoch  7][iter  110] loss: 230493.1250 RMSElog: 9.0377 grad_loss: 23040.2754 normal_loss: 0.0000
[epoch  7][iter  120] loss: 129682.7422 RMSElog: 8.4872 grad_loss: 12959.7871 normal_loss: 0.0000
[epoch  7][iter  130] loss: 204009.6719 RMSElog: 8.7814 grad_loss: 20392.1855 normal_loss: 0.0000
[epoch  7][iter  140] loss: 165551.6250 RMSElog: 8.8355 grad_loss: 16546.3262 normal_loss: 0.0000
[epoch  7][iter  150] loss: 146933.5312 RMSElog: 8.6116 grad_loss: 14684.7422 normal_loss: 0.0000
[epoch  7][iter  160] loss: 182295.5625 RMSElog: 9.0260 grad_loss: 18220.5312 normal_loss: 0.0000
[epoch  7][iter  170] loss: 142111.8125 RMSElog: 8.4758 grad_loss: 14202.7051 normal_loss: 0.0000
[epoch  7][iter  180] loss: 160642.7031 RMSElog: 8.8659 grad_loss: 16055.4043 normal_loss: 0.0000
[epoch  7][iter  190] loss: 104950.9453 RMSElog: 8.5890 grad_loss: 10486.5059 normal_loss: 0.0000
[epoch  7][iter  200] loss: 202090.5938 RMSElog: 8.7316 grad_loss: 20200.3262 normal_loss: 0.0000
[epoch  7][iter  210] loss: 185877.2031 RMSElog: 8.7837 grad_loss: 18578.9375 normal_loss: 0.0000
[epoch  7][iter  220] loss: 138909.1875 RMSElog: 8.6465 grad_loss: 13882.2715 normal_loss: 0.0000
[epoch  7][iter  230] loss: 104104.0000 RMSElog: 8.5583 grad_loss: 10401.8418 normal_loss: 0.0000
[epoch  7][iter  240] loss: 179715.7188 RMSElog: 9.0135 grad_loss: 17962.5586 normal_loss: 0.0000
[epoch  7][iter  250] loss: 142516.8906 RMSElog: 8.8361 grad_loss: 14242.8525 normal_loss: 0.0000
[epoch  7][iter  260] loss: 167656.8438 RMSElog: 8.9614 grad_loss: 16756.7227 normal_loss: 0.0000
[epoch  7][iter  270] loss: 206374.6250 RMSElog: 9.0254 grad_loss: 20628.4375 normal_loss: 0.0000
[epoch  7][iter  280] loss: 215926.6562 RMSElog: 8.8753 grad_loss: 21583.7910 normal_loss: 0.0000
[epoch  7][iter  290] loss: 125657.7500 RMSElog: 8.5766 grad_loss: 12557.1992 normal_loss: 0.0000
[epoch  7][iter  300] loss: 122331.0000 RMSElog: 8.3147 grad_loss: 12224.7852 normal_loss: 0.0000
[epoch  7][iter  310] loss: 140310.4375 RMSElog: 8.8277 grad_loss: 14022.2148 normal_loss: 0.0000
[epoch  7][iter  320] loss: 144632.3125 RMSElog: 8.7245 grad_loss: 14454.5059 normal_loss: 0.0000
[epoch  7][iter  330] loss: 183988.7500 RMSElog: 8.5899 grad_loss: 18390.2852 normal_loss: 0.0000
[epoch  7][iter  340] loss: 133440.8750 RMSElog: 8.6082 grad_loss: 13335.4795 normal_loss: 0.0000
[epoch  7][iter  350] loss: 214780.9531 RMSElog: 8.8385 grad_loss: 21469.2578 normal_loss: 0.0000
[epoch  7][iter  360] loss: 179623.1250 RMSElog: 8.9311 grad_loss: 17953.3809 normal_loss: 0.0000
[epoch  7][iter  370] loss: 155738.6875 RMSElog: 8.7667 grad_loss: 15565.1025 normal_loss: 0.0000
[epoch  7][iter  380] loss: 157680.5625 RMSElog: 8.8991 grad_loss: 15759.1562 normal_loss: 0.0000
[epoch  7][iter  390] loss: 102069.3047 RMSElog: 8.3872 grad_loss: 10198.5430 normal_loss: 0.0000
[epoch  7][iter  400] loss: 220668.4219 RMSElog: 8.8372 grad_loss: 22058.0039 normal_loss: 0.0000
[epoch  7][iter  410] loss: 167060.8594 RMSElog: 8.8282 grad_loss: 16697.2578 normal_loss: 0.0000
[epoch  7][iter  420] loss: 136773.5312 RMSElog: 8.6553 grad_loss: 13668.6973 normal_loss: 0.0000
[epoch  7][iter  430] loss: 203947.1875 RMSElog: 9.1650 grad_loss: 20385.5547 normal_loss: 0.0000
[epoch  7][iter  440] loss: 162534.4688 RMSElog: 9.0110 grad_loss: 16244.4355 normal_loss: 0.0000
[epoch  7][iter  450] loss: 140439.1875 RMSElog: 8.8134 grad_loss: 14035.1055 normal_loss: 0.0000
[epoch  7][iter  460] loss: 221186.5938 RMSElog: 8.8827 grad_loss: 22109.7773 normal_loss: 0.0000
[epoch  7][iter  470] loss: 108392.2188 RMSElog: 8.6057 grad_loss: 10830.6162 normal_loss: 0.0000
[epoch  7][iter  480] loss: 164157.1562 RMSElog: 8.8813 grad_loss: 16406.8340 normal_loss: 0.0000
[epoch  7][iter  490] loss: 145366.6250 RMSElog: 8.8645 grad_loss: 14527.7979 normal_loss: 0.0000
[epoch  7][iter  500] loss: 179877.4062 RMSElog: 8.7775 grad_loss: 17978.9629 normal_loss: 0.0000
[epoch  7][iter  510] loss: 159316.3906 RMSElog: 8.8898 grad_loss: 15922.7490 normal_loss: 0.0000
[epoch  7][iter  520] loss: 150276.0781 RMSElog: 8.6697 grad_loss: 15018.9375 normal_loss: 0.0000
[epoch  7][iter  530] loss: 177641.9688 RMSElog: 8.7926 grad_loss: 17755.4043 normal_loss: 0.0000
[epoch  7][iter  540] loss: 161607.8438 RMSElog: 8.8917 grad_loss: 16151.8936 normal_loss: 0.0000
[epoch  7][iter  550] loss: 224917.3438 RMSElog: 8.8131 grad_loss: 22482.9219 normal_loss: 0.0000
[epoch  7][iter  560] loss: 201347.2188 RMSElog: 9.0783 grad_loss: 20125.6445 normal_loss: 0.0000
[epoch  7][iter  570] loss: 115467.1562 RMSElog: 8.2157 grad_loss: 11538.5000 normal_loss: 0.0000
[epoch  7][iter  580] loss: 141419.6719 RMSElog: 8.6869 grad_loss: 14133.2812 normal_loss: 0.0000
[epoch  7][iter  590] loss: 202602.7344 RMSElog: 8.7332 grad_loss: 20251.5410 normal_loss: 0.0000
[epoch  8][iter    0] loss: 177919.9375 RMSElog: 8.9644 grad_loss: 17782.2832 normal_loss: 0.7466
[epoch  8][iter   10] loss: 166989.8438 RMSElog: 8.8269 grad_loss: 16689.4590 normal_loss: 0.6990
[epoch  8][iter   20] loss: 173325.7500 RMSElog: 8.8981 grad_loss: 17322.9219 normal_loss: 0.7547
[epoch  8][iter   30] loss: 170525.0000 RMSElog: 8.6524 grad_loss: 17043.1094 normal_loss: 0.7390
[epoch  8][iter   40] loss: 147441.4844 RMSElog: 8.5193 grad_loss: 14734.9209 normal_loss: 0.7078
[epoch  8][iter   50] loss: 129689.1016 RMSElog: 8.7523 grad_loss: 12959.4863 normal_loss: 0.6717
[epoch  8][iter   60] loss: 205341.3906 RMSElog: 8.8053 grad_loss: 20524.6641 normal_loss: 0.6697
[epoch  8][iter   70] loss: 100729.2656 RMSElog: 8.6538 grad_loss: 10063.6191 normal_loss: 0.6539
[epoch  8][iter   80] loss: 108399.4844 RMSElog: 8.6019 grad_loss: 10830.6074 normal_loss: 0.7390
[epoch  8][iter   90] loss: 159268.8906 RMSElog: 8.6360 grad_loss: 15917.5254 normal_loss: 0.7274
[epoch  8][iter  100] loss: 105683.1328 RMSElog: 8.1041 grad_loss: 10559.5449 normal_loss: 0.6641
[epoch  8][iter  110] loss: 178453.2500 RMSElog: 8.8958 grad_loss: 17835.7012 normal_loss: 0.7272
[epoch  8][iter  120] loss: 200934.0312 RMSElog: 8.8824 grad_loss: 20083.8301 normal_loss: 0.6891
[epoch  8][iter  130] loss: 206505.2812 RMSElog: 8.8251 grad_loss: 20641.0469 normal_loss: 0.6553
[epoch  8][iter  140] loss: 107925.6250 RMSElog: 8.1348 grad_loss: 10783.7441 normal_loss: 0.6833
[epoch  8][iter  150] loss: 150277.5156 RMSElog: 8.6576 grad_loss: 15018.4277 normal_loss: 0.6655
[epoch  8][iter  160] loss: 233368.8281 RMSElog: 9.0076 grad_loss: 23327.1992 normal_loss: 0.6756
[epoch  8][iter  170] loss: 153575.2188 RMSElog: 8.6737 grad_loss: 15348.2021 normal_loss: 0.6461
[epoch  8][iter  180] loss: 122337.6172 RMSElog: 8.3195 grad_loss: 12224.7754 normal_loss: 0.6667
[epoch  8][iter  190] loss: 138453.5781 RMSElog: 8.4975 grad_loss: 13836.1426 normal_loss: 0.7174
[epoch  8][iter  200] loss: 115442.6484 RMSElog: 8.6586 grad_loss: 11534.8613 normal_loss: 0.7453
[epoch  8][iter  210] loss: 165290.0938 RMSElog: 8.8728 grad_loss: 16519.4297 normal_loss: 0.7063
[epoch  8][iter  220] loss: 140317.7969 RMSElog: 8.8465 grad_loss: 14022.2227 normal_loss: 0.7109
[epoch  8][iter  230] loss: 159323.4062 RMSElog: 8.9043 grad_loss: 15922.7383 normal_loss: 0.6978
[epoch  8][iter  240] loss: 164163.4688 RMSElog: 8.8770 grad_loss: 16406.7988 normal_loss: 0.6716
[epoch  8][iter  250] loss: 146927.3594 RMSElog: 8.5245 grad_loss: 14683.4961 normal_loss: 0.7158
[epoch  8][iter  260] loss: 127483.0000 RMSElog: 8.3047 grad_loss: 12739.3057 normal_loss: 0.6898
[epoch  8][iter  270] loss: 232752.0000 RMSElog: 9.0408 grad_loss: 23265.4883 normal_loss: 0.6708
[epoch  8][iter  280] loss: 114903.5000 RMSElog: 8.2801 grad_loss: 11481.3965 normal_loss: 0.6726
[epoch  8][iter  290] loss: 165309.4531 RMSElog: 8.8404 grad_loss: 16521.4043 normal_loss: 0.7016
[epoch  8][iter  300] loss: 103924.9141 RMSElog: 8.1147 grad_loss: 10383.7021 normal_loss: 0.6751
[epoch  8][iter  310] loss: 104456.0859 RMSElog: 8.0728 grad_loss: 10436.8926 normal_loss: 0.6422
[epoch  8][iter  320] loss: 133267.2031 RMSElog: 8.6168 grad_loss: 13317.4502 normal_loss: 0.6528
[epoch  8][iter  330] loss: 144639.6719 RMSElog: 8.7777 grad_loss: 14454.5332 normal_loss: 0.6560
[epoch  8][iter  340] loss: 113885.5625 RMSElog: 8.6679 grad_loss: 11379.1416 normal_loss: 0.7471
[epoch  8][iter  350] loss: 207660.0312 RMSElog: 8.9370 grad_loss: 20756.4160 normal_loss: 0.6495
[epoch  8][iter  360] loss: 159808.1875 RMSElog: 8.8634 grad_loss: 15971.2520 normal_loss: 0.7031
[epoch  8][iter  370] loss: 178766.7812 RMSElog: 8.9135 grad_loss: 17867.0664 normal_loss: 0.6967
[epoch  8][iter  380] loss: 211516.3438 RMSElog: 8.8045 grad_loss: 21142.1719 normal_loss: 0.6581
[epoch  8][iter  390] loss: 154606.8438 RMSElog: 8.7310 grad_loss: 15451.2891 normal_loss: 0.6636
[epoch  8][iter  400] loss: 100625.9453 RMSElog: 8.0646 grad_loss: 10053.8838 normal_loss: 0.6463
[epoch  8][iter  410] loss: 133026.0781 RMSElog: 8.6348 grad_loss: 13293.3125 normal_loss: 0.6614
[epoch  8][iter  420] loss: 233376.7812 RMSElog: 9.0047 grad_loss: 23327.9883 normal_loss: 0.6856
[epoch  8][iter  430] loss: 180408.3594 RMSElog: 8.9562 grad_loss: 18031.1680 normal_loss: 0.7101
[epoch  8][iter  440] loss: 182296.7812 RMSElog: 8.9477 grad_loss: 18220.0508 normal_loss: 0.6796
[epoch  8][iter  450] loss: 140447.3906 RMSElog: 8.7950 grad_loss: 14035.1055 normal_loss: 0.8389
[epoch  8][iter  460] loss: 204629.0781 RMSElog: 8.9151 grad_loss: 20453.3379 normal_loss: 0.6535
[epoch  8][iter  470] loss: 155952.0312 RMSElog: 8.6991 grad_loss: 15585.7539 normal_loss: 0.7496
[epoch  8][iter  480] loss: 164751.0000 RMSElog: 8.8619 grad_loss: 16465.5195 normal_loss: 0.7178
[epoch  8][iter  490] loss: 136780.7969 RMSElog: 8.6646 grad_loss: 13668.6904 normal_loss: 0.7243
[epoch  8][iter  500] loss: 176244.7031 RMSElog: 9.0364 grad_loss: 17614.7305 normal_loss: 0.7031
[epoch  8][iter  510] loss: 108807.8516 RMSElog: 8.1704 grad_loss: 10871.9531 normal_loss: 0.6622
[epoch  8][iter  520] loss: 127054.7656 RMSElog: 8.7554 grad_loss: 12696.0654 normal_loss: 0.6553
[epoch  8][iter  530] loss: 162356.2500 RMSElog: 8.8313 grad_loss: 16226.0723 normal_loss: 0.7217
[epoch  8][iter  540] loss: 121816.5469 RMSElog: 8.2960 grad_loss: 12172.6846 normal_loss: 0.6734
[epoch  8][iter  550] loss: 142119.2656 RMSElog: 8.5093 grad_loss: 14202.7031 normal_loss: 0.7139
[epoch  8][iter  560] loss: 179284.0938 RMSElog: 8.7772 grad_loss: 17918.9004 normal_loss: 0.7320
[epoch  8][iter  570] loss: 177648.7344 RMSElog: 8.7840 grad_loss: 17755.3828 normal_loss: 0.7072
[epoch  8][iter  580] loss: 129149.8125 RMSElog: 8.9505 grad_loss: 12905.3311 normal_loss: 0.6999
[epoch  8][iter  590] loss: 195393.5000 RMSElog: 8.9314 grad_loss: 19529.7676 normal_loss: 0.6507
[epoch  9][iter    0] loss: 150304.6562 RMSElog: 8.8919 grad_loss: 15020.8672 normal_loss: 0.7062
[epoch  9][iter   10] loss: 160056.5781 RMSElog: 8.7079 grad_loss: 15996.2832 normal_loss: 0.6666
[epoch  9][iter   20] loss: 114296.8906 RMSElog: 8.4996 grad_loss: 11420.4629 normal_loss: 0.7268
[epoch  9][iter   30] loss: 121849.5391 RMSElog: 8.5464 grad_loss: 12175.6719 normal_loss: 0.7355
[epoch  9][iter   40] loss: 176938.1875 RMSElog: 9.0316 grad_loss: 17684.0820 normal_loss: 0.7044
[epoch  9][iter   50] loss: 188623.1562 RMSElog: 8.7577 grad_loss: 18852.8828 normal_loss: 0.6762
[epoch  9][iter   60] loss: 176477.2031 RMSElog: 8.7842 grad_loss: 17638.2188 normal_loss: 0.7162
[epoch  9][iter   70] loss: 170524.5938 RMSElog: 8.6538 grad_loss: 17043.0918 normal_loss: 0.7123
[epoch  9][iter   80] loss: 125296.7031 RMSElog: 8.6047 grad_loss: 12520.4316 normal_loss: 0.6333
[epoch  9][iter   90] loss: 102210.4766 RMSElog: 8.6776 grad_loss: 10211.6934 normal_loss: 0.6767
[epoch  9][iter  100] loss: 117674.5938 RMSElog: 8.4105 grad_loss: 11758.3809 normal_loss: 0.6675
[epoch  9][iter  110] loss: 135449.6250 RMSElog: 8.8562 grad_loss: 13535.4141 normal_loss: 0.6923
[epoch  9][iter  120] loss: 129148.6328 RMSElog: 8.8855 grad_loss: 12905.2939 normal_loss: 0.6836
[epoch  9][iter  130] loss: 87678.0078 RMSElog: 8.6605 grad_loss: 8758.4756 normal_loss: 0.6651
[epoch  9][iter  140] loss: 159269.3906 RMSElog: 8.6603 grad_loss: 15917.5469 normal_loss: 0.7324
[epoch  9][iter  150] loss: 167723.7656 RMSElog: 8.8673 grad_loss: 16762.7969 normal_loss: 0.7124
[epoch  9][iter  160] loss: 207864.8594 RMSElog: 9.0791 grad_loss: 20776.7305 normal_loss: 0.6765
[epoch  9][iter  170] loss: 95986.3672 RMSElog: 8.3244 grad_loss: 9589.6797 normal_loss: 0.6329
[epoch  9][iter  180] loss: 122429.9219 RMSElog: 8.2787 grad_loss: 12234.0371 normal_loss: 0.6764
[epoch  9][iter  190] loss: 218526.7812 RMSElog: 9.1074 grad_loss: 21842.8926 normal_loss: 0.6774
[epoch  9][iter  200] loss: 180408.2656 RMSElog: 8.9555 grad_loss: 18031.1641 normal_loss: 0.7065
[epoch  9][iter  210] loss: 133267.1094 RMSElog: 8.6159 grad_loss: 13317.4473 normal_loss: 0.6474
[epoch  9][iter  220] loss: 105718.1406 RMSElog: 8.0368 grad_loss: 10563.1016 normal_loss: 0.6761
[epoch  9][iter  230] loss: 185755.0938 RMSElog: 8.9121 grad_loss: 18565.8926 normal_loss: 0.7043
[epoch  9][iter  240] loss: 160863.3438 RMSElog: 8.8577 grad_loss: 16076.7979 normal_loss: 0.6790
[epoch  9][iter  250] loss: 191673.3438 RMSElog: 8.9500 grad_loss: 19157.7031 normal_loss: 0.6822
[epoch  9][iter  260] loss: 200447.8125 RMSElog: 8.7775 grad_loss: 20035.3613 normal_loss: 0.6425
[epoch  9][iter  270] loss: 221193.2656 RMSElog: 8.9015 grad_loss: 22109.7637 normal_loss: 0.6601
[epoch  9][iter  280] loss: 160768.1406 RMSElog: 8.8228 grad_loss: 16067.2646 normal_loss: 0.7267
[epoch  9][iter  290] loss: 119637.3438 RMSElog: 8.5627 grad_loss: 11954.5430 normal_loss: 0.6291
[epoch  9][iter  300] loss: 134614.9531 RMSElog: 8.7362 grad_loss: 13452.0781 normal_loss: 0.6809
[epoch  9][iter  310] loss: 198424.0469 RMSElog: 8.9099 grad_loss: 19832.8262 normal_loss: 0.6671
[epoch  9][iter  320] loss: 158908.4219 RMSElog: 8.7962 grad_loss: 15881.3516 normal_loss: 0.6952
[epoch  9][iter  330] loss: 164750.8125 RMSElog: 8.8552 grad_loss: 16465.5117 normal_loss: 0.7157
[epoch  9][iter  340] loss: 156980.8125 RMSElog: 9.2362 grad_loss: 15687.9707 normal_loss: 0.8750
[epoch  9][iter  350] loss: 181925.9531 RMSElog: 8.8900 grad_loss: 18182.9844 normal_loss: 0.7209
[epoch  9][iter  360] loss: 153703.9688 RMSElog: 8.7589 grad_loss: 15360.9766 normal_loss: 0.6612
[epoch  9][iter  370] loss: 148162.7656 RMSElog: 8.6949 grad_loss: 14806.9238 normal_loss: 0.6577
[epoch  9][iter  380] loss: 175282.9844 RMSElog: 8.6629 grad_loss: 17518.9473 normal_loss: 0.6888
[epoch  9][iter  390] loss: 156690.9531 RMSElog: 8.7536 grad_loss: 15659.6865 normal_loss: 0.6543
[epoch  9][iter  400] loss: 154839.0000 RMSElog: 8.7814 grad_loss: 15474.4248 normal_loss: 0.6935
[epoch  9][iter  410] loss: 163158.8281 RMSElog: 9.0230 grad_loss: 16306.1025 normal_loss: 0.7564
[epoch  9][iter  420] loss: 120723.3750 RMSElog: 8.2833 grad_loss: 12063.3809 normal_loss: 0.6738
[epoch  9][iter  430] loss: 172739.3750 RMSElog: 8.9670 grad_loss: 17264.2598 normal_loss: 0.7104
[epoch  9][iter  440] loss: 141426.7031 RMSElog: 8.6933 grad_loss: 14133.2676 normal_loss: 0.7101
[epoch  9][iter  450] loss: 215522.8125 RMSElog: 9.1431 grad_loss: 21542.4590 normal_loss: 0.6799
[epoch  9][iter  460] loss: 220567.6875 RMSElog: 9.0083 grad_loss: 22047.0879 normal_loss: 0.6738
[epoch  9][iter  470] loss: 119451.1719 RMSElog: 8.3478 grad_loss: 11936.0850 normal_loss: 0.6841
[epoch  9][iter  480] loss: 146196.1094 RMSElog: 8.7356 grad_loss: 14610.1855 normal_loss: 0.6909
[epoch  9][iter  490] loss: 165290.1406 RMSElog: 8.8766 grad_loss: 16519.4316 normal_loss: 0.7055
[epoch  9][iter  500] loss: 126949.8359 RMSElog: 8.4549 grad_loss: 12685.8594 normal_loss: 0.6689
[epoch  9][iter  510] loss: 145391.9844 RMSElog: 8.7185 grad_loss: 14529.7871 normal_loss: 0.6925
[epoch  9][iter  520] loss: 78496.6875 RMSElog: 8.6444 grad_loss: 7840.3667 normal_loss: 0.6579
[epoch  9][iter  530] loss: 122367.4609 RMSElog: 8.5778 grad_loss: 12227.5117 normal_loss: 0.6565
[epoch  9][iter  540] loss: 138589.5625 RMSElog: 8.5829 grad_loss: 13849.6895 normal_loss: 0.6844
[epoch  9][iter  550] loss: 167068.2969 RMSElog: 8.8649 grad_loss: 16697.2578 normal_loss: 0.7075
[epoch  9][iter  560] loss: 196899.7812 RMSElog: 8.9626 grad_loss: 19680.3438 normal_loss: 0.6712
[epoch  9][iter  570] loss: 184355.4531 RMSElog: 9.0667 grad_loss: 18425.7930 normal_loss: 0.6856
[epoch  9][iter  580] loss: 132996.7188 RMSElog: 8.5416 grad_loss: 13290.4502 normal_loss: 0.6795
[epoch  9][iter  590] loss: 179283.4375 RMSElog: 8.7510 grad_loss: 17918.8750 normal_loss: 0.7161
###########
#epochs 10#
###########
[epoch  0][iter    0] loss: 102.3135 RMSElog: 10.2314 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   10] loss: 101.2238 RMSElog: 10.1224 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   20] loss: 100.2499 RMSElog: 10.0250 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   30] loss: 102.8188 RMSElog: 10.2819 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   40] loss: 103.2318 RMSElog: 10.3232 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   50] loss: 101.0677 RMSElog: 10.1068 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   60] loss: 103.4272 RMSElog: 10.3427 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   70] loss: 103.4556 RMSElog: 10.3456 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   80] loss: 100.1805 RMSElog: 10.0181 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   90] loss: 99.2800 RMSElog: 9.9280 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  100] loss: 102.7809 RMSElog: 10.2781 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  110] loss: 103.4670 RMSElog: 10.3467 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  120] loss: 103.6301 RMSElog: 10.3630 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  130] loss: 102.5509 RMSElog: 10.2551 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  140] loss: 100.1063 RMSElog: 10.0106 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  150] loss: 98.9271 RMSElog: 9.8927 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  160] loss: 99.5770 RMSElog: 9.9577 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  170] loss: 98.4237 RMSElog: 9.8424 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  180] loss: 99.0515 RMSElog: 9.9052 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  190] loss: 94.9963 RMSElog: 9.4996 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  200] loss: 91.8876 RMSElog: 9.1888 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  210] loss: 99.9594 RMSElog: 9.9959 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  220] loss: 102.4397 RMSElog: 10.2440 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  230] loss: 100.9161 RMSElog: 10.0916 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  240] loss: 96.3701 RMSElog: 9.6370 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  250] loss: 98.3699 RMSElog: 9.8370 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  260] loss: 97.4739 RMSElog: 9.7474 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  270] loss: 98.2204 RMSElog: 9.8220 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  280] loss: 95.3719 RMSElog: 9.5372 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  290] loss: 97.8597 RMSElog: 9.7860 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  300] loss: 99.1950 RMSElog: 9.9195 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  310] loss: 98.4628 RMSElog: 9.8463 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  320] loss: 100.4167 RMSElog: 10.0417 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  330] loss: 101.2096 RMSElog: 10.1210 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  340] loss: 102.2834 RMSElog: 10.2283 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  350] loss: 96.2097 RMSElog: 9.6210 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  360] loss: 94.8568 RMSElog: 9.4857 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  370] loss: 98.0656 RMSElog: 9.8066 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  380] loss: 102.3742 RMSElog: 10.2374 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  390] loss: 98.1896 RMSElog: 9.8190 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  400] loss: 100.5797 RMSElog: 10.0580 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  410] loss: 99.0790 RMSElog: 9.9079 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  420] loss: 98.2229 RMSElog: 9.8223 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  430] loss: 98.1488 RMSElog: 9.8149 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  440] loss: 98.0889 RMSElog: 9.8089 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  450] loss: 99.2174 RMSElog: 9.9217 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  460] loss: 96.7827 RMSElog: 9.6783 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  470] loss: 102.7953 RMSElog: 10.2795 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  480] loss: 99.8606 RMSElog: 9.9861 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  490] loss: 101.9306 RMSElog: 10.1931 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  500] loss: 97.7419 RMSElog: 9.7742 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  510] loss: 103.7546 RMSElog: 10.3755 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  520] loss: 98.2798 RMSElog: 9.8280 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  530] loss: 95.7752 RMSElog: 9.5775 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  540] loss: 104.2948 RMSElog: 10.4295 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  550] loss: 98.3848 RMSElog: 9.8385 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  560] loss: 100.4348 RMSElog: 10.0435 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  570] loss: 100.8203 RMSElog: 10.0820 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  580] loss: 95.9753 RMSElog: 9.5975 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  590] loss: 101.1711 RMSElog: 10.1171 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter    0] loss: 92.2445 RMSElog: 9.2245 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   10] loss: 101.4293 RMSElog: 10.1429 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   20] loss: 101.4273 RMSElog: 10.1427 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   30] loss: 100.5521 RMSElog: 10.0552 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   40] loss: 103.3625 RMSElog: 10.3362 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   50] loss: 102.4334 RMSElog: 10.2433 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   60] loss: 98.3647 RMSElog: 9.8365 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   70] loss: 97.9115 RMSElog: 9.7912 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   80] loss: 97.3725 RMSElog: 9.7372 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   90] loss: 92.5885 RMSElog: 9.2589 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  100] loss: 100.8677 RMSElog: 10.0868 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  110] loss: 98.3780 RMSElog: 9.8378 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  120] loss: 96.6522 RMSElog: 9.6652 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  130] loss: 99.0329 RMSElog: 9.9033 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  140] loss: 101.8461 RMSElog: 10.1846 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  150] loss: 99.8561 RMSElog: 9.9856 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  160] loss: 101.0109 RMSElog: 10.1011 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  170] loss: 98.7588 RMSElog: 9.8759 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  180] loss: 97.6419 RMSElog: 9.7642 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  190] loss: 99.1366 RMSElog: 9.9137 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  200] loss: 101.4443 RMSElog: 10.1444 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  210] loss: 103.1233 RMSElog: 10.3123 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  220] loss: 95.0796 RMSElog: 9.5080 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  230] loss: 99.2238 RMSElog: 9.9224 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  240] loss: 100.5102 RMSElog: 10.0510 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  250] loss: 92.9547 RMSElog: 9.2955 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  260] loss: 96.8232 RMSElog: 9.6823 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  270] loss: 102.7209 RMSElog: 10.2721 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  280] loss: 93.2600 RMSElog: 9.3260 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  290] loss: 96.9437 RMSElog: 9.6944 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  300] loss: 99.5952 RMSElog: 9.9595 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  310] loss: 95.2370 RMSElog: 9.5237 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  320] loss: 96.9538 RMSElog: 9.6954 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  330] loss: 95.9639 RMSElog: 9.5964 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  340] loss: 102.0149 RMSElog: 10.2015 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  350] loss: 98.5336 RMSElog: 9.8534 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  360] loss: 95.2266 RMSElog: 9.5227 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  370] loss: 98.5303 RMSElog: 9.8530 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  380] loss: 97.4835 RMSElog: 9.7484 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  390] loss: 97.4220 RMSElog: 9.7422 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  400] loss: 99.6502 RMSElog: 9.9650 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  410] loss: 99.0681 RMSElog: 9.9068 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  420] loss: 97.8610 RMSElog: 9.7861 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  430] loss: 100.4440 RMSElog: 10.0444 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  440] loss: 98.1270 RMSElog: 9.8127 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  450] loss: 101.5931 RMSElog: 10.1593 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  460] loss: 98.3123 RMSElog: 9.8312 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  470] loss: 97.9899 RMSElog: 9.7990 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  480] loss: 99.8031 RMSElog: 9.9803 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  490] loss: 97.1366 RMSElog: 9.7137 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  500] loss: 100.3281 RMSElog: 10.0328 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  510] loss: 99.7421 RMSElog: 9.9742 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  520] loss: 97.1281 RMSElog: 9.7128 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  530] loss: 97.6969 RMSElog: 9.7697 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  540] loss: 96.6283 RMSElog: 9.6628 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  550] loss: 96.9431 RMSElog: 9.6943 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  560] loss: 96.6998 RMSElog: 9.6700 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  570] loss: 97.9865 RMSElog: 9.7987 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  580] loss: 91.5707 RMSElog: 9.1571 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  590] loss: 96.5924 RMSElog: 9.6592 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter    0] loss: 102.3307 RMSElog: 10.2331 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   10] loss: 92.1732 RMSElog: 9.2173 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   20] loss: 99.4173 RMSElog: 9.9417 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   30] loss: 103.2587 RMSElog: 10.3259 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   40] loss: 102.1108 RMSElog: 10.2111 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   50] loss: 99.9919 RMSElog: 9.9992 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   60] loss: 95.7525 RMSElog: 9.5752 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   70] loss: 98.5728 RMSElog: 9.8573 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   80] loss: 98.4721 RMSElog: 9.8472 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   90] loss: 98.4451 RMSElog: 9.8445 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  100] loss: 95.6860 RMSElog: 9.5686 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  110] loss: 99.0106 RMSElog: 9.9011 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  120] loss: 98.5889 RMSElog: 9.8589 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  130] loss: 101.5617 RMSElog: 10.1562 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  140] loss: 101.7556 RMSElog: 10.1756 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  150] loss: 96.8680 RMSElog: 9.6868 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  160] loss: 98.1861 RMSElog: 9.8186 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  170] loss: 101.6066 RMSElog: 10.1607 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  180] loss: 100.9788 RMSElog: 10.0979 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  190] loss: 96.1681 RMSElog: 9.6168 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  200] loss: 98.8453 RMSElog: 9.8845 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  210] loss: 95.3754 RMSElog: 9.5375 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  220] loss: 101.5263 RMSElog: 10.1526 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  230] loss: 96.3107 RMSElog: 9.6311 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  240] loss: 96.4644 RMSElog: 9.6464 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  250] loss: 99.9685 RMSElog: 9.9968 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  260] loss: 97.3688 RMSElog: 9.7369 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  270] loss: 96.5108 RMSElog: 9.6511 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  280] loss: 97.4221 RMSElog: 9.7422 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  290] loss: 100.5795 RMSElog: 10.0579 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  300] loss: 95.1995 RMSElog: 9.5199 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  310] loss: 91.5498 RMSElog: 9.1550 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  320] loss: 92.7554 RMSElog: 9.2755 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  330] loss: 93.5930 RMSElog: 9.3593 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  340] loss: 90.9774 RMSElog: 9.0977 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  350] loss: 96.6990 RMSElog: 9.6699 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  360] loss: 92.0260 RMSElog: 9.2026 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  370] loss: 85.6260 RMSElog: 8.5626 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  380] loss: 88.2072 RMSElog: 8.8207 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  390] loss: 91.4054 RMSElog: 9.1405 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  400] loss: 92.5896 RMSElog: 9.2590 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  410] loss: 94.8857 RMSElog: 9.4886 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  420] loss: 94.9565 RMSElog: 9.4957 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  430] loss: 92.5218 RMSElog: 9.2522 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  440] loss: 89.3740 RMSElog: 8.9374 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  450] loss: 90.4455 RMSElog: 9.0446 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  460] loss: 87.7536 RMSElog: 8.7754 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  470] loss: 90.1201 RMSElog: 9.0120 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  480] loss: 86.9116 RMSElog: 8.6912 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  490] loss: 88.2012 RMSElog: 8.8201 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  500] loss: 85.9688 RMSElog: 8.5969 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  510] loss: 89.5909 RMSElog: 8.9591 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  520] loss: 86.8693 RMSElog: 8.6869 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  530] loss: 88.8110 RMSElog: 8.8811 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  540] loss: 85.3311 RMSElog: 8.5331 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  550] loss: 90.5315 RMSElog: 9.0531 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  560] loss: 85.9529 RMSElog: 8.5953 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  570] loss: 84.7536 RMSElog: 8.4754 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  580] loss: 91.9952 RMSElog: 9.1995 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  590] loss: 91.2866 RMSElog: 9.1287 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter    0] loss: 87.9772 RMSElog: 8.7977 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   10] loss: 87.6433 RMSElog: 8.7643 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   20] loss: 90.0178 RMSElog: 9.0018 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   30] loss: 89.7253 RMSElog: 8.9725 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   40] loss: 89.3613 RMSElog: 8.9361 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   50] loss: 89.8821 RMSElog: 8.9882 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   60] loss: 87.0892 RMSElog: 8.7089 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   70] loss: 90.5604 RMSElog: 9.0560 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   80] loss: 87.5623 RMSElog: 8.7562 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   90] loss: 89.7400 RMSElog: 8.9740 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  100] loss: 91.1057 RMSElog: 9.1106 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  110] loss: 84.5432 RMSElog: 8.4543 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  120] loss: 88.8597 RMSElog: 8.8860 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  130] loss: 85.9379 RMSElog: 8.5938 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  140] loss: 89.8266 RMSElog: 8.9827 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  150] loss: 86.7147 RMSElog: 8.6715 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  160] loss: 84.4211 RMSElog: 8.4421 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  170] loss: 90.2267 RMSElog: 9.0227 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  180] loss: 89.4997 RMSElog: 8.9500 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  190] loss: 89.3549 RMSElog: 8.9355 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  200] loss: 89.5807 RMSElog: 8.9581 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  210] loss: 88.5077 RMSElog: 8.8508 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  220] loss: 90.3906 RMSElog: 9.0391 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  230] loss: 86.5177 RMSElog: 8.6518 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  240] loss: 89.9490 RMSElog: 8.9949 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  250] loss: 89.9695 RMSElog: 8.9969 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  260] loss: 88.5719 RMSElog: 8.8572 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  270] loss: 91.5446 RMSElog: 9.1545 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  280] loss: 86.9644 RMSElog: 8.6964 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  290] loss: 91.2576 RMSElog: 9.1258 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  300] loss: 83.9051 RMSElog: 8.3905 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  310] loss: 84.2646 RMSElog: 8.4265 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  320] loss: 86.1038 RMSElog: 8.6104 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  330] loss: 92.8254 RMSElog: 9.2825 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  340] loss: 89.5055 RMSElog: 8.9505 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  350] loss: 89.3037 RMSElog: 8.9304 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  360] loss: 88.6293 RMSElog: 8.8629 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  370] loss: 90.8041 RMSElog: 9.0804 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  380] loss: 84.2528 RMSElog: 8.4253 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  390] loss: 87.3390 RMSElog: 8.7339 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  400] loss: 86.5133 RMSElog: 8.6513 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  410] loss: 92.5960 RMSElog: 9.2596 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  420] loss: 89.3856 RMSElog: 8.9386 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  430] loss: 90.8305 RMSElog: 9.0830 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  440] loss: 88.8537 RMSElog: 8.8854 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  450] loss: 83.8644 RMSElog: 8.3864 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  460] loss: 88.6369 RMSElog: 8.8637 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  470] loss: 88.0027 RMSElog: 8.8003 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  480] loss: 89.6295 RMSElog: 8.9630 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  490] loss: 88.4372 RMSElog: 8.8437 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  500] loss: 89.3345 RMSElog: 8.9335 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  510] loss: 83.6774 RMSElog: 8.3677 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  520] loss: 89.2551 RMSElog: 8.9255 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  530] loss: 88.9273 RMSElog: 8.8927 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  540] loss: 88.5864 RMSElog: 8.8586 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  550] loss: 86.6584 RMSElog: 8.6658 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  560] loss: 88.8530 RMSElog: 8.8853 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  570] loss: 84.1069 RMSElog: 8.4107 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  580] loss: 82.9083 RMSElog: 8.2908 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  590] loss: 84.3208 RMSElog: 8.4321 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  4][iter    0] loss: 172094.5156 RMSElog: 8.8997 grad_loss: 17200.5508 normal_loss: 0.0000
[epoch  4][iter   10] loss: 110575.8594 RMSElog: 8.3300 grad_loss: 11049.2559 normal_loss: 0.0000
[epoch  4][iter   20] loss: 148159.0312 RMSElog: 8.8321 grad_loss: 14807.0713 normal_loss: 0.0000
[epoch  4][iter   30] loss: 196251.0938 RMSElog: 8.8575 grad_loss: 19616.2520 normal_loss: 0.0000
[epoch  4][iter   40] loss: 210496.1094 RMSElog: 8.9871 grad_loss: 21040.6250 normal_loss: 0.0000
[epoch  4][iter   50] loss: 105872.5781 RMSElog: 8.5087 grad_loss: 10578.7490 normal_loss: 0.0000
[epoch  4][iter   60] loss: 164744.7031 RMSElog: 8.8077 grad_loss: 16465.6621 normal_loss: 0.0000
[epoch  4][iter   70] loss: 139410.3750 RMSElog: 8.6875 grad_loss: 13932.3496 normal_loss: 0.0000
[epoch  4][iter   80] loss: 195481.3125 RMSElog: 8.8273 grad_loss: 19539.3027 normal_loss: 0.0000
[epoch  4][iter   90] loss: 218522.0000 RMSElog: 9.1757 grad_loss: 21843.0234 normal_loss: 0.0000
[epoch  4][iter  100] loss: 144957.2344 RMSElog: 8.9877 grad_loss: 14486.7363 normal_loss: 0.0000
[epoch  4][iter  110] loss: 160619.7812 RMSElog: 8.9033 grad_loss: 16053.0752 normal_loss: 0.0000
[epoch  4][iter  120] loss: 198419.0938 RMSElog: 8.9595 grad_loss: 19832.9512 normal_loss: 0.0000
[epoch  4][iter  130] loss: 200444.0469 RMSElog: 8.8685 grad_loss: 20035.5352 normal_loss: 0.0000
[epoch  4][iter  140] loss: 161064.5156 RMSElog: 8.7861 grad_loss: 16097.6660 normal_loss: 0.0000
[epoch  4][iter  150] loss: 191181.2812 RMSElog: 8.8805 grad_loss: 19109.2480 normal_loss: 0.0000
[epoch  4][iter  160] loss: 189717.9062 RMSElog: 8.9085 grad_loss: 18962.8828 normal_loss: 0.0000
[epoch  4][iter  170] loss: 106742.6719 RMSElog: 8.4036 grad_loss: 10665.8643 normal_loss: 0.0000
[epoch  4][iter  180] loss: 90461.4688 RMSElog: 8.4012 grad_loss: 9037.7451 normal_loss: 0.0000
[epoch  4][iter  190] loss: 162341.7969 RMSElog: 8.8258 grad_loss: 16225.3535 normal_loss: 0.0000
[epoch  4][iter  200] loss: 183458.0312 RMSElog: 8.9693 grad_loss: 18336.8340 normal_loss: 0.0000
[epoch  4][iter  210] loss: 148216.5625 RMSElog: 8.8169 grad_loss: 14812.8398 normal_loss: 0.0000
[epoch  4][iter  220] loss: 162349.9688 RMSElog: 8.8565 grad_loss: 16226.1406 normal_loss: 0.0000
[epoch  4][iter  230] loss: 105072.1562 RMSElog: 8.3675 grad_loss: 10498.8486 normal_loss: 0.0000
[epoch  4][iter  240] loss: 172229.9375 RMSElog: 8.8615 grad_loss: 17214.1328 normal_loss: 0.0000
[epoch  4][iter  250] loss: 100089.3828 RMSElog: 8.4363 grad_loss: 10000.5020 normal_loss: 0.0000
[epoch  4][iter  260] loss: 126000.0156 RMSElog: 8.5197 grad_loss: 12591.4824 normal_loss: 0.0000
[epoch  4][iter  270] loss: 140618.3125 RMSElog: 8.7097 grad_loss: 14053.1211 normal_loss: 0.0000
[epoch  4][iter  280] loss: 177642.6250 RMSElog: 8.8406 grad_loss: 17755.4219 normal_loss: 0.0000
[epoch  4][iter  290] loss: 144633.8906 RMSElog: 8.7950 grad_loss: 14454.5938 normal_loss: 0.0000
[epoch  4][iter  300] loss: 148518.2656 RMSElog: 8.8975 grad_loss: 14842.9297 normal_loss: 0.0000
[epoch  4][iter  310] loss: 159801.4688 RMSElog: 8.8495 grad_loss: 15971.2969 normal_loss: 0.0000
[epoch  4][iter  320] loss: 182296.1250 RMSElog: 9.0452 grad_loss: 18220.5684 normal_loss: 0.0000
[epoch  4][iter  330] loss: 163370.1562 RMSElog: 8.9824 grad_loss: 16328.0332 normal_loss: 0.0000
[epoch  4][iter  340] loss: 178055.9062 RMSElog: 8.9427 grad_loss: 17796.6465 normal_loss: 0.0000
[epoch  4][iter  350] loss: 165283.7188 RMSElog: 8.8713 grad_loss: 16519.5000 normal_loss: 0.0000
[epoch  4][iter  360] loss: 147740.7188 RMSElog: 8.6904 grad_loss: 14765.3818 normal_loss: 0.0000
[epoch  4][iter  370] loss: 103328.8281 RMSElog: 8.3203 grad_loss: 10324.5625 normal_loss: 0.0000
[epoch  4][iter  380] loss: 109119.0000 RMSElog: 8.4359 grad_loss: 10903.4648 normal_loss: 0.0000
[epoch  4][iter  390] loss: 138687.6875 RMSElog: 8.5945 grad_loss: 13860.1738 normal_loss: 0.0000
[epoch  4][iter  400] loss: 224918.1875 RMSElog: 8.8484 grad_loss: 22482.9707 normal_loss: 0.0000
[epoch  4][iter  410] loss: 126848.6562 RMSElog: 8.5279 grad_loss: 12676.3369 normal_loss: 0.0000
[epoch  4][iter  420] loss: 167760.1250 RMSElog: 8.8325 grad_loss: 16767.1797 normal_loss: 0.0000
[epoch  4][iter  430] loss: 129718.7578 RMSElog: 8.7351 grad_loss: 12963.1406 normal_loss: 0.0000
[epoch  4][iter  440] loss: 117669.1484 RMSElog: 8.4597 grad_loss: 11758.4551 normal_loss: 0.0000
[epoch  4][iter  450] loss: 102204.7734 RMSElog: 8.7373 grad_loss: 10211.7402 normal_loss: 0.0000
[epoch  4][iter  460] loss: 113400.1875 RMSElog: 8.3733 grad_loss: 11331.6455 normal_loss: 0.0000
[epoch  4][iter  470] loss: 175522.2500 RMSElog: 8.8420 grad_loss: 17543.3828 normal_loss: 0.0000
[epoch  4][iter  480] loss: 163569.4375 RMSElog: 8.7985 grad_loss: 16348.1455 normal_loss: 0.0000
[epoch  4][iter  490] loss: 80075.8281 RMSElog: 8.2635 grad_loss: 7999.3188 normal_loss: 0.0000
[epoch  4][iter  500] loss: 138924.6562 RMSElog: 8.7151 grad_loss: 13883.7500 normal_loss: 0.0000
[epoch  4][iter  510] loss: 117084.3594 RMSElog: 8.3002 grad_loss: 11700.1357 normal_loss: 0.0000
[epoch  4][iter  520] loss: 143415.4219 RMSElog: 8.5290 grad_loss: 14333.0127 normal_loss: 0.0000
[epoch  4][iter  530] loss: 159399.8281 RMSElog: 8.7125 grad_loss: 15931.2705 normal_loss: 0.0000
[epoch  4][iter  540] loss: 199581.0781 RMSElog: 8.8327 grad_loss: 19949.2754 normal_loss: 0.0000
[epoch  4][iter  550] loss: 141420.6562 RMSElog: 8.7317 grad_loss: 14133.3340 normal_loss: 0.0000
[epoch  4][iter  560] loss: 152537.8281 RMSElog: 8.6853 grad_loss: 15245.0977 normal_loss: 0.0000
[epoch  4][iter  570] loss: 158009.2031 RMSElog: 8.8102 grad_loss: 15792.1094 normal_loss: 0.0000
[epoch  4][iter  580] loss: 148768.1875 RMSElog: 8.8558 grad_loss: 14867.9639 normal_loss: 0.0000
[epoch  4][iter  590] loss: 181267.9531 RMSElog: 8.7896 grad_loss: 18118.0059 normal_loss: 0.0000
[epoch  5][iter    0] loss: 149109.1562 RMSElog: 8.8451 grad_loss: 14902.0703 normal_loss: 0.0000
[epoch  5][iter   10] loss: 163763.3125 RMSElog: 8.7742 grad_loss: 16367.5566 normal_loss: 0.0000
[epoch  5][iter   20] loss: 147183.9219 RMSElog: 8.8448 grad_loss: 14709.5469 normal_loss: 0.0000
[epoch  5][iter   30] loss: 220668.8906 RMSElog: 8.8515 grad_loss: 22058.0371 normal_loss: 0.0000
[epoch  5][iter   40] loss: 144168.2031 RMSElog: 8.6136 grad_loss: 14408.2070 normal_loss: 0.0000
[epoch  5][iter   50] loss: 160720.5625 RMSElog: 8.9580 grad_loss: 16063.0977 normal_loss: 0.0000
[epoch  5][iter   60] loss: 147519.0312 RMSElog: 8.7349 grad_loss: 14743.1689 normal_loss: 0.0000
[epoch  5][iter   70] loss: 127439.1328 RMSElog: 8.4032 grad_loss: 12735.5098 normal_loss: 0.0000
[epoch  5][iter   80] loss: 146439.2500 RMSElog: 8.7332 grad_loss: 14635.1914 normal_loss: 0.0000
[epoch  5][iter   90] loss: 158855.9844 RMSElog: 8.8295 grad_loss: 15876.7695 normal_loss: 0.0000
[epoch  5][iter  100] loss: 233371.7344 RMSElog: 9.0804 grad_loss: 23328.0938 normal_loss: 0.0000
[epoch  5][iter  110] loss: 125461.3359 RMSElog: 8.3995 grad_loss: 12537.7344 normal_loss: 0.0000
[epoch  5][iter  120] loss: 143879.0312 RMSElog: 8.7642 grad_loss: 14379.1387 normal_loss: 0.0000
[epoch  5][iter  130] loss: 165430.6875 RMSElog: 9.0156 grad_loss: 16534.0527 normal_loss: 0.0000
[epoch  5][iter  140] loss: 187211.5781 RMSElog: 8.9013 grad_loss: 18712.2578 normal_loss: 0.0000
[epoch  5][iter  150] loss: 114154.4141 RMSElog: 8.5370 grad_loss: 11406.9043 normal_loss: 0.0000
[epoch  5][iter  160] loss: 167759.3750 RMSElog: 8.7876 grad_loss: 16767.1504 normal_loss: 0.0000
[epoch  5][iter  170] loss: 147740.3906 RMSElog: 8.6625 grad_loss: 14765.3770 normal_loss: 0.0000
[epoch  5][iter  180] loss: 191343.0000 RMSElog: 8.7506 grad_loss: 19125.5508 normal_loss: 0.0000
[epoch  5][iter  190] loss: 167393.1406 RMSElog: 8.9217 grad_loss: 16730.3926 normal_loss: 0.0000
[epoch  5][iter  200] loss: 170668.0312 RMSElog: 8.9555 grad_loss: 17057.8477 normal_loss: 0.0000
[epoch  5][iter  210] loss: 121937.1172 RMSElog: 8.7462 grad_loss: 12184.9658 normal_loss: 0.0000
[epoch  5][iter  220] loss: 164743.8125 RMSElog: 8.7797 grad_loss: 16465.6016 normal_loss: 0.0000
[epoch  5][iter  230] loss: 138909.5156 RMSElog: 8.6588 grad_loss: 13882.2930 normal_loss: 0.0000
[epoch  5][iter  240] loss: 160003.2500 RMSElog: 8.8348 grad_loss: 15991.4902 normal_loss: 0.0000
[epoch  5][iter  250] loss: 103507.7344 RMSElog: 8.3892 grad_loss: 10342.3848 normal_loss: 0.0000
[epoch  5][iter  260] loss: 194550.5469 RMSElog: 8.7881 grad_loss: 19446.2676 normal_loss: 0.0000
[epoch  5][iter  270] loss: 112687.4062 RMSElog: 8.1938 grad_loss: 11260.5469 normal_loss: 0.0000
[epoch  5][iter  280] loss: 230493.6719 RMSElog: 9.0857 grad_loss: 23040.2812 normal_loss: 0.0000
[epoch  5][iter  290] loss: 123507.9062 RMSElog: 8.7328 grad_loss: 12342.0586 normal_loss: 0.0000
[epoch  5][iter  300] loss: 239426.8125 RMSElog: 9.0768 grad_loss: 23933.6055 normal_loss: 0.0000
[epoch  5][iter  310] loss: 174606.0938 RMSElog: 8.8156 grad_loss: 17451.7930 normal_loss: 0.0000
[epoch  5][iter  320] loss: 154282.9688 RMSElog: 8.6370 grad_loss: 15419.6602 normal_loss: 0.0000
[epoch  5][iter  330] loss: 149011.9375 RMSElog: 8.6589 grad_loss: 14892.5352 normal_loss: 0.0000
[epoch  5][iter  340] loss: 227298.0469 RMSElog: 9.1557 grad_loss: 22720.6484 normal_loss: 0.0000
[epoch  5][iter  350] loss: 109117.3438 RMSElog: 8.3241 grad_loss: 10903.4102 normal_loss: 0.0000
[epoch  5][iter  360] loss: 198266.7969 RMSElog: 8.8530 grad_loss: 19817.8262 normal_loss: 0.0000
[epoch  5][iter  370] loss: 132017.6719 RMSElog: 8.8836 grad_loss: 13192.8828 normal_loss: 0.0000
[epoch  5][iter  380] loss: 138994.0781 RMSElog: 8.6477 grad_loss: 13890.7607 normal_loss: 0.0000
[epoch  5][iter  390] loss: 190911.5312 RMSElog: 9.0589 grad_loss: 19082.0938 normal_loss: 0.0000
[epoch  5][iter  400] loss: 199046.0000 RMSElog: 8.8871 grad_loss: 19895.7129 normal_loss: 0.0000
[epoch  5][iter  410] loss: 146189.5469 RMSElog: 8.7545 grad_loss: 14610.2002 normal_loss: 0.0000
[epoch  5][iter  420] loss: 154005.0781 RMSElog: 8.7068 grad_loss: 15391.8008 normal_loss: 0.0000
[epoch  5][iter  430] loss: 226923.5000 RMSElog: 8.9726 grad_loss: 22683.3770 normal_loss: 0.0000
[epoch  5][iter  440] loss: 167708.0312 RMSElog: 8.9890 grad_loss: 16761.8145 normal_loss: 0.0000
[epoch  5][iter  450] loss: 182838.3438 RMSElog: 9.0015 grad_loss: 18274.8320 normal_loss: 0.0000
[epoch  5][iter  460] loss: 170034.2500 RMSElog: 8.8061 grad_loss: 16994.6191 normal_loss: 0.0000
[epoch  5][iter  470] loss: 141142.8281 RMSElog: 8.3860 grad_loss: 14105.8965 normal_loss: 0.0000
[epoch  5][iter  480] loss: 183066.7188 RMSElog: 8.6078 grad_loss: 18298.0645 normal_loss: 0.0000
[epoch  5][iter  490] loss: 177790.1406 RMSElog: 9.0123 grad_loss: 17770.0020 normal_loss: 0.0000
[epoch  5][iter  500] loss: 154265.1875 RMSElog: 8.6818 grad_loss: 15417.8369 normal_loss: 0.0000
[epoch  5][iter  510] loss: 105866.9922 RMSElog: 8.1459 grad_loss: 10578.5537 normal_loss: 0.0000
[epoch  5][iter  520] loss: 152747.5938 RMSElog: 8.7091 grad_loss: 15266.0498 normal_loss: 0.0000
[epoch  5][iter  530] loss: 108392.2188 RMSElog: 8.6123 grad_loss: 10830.6094 normal_loss: 0.0000
[epoch  5][iter  540] loss: 110857.4062 RMSElog: 8.6816 grad_loss: 11077.0586 normal_loss: 0.0000
[epoch  5][iter  550] loss: 190946.6562 RMSElog: 8.8860 grad_loss: 19085.7793 normal_loss: 0.0000
[epoch  5][iter  560] loss: 177641.9531 RMSElog: 8.7910 grad_loss: 17755.4043 normal_loss: 0.0000
[epoch  5][iter  570] loss: 117084.1250 RMSElog: 8.2907 grad_loss: 11700.1211 normal_loss: 0.0000
[epoch  5][iter  580] loss: 114897.6953 RMSElog: 8.3066 grad_loss: 11481.4629 normal_loss: 0.0000
[epoch  5][iter  590] loss: 110779.2578 RMSElog: 8.1622 grad_loss: 11069.7637 normal_loss: 0.0000
[epoch  6][iter    0] loss: 189480.8125 RMSElog: 8.9698 grad_loss: 18939.1113 normal_loss: 0.0000
[epoch  6][iter   10] loss: 152308.1719 RMSElog: 8.7185 grad_loss: 15222.0986 normal_loss: 0.0000
[epoch  6][iter   20] loss: 114896.9219 RMSElog: 8.2777 grad_loss: 11481.4150 normal_loss: 0.0000
[epoch  6][iter   30] loss: 201137.9375 RMSElog: 8.8493 grad_loss: 20104.9434 normal_loss: 0.0000
[epoch  6][iter   40] loss: 147584.3125 RMSElog: 8.6154 grad_loss: 14749.8154 normal_loss: 0.0000
[epoch  6][iter   50] loss: 183847.7344 RMSElog: 9.0423 grad_loss: 18375.7305 normal_loss: 0.0000
[epoch  6][iter   60] loss: 140310.7188 RMSElog: 8.8451 grad_loss: 14022.2275 normal_loss: 0.0000
[epoch  6][iter   70] loss: 72267.1953 RMSElog: 8.4859 grad_loss: 7218.2334 normal_loss: 0.0000
[epoch  6][iter   80] loss: 116045.8438 RMSElog: 8.2861 grad_loss: 11596.2979 normal_loss: 0.0000
[epoch  6][iter   90] loss: 145296.3906 RMSElog: 8.5958 grad_loss: 14521.0439 normal_loss: 0.0000
[epoch  6][iter  100] loss: 135944.7500 RMSElog: 8.7386 grad_loss: 13585.7363 normal_loss: 0.0000
[epoch  6][iter  110] loss: 115638.8906 RMSElog: 8.5076 grad_loss: 11555.3809 normal_loss: 0.0000
[epoch  6][iter  120] loss: 125258.5469 RMSElog: 8.4539 grad_loss: 12517.4004 normal_loss: 0.0000
[epoch  6][iter  130] loss: 222992.4375 RMSElog: 9.0680 grad_loss: 22290.1758 normal_loss: 0.0000
[epoch  6][iter  140] loss: 174739.1250 RMSElog: 8.7741 grad_loss: 17465.1387 normal_loss: 0.0000
[epoch  6][iter  150] loss: 127036.7266 RMSElog: 8.4142 grad_loss: 12695.2588 normal_loss: 0.0000
[epoch  6][iter  160] loss: 109411.0625 RMSElog: 8.0647 grad_loss: 10933.0420 normal_loss: 0.0000
[epoch  6][iter  170] loss: 199046.1094 RMSElog: 8.8866 grad_loss: 19895.7246 normal_loss: 0.0000
[epoch  6][iter  180] loss: 163368.6250 RMSElog: 8.8567 grad_loss: 16328.0068 normal_loss: 0.0000
[epoch  6][iter  190] loss: 154832.4062 RMSElog: 8.7957 grad_loss: 15474.4453 normal_loss: 0.0000
[epoch  6][iter  200] loss: 206375.1719 RMSElog: 9.0316 grad_loss: 20628.4863 normal_loss: 0.0000
[epoch  6][iter  210] loss: 170465.3281 RMSElog: 8.7808 grad_loss: 17037.7520 normal_loss: 0.0000
[epoch  6][iter  220] loss: 152522.8906 RMSElog: 8.7462 grad_loss: 15243.5430 normal_loss: 0.0000
[epoch  6][iter  230] loss: 138446.3438 RMSElog: 8.4985 grad_loss: 13836.1367 normal_loss: 0.0000
[epoch  6][iter  240] loss: 115507.3516 RMSElog: 8.3382 grad_loss: 11542.3975 normal_loss: 0.0000
[epoch  6][iter  250] loss: 148767.0938 RMSElog: 8.7817 grad_loss: 14867.9287 normal_loss: 0.0000
[epoch  6][iter  260] loss: 129142.6719 RMSElog: 8.9247 grad_loss: 12905.3428 normal_loss: 0.0000
[epoch  6][iter  270] loss: 190910.9688 RMSElog: 9.0376 grad_loss: 19082.0605 normal_loss: 0.0000
[epoch  6][iter  280] loss: 180956.1875 RMSElog: 8.9731 grad_loss: 18086.6465 normal_loss: 0.0000
[epoch  6][iter  290] loss: 162868.7031 RMSElog: 8.8133 grad_loss: 16278.0566 normal_loss: 0.0000
[epoch  6][iter  300] loss: 153972.7344 RMSElog: 8.6104 grad_loss: 15388.6631 normal_loss: 0.0000
[epoch  6][iter  310] loss: 153940.2031 RMSElog: 8.9761 grad_loss: 15385.0439 normal_loss: 0.0000
[epoch  6][iter  320] loss: 147887.1875 RMSElog: 8.6187 grad_loss: 14780.0996 normal_loss: 0.0000
[epoch  6][iter  330] loss: 154600.4688 RMSElog: 8.7331 grad_loss: 15451.3135 normal_loss: 0.0000
[epoch  6][iter  340] loss: 166047.5938 RMSElog: 8.7657 grad_loss: 16595.9941 normal_loss: 0.0000
[epoch  6][iter  350] loss: 215926.8438 RMSElog: 8.8737 grad_loss: 21583.8105 normal_loss: 0.0000
[epoch  6][iter  360] loss: 100639.8281 RMSElog: 8.7737 grad_loss: 10055.2090 normal_loss: 0.0000
[epoch  6][iter  370] loss: 181959.2188 RMSElog: 8.9503 grad_loss: 18186.9707 normal_loss: 0.0000
[epoch  6][iter  380] loss: 173139.3750 RMSElog: 8.6262 grad_loss: 17305.3105 normal_loss: 0.0000
[epoch  6][iter  390] loss: 148517.0938 RMSElog: 8.8206 grad_loss: 14842.8887 normal_loss: 0.0000
[epoch  6][iter  400] loss: 100619.5781 RMSElog: 8.0538 grad_loss: 10053.9043 normal_loss: 0.0000
[epoch  6][iter  410] loss: 104310.0859 RMSElog: 8.0500 grad_loss: 10422.9590 normal_loss: 0.0000
[epoch  6][iter  420] loss: 125999.3750 RMSElog: 8.4972 grad_loss: 12591.4404 normal_loss: 0.0000
[epoch  6][iter  430] loss: 220561.1562 RMSElog: 9.0035 grad_loss: 22047.1113 normal_loss: 0.0000
[epoch  6][iter  440] loss: 141419.5625 RMSElog: 8.6851 grad_loss: 14133.2715 normal_loss: 0.0000
[epoch  6][iter  450] loss: 135181.0469 RMSElog: 8.4705 grad_loss: 13509.6338 normal_loss: 0.0000
[epoch  6][iter  460] loss: 102204.4844 RMSElog: 8.7017 grad_loss: 10211.7461 normal_loss: 0.0000
[epoch  6][iter  470] loss: 173941.9531 RMSElog: 8.8422 grad_loss: 17385.3535 normal_loss: 0.0000
[epoch  6][iter  480] loss: 147574.5156 RMSElog: 8.8071 grad_loss: 14748.6445 normal_loss: 0.0000
[epoch  6][iter  490] loss: 152494.0781 RMSElog: 8.7545 grad_loss: 15240.6523 normal_loss: 0.0000
[epoch  6][iter  500] loss: 185471.9688 RMSElog: 8.8847 grad_loss: 18538.3125 normal_loss: 0.0000
[epoch  6][iter  510] loss: 132016.7344 RMSElog: 8.8132 grad_loss: 13192.8594 normal_loss: 0.0000
[epoch  6][iter  520] loss: 90460.4531 RMSElog: 8.3470 grad_loss: 9037.6982 normal_loss: 0.0000
[epoch  6][iter  530] loss: 231671.2656 RMSElog: 9.1308 grad_loss: 23157.9961 normal_loss: 0.0000
[epoch  6][iter  540] loss: 156956.7031 RMSElog: 8.8264 grad_loss: 15686.8447 normal_loss: 0.0000
[epoch  6][iter  550] loss: 198417.8125 RMSElog: 8.9116 grad_loss: 19832.8691 normal_loss: 0.0000
[epoch  6][iter  560] loss: 106486.8359 RMSElog: 8.0394 grad_loss: 10640.6445 normal_loss: 0.0000
[epoch  6][iter  570] loss: 152514.3906 RMSElog: 8.7014 grad_loss: 15242.7383 normal_loss: 0.0000
[epoch  6][iter  580] loss: 116557.0703 RMSElog: 8.5157 grad_loss: 11647.1914 normal_loss: 0.0000
[epoch  6][iter  590] loss: 208158.4375 RMSElog: 9.1278 grad_loss: 20806.7168 normal_loss: 0.0000
[epoch  7][iter    0] loss: 194550.2188 RMSElog: 8.7881 grad_loss: 19446.2344 normal_loss: 0.0000
[epoch  7][iter   10] loss: 173139.3594 RMSElog: 8.6267 grad_loss: 17305.3086 normal_loss: 0.0000
[epoch  7][iter   20] loss: 162533.4688 RMSElog: 8.9302 grad_loss: 16244.4160 normal_loss: 0.0000
[epoch  7][iter   30] loss: 196892.9531 RMSElog: 8.9452 grad_loss: 19680.3496 normal_loss: 0.0000
[epoch  7][iter   40] loss: 195415.2500 RMSElog: 8.5905 grad_loss: 19532.9355 normal_loss: 0.0000
[epoch  7][iter   50] loss: 163703.2969 RMSElog: 8.6213 grad_loss: 16361.7080 normal_loss: 0.0000
[epoch  7][iter   60] loss: 206374.5156 RMSElog: 9.0098 grad_loss: 20628.4414 normal_loss: 0.0000
[epoch  7][iter   70] loss: 186026.1562 RMSElog: 8.8647 grad_loss: 18593.7500 normal_loss: 0.0000
[epoch  7][iter   80] loss: 159317.1406 RMSElog: 8.9283 grad_loss: 15922.7852 normal_loss: 0.0000
[epoch  7][iter   90] loss: 166982.7188 RMSElog: 8.8057 grad_loss: 16689.4648 normal_loss: 0.0000
[epoch  7][iter  100] loss: 182542.4844 RMSElog: 8.9302 grad_loss: 18245.3184 normal_loss: 0.0000
[epoch  7][iter  110] loss: 159262.1562 RMSElog: 8.6516 grad_loss: 15917.5635 normal_loss: 0.0000
[epoch  7][iter  120] loss: 148111.5625 RMSElog: 8.7533 grad_loss: 14802.4033 normal_loss: 0.0000
[epoch  7][iter  130] loss: 122653.2734 RMSElog: 8.7044 grad_loss: 12256.6230 normal_loss: 0.0000
[epoch  7][iter  140] loss: 100619.9609 RMSElog: 8.0668 grad_loss: 10053.9297 normal_loss: 0.0000
[epoch  7][iter  150] loss: 141839.5469 RMSElog: 8.4384 grad_loss: 14175.5156 normal_loss: 0.0000
[epoch  7][iter  160] loss: 166184.1875 RMSElog: 8.8485 grad_loss: 16609.5703 normal_loss: 0.0000
[epoch  7][iter  170] loss: 191946.1875 RMSElog: 8.8857 grad_loss: 19185.7344 normal_loss: 0.0000
[epoch  7][iter  180] loss: 176237.8906 RMSElog: 9.0383 grad_loss: 17614.7500 normal_loss: 0.0000
[epoch  7][iter  190] loss: 104310.0781 RMSElog: 8.0537 grad_loss: 10422.9541 normal_loss: 0.0000
[epoch  7][iter  200] loss: 226923.6094 RMSElog: 8.9631 grad_loss: 22683.3984 normal_loss: 0.0000
[epoch  7][iter  210] loss: 126943.3906 RMSElog: 8.4551 grad_loss: 12685.8838 normal_loss: 0.0000
[epoch  7][iter  220] loss: 125258.4688 RMSElog: 8.4480 grad_loss: 12517.3984 normal_loss: 0.0000
[epoch  7][iter  230] loss: 208794.5312 RMSElog: 8.8114 grad_loss: 20870.6426 normal_loss: 0.0000
[epoch  7][iter  240] loss: 132399.3125 RMSElog: 8.7331 grad_loss: 13231.1973 normal_loss: 0.0000
[epoch  7][iter  250] loss: 174983.9219 RMSElog: 8.8092 grad_loss: 17489.5840 normal_loss: 0.0000
[epoch  7][iter  260] loss: 185044.9375 RMSElog: 8.7426 grad_loss: 18495.7520 normal_loss: 0.0000
[epoch  7][iter  270] loss: 170033.3750 RMSElog: 8.7695 grad_loss: 16994.5684 normal_loss: 0.0000
[epoch  7][iter  280] loss: 107451.2891 RMSElog: 8.2074 grad_loss: 10736.9219 normal_loss: 0.0000
[epoch  7][iter  290] loss: 147456.3750 RMSElog: 8.7375 grad_loss: 14736.9004 normal_loss: 0.0000
[epoch  7][iter  300] loss: 207858.0625 RMSElog: 9.0574 grad_loss: 20776.7500 normal_loss: 0.0000
[epoch  7][iter  310] loss: 106740.8750 RMSElog: 8.3015 grad_loss: 10665.7861 normal_loss: 0.0000
[epoch  7][iter  320] loss: 106486.8359 RMSElog: 8.0410 grad_loss: 10640.6426 normal_loss: 0.0000
[epoch  7][iter  330] loss: 230493.1094 RMSElog: 9.0455 grad_loss: 23040.2656 normal_loss: 0.0000
[epoch  7][iter  340] loss: 146438.7656 RMSElog: 8.6975 grad_loss: 14635.1797 normal_loss: 0.0000
[epoch  7][iter  350] loss: 214041.0781 RMSElog: 8.8020 grad_loss: 21395.3047 normal_loss: 0.0000
[epoch  7][iter  360] loss: 110572.9766 RMSElog: 8.1418 grad_loss: 11049.1562 normal_loss: 0.0000
[epoch  7][iter  370] loss: 181439.3594 RMSElog: 8.8685 grad_loss: 18135.0664 normal_loss: 0.0000
[epoch  7][iter  380] loss: 174605.9062 RMSElog: 8.8096 grad_loss: 17451.7793 normal_loss: 0.0000
[epoch  7][iter  390] loss: 108770.2188 RMSElog: 8.1131 grad_loss: 10868.9082 normal_loss: 0.0000
[epoch  7][iter  400] loss: 177909.4688 RMSElog: 8.7598 grad_loss: 17782.1875 normal_loss: 0.0000
[epoch  7][iter  410] loss: 114289.4922 RMSElog: 8.4828 grad_loss: 11420.4668 normal_loss: 0.0000
[epoch  7][iter  420] loss: 197688.9219 RMSElog: 9.1550 grad_loss: 19759.7383 normal_loss: 0.0000
[epoch  7][iter  430] loss: 173548.5625 RMSElog: 8.9982 grad_loss: 17345.8574 normal_loss: 0.0000
[epoch  7][iter  440] loss: 157401.8594 RMSElog: 8.9014 grad_loss: 15731.2852 normal_loss: 0.0000
[epoch  7][iter  450] loss: 148220.2188 RMSElog: 8.7176 grad_loss: 14813.3047 normal_loss: 0.0000
[epoch  7][iter  460] loss: 167931.4844 RMSElog: 8.6907 grad_loss: 16784.4570 normal_loss: 0.0000
[epoch  7][iter  470] loss: 146933.4219 RMSElog: 8.6062 grad_loss: 14684.7363 normal_loss: 0.0000
[epoch  7][iter  480] loss: 208157.9375 RMSElog: 9.1125 grad_loss: 20806.6797 normal_loss: 0.0000
[epoch  7][iter  490] loss: 160413.3125 RMSElog: 8.8757 grad_loss: 16032.4551 normal_loss: 0.0000
[epoch  7][iter  500] loss: 154264.8594 RMSElog: 8.6691 grad_loss: 15417.8174 normal_loss: 0.0000
[epoch  7][iter  510] loss: 145366.3125 RMSElog: 8.8527 grad_loss: 14527.7793 normal_loss: 0.0000
[epoch  7][iter  520] loss: 176200.7969 RMSElog: 8.9960 grad_loss: 17611.0840 normal_loss: 0.0000
[epoch  7][iter  530] loss: 113178.2891 RMSElog: 8.5698 grad_loss: 11309.2598 normal_loss: 0.0000
[epoch  7][iter  540] loss: 204622.5156 RMSElog: 8.8920 grad_loss: 20453.3594 normal_loss: 0.0000
[epoch  7][iter  550] loss: 139073.3438 RMSElog: 8.6948 grad_loss: 13898.6406 normal_loss: 0.0000
[epoch  7][iter  560] loss: 175333.5938 RMSElog: 8.9568 grad_loss: 17524.4023 normal_loss: 0.0000
[epoch  7][iter  570] loss: 143878.2656 RMSElog: 8.7153 grad_loss: 14379.1123 normal_loss: 0.0000
[epoch  7][iter  580] loss: 150341.4219 RMSElog: 8.8975 grad_loss: 15025.2441 normal_loss: 0.0000
[epoch  7][iter  590] loss: 194964.4062 RMSElog: 8.8365 grad_loss: 19487.6055 normal_loss: 0.0000
[epoch  8][iter    0] loss: 227060.7812 RMSElog: 9.0871 grad_loss: 22696.2773 normal_loss: 0.7125
[epoch  8][iter   10] loss: 213383.7500 RMSElog: 8.9105 grad_loss: 21328.7598 normal_loss: 0.7058
[epoch  8][iter   20] loss: 177648.9219 RMSElog: 8.7871 grad_loss: 17755.3887 normal_loss: 0.7161
[epoch  8][iter   30] loss: 172099.3750 RMSElog: 8.7964 grad_loss: 17200.4277 normal_loss: 0.7123
[epoch  8][iter   40] loss: 135188.3438 RMSElog: 8.4755 grad_loss: 13509.6367 normal_loss: 0.7213
[epoch  8][iter   50] loss: 139857.6250 RMSElog: 8.2324 grad_loss: 13976.7686 normal_loss: 0.7615
[epoch  8][iter   60] loss: 109237.0938 RMSElog: 8.1125 grad_loss: 10914.9238 normal_loss: 0.6733
[epoch  8][iter   70] loss: 185051.9375 RMSElog: 8.7561 grad_loss: 18495.7305 normal_loss: 0.7064
[epoch  8][iter   80] loss: 111901.4453 RMSElog: 8.4328 grad_loss: 11180.9668 normal_loss: 0.7450
[epoch  8][iter   90] loss: 119411.2188 RMSElog: 8.5415 grad_loss: 11931.9287 normal_loss: 0.6524
[epoch  8][iter  100] loss: 179723.1094 RMSElog: 9.0340 grad_loss: 17962.5879 normal_loss: 0.6894
[epoch  8][iter  110] loss: 160034.5312 RMSElog: 8.7904 grad_loss: 15993.9346 normal_loss: 0.7289
[epoch  8][iter  120] loss: 156980.5156 RMSElog: 9.2099 grad_loss: 15687.9678 normal_loss: 0.8743
[epoch  8][iter  130] loss: 226845.3438 RMSElog: 9.0405 grad_loss: 22674.8203 normal_loss: 0.6730
[epoch  8][iter  140] loss: 133026.8438 RMSElog: 8.6565 grad_loss: 13293.3535 normal_loss: 0.6753
[epoch  8][iter  150] loss: 101203.6016 RMSElog: 8.6456 grad_loss: 10110.9941 normal_loss: 0.7211
[epoch  8][iter  160] loss: 217892.7344 RMSElog: 8.8913 grad_loss: 21779.7227 normal_loss: 0.6598
[epoch  8][iter  170] loss: 208165.4844 RMSElog: 9.1335 grad_loss: 20806.7031 normal_loss: 0.7129
[epoch  8][iter  180] loss: 154839.2344 RMSElog: 8.7962 grad_loss: 15474.4297 normal_loss: 0.6974
[epoch  8][iter  190] loss: 138453.6562 RMSElog: 8.5112 grad_loss: 13836.1377 normal_loss: 0.7171
[epoch  8][iter  200] loss: 143443.1406 RMSElog: 8.6663 grad_loss: 14334.9570 normal_loss: 0.6900
[epoch  8][iter  210] loss: 215933.5781 RMSElog: 8.8994 grad_loss: 21583.8047 normal_loss: 0.6543
[epoch  8][iter  220] loss: 148222.3750 RMSElog: 8.7894 grad_loss: 14812.7773 normal_loss: 0.6718
[epoch  8][iter  230] loss: 191349.0312 RMSElog: 8.7253 grad_loss: 19125.5215 normal_loss: 0.6554
[epoch  8][iter  240] loss: 231678.5312 RMSElog: 9.1265 grad_loss: 23158.0098 normal_loss: 0.7164
[epoch  8][iter  250] loss: 241953.2031 RMSElog: 9.0349 grad_loss: 24185.5781 normal_loss: 0.7066
[epoch  8][iter  260] loss: 165957.9688 RMSElog: 8.7859 grad_loss: 16586.3438 normal_loss: 0.6670
[epoch  8][iter  270] loss: 183462.5938 RMSElog: 8.8723 grad_loss: 18336.7031 normal_loss: 0.6837
[epoch  8][iter  280] loss: 198272.6875 RMSElog: 8.8241 grad_loss: 19817.7695 normal_loss: 0.6760
[epoch  8][iter  290] loss: 127482.7266 RMSElog: 8.2842 grad_loss: 12739.3057 normal_loss: 0.6831
[epoch  8][iter  300] loss: 174613.1406 RMSElog: 8.8241 grad_loss: 17451.7676 normal_loss: 0.7218
[epoch  8][iter  310] loss: 110784.6016 RMSElog: 8.1056 grad_loss: 11069.6924 normal_loss: 0.6624
[epoch  8][iter  320] loss: 188096.5469 RMSElog: 8.9468 grad_loss: 18800.0430 normal_loss: 0.6638
[epoch  8][iter  330] loss: 107883.3203 RMSElog: 8.0758 grad_loss: 10779.5898 normal_loss: 0.6656
[epoch  8][iter  340] loss: 174548.8438 RMSElog: 8.7465 grad_loss: 17445.4219 normal_loss: 0.7171
[epoch  8][iter  350] loss: 177272.9062 RMSElog: 8.8978 grad_loss: 17717.6934 normal_loss: 0.6999
[epoch  8][iter  360] loss: 194387.2031 RMSElog: 8.8273 grad_loss: 19429.2070 normal_loss: 0.6846
[epoch  8][iter  370] loss: 125265.9375 RMSElog: 8.4530 grad_loss: 12517.3984 normal_loss: 0.7424
[epoch  8][iter  380] loss: 178062.2188 RMSElog: 8.8989 grad_loss: 17796.5859 normal_loss: 0.7378
[epoch  8][iter  390] loss: 182549.2188 RMSElog: 8.9479 grad_loss: 18245.2832 normal_loss: 0.6914
[epoch  8][iter  400] loss: 115326.3594 RMSElog: 8.2980 grad_loss: 11523.6709 normal_loss: 0.6666
[epoch  8][iter  410] loss: 146940.9062 RMSElog: 8.6163 grad_loss: 14684.7373 normal_loss: 0.7375
[epoch  8][iter  420] loss: 114904.0312 RMSElog: 8.2873 grad_loss: 11481.4258 normal_loss: 0.6903
[epoch  8][iter  430] loss: 128864.4922 RMSElog: 8.6651 grad_loss: 12877.1084 normal_loss: 0.6755
[epoch  8][iter  440] loss: 186939.0781 RMSElog: 8.8957 grad_loss: 18684.3477 normal_loss: 0.6647
[epoch  8][iter  450] loss: 113898.8438 RMSElog: 8.1197 grad_loss: 11381.0850 normal_loss: 0.6798
[epoch  8][iter  460] loss: 114488.1328 RMSElog: 8.2838 grad_loss: 11439.8281 normal_loss: 0.7010
[epoch  8][iter  470] loss: 107458.1875 RMSElog: 8.2133 grad_loss: 10736.9092 normal_loss: 0.6961
[epoch  8][iter  480] loss: 146195.6562 RMSElog: 8.7227 grad_loss: 14610.1670 normal_loss: 0.6757
[epoch  8][iter  490] loss: 191673.4688 RMSElog: 8.9501 grad_loss: 19157.7109 normal_loss: 0.6875
[epoch  8][iter  500] loss: 150282.6406 RMSElog: 8.6756 grad_loss: 15018.9297 normal_loss: 0.6591
[epoch  8][iter  510] loss: 114363.7969 RMSElog: 8.6003 grad_loss: 11427.0547 normal_loss: 0.7242
[epoch  8][iter  520] loss: 114883.2500 RMSElog: 8.6594 grad_loss: 11478.9336 normal_loss: 0.7321
[epoch  8][iter  530] loss: 100967.3906 RMSElog: 8.1343 grad_loss: 10087.9385 normal_loss: 0.6663
[epoch  8][iter  540] loss: 147581.3438 RMSElog: 8.8031 grad_loss: 14748.6426 normal_loss: 0.6896
[epoch  8][iter  550] loss: 163682.0781 RMSElog: 8.7972 grad_loss: 16358.6348 normal_loss: 0.7762
[epoch  8][iter  560] loss: 214787.8750 RMSElog: 8.8688 grad_loss: 21469.2578 normal_loss: 0.6593
[epoch  8][iter  570] loss: 158014.5938 RMSElog: 8.7762 grad_loss: 15792.0273 normal_loss: 0.6566
[epoch  8][iter  580] loss: 183074.1250 RMSElog: 8.6298 grad_loss: 18298.0645 normal_loss: 0.7196
[epoch  8][iter  590] loss: 228033.8438 RMSElog: 8.9295 grad_loss: 22793.7500 normal_loss: 0.7052
[epoch  9][iter    0] loss: 122661.9453 RMSElog: 8.7229 grad_loss: 12256.6191 normal_loss: 0.8529
[epoch  9][iter   10] loss: 206060.9375 RMSElog: 8.7639 grad_loss: 20596.6680 normal_loss: 0.6626
[epoch  9][iter   20] loss: 103332.1172 RMSElog: 8.0700 grad_loss: 10324.4844 normal_loss: 0.6569
[epoch  9][iter   30] loss: 146142.0469 RMSElog: 8.5881 grad_loss: 14604.8818 normal_loss: 0.7353
[epoch  9][iter   40] loss: 167723.4531 RMSElog: 8.8568 grad_loss: 16762.7930 normal_loss: 0.6963
[epoch  9][iter   50] loss: 160623.6562 RMSElog: 8.8013 grad_loss: 16052.9111 normal_loss: 0.6536
[epoch  9][iter   60] loss: 196255.0938 RMSElog: 8.7733 grad_loss: 19616.0781 normal_loss: 0.6575
[epoch  9][iter   70] loss: 127445.3750 RMSElog: 8.3974 grad_loss: 12735.4736 normal_loss: 0.6657
[epoch  9][iter   80] loss: 135450.0312 RMSElog: 8.8597 grad_loss: 13535.4336 normal_loss: 0.7111
[epoch  9][iter   90] loss: 78496.3594 RMSElog: 8.6155 grad_loss: 7840.3652 normal_loss: 0.6557
[epoch  9][iter  100] loss: 217893.2031 RMSElog: 8.8985 grad_loss: 21779.7422 normal_loss: 0.6801
[epoch  9][iter  110] loss: 185127.6250 RMSElog: 8.9112 grad_loss: 18503.0801 normal_loss: 0.7700
[epoch  9][iter  120] loss: 177648.8906 RMSElog: 8.7896 grad_loss: 17755.3887 normal_loss: 0.7111
[epoch  9][iter  130] loss: 138453.5000 RMSElog: 8.5058 grad_loss: 13836.1318 normal_loss: 0.7120
[epoch  9][iter  140] loss: 157101.8750 RMSElog: 8.8202 grad_loss: 15700.6924 normal_loss: 0.6749
[epoch  9][iter  150] loss: 105878.6719 RMSElog: 8.4898 grad_loss: 10578.6729 normal_loss: 0.7042
[epoch  9][iter  160] loss: 130124.5000 RMSElog: 8.3024 grad_loss: 13003.4678 normal_loss: 0.6795
[epoch  9][iter  170] loss: 121894.4531 RMSElog: 8.2877 grad_loss: 12180.4629 normal_loss: 0.6940
[epoch  9][iter  180] loss: 148227.1250 RMSElog: 8.7249 grad_loss: 14813.2998 normal_loss: 0.6876
[epoch  9][iter  190] loss: 176892.4844 RMSElog: 8.9760 grad_loss: 17679.6191 normal_loss: 0.6532
[epoch  9][iter  200] loss: 199053.4688 RMSElog: 8.8974 grad_loss: 19895.7148 normal_loss: 0.7366
[epoch  9][iter  210] loss: 161627.8438 RMSElog: 8.9568 grad_loss: 16153.1660 normal_loss: 0.6616
[epoch  9][iter  220] loss: 144174.7969 RMSElog: 8.6167 grad_loss: 14408.1797 normal_loss: 0.6831
[epoch  9][iter  230] loss: 161793.8594 RMSElog: 8.8565 grad_loss: 16169.8770 normal_loss: 0.6524
[epoch  9][iter  240] loss: 235192.0469 RMSElog: 9.1072 grad_loss: 23509.4102 normal_loss: 0.6876
[epoch  9][iter  250] loss: 132024.0781 RMSElog: 8.8307 grad_loss: 13192.8672 normal_loss: 0.7091
[epoch  9][iter  260] loss: 194556.2188 RMSElog: 8.7911 grad_loss: 19446.1777 normal_loss: 0.6517
[epoch  9][iter  270] loss: 190917.5000 RMSElog: 9.0470 grad_loss: 19082.0391 normal_loss: 0.6649
[epoch  9][iter  280] loss: 164750.3281 RMSElog: 8.8205 grad_loss: 16465.5020 normal_loss: 0.7112
[epoch  9][iter  290] loss: 157043.2656 RMSElog: 8.8769 grad_loss: 15694.7939 normal_loss: 0.6556
[epoch  9][iter  300] loss: 151704.3906 RMSElog: 8.7894 grad_loss: 15161.0049 normal_loss: 0.6450
[epoch  9][iter  310] loss: 143441.8594 RMSElog: 8.6194 grad_loss: 14334.9111 normal_loss: 0.6567
[epoch  9][iter  320] loss: 142575.4844 RMSElog: 8.5828 grad_loss: 14248.3105 normal_loss: 0.6551
[epoch  9][iter  330] loss: 163236.0625 RMSElog: 8.8294 grad_loss: 16314.0859 normal_loss: 0.6905
[epoch  9][iter  340] loss: 150304.7656 RMSElog: 8.8926 grad_loss: 15020.8711 normal_loss: 0.7125
[epoch  9][iter  350] loss: 104316.7891 RMSElog: 8.0778 grad_loss: 10422.9434 normal_loss: 0.6577
[epoch  9][iter  360] loss: 135797.7812 RMSElog: 8.4565 grad_loss: 13570.6143 normal_loss: 0.7078
[epoch  9][iter  370] loss: 148118.6875 RMSElog: 8.7699 grad_loss: 14802.4023 normal_loss: 0.6968
[epoch  9][iter  380] loss: 160649.5000 RMSElog: 8.8861 grad_loss: 16055.3994 normal_loss: 0.6652
[epoch  9][iter  390] loss: 182296.2188 RMSElog: 8.9552 grad_loss: 18220.0195 normal_loss: 0.6467
[epoch  9][iter  400] loss: 160056.8281 RMSElog: 8.7123 grad_loss: 15996.3047 normal_loss: 0.6660
[epoch  9][iter  410] loss: 206381.3906 RMSElog: 9.0296 grad_loss: 20628.4277 normal_loss: 0.6822
[epoch  9][iter  420] loss: 154290.6094 RMSElog: 8.6591 grad_loss: 15419.7227 normal_loss: 0.6793
[epoch  9][iter  430] loss: 154594.2344 RMSElog: 8.7605 grad_loss: 15449.9268 normal_loss: 0.7358
[epoch  9][iter  440] loss: 133267.2812 RMSElog: 8.6368 grad_loss: 13317.4502 normal_loss: 0.6413
[epoch  9][iter  450] loss: 214047.8125 RMSElog: 8.8188 grad_loss: 21395.2910 normal_loss: 0.6710
[epoch  9][iter  460] loss: 127757.1484 RMSElog: 8.6942 grad_loss: 12766.3193 normal_loss: 0.7014
[epoch  9][iter  470] loss: 157408.5469 RMSElog: 8.8851 grad_loss: 15731.2754 normal_loss: 0.6940
[epoch  9][iter  480] loss: 215522.4844 RMSElog: 9.1298 grad_loss: 21542.4512 normal_loss: 0.6687
[epoch  9][iter  490] loss: 155952.0469 RMSElog: 8.6956 grad_loss: 15585.7598 normal_loss: 0.7489
[epoch  9][iter  500] loss: 188998.5938 RMSElog: 8.9219 grad_loss: 18890.2383 normal_loss: 0.6986
[epoch  9][iter  510] loss: 117386.7344 RMSElog: 8.4470 grad_loss: 11729.5625 normal_loss: 0.6644
[epoch  9][iter  520] loss: 165957.5156 RMSElog: 8.7814 grad_loss: 16586.3203 normal_loss: 0.6502
[epoch  9][iter  530] loss: 100625.7891 RMSElog: 8.0561 grad_loss: 10053.8809 normal_loss: 0.6429
[epoch  9][iter  540] loss: 115326.1094 RMSElog: 8.2812 grad_loss: 11523.6611 normal_loss: 0.6693
[epoch  9][iter  550] loss: 137308.5625 RMSElog: 8.5518 grad_loss: 13721.6221 normal_loss: 0.6824
[epoch  9][iter  560] loss: 112298.8125 RMSElog: 8.3380 grad_loss: 11220.8691 normal_loss: 0.6738
[epoch  9][iter  570] loss: 133026.3906 RMSElog: 8.6637 grad_loss: 13293.3213 normal_loss: 0.6535
[epoch  9][iter  580] loss: 109124.1328 RMSElog: 8.3081 grad_loss: 10903.4141 normal_loss: 0.6919
[epoch  9][iter  590] loss: 239433.2812 RMSElog: 9.0530 grad_loss: 23933.5781 normal_loss: 0.6978
###########
#epochs 30#
###########
[epoch  0][iter    0] loss: 102.9274 RMSElog: 10.2927 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   10] loss: 104.2282 RMSElog: 10.4228 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   20] loss: 103.1048 RMSElog: 10.3105 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   30] loss: 102.0529 RMSElog: 10.2053 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   40] loss: 102.8384 RMSElog: 10.2838 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   50] loss: 106.0400 RMSElog: 10.6040 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   60] loss: 105.2535 RMSElog: 10.5254 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   70] loss: 101.1415 RMSElog: 10.1142 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   80] loss: 106.6197 RMSElog: 10.6620 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   90] loss: 100.6064 RMSElog: 10.0606 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  100] loss: 100.0012 RMSElog: 10.0001 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  110] loss: 102.8872 RMSElog: 10.2887 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  120] loss: 101.5198 RMSElog: 10.1520 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  130] loss: 103.1917 RMSElog: 10.3192 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  140] loss: 97.6046 RMSElog: 9.7605 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  150] loss: 99.8302 RMSElog: 9.9830 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  160] loss: 99.3478 RMSElog: 9.9348 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  170] loss: 101.8391 RMSElog: 10.1839 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  180] loss: 95.1691 RMSElog: 9.5169 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  190] loss: 98.5007 RMSElog: 9.8501 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  200] loss: 97.0059 RMSElog: 9.7006 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  210] loss: 103.3939 RMSElog: 10.3394 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  220] loss: 97.3976 RMSElog: 9.7398 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  230] loss: 101.4414 RMSElog: 10.1441 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  240] loss: 101.4538 RMSElog: 10.1454 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  250] loss: 101.7213 RMSElog: 10.1721 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  260] loss: 99.4729 RMSElog: 9.9473 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  270] loss: 97.2313 RMSElog: 9.7231 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  280] loss: 97.6442 RMSElog: 9.7644 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  290] loss: 100.8997 RMSElog: 10.0900 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  300] loss: 99.0118 RMSElog: 9.9012 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  310] loss: 93.2950 RMSElog: 9.3295 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  320] loss: 99.5392 RMSElog: 9.9539 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  330] loss: 98.7549 RMSElog: 9.8755 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  340] loss: 97.8144 RMSElog: 9.7814 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  350] loss: 95.7263 RMSElog: 9.5726 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  360] loss: 98.8081 RMSElog: 9.8808 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  370] loss: 99.2044 RMSElog: 9.9204 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  380] loss: 96.4834 RMSElog: 9.6483 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  390] loss: 98.1925 RMSElog: 9.8192 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  400] loss: 98.3895 RMSElog: 9.8389 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  410] loss: 101.1052 RMSElog: 10.1105 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  420] loss: 98.9526 RMSElog: 9.8953 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  430] loss: 98.7744 RMSElog: 9.8774 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  440] loss: 98.9576 RMSElog: 9.8958 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  450] loss: 96.7298 RMSElog: 9.6730 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  460] loss: 92.3266 RMSElog: 9.2327 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  470] loss: 96.6792 RMSElog: 9.6679 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  480] loss: 97.4122 RMSElog: 9.7412 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  490] loss: 102.5421 RMSElog: 10.2542 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  500] loss: 97.6466 RMSElog: 9.7647 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  510] loss: 99.1555 RMSElog: 9.9155 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  520] loss: 101.1795 RMSElog: 10.1179 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  530] loss: 97.4311 RMSElog: 9.7431 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  540] loss: 104.4048 RMSElog: 10.4405 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  550] loss: 96.9290 RMSElog: 9.6929 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  560] loss: 102.3190 RMSElog: 10.2319 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  570] loss: 102.4920 RMSElog: 10.2492 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  580] loss: 100.0338 RMSElog: 10.0034 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  590] loss: 95.7702 RMSElog: 9.5770 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter    0] loss: 97.3725 RMSElog: 9.7373 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   10] loss: 98.8242 RMSElog: 9.8824 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   20] loss: 97.6610 RMSElog: 9.7661 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   30] loss: 99.1316 RMSElog: 9.9132 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   40] loss: 99.7010 RMSElog: 9.9701 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   50] loss: 100.3693 RMSElog: 10.0369 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   60] loss: 101.0962 RMSElog: 10.1096 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   70] loss: 92.4874 RMSElog: 9.2487 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   80] loss: 98.5828 RMSElog: 9.8583 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   90] loss: 99.5540 RMSElog: 9.9554 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  100] loss: 100.4506 RMSElog: 10.0451 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  110] loss: 96.1339 RMSElog: 9.6134 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  120] loss: 98.2967 RMSElog: 9.8297 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  130] loss: 97.2617 RMSElog: 9.7262 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  140] loss: 97.3629 RMSElog: 9.7363 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  150] loss: 97.6852 RMSElog: 9.7685 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  160] loss: 101.0806 RMSElog: 10.1081 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  170] loss: 100.7399 RMSElog: 10.0740 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  180] loss: 98.8132 RMSElog: 9.8813 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  190] loss: 101.4369 RMSElog: 10.1437 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  200] loss: 97.4427 RMSElog: 9.7443 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  210] loss: 102.9301 RMSElog: 10.2930 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  220] loss: 100.7814 RMSElog: 10.0781 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  230] loss: 98.2514 RMSElog: 9.8251 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  240] loss: 104.3231 RMSElog: 10.4323 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  250] loss: 100.5506 RMSElog: 10.0551 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  260] loss: 100.0973 RMSElog: 10.0097 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  270] loss: 101.1678 RMSElog: 10.1168 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  280] loss: 94.9582 RMSElog: 9.4958 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  290] loss: 97.2725 RMSElog: 9.7272 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  300] loss: 98.9250 RMSElog: 9.8925 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  310] loss: 98.1928 RMSElog: 9.8193 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  320] loss: 97.1649 RMSElog: 9.7165 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  330] loss: 97.8473 RMSElog: 9.7847 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  340] loss: 99.7426 RMSElog: 9.9743 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  350] loss: 97.0594 RMSElog: 9.7059 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  360] loss: 95.8221 RMSElog: 9.5822 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  370] loss: 99.5053 RMSElog: 9.9505 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  380] loss: 91.8323 RMSElog: 9.1832 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  390] loss: 98.7456 RMSElog: 9.8746 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  400] loss: 99.0790 RMSElog: 9.9079 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  410] loss: 99.9198 RMSElog: 9.9920 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  420] loss: 100.7322 RMSElog: 10.0732 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  430] loss: 102.8158 RMSElog: 10.2816 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  440] loss: 94.0102 RMSElog: 9.4010 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  450] loss: 101.4893 RMSElog: 10.1489 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  460] loss: 98.9213 RMSElog: 9.8921 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  470] loss: 97.1615 RMSElog: 9.7162 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  480] loss: 96.4670 RMSElog: 9.6467 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  490] loss: 98.7244 RMSElog: 9.8724 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  500] loss: 98.5405 RMSElog: 9.8540 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  510] loss: 102.3569 RMSElog: 10.2357 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  520] loss: 98.1238 RMSElog: 9.8124 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  530] loss: 99.5332 RMSElog: 9.9533 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  540] loss: 101.8391 RMSElog: 10.1839 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  550] loss: 101.0468 RMSElog: 10.1047 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  560] loss: 98.9291 RMSElog: 9.8929 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  570] loss: 95.4197 RMSElog: 9.5420 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  580] loss: 97.8103 RMSElog: 9.7810 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  590] loss: 100.2282 RMSElog: 10.0228 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter    0] loss: 102.4243 RMSElog: 10.2424 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   10] loss: 91.9529 RMSElog: 9.1953 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   20] loss: 103.6160 RMSElog: 10.3616 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   30] loss: 100.7729 RMSElog: 10.0773 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   40] loss: 97.0063 RMSElog: 9.7006 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   50] loss: 93.2310 RMSElog: 9.3231 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   60] loss: 96.1709 RMSElog: 9.6171 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   70] loss: 100.2436 RMSElog: 10.0244 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   80] loss: 103.2854 RMSElog: 10.3285 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   90] loss: 97.3095 RMSElog: 9.7309 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  100] loss: 96.5947 RMSElog: 9.6595 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  110] loss: 98.9987 RMSElog: 9.8999 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  120] loss: 102.8692 RMSElog: 10.2869 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  130] loss: 96.0178 RMSElog: 9.6018 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  140] loss: 96.4718 RMSElog: 9.6472 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  150] loss: 97.3049 RMSElog: 9.7305 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  160] loss: 92.2618 RMSElog: 9.2262 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  170] loss: 99.6160 RMSElog: 9.9616 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  180] loss: 97.1106 RMSElog: 9.7111 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  190] loss: 99.2809 RMSElog: 9.9281 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  200] loss: 100.1553 RMSElog: 10.0155 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  210] loss: 96.4818 RMSElog: 9.6482 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  220] loss: 97.5051 RMSElog: 9.7505 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  230] loss: 98.8645 RMSElog: 9.8865 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  240] loss: 98.5694 RMSElog: 9.8569 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  250] loss: 99.0997 RMSElog: 9.9100 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  260] loss: 96.5244 RMSElog: 9.6524 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  270] loss: 95.8025 RMSElog: 9.5802 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  280] loss: 101.9858 RMSElog: 10.1986 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  290] loss: 98.6376 RMSElog: 9.8638 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  300] loss: 97.0698 RMSElog: 9.7070 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  310] loss: 103.6373 RMSElog: 10.3637 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  320] loss: 96.8528 RMSElog: 9.6853 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  330] loss: 97.9277 RMSElog: 9.7928 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  340] loss: 98.3067 RMSElog: 9.8307 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  350] loss: 97.4117 RMSElog: 9.7412 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  360] loss: 98.1268 RMSElog: 9.8127 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  370] loss: 100.2740 RMSElog: 10.0274 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  380] loss: 99.3855 RMSElog: 9.9385 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  390] loss: 95.9084 RMSElog: 9.5908 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  400] loss: 96.3361 RMSElog: 9.6336 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  410] loss: 99.1921 RMSElog: 9.9192 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  420] loss: 98.5782 RMSElog: 9.8578 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  430] loss: 99.4141 RMSElog: 9.9414 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  440] loss: 96.3519 RMSElog: 9.6352 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  450] loss: 97.8152 RMSElog: 9.7815 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  460] loss: 98.8887 RMSElog: 9.8889 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  470] loss: 89.4831 RMSElog: 8.9483 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  480] loss: 91.6247 RMSElog: 9.1625 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  490] loss: 96.2682 RMSElog: 9.6268 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  500] loss: 90.6325 RMSElog: 9.0632 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  510] loss: 89.5761 RMSElog: 8.9576 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  520] loss: 95.0711 RMSElog: 9.5071 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  530] loss: 88.7353 RMSElog: 8.8735 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  540] loss: 92.7259 RMSElog: 9.2726 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  550] loss: 92.5380 RMSElog: 9.2538 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  560] loss: 90.8221 RMSElog: 9.0822 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  570] loss: 94.7823 RMSElog: 9.4782 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  580] loss: 93.8251 RMSElog: 9.3825 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  590] loss: 91.7924 RMSElog: 9.1792 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter    0] loss: 92.4858 RMSElog: 9.2486 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   10] loss: 91.5291 RMSElog: 9.1529 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   20] loss: 91.7691 RMSElog: 9.1769 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   30] loss: 89.6363 RMSElog: 8.9636 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   40] loss: 89.6503 RMSElog: 8.9650 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   50] loss: 90.1623 RMSElog: 9.0162 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   60] loss: 91.0928 RMSElog: 9.1093 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   70] loss: 88.1729 RMSElog: 8.8173 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   80] loss: 89.9531 RMSElog: 8.9953 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   90] loss: 88.0089 RMSElog: 8.8009 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  100] loss: 91.6993 RMSElog: 9.1699 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  110] loss: 85.9397 RMSElog: 8.5940 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  120] loss: 89.9050 RMSElog: 8.9905 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  130] loss: 85.6513 RMSElog: 8.5651 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  140] loss: 91.2722 RMSElog: 9.1272 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  150] loss: 85.5241 RMSElog: 8.5524 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  160] loss: 92.8644 RMSElog: 9.2864 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  170] loss: 91.3951 RMSElog: 9.1395 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  180] loss: 86.9529 RMSElog: 8.6953 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  190] loss: 84.1512 RMSElog: 8.4151 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  200] loss: 88.0086 RMSElog: 8.8009 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  210] loss: 85.0126 RMSElog: 8.5013 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  220] loss: 89.5374 RMSElog: 8.9537 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  230] loss: 91.4635 RMSElog: 9.1464 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  240] loss: 91.8199 RMSElog: 9.1820 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  250] loss: 84.8887 RMSElog: 8.4889 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  260] loss: 88.4178 RMSElog: 8.8418 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  270] loss: 91.9764 RMSElog: 9.1976 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  280] loss: 88.8448 RMSElog: 8.8845 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  290] loss: 84.4858 RMSElog: 8.4486 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  300] loss: 89.8231 RMSElog: 8.9823 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  310] loss: 88.0931 RMSElog: 8.8093 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  320] loss: 91.4240 RMSElog: 9.1424 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  330] loss: 89.1586 RMSElog: 8.9159 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  340] loss: 87.5430 RMSElog: 8.7543 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  350] loss: 88.3712 RMSElog: 8.8371 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  360] loss: 87.3347 RMSElog: 8.7335 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  370] loss: 91.4483 RMSElog: 9.1448 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  380] loss: 89.4424 RMSElog: 8.9442 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  390] loss: 90.0716 RMSElog: 9.0072 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  400] loss: 86.1600 RMSElog: 8.6160 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  410] loss: 89.2689 RMSElog: 8.9269 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  420] loss: 88.4586 RMSElog: 8.8459 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  430] loss: 86.2510 RMSElog: 8.6251 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  440] loss: 87.4250 RMSElog: 8.7425 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  450] loss: 88.6049 RMSElog: 8.8605 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  460] loss: 84.3502 RMSElog: 8.4350 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  470] loss: 84.6590 RMSElog: 8.4659 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  480] loss: 89.9231 RMSElog: 8.9923 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  490] loss: 89.3376 RMSElog: 8.9338 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  500] loss: 88.2880 RMSElog: 8.8288 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  510] loss: 90.2789 RMSElog: 9.0279 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  520] loss: 86.0258 RMSElog: 8.6026 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  530] loss: 84.8863 RMSElog: 8.4886 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  540] loss: 84.2082 RMSElog: 8.4208 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  550] loss: 83.0370 RMSElog: 8.3037 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  560] loss: 88.8945 RMSElog: 8.8894 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  570] loss: 87.6894 RMSElog: 8.7689 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  580] loss: 90.2877 RMSElog: 9.0288 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  590] loss: 90.8958 RMSElog: 9.0896 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  4][iter    0] loss: 202996.2656 RMSElog: 8.8611 grad_loss: 20290.7656 normal_loss: 0.0000
[epoch  4][iter   10] loss: 180957.8750 RMSElog: 9.0215 grad_loss: 18086.7656 normal_loss: 0.0000
[epoch  4][iter   20] loss: 201477.9688 RMSElog: 9.0620 grad_loss: 20138.7344 normal_loss: 0.0000
[epoch  4][iter   30] loss: 154834.4531 RMSElog: 8.8968 grad_loss: 15474.5488 normal_loss: 0.0000
[epoch  4][iter   40] loss: 119900.8438 RMSElog: 8.6018 grad_loss: 11981.4824 normal_loss: 0.0000
[epoch  4][iter   50] loss: 166522.0000 RMSElog: 9.0440 grad_loss: 16643.1543 normal_loss: 0.0000
[epoch  4][iter   60] loss: 128536.6328 RMSElog: 8.7229 grad_loss: 12844.9404 normal_loss: 0.0000
[epoch  4][iter   70] loss: 165628.0625 RMSElog: 8.8691 grad_loss: 16553.9375 normal_loss: 0.0000
[epoch  4][iter   80] loss: 144562.6719 RMSElog: 8.1684 grad_loss: 14448.0996 normal_loss: 0.0000
[epoch  4][iter   90] loss: 178056.1719 RMSElog: 8.9499 grad_loss: 17796.6680 normal_loss: 0.0000
[epoch  4][iter  100] loss: 142113.9375 RMSElog: 8.5920 grad_loss: 14202.8027 normal_loss: 0.0000
[epoch  4][iter  110] loss: 114290.2188 RMSElog: 8.5255 grad_loss: 11420.4961 normal_loss: 0.0000
[epoch  4][iter  120] loss: 100954.6094 RMSElog: 8.2601 grad_loss: 10087.2012 normal_loss: 0.0000
[epoch  4][iter  130] loss: 148113.1406 RMSElog: 8.8302 grad_loss: 14802.4844 normal_loss: 0.0000
[epoch  4][iter  140] loss: 127090.5547 RMSElog: 8.6961 grad_loss: 12700.3594 normal_loss: 0.0000
[epoch  4][iter  150] loss: 185046.4688 RMSElog: 8.8162 grad_loss: 18495.8301 normal_loss: 0.0000
[epoch  4][iter  160] loss: 138995.3438 RMSElog: 8.7027 grad_loss: 13890.8311 normal_loss: 0.0000
[epoch  4][iter  170] loss: 106742.8828 RMSElog: 8.4192 grad_loss: 10665.8691 normal_loss: 0.0000
[epoch  4][iter  180] loss: 153941.0781 RMSElog: 9.0099 grad_loss: 15385.0986 normal_loss: 0.0000
[epoch  4][iter  190] loss: 154602.0312 RMSElog: 8.8024 grad_loss: 15451.4004 normal_loss: 0.0000
[epoch  4][iter  200] loss: 154266.8125 RMSElog: 8.7289 grad_loss: 15417.9531 normal_loss: 0.0000
[epoch  4][iter  210] loss: 100089.1094 RMSElog: 8.4238 grad_loss: 10000.4873 normal_loss: 0.0000
[epoch  4][iter  220] loss: 176932.7344 RMSElog: 9.0977 grad_loss: 17684.1758 normal_loss: 0.0000
[epoch  4][iter  230] loss: 174982.1875 RMSElog: 9.1416 grad_loss: 17489.0781 normal_loss: 0.0000
[epoch  4][iter  240] loss: 130406.1562 RMSElog: 8.6674 grad_loss: 13031.9482 normal_loss: 0.0000
[epoch  4][iter  250] loss: 104430.4531 RMSElog: 8.5740 grad_loss: 10434.4707 normal_loss: 0.0000
[epoch  4][iter  260] loss: 241948.4062 RMSElog: 9.1377 grad_loss: 24185.7031 normal_loss: 0.0000
[epoch  4][iter  270] loss: 150298.6562 RMSElog: 8.8616 grad_loss: 15021.0049 normal_loss: 0.0000
[epoch  4][iter  280] loss: 211614.8125 RMSElog: 9.0474 grad_loss: 21152.4336 normal_loss: 0.0000
[epoch  4][iter  290] loss: 158902.8906 RMSElog: 8.8596 grad_loss: 15881.4297 normal_loss: 0.0000
[epoch  4][iter  300] loss: 104105.4297 RMSElog: 8.6425 grad_loss: 10401.9004 normal_loss: 0.0000
[epoch  4][iter  310] loss: 129684.0156 RMSElog: 8.5471 grad_loss: 12959.8545 normal_loss: 0.0000
[epoch  4][iter  320] loss: 115474.5703 RMSElog: 8.6005 grad_loss: 11538.8564 normal_loss: 0.0000
[epoch  4][iter  330] loss: 127750.5312 RMSElog: 8.7010 grad_loss: 12766.3516 normal_loss: 0.0000
[epoch  4][iter  340] loss: 167771.8906 RMSElog: 8.8928 grad_loss: 16768.2969 normal_loss: 0.0000
[epoch  4][iter  350] loss: 108773.5938 RMSElog: 8.3597 grad_loss: 10869.0000 normal_loss: 0.0000
[epoch  4][iter  360] loss: 146934.2344 RMSElog: 8.6673 grad_loss: 14684.7568 normal_loss: 0.0000
[epoch  4][iter  370] loss: 112689.6016 RMSElog: 8.3297 grad_loss: 11260.6299 normal_loss: 0.0000
[epoch  4][iter  380] loss: 165988.0312 RMSElog: 8.9564 grad_loss: 16589.8457 normal_loss: 0.0000
[epoch  4][iter  390] loss: 181441.3438 RMSElog: 8.9513 grad_loss: 18135.1836 normal_loss: 0.0000
[epoch  4][iter  400] loss: 163704.3906 RMSElog: 8.6910 grad_loss: 16361.7471 normal_loss: 0.0000
[epoch  4][iter  410] loss: 223849.9844 RMSElog: 9.1459 grad_loss: 22375.8516 normal_loss: 0.0000
[epoch  4][iter  420] loss: 111494.2344 RMSElog: 8.4179 grad_loss: 11141.0059 normal_loss: 0.0000
[epoch  4][iter  430] loss: 166184.8281 RMSElog: 8.8702 grad_loss: 16609.6113 normal_loss: 0.0000
[epoch  4][iter  440] loss: 105072.0938 RMSElog: 8.3710 grad_loss: 10498.8379 normal_loss: 0.0000
[epoch  4][iter  450] loss: 136846.6562 RMSElog: 8.4544 grad_loss: 13676.2119 normal_loss: 0.0000
[epoch  4][iter  460] loss: 211900.4688 RMSElog: 8.9138 grad_loss: 21181.1328 normal_loss: 0.0000
[epoch  4][iter  470] loss: 104952.2969 RMSElog: 8.6553 grad_loss: 10486.5742 normal_loss: 0.0000
[epoch  4][iter  480] loss: 116558.1172 RMSElog: 8.5809 grad_loss: 11647.2305 normal_loss: 0.0000
[epoch  4][iter  490] loss: 150127.7969 RMSElog: 8.8380 grad_loss: 15003.9414 normal_loss: 0.0000
[epoch  4][iter  500] loss: 160051.3750 RMSElog: 8.7501 grad_loss: 15996.3877 normal_loss: 0.0000
[epoch  4][iter  510] loss: 195389.6719 RMSElog: 9.0479 grad_loss: 19529.9180 normal_loss: 0.0000
[epoch  4][iter  520] loss: 125483.9141 RMSElog: 8.8270 grad_loss: 12539.5645 normal_loss: 0.0000
[epoch  4][iter  530] loss: 176239.0938 RMSElog: 9.0978 grad_loss: 17614.8125 normal_loss: 0.0000
[epoch  4][iter  540] loss: 165283.7188 RMSElog: 8.8903 grad_loss: 16519.4805 normal_loss: 0.0000
[epoch  4][iter  550] loss: 135187.8750 RMSElog: 8.6036 grad_loss: 13510.1836 normal_loss: 0.0000
[epoch  4][iter  560] loss: 136481.1094 RMSElog: 8.7399 grad_loss: 13639.3711 normal_loss: 0.0000
[epoch  4][iter  570] loss: 207892.1562 RMSElog: 8.8414 grad_loss: 20780.3730 normal_loss: 0.0000
[epoch  4][iter  580] loss: 188477.0625 RMSElog: 8.9865 grad_loss: 18838.7207 normal_loss: 0.0000
[epoch  4][iter  590] loss: 201138.4688 RMSElog: 8.8662 grad_loss: 20104.9824 normal_loss: 0.0000
[epoch  5][iter    0] loss: 200928.0000 RMSElog: 8.9016 grad_loss: 20083.8984 normal_loss: 0.0000
[epoch  5][iter   10] loss: 119877.5781 RMSElog: 8.6931 grad_loss: 11979.0645 normal_loss: 0.0000
[epoch  5][iter   20] loss: 109412.8828 RMSElog: 8.2129 grad_loss: 10933.0752 normal_loss: 0.0000
[epoch  5][iter   30] loss: 158010.0156 RMSElog: 8.8622 grad_loss: 15792.1396 normal_loss: 0.0000
[epoch  5][iter   40] loss: 241947.1250 RMSElog: 9.0783 grad_loss: 24185.6348 normal_loss: 0.0000
[epoch  5][iter   50] loss: 160858.2500 RMSElog: 8.9415 grad_loss: 16076.8828 normal_loss: 0.0000
[epoch  5][iter   60] loss: 155887.2812 RMSElog: 8.6949 grad_loss: 15580.0332 normal_loss: 0.0000
[epoch  5][iter   70] loss: 123271.2891 RMSElog: 8.7807 grad_loss: 12318.3486 normal_loss: 0.0000
[epoch  5][iter   80] loss: 217886.8125 RMSElog: 8.9192 grad_loss: 21779.7617 normal_loss: 0.0000
[epoch  5][iter   90] loss: 135182.0000 RMSElog: 8.5160 grad_loss: 13509.6836 normal_loss: 0.0000
[epoch  5][iter  100] loss: 178760.5625 RMSElog: 8.9350 grad_loss: 17867.1211 normal_loss: 0.0000
[epoch  5][iter  110] loss: 153424.7969 RMSElog: 8.8578 grad_loss: 15333.6221 normal_loss: 0.0000
[epoch  5][iter  120] loss: 179877.7812 RMSElog: 8.7892 grad_loss: 17978.9883 normal_loss: 0.0000
[epoch  5][iter  130] loss: 196249.8594 RMSElog: 8.8165 grad_loss: 19616.1699 normal_loss: 0.0000
[epoch  5][iter  140] loss: 191534.0469 RMSElog: 8.7289 grad_loss: 19144.6758 normal_loss: 0.0000
[epoch  5][iter  150] loss: 149345.0625 RMSElog: 8.7470 grad_loss: 14925.7598 normal_loss: 0.0000
[epoch  5][iter  160] loss: 105871.8125 RMSElog: 8.4857 grad_loss: 10578.6963 normal_loss: 0.0000
[epoch  5][iter  170] loss: 165430.1719 RMSElog: 8.9773 grad_loss: 16534.0410 normal_loss: 0.0000
[epoch  5][iter  180] loss: 176238.2500 RMSElog: 9.0513 grad_loss: 17614.7734 normal_loss: 0.0000
[epoch  5][iter  190] loss: 116046.1016 RMSElog: 8.3178 grad_loss: 11596.2930 normal_loss: 0.0000
[epoch  5][iter  200] loss: 198718.0312 RMSElog: 8.9270 grad_loss: 19862.8750 normal_loss: 0.0000
[epoch  5][iter  210] loss: 170333.7344 RMSElog: 8.9375 grad_loss: 17024.4355 normal_loss: 0.0000
[epoch  5][iter  220] loss: 159775.5938 RMSElog: 8.7398 grad_loss: 15968.8184 normal_loss: 0.0000
[epoch  5][iter  230] loss: 198418.2812 RMSElog: 8.9344 grad_loss: 19832.8945 normal_loss: 0.0000
[epoch  5][iter  240] loss: 140255.8594 RMSElog: 8.6391 grad_loss: 14016.9473 normal_loss: 0.0000
[epoch  5][iter  250] loss: 140312.1562 RMSElog: 8.9512 grad_loss: 14022.2646 normal_loss: 0.0000
[epoch  5][iter  260] loss: 146921.0625 RMSElog: 8.5627 grad_loss: 14683.5430 normal_loss: 0.0000
[epoch  5][iter  270] loss: 158902.0938 RMSElog: 8.8217 grad_loss: 15881.3877 normal_loss: 0.0000
[epoch  5][iter  280] loss: 122424.6797 RMSElog: 8.3586 grad_loss: 12234.1094 normal_loss: 0.0000
[epoch  5][iter  290] loss: 144168.0625 RMSElog: 8.6080 grad_loss: 14408.1973 normal_loss: 0.0000
[epoch  5][iter  300] loss: 167320.7656 RMSElog: 8.7931 grad_loss: 16723.2832 normal_loss: 0.0000
[epoch  5][iter  310] loss: 157786.0781 RMSElog: 8.7556 grad_loss: 15769.8525 normal_loss: 0.0000
[epoch  5][iter  320] loss: 174980.5312 RMSElog: 9.0231 grad_loss: 17489.0293 normal_loss: 0.0000
[epoch  5][iter  330] loss: 114356.9531 RMSElog: 8.6170 grad_loss: 11427.0781 normal_loss: 0.0000
[epoch  5][iter  340] loss: 211510.4844 RMSElog: 8.8152 grad_loss: 21142.2344 normal_loss: 0.0000
[epoch  5][iter  350] loss: 173696.7969 RMSElog: 8.9229 grad_loss: 17360.7559 normal_loss: 0.0000
[epoch  5][iter  360] loss: 162409.7969 RMSElog: 8.8565 grad_loss: 16232.1230 normal_loss: 0.0000
[epoch  5][iter  370] loss: 119405.2266 RMSElog: 8.5578 grad_loss: 11931.9648 normal_loss: 0.0000
[epoch  5][iter  380] loss: 112830.9453 RMSElog: 8.6221 grad_loss: 11274.4727 normal_loss: 0.0000
[epoch  5][iter  390] loss: 130719.2656 RMSElog: 8.7760 grad_loss: 13063.1504 normal_loss: 0.0000
[epoch  5][iter  400] loss: 100639.8516 RMSElog: 8.7642 grad_loss: 10055.2207 normal_loss: 0.0000
[epoch  5][iter  410] loss: 208794.8125 RMSElog: 8.8197 grad_loss: 20870.6602 normal_loss: 0.0000
[epoch  5][iter  420] loss: 136846.3125 RMSElog: 8.4504 grad_loss: 13676.1816 normal_loss: 0.0000
[epoch  5][iter  430] loss: 144632.8438 RMSElog: 8.7406 grad_loss: 14454.5449 normal_loss: 0.0000
[epoch  5][iter  440] loss: 153697.7500 RMSElog: 8.7682 grad_loss: 15361.0059 normal_loss: 0.0000
[epoch  5][iter  450] loss: 127606.4922 RMSElog: 8.5262 grad_loss: 12752.1230 normal_loss: 0.0000
[epoch  5][iter  460] loss: 147347.6562 RMSElog: 8.5743 grad_loss: 14726.1914 normal_loss: 0.0000
[epoch  5][iter  470] loss: 188690.6250 RMSElog: 8.7363 grad_loss: 18860.3262 normal_loss: 0.0000
[epoch  5][iter  480] loss: 170667.7344 RMSElog: 8.9364 grad_loss: 17057.8379 normal_loss: 0.0000
[epoch  5][iter  490] loss: 179623.2656 RMSElog: 8.9259 grad_loss: 17953.4004 normal_loss: 0.0000
[epoch  5][iter  500] loss: 175333.7812 RMSElog: 8.9505 grad_loss: 17524.4277 normal_loss: 0.0000
[epoch  5][iter  510] loss: 127439.3828 RMSElog: 8.4231 grad_loss: 12735.5156 normal_loss: 0.0000
[epoch  5][iter  520] loss: 105799.4219 RMSElog: 8.4401 grad_loss: 10571.5020 normal_loss: 0.0000
[epoch  5][iter  530] loss: 218521.7812 RMSElog: 9.1784 grad_loss: 21843.0000 normal_loss: 0.0000
[epoch  5][iter  540] loss: 128535.6250 RMSElog: 8.6993 grad_loss: 12844.8633 normal_loss: 0.0000
[epoch  5][iter  550] loss: 122653.8281 RMSElog: 8.7516 grad_loss: 12256.6309 normal_loss: 0.0000
[epoch  5][iter  560] loss: 102204.4844 RMSElog: 8.7204 grad_loss: 10211.7275 normal_loss: 0.0000
[epoch  5][iter  570] loss: 135016.1094 RMSElog: 8.3757 grad_loss: 13493.2344 normal_loss: 0.0000
[epoch  5][iter  580] loss: 163751.8125 RMSElog: 8.6875 grad_loss: 16366.4941 normal_loss: 0.0000
[epoch  5][iter  590] loss: 163368.6094 RMSElog: 8.8512 grad_loss: 16328.0098 normal_loss: 0.0000
[epoch  6][iter    0] loss: 148156.5312 RMSElog: 8.6798 grad_loss: 14806.9727 normal_loss: 0.0000
[epoch  6][iter   10] loss: 150270.8594 RMSElog: 8.6406 grad_loss: 15018.4453 normal_loss: 0.0000
[epoch  6][iter   20] loss: 177909.7656 RMSElog: 8.7782 grad_loss: 17782.1992 normal_loss: 0.0000
[epoch  6][iter   30] loss: 185472.2656 RMSElog: 8.9050 grad_loss: 18538.3223 normal_loss: 0.0000
[epoch  6][iter   40] loss: 121842.2734 RMSElog: 8.5501 grad_loss: 12175.6777 normal_loss: 0.0000
[epoch  6][iter   50] loss: 142569.7656 RMSElog: 8.6077 grad_loss: 14248.3691 normal_loss: 0.0000
[epoch  6][iter   60] loss: 165626.4219 RMSElog: 8.7967 grad_loss: 16553.8457 normal_loss: 0.0000
[epoch  6][iter   70] loss: 218597.9531 RMSElog: 8.8743 grad_loss: 21850.9199 normal_loss: 0.0000
[epoch  6][iter   80] loss: 167392.2812 RMSElog: 8.8440 grad_loss: 16730.3848 normal_loss: 0.0000
[epoch  6][iter   90] loss: 125658.9219 RMSElog: 8.6487 grad_loss: 12557.2441 normal_loss: 0.0000
[epoch  6][iter  100] loss: 206498.9844 RMSElog: 8.8139 grad_loss: 20641.0840 normal_loss: 0.0000
[epoch  6][iter  110] loss: 180635.7969 RMSElog: 8.9021 grad_loss: 18054.6777 normal_loss: 0.0000
[epoch  6][iter  120] loss: 142234.7500 RMSElog: 8.4177 grad_loss: 14215.0566 normal_loss: 0.0000
[epoch  6][iter  130] loss: 195749.6094 RMSElog: 8.8270 grad_loss: 19566.1348 normal_loss: 0.0000
[epoch  6][iter  140] loss: 180724.1875 RMSElog: 8.8798 grad_loss: 18063.5391 normal_loss: 0.0000
[epoch  6][iter  150] loss: 167930.6562 RMSElog: 8.6403 grad_loss: 16784.4258 normal_loss: 0.0000
[epoch  6][iter  160] loss: 241946.0938 RMSElog: 9.0438 grad_loss: 24185.5664 normal_loss: 0.0000
[epoch  6][iter  170] loss: 185748.1250 RMSElog: 8.8967 grad_loss: 18565.9160 normal_loss: 0.0000
[epoch  6][iter  180] loss: 163228.1094 RMSElog: 8.7382 grad_loss: 16314.0732 normal_loss: 0.0000
[epoch  6][iter  190] loss: 100952.6719 RMSElog: 8.1623 grad_loss: 10087.1055 normal_loss: 0.0000
[epoch  6][iter  200] loss: 203065.4531 RMSElog: 8.7327 grad_loss: 20297.8125 normal_loss: 0.0000
[epoch  6][iter  210] loss: 185119.7500 RMSElog: 8.9003 grad_loss: 18503.0742 normal_loss: 0.0000
[epoch  6][iter  220] loss: 141419.8125 RMSElog: 8.7000 grad_loss: 14133.2812 normal_loss: 0.0000
[epoch  6][iter  230] loss: 153698.4062 RMSElog: 8.8049 grad_loss: 15361.0361 normal_loss: 0.0000
[epoch  6][iter  240] loss: 208158.6250 RMSElog: 9.1467 grad_loss: 20806.7168 normal_loss: 0.0000
[epoch  6][iter  250] loss: 129181.8359 RMSElog: 8.8183 grad_loss: 12909.3652 normal_loss: 0.0000
[epoch  6][iter  260] loss: 163244.3906 RMSElog: 8.8901 grad_loss: 16315.5488 normal_loss: 0.0000
[epoch  6][iter  270] loss: 103786.2109 RMSElog: 8.1827 grad_loss: 10370.4385 normal_loss: 0.0000
[epoch  6][iter  280] loss: 121161.0859 RMSElog: 8.7453 grad_loss: 12107.3633 normal_loss: 0.0000
[epoch  6][iter  290] loss: 146757.8438 RMSElog: 8.7873 grad_loss: 14666.9971 normal_loss: 0.0000
[epoch  6][iter  300] loss: 176200.8594 RMSElog: 8.9970 grad_loss: 17611.0898 normal_loss: 0.0000
[epoch  6][iter  310] loss: 191666.6406 RMSElog: 8.9258 grad_loss: 19157.7383 normal_loss: 0.0000
[epoch  6][iter  320] loss: 217146.6875 RMSElog: 8.8780 grad_loss: 21705.7891 normal_loss: 0.0000
[epoch  6][iter  330] loss: 122887.8125 RMSElog: 8.6602 grad_loss: 12280.1211 normal_loss: 0.0000
[epoch  6][iter  340] loss: 104104.2109 RMSElog: 8.5581 grad_loss: 10401.8633 normal_loss: 0.0000
[epoch  6][iter  350] loss: 167771.0312 RMSElog: 8.8553 grad_loss: 16768.2480 normal_loss: 0.0000
[epoch  6][iter  360] loss: 130403.7891 RMSElog: 8.5275 grad_loss: 13031.8516 normal_loss: 0.0000
[epoch  6][iter  370] loss: 195387.9531 RMSElog: 8.9664 grad_loss: 19529.8281 normal_loss: 0.0000
[epoch  6][iter  380] loss: 112686.9375 RMSElog: 8.1347 grad_loss: 11260.5586 normal_loss: 0.0000
[epoch  6][iter  390] loss: 167716.7500 RMSElog: 8.8744 grad_loss: 16762.8008 normal_loss: 0.0000
[epoch  6][iter  400] loss: 104413.7578 RMSElog: 8.2783 grad_loss: 10433.0977 normal_loss: 0.0000
[epoch  6][iter  410] loss: 195973.3438 RMSElog: 8.9761 grad_loss: 19588.3574 normal_loss: 0.0000
[epoch  6][iter  420] loss: 115507.4688 RMSElog: 8.3553 grad_loss: 11542.3916 normal_loss: 0.0000
[epoch  6][iter  430] loss: 164820.6406 RMSElog: 8.7267 grad_loss: 16473.3379 normal_loss: 0.0000
[epoch  6][iter  440] loss: 120262.9297 RMSElog: 8.2454 grad_loss: 12018.0479 normal_loss: 0.0000
[epoch  6][iter  450] loss: 162497.2344 RMSElog: 8.8936 grad_loss: 16240.8301 normal_loss: 0.0000
[epoch  6][iter  460] loss: 150296.3906 RMSElog: 8.7259 grad_loss: 15020.9141 normal_loss: 0.0000
[epoch  6][iter  470] loss: 105676.2969 RMSElog: 8.0708 grad_loss: 10559.5586 normal_loss: 0.0000
[epoch  6][iter  480] loss: 165283.5312 RMSElog: 8.9011 grad_loss: 16519.4531 normal_loss: 0.0000
[epoch  6][iter  490] loss: 160002.9531 RMSElog: 8.8201 grad_loss: 15991.4756 normal_loss: 0.0000
[epoch  6][iter  500] loss: 120420.1641 RMSElog: 8.3792 grad_loss: 12033.6377 normal_loss: 0.0000
[epoch  6][iter  510] loss: 178055.2344 RMSElog: 8.9186 grad_loss: 17796.6055 normal_loss: 0.0000
[epoch  6][iter  520] loss: 128951.9219 RMSElog: 8.3060 grad_loss: 12886.8867 normal_loss: 0.0000
[epoch  6][iter  530] loss: 146920.5625 RMSElog: 8.5360 grad_loss: 14683.5195 normal_loss: 0.0000
[epoch  6][iter  540] loss: 135187.1250 RMSElog: 8.5496 grad_loss: 13510.1621 normal_loss: 0.0000
[epoch  6][iter  550] loss: 160719.8281 RMSElog: 8.7716 grad_loss: 16063.2109 normal_loss: 0.0000
[epoch  6][iter  560] loss: 165550.9531 RMSElog: 8.7975 grad_loss: 16546.2988 normal_loss: 0.0000
[epoch  6][iter  570] loss: 112667.5625 RMSElog: 8.1606 grad_loss: 11258.5957 normal_loss: 0.0000
[epoch  6][iter  580] loss: 116045.1953 RMSElog: 8.2507 grad_loss: 11596.2686 normal_loss: 0.0000
[epoch  6][iter  590] loss: 103283.5000 RMSElog: 8.5973 grad_loss: 10319.7520 normal_loss: 0.0000
[epoch  7][iter    0] loss: 105847.2266 RMSElog: 8.0634 grad_loss: 10576.6592 normal_loss: 0.0000
[epoch  7][iter   10] loss: 186932.2500 RMSElog: 8.8775 grad_loss: 18684.3477 normal_loss: 0.0000
[epoch  7][iter   20] loss: 135181.0469 RMSElog: 8.4643 grad_loss: 13509.6406 normal_loss: 0.0000
[epoch  7][iter   30] loss: 175975.0156 RMSElog: 9.1976 grad_loss: 17588.3047 normal_loss: 0.0000
[epoch  7][iter   40] loss: 140438.9844 RMSElog: 8.7921 grad_loss: 14035.1064 normal_loss: 0.0000
[epoch  7][iter   50] loss: 160443.5781 RMSElog: 8.8751 grad_loss: 16035.4824 normal_loss: 0.0000
[epoch  7][iter   60] loss: 106922.2188 RMSElog: 8.3062 grad_loss: 10683.9150 normal_loss: 0.0000
[epoch  7][iter   70] loss: 142234.7031 RMSElog: 8.4129 grad_loss: 14215.0576 normal_loss: 0.0000
[epoch  7][iter   80] loss: 140254.5625 RMSElog: 8.5562 grad_loss: 14016.9004 normal_loss: 0.0000
[epoch  7][iter   90] loss: 204623.3750 RMSElog: 8.9473 grad_loss: 20453.3906 normal_loss: 0.0000
[epoch  7][iter  100] loss: 167392.1250 RMSElog: 8.8259 grad_loss: 16730.3867 normal_loss: 0.0000
[epoch  7][iter  110] loss: 232745.3438 RMSElog: 9.0304 grad_loss: 23265.5039 normal_loss: 0.0000
[epoch  7][iter  120] loss: 151379.7188 RMSElog: 8.5071 grad_loss: 15129.4648 normal_loss: 0.0000
[epoch  7][iter  130] loss: 194379.8594 RMSElog: 8.7982 grad_loss: 19429.1875 normal_loss: 0.0000
[epoch  7][iter  140] loss: 149345.3125 RMSElog: 8.7619 grad_loss: 14925.7695 normal_loss: 0.0000
[epoch  7][iter  150] loss: 174605.8438 RMSElog: 8.8040 grad_loss: 17451.7793 normal_loss: 0.0000
[epoch  7][iter  160] loss: 216204.0938 RMSElog: 8.8497 grad_loss: 21611.5605 normal_loss: 0.0000
[epoch  7][iter  170] loss: 103929.2812 RMSElog: 8.3468 grad_loss: 10384.5811 normal_loss: 0.0000
[epoch  7][iter  180] loss: 177265.7500 RMSElog: 8.8743 grad_loss: 17717.6992 normal_loss: 0.0000
[epoch  7][iter  190] loss: 137301.3594 RMSElog: 8.5210 grad_loss: 13721.6152 normal_loss: 0.0000
[epoch  7][iter  200] loss: 162348.8438 RMSElog: 8.8114 grad_loss: 16226.0732 normal_loss: 0.0000
[epoch  7][iter  210] loss: 136038.5781 RMSElog: 8.3079 grad_loss: 13595.5508 normal_loss: 0.0000
[epoch  7][iter  220] loss: 135087.9219 RMSElog: 8.6197 grad_loss: 13500.1719 normal_loss: 0.0000
[epoch  7][iter  230] loss: 163674.4688 RMSElog: 8.8113 grad_loss: 16358.6348 normal_loss: 0.0000
[epoch  7][iter  240] loss: 160761.2188 RMSElog: 8.8279 grad_loss: 16067.2939 normal_loss: 0.0000
[epoch  7][iter  250] loss: 106152.5312 RMSElog: 8.1217 grad_loss: 10607.1309 normal_loss: 0.0000
[epoch  7][iter  260] loss: 144633.4688 RMSElog: 8.7948 grad_loss: 14454.5518 normal_loss: 0.0000
[epoch  7][iter  270] loss: 119898.9688 RMSElog: 8.5135 grad_loss: 11981.3828 normal_loss: 0.0000
[epoch  7][iter  280] loss: 165302.8906 RMSElog: 8.8649 grad_loss: 16521.4238 normal_loss: 0.0000
[epoch  7][iter  290] loss: 180295.3281 RMSElog: 8.8723 grad_loss: 18020.6602 normal_loss: 0.0000
[epoch  7][iter  300] loss: 115634.0234 RMSElog: 8.5879 grad_loss: 11554.8145 normal_loss: 0.0000
[epoch  7][iter  310] loss: 155886.2656 RMSElog: 8.6481 grad_loss: 15579.9785 normal_loss: 0.0000
[epoch  7][iter  320] loss: 126847.8438 RMSElog: 8.4963 grad_loss: 12676.2881 normal_loss: 0.0000
[epoch  7][iter  330] loss: 117379.5781 RMSElog: 8.4074 grad_loss: 11729.5508 normal_loss: 0.0000
[epoch  7][iter  340] loss: 167707.9688 RMSElog: 8.9835 grad_loss: 16761.8125 normal_loss: 0.0000
[epoch  7][iter  350] loss: 151697.6406 RMSElog: 8.7429 grad_loss: 15161.0215 normal_loss: 0.0000
[epoch  7][iter  360] loss: 176774.2344 RMSElog: 8.7693 grad_loss: 17668.6543 normal_loss: 0.0000
[epoch  7][iter  370] loss: 185877.9688 RMSElog: 8.8260 grad_loss: 18578.9707 normal_loss: 0.0000
[epoch  7][iter  380] loss: 159774.8594 RMSElog: 8.6991 grad_loss: 15968.7871 normal_loss: 0.0000
[epoch  7][iter  390] loss: 122903.0859 RMSElog: 8.5754 grad_loss: 12281.7334 normal_loss: 0.0000
[epoch  7][iter  400] loss: 203947.2500 RMSElog: 9.1548 grad_loss: 20385.5703 normal_loss: 0.0000
[epoch  7][iter  410] loss: 120262.8438 RMSElog: 8.2430 grad_loss: 12018.0410 normal_loss: 0.0000
[epoch  7][iter  420] loss: 103506.1406 RMSElog: 8.2433 grad_loss: 10342.3711 normal_loss: 0.0000
[epoch  7][iter  430] loss: 181983.2656 RMSElog: 9.0777 grad_loss: 18189.2480 normal_loss: 0.0000
[epoch  7][iter  440] loss: 110572.4297 RMSElog: 8.1015 grad_loss: 11049.1416 normal_loss: 0.0000
[epoch  7][iter  450] loss: 110204.4531 RMSElog: 8.0530 grad_loss: 11012.3926 normal_loss: 0.0000
[epoch  7][iter  460] loss: 232955.0625 RMSElog: 8.9595 grad_loss: 23286.5469 normal_loss: 0.0000
[epoch  7][iter  470] loss: 191180.1406 RMSElog: 8.8343 grad_loss: 19109.1797 normal_loss: 0.0000
[epoch  7][iter  480] loss: 208795.1406 RMSElog: 8.8386 grad_loss: 20870.6758 normal_loss: 0.0000
[epoch  7][iter  490] loss: 231948.7812 RMSElog: 9.0600 grad_loss: 23185.8184 normal_loss: 0.0000
[epoch  7][iter  500] loss: 138993.8438 RMSElog: 8.6402 grad_loss: 13890.7441 normal_loss: 0.0000
[epoch  7][iter  510] loss: 143435.8594 RMSElog: 8.6401 grad_loss: 14334.9463 normal_loss: 0.0000
[epoch  7][iter  520] loss: 183066.5000 RMSElog: 8.5975 grad_loss: 18298.0527 normal_loss: 0.0000
[epoch  7][iter  530] loss: 152493.8281 RMSElog: 8.7277 grad_loss: 15240.6553 normal_loss: 0.0000
[epoch  7][iter  540] loss: 163243.3281 RMSElog: 8.8267 grad_loss: 16315.5059 normal_loss: 0.0000
[epoch  7][iter  550] loss: 208157.9062 RMSElog: 9.1016 grad_loss: 20806.6895 normal_loss: 0.0000
[epoch  7][iter  560] loss: 205334.5000 RMSElog: 8.7901 grad_loss: 20524.6582 normal_loss: 0.0000
[epoch  7][iter  570] loss: 100619.4844 RMSElog: 8.0502 grad_loss: 10053.8984 normal_loss: 0.0000
[epoch  7][iter  580] loss: 155738.6875 RMSElog: 8.7627 grad_loss: 15565.1055 normal_loss: 0.0000
[epoch  7][iter  590] loss: 160049.6875 RMSElog: 8.6418 grad_loss: 15996.3271 normal_loss: 0.0000
[epoch  8][iter    0] loss: 137237.4844 RMSElog: 8.9370 grad_loss: 13714.0439 normal_loss: 0.7664
[epoch  8][iter   10] loss: 141426.4219 RMSElog: 8.6854 grad_loss: 14133.2539 normal_loss: 0.7029
[epoch  8][iter   20] loss: 149525.2656 RMSElog: 8.8471 grad_loss: 14942.9746 normal_loss: 0.7048
[epoch  8][iter   30] loss: 124229.8281 RMSElog: 8.6393 grad_loss: 12413.6465 normal_loss: 0.6965
[epoch  8][iter   40] loss: 133268.3750 RMSElog: 8.6790 grad_loss: 13317.4883 normal_loss: 0.6714
[epoch  8][iter   50] loss: 179618.3594 RMSElog: 9.0432 grad_loss: 17952.0605 normal_loss: 0.7328
[epoch  8][iter   60] loss: 112517.9766 RMSElog: 8.4950 grad_loss: 11242.6230 normal_loss: 0.6798
[epoch  8][iter   70] loss: 102075.5547 RMSElog: 8.3620 grad_loss: 10198.5195 normal_loss: 0.6738
[epoch  8][iter   80] loss: 163758.6250 RMSElog: 8.6809 grad_loss: 16366.4590 normal_loss: 0.7223
[epoch  8][iter   90] loss: 106159.3672 RMSElog: 8.1296 grad_loss: 10607.1348 normal_loss: 0.6719
[epoch  8][iter  100] loss: 221193.6094 RMSElog: 8.9005 grad_loss: 22109.7871 normal_loss: 0.6748
[epoch  8][iter  110] loss: 233376.7812 RMSElog: 9.0101 grad_loss: 23327.9844 normal_loss: 0.6844
[epoch  8][iter  120] loss: 177916.4062 RMSElog: 8.7851 grad_loss: 17782.1758 normal_loss: 0.6800
[epoch  8][iter  130] loss: 210500.8125 RMSElog: 8.9575 grad_loss: 21040.4668 normal_loss: 0.6579
[epoch  8][iter  140] loss: 120571.0938 RMSElog: 8.6476 grad_loss: 12047.7656 normal_loss: 0.6960
[epoch  8][iter  150] loss: 152529.3281 RMSElog: 8.7436 grad_loss: 15243.5293 normal_loss: 0.6598
[epoch  8][iter  160] loss: 182171.3438 RMSElog: 8.9769 grad_loss: 18207.4336 normal_loss: 0.7239
[epoch  8][iter  170] loss: 200934.0938 RMSElog: 8.8719 grad_loss: 20083.8379 normal_loss: 0.7016
[epoch  8][iter  180] loss: 156980.8438 RMSElog: 9.2400 grad_loss: 15687.9678 normal_loss: 0.8760
[epoch  8][iter  190] loss: 183073.5312 RMSElog: 8.6090 grad_loss: 18298.0449 normal_loss: 0.6986
[epoch  8][iter  200] loss: 143594.9688 RMSElog: 8.5920 grad_loss: 14350.1963 normal_loss: 0.7078
[epoch  8][iter  210] loss: 104725.8281 RMSElog: 8.1230 grad_loss: 10463.7969 normal_loss: 0.6630
[epoch  8][iter  220] loss: 154839.8125 RMSElog: 8.8230 grad_loss: 15474.4453 normal_loss: 0.7131
[epoch  8][iter  230] loss: 111901.5938 RMSElog: 8.4750 grad_loss: 11180.9629 normal_loss: 0.7217
[epoch  8][iter  240] loss: 127483.3750 RMSElog: 8.3110 grad_loss: 12739.3311 normal_loss: 0.6958
[epoch  8][iter  250] loss: 151351.0469 RMSElog: 8.6390 grad_loss: 15125.7539 normal_loss: 0.7118
[epoch  8][iter  260] loss: 144569.5156 RMSElog: 8.1271 grad_loss: 14448.0869 normal_loss: 0.7372
[epoch  8][iter  270] loss: 134796.7656 RMSElog: 8.3729 grad_loss: 13470.6016 normal_loss: 0.7025
[epoch  8][iter  280] loss: 150278.0938 RMSElog: 8.6764 grad_loss: 15018.4668 normal_loss: 0.6652
[epoch  8][iter  290] loss: 111645.7500 RMSElog: 8.6222 grad_loss: 11155.2051 normal_loss: 0.7479
[epoch  8][iter  300] loss: 154687.6562 RMSElog: 8.8183 grad_loss: 15459.2627 normal_loss: 0.6841
[epoch  8][iter  310] loss: 150588.5625 RMSElog: 8.7873 grad_loss: 15049.3984 normal_loss: 0.6707
[epoch  8][iter  320] loss: 163575.2656 RMSElog: 8.7584 grad_loss: 16348.0938 normal_loss: 0.6739
[epoch  8][iter  330] loss: 113185.7109 RMSElog: 8.5776 grad_loss: 11309.2656 normal_loss: 0.7281
[epoch  8][iter  340] loss: 188998.6875 RMSElog: 8.9084 grad_loss: 18890.2500 normal_loss: 0.7113
[epoch  8][iter  350] loss: 166191.0625 RMSElog: 8.8434 grad_loss: 16609.5664 normal_loss: 0.6962
[epoch  8][iter  360] loss: 140261.3750 RMSElog: 8.5796 grad_loss: 14016.8945 normal_loss: 0.6619
[epoch  8][iter  370] loss: 217154.0625 RMSElog: 8.9308 grad_loss: 21705.7988 normal_loss: 0.6764
[epoch  8][iter  380] loss: 195394.5312 RMSElog: 8.9682 grad_loss: 19529.8105 normal_loss: 0.6733
[epoch  8][iter  390] loss: 160864.1875 RMSElog: 8.8916 grad_loss: 16076.8359 normal_loss: 0.6914
[epoch  8][iter  400] loss: 137244.5312 RMSElog: 8.9035 grad_loss: 13714.7812 normal_loss: 0.7687
[epoch  8][iter  410] loss: 135679.9688 RMSElog: 8.3786 grad_loss: 13558.9121 normal_loss: 0.7061
[epoch  8][iter  420] loss: 226930.6250 RMSElog: 9.0039 grad_loss: 22683.3867 normal_loss: 0.6726
[epoch  8][iter  430] loss: 175340.6406 RMSElog: 8.9638 grad_loss: 17524.3926 normal_loss: 0.7090
[epoch  8][iter  440] loss: 135797.3125 RMSElog: 8.4433 grad_loss: 13570.5947 normal_loss: 0.6933
[epoch  8][iter  450] loss: 184355.6250 RMSElog: 9.0550 grad_loss: 18425.8008 normal_loss: 0.7076
[epoch  8][iter  460] loss: 164163.5312 RMSElog: 8.8672 grad_loss: 16406.8027 normal_loss: 0.6845
[epoch  8][iter  470] loss: 163769.2812 RMSElog: 8.7598 grad_loss: 16367.4912 normal_loss: 0.6765
[epoch  8][iter  480] loss: 121894.7188 RMSElog: 8.3266 grad_loss: 12180.4678 normal_loss: 0.6777
[epoch  8][iter  490] loss: 207666.8594 RMSElog: 8.8902 grad_loss: 20757.0801 normal_loss: 0.7142
[epoch  8][iter  500] loss: 122894.6406 RMSElog: 8.6629 grad_loss: 12280.1113 normal_loss: 0.6892
[epoch  8][iter  510] loss: 142677.6562 RMSElog: 8.7019 grad_loss: 14258.3730 normal_loss: 0.6905
[epoch  8][iter  520] loss: 166475.6406 RMSElog: 8.8092 grad_loss: 16638.0547 normal_loss: 0.7011
[epoch  8][iter  530] loss: 167938.0312 RMSElog: 8.6540 grad_loss: 16784.4375 normal_loss: 0.7115
[epoch  8][iter  540] loss: 197695.0781 RMSElog: 9.1346 grad_loss: 19759.6953 normal_loss: 0.6774
[epoch  8][iter  550] loss: 154146.2812 RMSElog: 8.8741 grad_loss: 15405.0859 normal_loss: 0.6688
[epoch  8][iter  560] loss: 129689.3828 RMSElog: 8.4880 grad_loss: 12959.7666 normal_loss: 0.6839
[epoch  8][iter  570] loss: 165557.8281 RMSElog: 8.8043 grad_loss: 16546.2852 normal_loss: 0.6930
[epoch  8][iter  580] loss: 159269.0469 RMSElog: 8.6377 grad_loss: 15917.5342 normal_loss: 0.7331
[epoch  8][iter  590] loss: 175282.7969 RMSElog: 8.6264 grad_loss: 17518.9492 normal_loss: 0.7030
[epoch  9][iter    0] loss: 216489.6875 RMSElog: 8.9471 grad_loss: 21639.3555 normal_loss: 0.6656
[epoch  9][iter   10] loss: 142241.7500 RMSElog: 8.4143 grad_loss: 14215.0439 normal_loss: 0.7175
[epoch  9][iter   20] loss: 114364.0156 RMSElog: 8.6011 grad_loss: 11427.0596 normal_loss: 0.7398
[epoch  9][iter   30] loss: 158015.4375 RMSElog: 8.8053 grad_loss: 15792.0645 normal_loss: 0.6739
[epoch  9][iter   40] loss: 133026.9062 RMSElog: 8.6762 grad_loss: 13293.3506 normal_loss: 0.6641
[epoch  9][iter   50] loss: 179885.1719 RMSElog: 8.8213 grad_loss: 17978.9824 normal_loss: 0.7132
[epoch  9][iter   60] loss: 173703.3125 RMSElog: 8.9044 grad_loss: 17360.7188 normal_loss: 0.7081
[epoch  9][iter   70] loss: 121968.6875 RMSElog: 8.4452 grad_loss: 12187.6836 normal_loss: 0.7407
[epoch  9][iter   80] loss: 175340.5938 RMSElog: 8.9611 grad_loss: 17524.3887 normal_loss: 0.7080
[epoch  9][iter   90] loss: 151335.7969 RMSElog: 8.7306 grad_loss: 15124.1846 normal_loss: 0.6644
[epoch  9][iter  100] loss: 149114.2812 RMSElog: 8.7864 grad_loss: 14901.9668 normal_loss: 0.6746
[epoch  9][iter  110] loss: 130624.5469 RMSElog: 8.7171 grad_loss: 13053.0605 normal_loss: 0.6782
[epoch  9][iter  120] loss: 181990.7969 RMSElog: 9.0970 grad_loss: 18189.2480 normal_loss: 0.7343
[epoch  9][iter  130] loss: 185051.9375 RMSElog: 8.7503 grad_loss: 18495.7344 normal_loss: 0.7083
[epoch  9][iter  140] loss: 103290.2969 RMSElog: 8.6054 grad_loss: 10319.7354 normal_loss: 0.6888
[epoch  9][iter  150] loss: 104067.0000 RMSElog: 8.5041 grad_loss: 10397.5234 normal_loss: 0.6731
[epoch  9][iter  160] loss: 214470.7031 RMSElog: 8.8989 grad_loss: 21437.5098 normal_loss: 0.6626
[epoch  9][iter  170] loss: 183854.7031 RMSElog: 9.0401 grad_loss: 18375.7129 normal_loss: 0.7167
[epoch  9][iter  180] loss: 128541.8125 RMSElog: 8.6426 grad_loss: 12844.8291 normal_loss: 0.7103
[epoch  9][iter  190] loss: 165957.2812 RMSElog: 8.7612 grad_loss: 16586.3105 normal_loss: 0.6557
[epoch  9][iter  200] loss: 154538.5938 RMSElog: 8.8730 grad_loss: 15444.2949 normal_loss: 0.6912
[epoch  9][iter  210] loss: 147525.3281 RMSElog: 8.7259 grad_loss: 14743.1396 normal_loss: 0.6679
[epoch  9][iter  220] loss: 130726.2344 RMSElog: 8.7388 grad_loss: 13063.1436 normal_loss: 0.7406
[epoch  9][iter  230] loss: 100729.6953 RMSElog: 8.6486 grad_loss: 10063.6484 normal_loss: 0.6729
[epoch  9][iter  240] loss: 162356.6719 RMSElog: 8.8812 grad_loss: 16226.0781 normal_loss: 0.7083
[epoch  9][iter  250] loss: 167715.1562 RMSElog: 9.0175 grad_loss: 16761.8066 normal_loss: 0.6923
[epoch  9][iter  260] loss: 218748.3750 RMSElog: 9.4059 grad_loss: 21864.5332 normal_loss: 0.8988
[epoch  9][iter  270] loss: 156963.6719 RMSElog: 8.8679 grad_loss: 15686.8398 normal_loss: 0.6589
[epoch  9][iter  280] loss: 158908.9219 RMSElog: 8.8194 grad_loss: 15881.3652 normal_loss: 0.7080
[epoch  9][iter  290] loss: 137745.5625 RMSElog: 8.6289 grad_loss: 13765.2656 normal_loss: 0.6610
[epoch  9][iter  300] loss: 194556.0781 RMSElog: 8.7755 grad_loss: 19446.1758 normal_loss: 0.6571
[epoch  9][iter  310] loss: 179617.6562 RMSElog: 9.0079 grad_loss: 17952.0371 normal_loss: 0.7209
[epoch  9][iter  320] loss: 175277.9531 RMSElog: 8.8023 grad_loss: 17518.3242 normal_loss: 0.6688
[epoch  9][iter  330] loss: 202097.1094 RMSElog: 8.7504 grad_loss: 20200.3047 normal_loss: 0.6567
[epoch  9][iter  340] loss: 139078.9531 RMSElog: 8.6454 grad_loss: 13898.5752 normal_loss: 0.6749
[epoch  9][iter  350] loss: 163681.9062 RMSElog: 8.8044 grad_loss: 16358.6328 normal_loss: 0.7533
[epoch  9][iter  360] loss: 140918.7656 RMSElog: 8.4501 grad_loss: 14082.7500 normal_loss: 0.6762
[epoch  9][iter  370] loss: 142119.4375 RMSElog: 8.5252 grad_loss: 14202.7129 normal_loss: 0.7051
[epoch  9][iter  380] loss: 139415.9688 RMSElog: 8.6795 grad_loss: 13932.2451 normal_loss: 0.6726
[epoch  9][iter  390] loss: 161615.4844 RMSElog: 8.9556 grad_loss: 16151.9199 normal_loss: 0.6724
[epoch  9][iter  400] loss: 121943.0625 RMSElog: 8.7085 grad_loss: 12184.9229 normal_loss: 0.6758
[epoch  9][iter  410] loss: 164750.5625 RMSElog: 8.8329 grad_loss: 16465.5098 normal_loss: 0.7157
[epoch  9][iter  420] loss: 103791.9922 RMSElog: 8.1168 grad_loss: 10370.4189 normal_loss: 0.6629
[epoch  9][iter  430] loss: 149352.1406 RMSElog: 8.7327 grad_loss: 14925.7383 normal_loss: 0.7431
[epoch  9][iter  440] loss: 175528.8125 RMSElog: 8.8350 grad_loss: 17543.3555 normal_loss: 0.6888
[epoch  9][iter  450] loss: 105872.3906 RMSElog: 8.0585 grad_loss: 10578.5254 normal_loss: 0.6552
[epoch  9][iter  460] loss: 160449.4688 RMSElog: 8.8380 grad_loss: 16035.4248 normal_loss: 0.6844
[epoch  9][iter  470] loss: 135193.5625 RMSElog: 8.5662 grad_loss: 13510.1289 normal_loss: 0.6600
[epoch  9][iter  480] loss: 147463.7344 RMSElog: 8.7594 grad_loss: 14736.9082 normal_loss: 0.7050
[epoch  9][iter  490] loss: 167327.3594 RMSElog: 8.7853 grad_loss: 16723.2461 normal_loss: 0.7046
[epoch  9][iter  500] loss: 105770.7344 RMSElog: 8.0945 grad_loss: 10568.3311 normal_loss: 0.6478
[epoch  9][iter  510] loss: 101431.5234 RMSElog: 8.6345 grad_loss: 10133.8389 normal_loss: 0.6791
[epoch  9][iter  520] loss: 128258.1406 RMSElog: 8.5159 grad_loss: 12816.6406 normal_loss: 0.6586
[epoch  9][iter  530] loss: 160420.5156 RMSElog: 8.9233 grad_loss: 16032.4648 normal_loss: 0.6643
[epoch  9][iter  540] loss: 129148.9062 RMSElog: 8.8850 grad_loss: 12905.3135 normal_loss: 0.6921
[epoch  9][iter  550] loss: 139000.4219 RMSElog: 8.6358 grad_loss: 13890.7246 normal_loss: 0.6820
[epoch  9][iter  560] loss: 144174.3438 RMSElog: 8.5951 grad_loss: 14408.1592 normal_loss: 0.6799
[epoch  9][iter  570] loss: 167067.9531 RMSElog: 8.8487 grad_loss: 16697.2441 normal_loss: 0.7014
[epoch  9][iter  580] loss: 149111.3906 RMSElog: 8.6636 grad_loss: 14901.7578 normal_loss: 0.7175
[epoch  9][iter  590] loss: 134614.7500 RMSElog: 8.7139 grad_loss: 13452.0742 normal_loss: 0.6870
[epoch 10][iter    0] loss: 148118.5781 RMSElog: 8.7601 grad_loss: 14802.3965 normal_loss: 0.7016
[epoch 10][iter   10] loss: 153947.7656 RMSElog: 8.9784 grad_loss: 15385.0410 normal_loss: 0.7571
[epoch 10][iter   20] loss: 72273.5781 RMSElog: 8.4832 grad_loss: 7218.2002 normal_loss: 0.6741
[epoch 10][iter   30] loss: 178062.2812 RMSElog: 8.8992 grad_loss: 17796.5977 normal_loss: 0.7330
[epoch 10][iter   40] loss: 195756.7812 RMSElog: 8.8725 grad_loss: 19566.1289 normal_loss: 0.6759
[epoch 10][iter   50] loss: 151335.5938 RMSElog: 8.7241 grad_loss: 15124.1748 normal_loss: 0.6602
[epoch 10][iter   60] loss: 188623.1094 RMSElog: 8.7450 grad_loss: 18852.8789 normal_loss: 0.6866
[epoch 10][iter   70] loss: 128258.0469 RMSElog: 8.5073 grad_loss: 12816.6396 normal_loss: 0.6578
[epoch 10][iter   80] loss: 155745.6875 RMSElog: 8.7743 grad_loss: 15565.0879 normal_loss: 0.7070
[epoch 10][iter   90] loss: 150277.7969 RMSElog: 8.6835 grad_loss: 15018.4463 normal_loss: 0.6508
[epoch 10][iter  100] loss: 154271.0469 RMSElog: 8.6669 grad_loss: 15417.7793 normal_loss: 0.6587
[epoch 10][iter  110] loss: 109236.9375 RMSElog: 8.1015 grad_loss: 10914.9199 normal_loss: 0.6718
[epoch 10][iter  120] loss: 161068.5625 RMSElog: 8.6721 grad_loss: 16097.5156 normal_loss: 0.6678
[epoch 10][iter  130] loss: 141149.6875 RMSElog: 8.3799 grad_loss: 14105.8867 normal_loss: 0.7020
[epoch 10][iter  140] loss: 160918.3125 RMSElog: 8.8353 grad_loss: 16082.2842 normal_loss: 0.7125
[epoch 10][iter  150] loss: 182296.1875 RMSElog: 8.9466 grad_loss: 18220.0176 normal_loss: 0.6538
[epoch 10][iter  160] loss: 107924.1719 RMSElog: 8.0621 grad_loss: 10783.6895 normal_loss: 0.6651
[epoch 10][iter  170] loss: 195421.8594 RMSElog: 8.5884 grad_loss: 19532.9062 normal_loss: 0.6920
[epoch 10][iter  180] loss: 165992.3750 RMSElog: 8.8766 grad_loss: 16589.6992 normal_loss: 0.6612
[epoch 10][iter  190] loss: 171571.5312 RMSElog: 8.6884 grad_loss: 17147.7402 normal_loss: 0.7244
[epoch 10][iter  200] loss: 114296.7266 RMSElog: 8.4887 grad_loss: 11420.4600 normal_loss: 0.7245
[epoch 10][iter  210] loss: 175983.4062 RMSElog: 9.1607 grad_loss: 17588.3008 normal_loss: 0.8780
[epoch 10][iter  220] loss: 145598.1406 RMSElog: 8.8238 grad_loss: 14550.3174 normal_loss: 0.6731
[epoch 10][iter  230] loss: 177273.3750 RMSElog: 8.9045 grad_loss: 17717.7168 normal_loss: 0.7177
[epoch 10][iter  240] loss: 201354.6094 RMSElog: 9.1313 grad_loss: 20125.6426 normal_loss: 0.6884
[epoch 10][iter  250] loss: 118724.8125 RMSElog: 8.3076 grad_loss: 11863.5010 normal_loss: 0.6727
[epoch 10][iter  260] loss: 135680.3750 RMSElog: 8.4131 grad_loss: 13558.9268 normal_loss: 0.6971
[epoch 10][iter  270] loss: 107933.4531 RMSElog: 8.4108 grad_loss: 10784.2578 normal_loss: 0.6772
[epoch 10][iter  280] loss: 170340.7500 RMSElog: 8.9683 grad_loss: 17024.4219 normal_loss: 0.6830
[epoch 10][iter  290] loss: 158614.2500 RMSElog: 8.8240 grad_loss: 15851.9062 normal_loss: 0.6943
[epoch 10][iter  300] loss: 152529.1406 RMSElog: 8.7363 grad_loss: 15243.5234 normal_loss: 0.6542
[epoch 10][iter  310] loss: 186938.7656 RMSElog: 8.8827 grad_loss: 18684.3301 normal_loss: 0.6647
[epoch 10][iter  320] loss: 195979.5156 RMSElog: 8.9605 grad_loss: 19588.3242 normal_loss: 0.6663
[epoch 10][iter  330] loss: 155463.7656 RMSElog: 8.9342 grad_loss: 15536.7822 normal_loss: 0.6602
[epoch 10][iter  340] loss: 180188.1562 RMSElog: 8.7507 grad_loss: 18009.3809 normal_loss: 0.6857
[epoch 10][iter  350] loss: 101203.1094 RMSElog: 8.6335 grad_loss: 10110.9727 normal_loss: 0.7040
[epoch 10][iter  360] loss: 114363.9453 RMSElog: 8.6002 grad_loss: 11427.0596 normal_loss: 0.7342
[epoch 10][iter  370] loss: 119451.4375 RMSElog: 8.3723 grad_loss: 11936.0938 normal_loss: 0.6776
[epoch 10][iter  380] loss: 123515.3047 RMSElog: 8.7140 grad_loss: 12342.0488 normal_loss: 0.7673
[epoch 10][iter  390] loss: 117051.7109 RMSElog: 8.6487 grad_loss: 11695.7861 normal_loss: 0.7366
[epoch 10][iter  400] loss: 100958.8281 RMSElog: 8.1534 grad_loss: 10087.0771 normal_loss: 0.6523
[epoch 10][iter  410] loss: 196255.0312 RMSElog: 8.7665 grad_loss: 19616.0781 normal_loss: 0.6604
[epoch 10][iter  420] loss: 196900.1406 RMSElog: 8.9905 grad_loss: 19680.3555 normal_loss: 0.6676
[epoch 10][iter  430] loss: 176938.1406 RMSElog: 9.0282 grad_loss: 17684.0781 normal_loss: 0.7083
[epoch 10][iter  440] loss: 191952.5781 RMSElog: 8.8666 grad_loss: 19185.6895 normal_loss: 0.7007
[epoch 10][iter  450] loss: 179617.5938 RMSElog: 9.0094 grad_loss: 17952.0352 normal_loss: 0.7152
[epoch 10][iter  460] loss: 202609.6875 RMSElog: 8.7520 grad_loss: 20251.5469 normal_loss: 0.6704
[epoch 10][iter  470] loss: 134614.6562 RMSElog: 8.7165 grad_loss: 13452.0693 normal_loss: 0.6791
[epoch 10][iter  480] loss: 130507.5000 RMSElog: 8.6125 grad_loss: 13041.4795 normal_loss: 0.6587
[epoch 10][iter  490] loss: 175507.4062 RMSElog: 9.0946 grad_loss: 17540.9160 normal_loss: 0.7302
[epoch 10][iter  500] loss: 181990.7188 RMSElog: 9.0920 grad_loss: 18189.2480 normal_loss: 0.7334
[epoch 10][iter  510] loss: 156550.3750 RMSElog: 9.1585 grad_loss: 15645.0088 normal_loss: 0.8704
[epoch 10][iter  520] loss: 216489.5000 RMSElog: 8.9458 grad_loss: 21639.3457 normal_loss: 0.6592
[epoch 10][iter  530] loss: 177920.3125 RMSElog: 9.0191 grad_loss: 17782.2871 normal_loss: 0.7255
[epoch 10][iter  540] loss: 208164.5625 RMSElog: 9.1110 grad_loss: 20806.6641 normal_loss: 0.6819
[epoch 10][iter  550] loss: 107458.0938 RMSElog: 8.2226 grad_loss: 10736.9004 normal_loss: 0.6865
[epoch 10][iter  560] loss: 164827.3438 RMSElog: 8.7345 grad_loss: 16473.3086 normal_loss: 0.6906
[epoch 10][iter  570] loss: 149352.0938 RMSElog: 8.7265 grad_loss: 14925.7383 normal_loss: 0.7447
[epoch 10][iter  580] loss: 168528.5156 RMSElog: 8.6710 grad_loss: 16843.4941 normal_loss: 0.6863
[epoch 10][iter  590] loss: 127756.1875 RMSElog: 8.6521 grad_loss: 12766.2832 normal_loss: 0.6835
[epoch 11][iter    0] loss: 140447.1719 RMSElog: 8.7914 grad_loss: 14035.0957 normal_loss: 0.8313
[epoch 11][iter   10] loss: 214787.5156 RMSElog: 8.8500 grad_loss: 21469.2422 normal_loss: 0.6598
[epoch 11][iter   20] loss: 154761.1875 RMSElog: 8.8007 grad_loss: 15466.5801 normal_loss: 0.7375
[epoch 11][iter   30] loss: 188623.9375 RMSElog: 8.7905 grad_loss: 18852.9121 normal_loss: 0.6915
[epoch 11][iter   40] loss: 114297.0391 RMSElog: 8.5075 grad_loss: 11420.4736 normal_loss: 0.7230
[epoch 11][iter   50] loss: 177273.2500 RMSElog: 8.9028 grad_loss: 17717.7090 normal_loss: 0.7128
[epoch 11][iter   60] loss: 126854.2344 RMSElog: 8.5060 grad_loss: 12676.2646 normal_loss: 0.6535
[epoch 11][iter   70] loss: 129689.2109 RMSElog: 8.4865 grad_loss: 12959.7598 normal_loss: 0.6750
[epoch 11][iter   80] loss: 105877.4844 RMSElog: 8.4274 grad_loss: 10578.6387 normal_loss: 0.6813
[epoch 11][iter   90] loss: 194971.8750 RMSElog: 8.8553 grad_loss: 19487.6055 normal_loss: 0.7275
[epoch 11][iter  100] loss: 189521.9375 RMSElog: 8.7803 grad_loss: 18942.7402 normal_loss: 0.6711
[epoch 11][iter  110] loss: 147893.5625 RMSElog: 8.6234 grad_loss: 14780.0762 normal_loss: 0.6558
[epoch 11][iter  120] loss: 124615.2266 RMSElog: 8.5117 grad_loss: 12452.3340 normal_loss: 0.6764
[epoch 11][iter  130] loss: 100967.2344 RMSElog: 8.1292 grad_loss: 10087.9336 normal_loss: 0.6611
[epoch 11][iter  140] loss: 218748.2188 RMSElog: 9.3981 grad_loss: 21864.5293 normal_loss: 0.8937
[epoch 11][iter  150] loss: 175983.2812 RMSElog: 9.1527 grad_loss: 17588.2988 normal_loss: 0.8768
[epoch 11][iter  160] loss: 183994.9688 RMSElog: 8.5748 grad_loss: 18390.2266 normal_loss: 0.6949
[epoch 11][iter  170] loss: 141845.8750 RMSElog: 8.4132 grad_loss: 14175.4688 normal_loss: 0.7057
[epoch 11][iter  180] loss: 127482.7734 RMSElog: 8.2801 grad_loss: 12739.3076 normal_loss: 0.6897
[epoch 11][iter  190] loss: 121816.4062 RMSElog: 8.2788 grad_loss: 12172.6875 normal_loss: 0.6750
[epoch 11][iter  200] loss: 151703.8594 RMSElog: 8.7519 grad_loss: 15160.9863 normal_loss: 0.6472
[epoch 11][iter  210] loss: 176207.9062 RMSElog: 8.9985 grad_loss: 17611.0820 normal_loss: 0.7100
[epoch 11][iter  220] loss: 121968.9531 RMSElog: 8.4710 grad_loss: 12187.6904 normal_loss: 0.7339
[epoch 11][iter  230] loss: 147354.4844 RMSElog: 8.6036 grad_loss: 14726.1465 normal_loss: 0.6987
[epoch 11][iter  240] loss: 208165.2344 RMSElog: 9.1494 grad_loss: 20806.6895 normal_loss: 0.6856
[epoch 11][iter  250] loss: 203541.8438 RMSElog: 8.8069 grad_loss: 20344.7090 normal_loss: 0.6675
[epoch 11][iter  260] loss: 227304.1562 RMSElog: 9.1563 grad_loss: 22720.5977 normal_loss: 0.6622
[epoch 11][iter  270] loss: 107933.2031 RMSElog: 8.4019 grad_loss: 10784.2441 normal_loss: 0.6734
[epoch 11][iter  280] loss: 157793.2188 RMSElog: 8.7655 grad_loss: 15769.8428 normal_loss: 0.7130
[epoch 11][iter  290] loss: 107458.0156 RMSElog: 8.2176 grad_loss: 10736.8965 normal_loss: 0.6876
[epoch 11][iter  300] loss: 175282.5312 RMSElog: 8.6277 grad_loss: 17518.9375 normal_loss: 0.6889
[epoch 11][iter  310] loss: 167442.0625 RMSElog: 8.8054 grad_loss: 16734.6641 normal_loss: 0.7377
[epoch 11][iter  320] loss: 173145.9219 RMSElog: 8.6114 grad_loss: 17305.2793 normal_loss: 0.7003
[epoch 11][iter  330] loss: 121893.6562 RMSElog: 8.2697 grad_loss: 12180.4277 normal_loss: 0.6676
[epoch 11][iter  340] loss: 110566.8750 RMSElog: 8.6095 grad_loss: 11047.3691 normal_loss: 0.7093
[epoch 11][iter  350] loss: 195421.8125 RMSElog: 8.5835 grad_loss: 19532.9043 normal_loss: 0.6937
[epoch 11][iter  360] loss: 129143.3672 RMSElog: 8.6691 grad_loss: 12904.9707 normal_loss: 0.6970
[epoch 11][iter  370] loss: 147190.2188 RMSElog: 8.8451 grad_loss: 14709.5098 normal_loss: 0.6683
[epoch 11][iter  380] loss: 154839.4062 RMSElog: 8.8134 grad_loss: 15474.4297 normal_loss: 0.6981
[epoch 11][iter  390] loss: 135951.5469 RMSElog: 8.7270 grad_loss: 13585.7090 normal_loss: 0.7192
[epoch 11][iter  400] loss: 158861.3906 RMSElog: 8.6972 grad_loss: 15876.7266 normal_loss: 0.7159
[epoch 11][iter  410] loss: 138589.7031 RMSElog: 8.5791 grad_loss: 13849.6982 normal_loss: 0.6922
[epoch 11][iter  420] loss: 170674.5625 RMSElog: 8.9362 grad_loss: 17057.8145 normal_loss: 0.7069
[epoch 11][iter  430] loss: 148523.6875 RMSElog: 8.7982 grad_loss: 14842.8701 normal_loss: 0.7000
[epoch 11][iter  440] loss: 153480.9062 RMSElog: 8.8384 grad_loss: 15338.6045 normal_loss: 0.6463
[epoch 11][iter  450] loss: 129688.7891 RMSElog: 8.7209 grad_loss: 12959.4844 normal_loss: 0.6742
[epoch 11][iter  460] loss: 104455.9219 RMSElog: 8.0548 grad_loss: 10436.8936 normal_loss: 0.6435
[epoch 11][iter  470] loss: 133447.5781 RMSElog: 8.6112 grad_loss: 13335.4668 normal_loss: 0.6795
[epoch 11][iter  480] loss: 129724.6406 RMSElog: 8.7315 grad_loss: 12963.0625 normal_loss: 0.6699
[epoch 11][iter  490] loss: 188641.6562 RMSElog: 8.9863 grad_loss: 18854.5098 normal_loss: 0.6708
[epoch 11][iter  500] loss: 216210.5469 RMSElog: 8.8604 grad_loss: 21611.5312 normal_loss: 0.6626
[epoch 11][iter  510] loss: 134657.5938 RMSElog: 8.5776 grad_loss: 13456.5127 normal_loss: 0.6688
[epoch 11][iter  520] loss: 167067.7500 RMSElog: 8.8368 grad_loss: 16697.2402 normal_loss: 0.6995
[epoch 11][iter  530] loss: 148227.7188 RMSElog: 8.7543 grad_loss: 14813.3223 normal_loss: 0.6967
[epoch 11][iter  540] loss: 152500.3594 RMSElog: 8.7018 grad_loss: 15240.6299 normal_loss: 0.7045
[epoch 11][iter  550] loss: 130410.1406 RMSElog: 8.5363 grad_loss: 13031.8223 normal_loss: 0.6556
[epoch 11][iter  560] loss: 182296.1250 RMSElog: 8.9530 grad_loss: 18220.0137 normal_loss: 0.6459
[epoch 11][iter  570] loss: 126799.7812 RMSElog: 8.4662 grad_loss: 12670.7959 normal_loss: 0.7168
[epoch 11][iter  580] loss: 101431.2344 RMSElog: 8.6140 grad_loss: 10133.8291 normal_loss: 0.6802
[epoch 11][iter  590] loss: 188998.5312 RMSElog: 8.9084 grad_loss: 18890.2441 normal_loss: 0.7016
[epoch 12][iter    0] loss: 187216.1250 RMSElog: 8.8103 grad_loss: 18712.1367 normal_loss: 0.6666
[epoch 12][iter   10] loss: 172949.9844 RMSElog: 8.8979 grad_loss: 17285.4180 normal_loss: 0.6814
[epoch 12][iter   20] loss: 180188.0625 RMSElog: 8.7464 grad_loss: 18009.3750 normal_loss: 0.6856
[epoch 12][iter   30] loss: 122313.1406 RMSElog: 8.6250 grad_loss: 12222.0264 normal_loss: 0.6632
[epoch 12][iter   40] loss: 178453.3125 RMSElog: 8.9139 grad_loss: 17835.7051 normal_loss: 0.7128
[epoch 12][iter   50] loss: 177273.1094 RMSElog: 8.8978 grad_loss: 17717.7031 normal_loss: 0.7096
[epoch 12][iter   60] loss: 202097.0000 RMSElog: 8.7444 grad_loss: 20200.3008 normal_loss: 0.6549
[epoch 12][iter   70] loss: 140447.1250 RMSElog: 8.7906 grad_loss: 14035.0977 normal_loss: 0.8231
[epoch 12][iter   80] loss: 149352.1094 RMSElog: 8.7281 grad_loss: 14925.7402 normal_loss: 0.7425
[epoch 12][iter   90] loss: 129188.4297 RMSElog: 8.8110 grad_loss: 12909.3535 normal_loss: 0.6775
[epoch 12][iter  100] loss: 162503.6094 RMSElog: 8.9012 grad_loss: 16240.8018 normal_loss: 0.6581
[epoch 12][iter  110] loss: 106157.8594 RMSElog: 8.0448 grad_loss: 10607.0801 normal_loss: 0.6612
[epoch 12][iter  120] loss: 191187.4062 RMSElog: 8.8390 grad_loss: 19109.1758 normal_loss: 0.7247
[epoch 12][iter  130] loss: 172667.7188 RMSElog: 8.9277 grad_loss: 17257.1445 normal_loss: 0.6985
[epoch 12][iter  140] loss: 122367.6250 RMSElog: 8.5964 grad_loss: 12227.5195 normal_loss: 0.6468
[epoch 12][iter  150] loss: 116562.6953 RMSElog: 8.4575 grad_loss: 11647.1367 normal_loss: 0.6757
[epoch 12][iter  160] loss: 228318.5312 RMSElog: 9.0065 grad_loss: 22822.1836 normal_loss: 0.6636
[epoch 12][iter  170] loss: 146195.6562 RMSElog: 8.7254 grad_loss: 14610.1650 normal_loss: 0.6751
[epoch 12][iter  180] loss: 156154.2344 RMSElog: 8.8526 grad_loss: 15605.9277 normal_loss: 0.6433
[epoch 12][iter  190] loss: 128864.6172 RMSElog: 8.6691 grad_loss: 12877.1191 normal_loss: 0.6735
[epoch 12][iter  200] loss: 112692.9766 RMSElog: 8.1027 grad_loss: 11260.5195 normal_loss: 0.6753
[epoch 12][iter  210] loss: 211516.1250 RMSElog: 8.8029 grad_loss: 21142.1582 normal_loss: 0.6526
[epoch 12][iter  220] loss: 103500.6250 RMSElog: 8.5687 grad_loss: 10340.8164 normal_loss: 0.6774
[epoch 12][iter  230] loss: 188623.9219 RMSElog: 8.7945 grad_loss: 18852.9121 normal_loss: 0.6861
[epoch 12][iter  240] loss: 195422.5938 RMSElog: 8.6267 grad_loss: 19532.9336 normal_loss: 0.6994
[epoch 12][iter  250] loss: 177044.6562 RMSElog: 9.0152 grad_loss: 17694.7832 normal_loss: 0.6658
[epoch 12][iter  260] loss: 181926.4844 RMSElog: 8.9097 grad_loss: 18183.0039 normal_loss: 0.7348
[epoch 12][iter  270] loss: 239433.3750 RMSElog: 9.0796 grad_loss: 23933.5781 normal_loss: 0.6798
[epoch 12][iter  280] loss: 198015.2500 RMSElog: 8.8934 grad_loss: 19791.9648 normal_loss: 0.6681
[epoch 12][iter  290] loss: 180408.2500 RMSElog: 8.9460 grad_loss: 18031.1680 normal_loss: 0.7108
[epoch 12][iter  300] loss: 202609.5312 RMSElog: 8.7502 grad_loss: 20251.5391 normal_loss: 0.6643
[epoch 12][iter  310] loss: 170339.7812 RMSElog: 8.9142 grad_loss: 17024.3887 normal_loss: 0.6764
[epoch 12][iter  320] loss: 128302.1875 RMSElog: 8.6144 grad_loss: 12820.9336 normal_loss: 0.6710
[epoch 12][iter  330] loss: 167191.7500 RMSElog: 8.7906 grad_loss: 16709.7012 normal_loss: 0.6827
[epoch 12][iter  340] loss: 164397.3281 RMSElog: 8.9606 grad_loss: 16430.0820 normal_loss: 0.6902
[epoch 12][iter  350] loss: 135187.8594 RMSElog: 8.4655 grad_loss: 13509.6172 normal_loss: 0.7031
[epoch 12][iter  360] loss: 158211.1875 RMSElog: 8.7878 grad_loss: 15811.6709 normal_loss: 0.6596
[epoch 12][iter  370] loss: 166526.7188 RMSElog: 8.9654 grad_loss: 16643.0156 normal_loss: 0.6915
[epoch 12][iter  380] loss: 104457.4062 RMSElog: 8.1640 grad_loss: 10436.9297 normal_loss: 0.6469
[epoch 12][iter  390] loss: 160010.7500 RMSElog: 8.8461 grad_loss: 15991.4854 normal_loss: 0.7444
[epoch 12][iter  400] loss: 122909.7969 RMSElog: 8.5430 grad_loss: 12281.7139 normal_loss: 0.7225
[epoch 12][iter  410] loss: 102976.6562 RMSElog: 8.3307 grad_loss: 10288.6670 normal_loss: 0.6682
[epoch 12][iter  420] loss: 162875.6875 RMSElog: 8.8546 grad_loss: 16278.0410 normal_loss: 0.6742
[epoch 12][iter  430] loss: 140918.5625 RMSElog: 8.4413 grad_loss: 14082.7451 normal_loss: 0.6690
[epoch 12][iter  440] loss: 162522.0781 RMSElog: 8.7847 grad_loss: 16242.7617 normal_loss: 0.6612
[epoch 12][iter  450] loss: 162699.5625 RMSElog: 8.9206 grad_loss: 16260.3008 normal_loss: 0.7341
[epoch 12][iter  460] loss: 173063.2031 RMSElog: 8.9886 grad_loss: 17296.6816 normal_loss: 0.6513
[epoch 12][iter  470] loss: 180729.7188 RMSElog: 8.8359 grad_loss: 18063.4727 normal_loss: 0.6650
[epoch 12][iter  480] loss: 155464.5156 RMSElog: 8.9940 grad_loss: 15536.7959 normal_loss: 0.6619
[epoch 12][iter  490] loss: 135951.4062 RMSElog: 8.7123 grad_loss: 13585.7041 normal_loss: 0.7250
[epoch 12][iter  500] loss: 196416.1719 RMSElog: 8.8213 grad_loss: 19632.1328 normal_loss: 0.6628
[epoch 12][iter  510] loss: 144961.6719 RMSElog: 8.8872 grad_loss: 14486.6172 normal_loss: 0.6627
[epoch 12][iter  520] loss: 101202.9688 RMSElog: 8.6319 grad_loss: 10110.9668 normal_loss: 0.6986
[epoch 12][iter  530] loss: 169000.3438 RMSElog: 8.6925 grad_loss: 16890.5859 normal_loss: 0.7566
[epoch 12][iter  540] loss: 223855.5625 RMSElog: 9.1115 grad_loss: 22375.7637 normal_loss: 0.6808
[epoch 12][iter  550] loss: 196656.5312 RMSElog: 8.7326 grad_loss: 19656.2617 normal_loss: 0.6583
[epoch 12][iter  560] loss: 191673.2656 RMSElog: 8.9319 grad_loss: 19157.7031 normal_loss: 0.6911
[epoch 12][iter  570] loss: 183854.5312 RMSElog: 9.0360 grad_loss: 18375.7090 normal_loss: 0.7098
[epoch 12][iter  580] loss: 137237.0000 RMSElog: 8.9361 grad_loss: 13714.0332 normal_loss: 0.7292
[epoch 12][iter  590] loss: 103935.8125 RMSElog: 8.3448 grad_loss: 10384.5518 normal_loss: 0.6846
[epoch 13][iter    0] loss: 103500.0703 RMSElog: 8.5439 grad_loss: 10340.7949 normal_loss: 0.6684
[epoch 13][iter   10] loss: 181273.1094 RMSElog: 8.7460 grad_loss: 18117.8926 normal_loss: 0.6725
[epoch 13][iter   20] loss: 107882.7969 RMSElog: 8.0601 grad_loss: 10779.5625 normal_loss: 0.6558
[epoch 13][iter   30] loss: 165992.9375 RMSElog: 8.9054 grad_loss: 16589.7188 normal_loss: 0.6685
[epoch 13][iter   40] loss: 207897.7969 RMSElog: 8.8308 grad_loss: 20780.2949 normal_loss: 0.6552
[epoch 13][iter   50] loss: 152543.9062 RMSElog: 8.6826 grad_loss: 15245.0439 normal_loss: 0.6638
[epoch 13][iter   60] loss: 166989.2188 RMSElog: 8.8055 grad_loss: 16689.4316 normal_loss: 0.6848
[epoch 13][iter   70] loss: 146559.6562 RMSElog: 8.5718 grad_loss: 14646.6914 normal_loss: 0.7018
[epoch 13][iter   80] loss: 158861.2344 RMSElog: 8.6916 grad_loss: 15876.7207 normal_loss: 0.7105
[epoch 13][iter   90] loss: 194556.6406 RMSElog: 8.8043 grad_loss: 19446.1992 normal_loss: 0.6607
[epoch 13][iter  100] loss: 167664.1562 RMSElog: 8.9657 grad_loss: 16756.7090 normal_loss: 0.7430
[epoch 13][iter  110] loss: 195979.3125 RMSElog: 8.9595 grad_loss: 19588.3125 normal_loss: 0.6603
[epoch 13][iter  120] loss: 165956.9062 RMSElog: 8.7485 grad_loss: 16586.2930 normal_loss: 0.6497
[epoch 13][iter  130] loss: 180302.1250 RMSElog: 8.8814 grad_loss: 18020.6328 normal_loss: 0.6984
[epoch 13][iter  140] loss: 106747.5391 RMSElog: 8.3114 grad_loss: 10665.7656 normal_loss: 0.6770
[epoch 13][iter  150] loss: 133005.2656 RMSElog: 8.5117 grad_loss: 13291.3789 normal_loss: 0.6353
[epoch 13][iter  160] loss: 183462.2031 RMSElog: 8.8559 grad_loss: 18336.6875 normal_loss: 0.6785
[epoch 13][iter  170] loss: 195393.8281 RMSElog: 8.9391 grad_loss: 19529.7793 normal_loss: 0.6640
[epoch 13][iter  180] loss: 189721.9688 RMSElog: 8.8338 grad_loss: 18962.7051 normal_loss: 0.6590
[epoch 13][iter  190] loss: 105717.4609 RMSElog: 8.0004 grad_loss: 10563.0801 normal_loss: 0.6656
[epoch 13][iter  200] loss: 164750.2969 RMSElog: 8.8200 grad_loss: 16465.4980 normal_loss: 0.7114
[epoch 13][iter  210] loss: 117051.4766 RMSElog: 8.6430 grad_loss: 11695.7754 normal_loss: 0.7299
[epoch 13][iter  220] loss: 180188.7500 RMSElog: 8.7657 grad_loss: 18009.4121 normal_loss: 0.6965
[epoch 13][iter  230] loss: 241952.9844 RMSElog: 9.0427 grad_loss: 24185.5664 normal_loss: 0.6896
[epoch 13][iter  240] loss: 114364.2266 RMSElog: 8.6081 grad_loss: 11427.0781 normal_loss: 0.7366
[epoch 13][iter  250] loss: 195651.4062 RMSElog: 8.8086 grad_loss: 19555.6543 normal_loss: 0.6785
[epoch 13][iter  260] loss: 100646.7188 RMSElog: 8.7987 grad_loss: 10055.1914 normal_loss: 0.6819
[epoch 13][iter  270] loss: 153704.4062 RMSElog: 8.7929 grad_loss: 15360.9941 normal_loss: 0.6542
[epoch 13][iter  280] loss: 90467.7500 RMSElog: 8.3913 grad_loss: 9037.6963 normal_loss: 0.6871
[epoch 13][iter  290] loss: 147525.4062 RMSElog: 8.7388 grad_loss: 14743.1387 normal_loss: 0.6622
[epoch 13][iter  300] loss: 178766.4688 RMSElog: 8.8836 grad_loss: 17867.0625 normal_loss: 0.7008
[epoch 13][iter  310] loss: 150282.4062 RMSElog: 8.6627 grad_loss: 15018.9199 normal_loss: 0.6568
[epoch 13][iter  320] loss: 114487.0625 RMSElog: 8.2446 grad_loss: 11439.7871 normal_loss: 0.6752
[epoch 13][iter  330] loss: 149524.8750 RMSElog: 8.8392 grad_loss: 14942.9600 normal_loss: 0.6894
[epoch 13][iter  340] loss: 163234.3906 RMSElog: 8.7295 grad_loss: 16314.0420 normal_loss: 0.6684
[epoch 13][iter  350] loss: 159323.0625 RMSElog: 8.8861 grad_loss: 15922.7266 normal_loss: 0.6945
[epoch 13][iter  360] loss: 150681.2188 RMSElog: 8.7331 grad_loss: 15058.6934 normal_loss: 0.6953
[epoch 13][iter  370] loss: 149789.4375 RMSElog: 8.7784 grad_loss: 14969.4668 normal_loss: 0.6990
[epoch 13][iter  380] loss: 197500.2812 RMSElog: 8.9172 grad_loss: 19740.4473 normal_loss: 0.6613
[epoch 13][iter  390] loss: 203000.5938 RMSElog: 8.8337 grad_loss: 20290.5703 normal_loss: 0.6544
[epoch 13][iter  400] loss: 138694.2500 RMSElog: 8.5484 grad_loss: 13860.1426 normal_loss: 0.7341
[epoch 13][iter  410] loss: 160862.9844 RMSElog: 8.8426 grad_loss: 16076.7881 normal_loss: 0.6674
[epoch 13][iter  420] loss: 105771.0781 RMSElog: 8.1136 grad_loss: 10568.3418 normal_loss: 0.6521
[epoch 13][iter  430] loss: 200933.9219 RMSElog: 8.8634 grad_loss: 20083.8340 normal_loss: 0.6944
[epoch 13][iter  440] loss: 134614.5469 RMSElog: 8.7116 grad_loss: 13452.0625 normal_loss: 0.6802
[epoch 13][iter  450] loss: 201482.4219 RMSElog: 8.9603 grad_loss: 20138.6074 normal_loss: 0.6733
[epoch 13][iter  460] loss: 131922.2188 RMSElog: 8.5448 grad_loss: 13183.0234 normal_loss: 0.6536
[epoch 13][iter  470] loss: 110566.8359 RMSElog: 8.6109 grad_loss: 11047.3691 normal_loss: 0.7034
[epoch 13][iter  480] loss: 239748.2812 RMSElog: 8.9721 grad_loss: 23965.1836 normal_loss: 0.6713
[epoch 13][iter  490] loss: 116051.5547 RMSElog: 8.2503 grad_loss: 11596.2402 normal_loss: 0.6647
[epoch 13][iter  500] loss: 147893.4531 RMSElog: 8.6205 grad_loss: 14780.0703 normal_loss: 0.6546
[epoch 13][iter  510] loss: 130507.4219 RMSElog: 8.6106 grad_loss: 13041.4756 normal_loss: 0.6563
[epoch 13][iter  520] loss: 130725.8203 RMSElog: 8.7264 grad_loss: 13063.1211 normal_loss: 0.7343
[epoch 13][iter  530] loss: 188623.8750 RMSElog: 8.7906 grad_loss: 18852.9082 normal_loss: 0.6866
[epoch 13][iter  540] loss: 142526.8594 RMSElog: 9.0247 grad_loss: 14242.9824 normal_loss: 0.6794
[epoch 13][iter  550] loss: 179617.5156 RMSElog: 9.0090 grad_loss: 17952.0312 normal_loss: 0.7106
[epoch 13][iter  560] loss: 167714.5938 RMSElog: 8.9874 grad_loss: 16761.7891 normal_loss: 0.6807
[epoch 13][iter  570] loss: 104066.9688 RMSElog: 8.5009 grad_loss: 10397.5254 normal_loss: 0.6706
[epoch 13][iter  580] loss: 148118.4375 RMSElog: 8.7477 grad_loss: 14802.3926 normal_loss: 0.7031
[epoch 13][iter  590] loss: 210634.3594 RMSElog: 9.1506 grad_loss: 21053.5957 normal_loss: 0.6900
[epoch 14][iter    0] loss: 176244.6250 RMSElog: 9.0363 grad_loss: 17614.7285 normal_loss: 0.6975
[epoch 14][iter   10] loss: 112517.5000 RMSElog: 8.4821 grad_loss: 11242.6064 normal_loss: 0.6612
[epoch 14][iter   20] loss: 211905.6406 RMSElog: 8.8651 grad_loss: 21181.0371 normal_loss: 0.6629
[epoch 14][iter   30] loss: 208165.0312 RMSElog: 9.1418 grad_loss: 20806.6816 normal_loss: 0.6804
[epoch 14][iter   40] loss: 200934.3750 RMSElog: 8.9077 grad_loss: 20083.8418 normal_loss: 0.6884
[epoch 14][iter   50] loss: 211618.8125 RMSElog: 8.9323 grad_loss: 21152.2871 normal_loss: 0.6620
[epoch 14][iter   60] loss: 107882.7812 RMSElog: 8.0606 grad_loss: 10779.5625 normal_loss: 0.6549
[epoch 14][iter   70] loss: 174359.6250 RMSElog: 9.0466 grad_loss: 17426.2148 normal_loss: 0.7002
[epoch 14][iter   80] loss: 198272.0469 RMSElog: 8.8034 grad_loss: 19817.7422 normal_loss: 0.6593
[epoch 14][iter   90] loss: 179283.8281 RMSElog: 8.7672 grad_loss: 17918.8906 normal_loss: 0.7241
[epoch 14][iter  100] loss: 121168.4219 RMSElog: 8.7423 grad_loss: 12107.3535 normal_loss: 0.7461
[epoch 14][iter  110] loss: 162961.0312 RMSElog: 8.6544 grad_loss: 16286.7598 normal_loss: 0.6881
[epoch 14][iter  120] loss: 232751.7188 RMSElog: 9.0215 grad_loss: 23265.4785 normal_loss: 0.6716
[epoch 14][iter  130] loss: 185884.1875 RMSElog: 8.7816 grad_loss: 18578.9375 normal_loss: 0.6987
[epoch 14][iter  140] loss: 129143.3906 RMSElog: 8.6838 grad_loss: 12904.9668 normal_loss: 0.6886
[epoch 14][iter  150] loss: 179884.2188 RMSElog: 8.7763 grad_loss: 17978.9473 normal_loss: 0.6984
[epoch 14][iter  160] loss: 117385.7656 RMSElog: 8.3892 grad_loss: 11729.5273 normal_loss: 0.6596
[epoch 14][iter  170] loss: 133447.5000 RMSElog: 8.6087 grad_loss: 13335.4639 normal_loss: 0.6780
[epoch 14][iter  180] loss: 156980.5312 RMSElog: 9.2238 grad_loss: 15687.9600 normal_loss: 0.8689
[epoch 14][iter  190] loss: 122366.7969 RMSElog: 8.5435 grad_loss: 12227.4893 normal_loss: 0.6463
[epoch 14][iter  200] loss: 101431.1406 RMSElog: 8.6136 grad_loss: 10133.8252 normal_loss: 0.6755
[epoch 14][iter  210] loss: 207666.5469 RMSElog: 8.8834 grad_loss: 20757.0703 normal_loss: 0.7011
[epoch 14][iter  220] loss: 174613.2031 RMSElog: 8.8340 grad_loss: 17451.7754 normal_loss: 0.7113
[epoch 14][iter  230] loss: 126005.4844 RMSElog: 8.4699 grad_loss: 12591.3975 normal_loss: 0.6814
[epoch 14][iter  240] loss: 127043.1094 RMSElog: 8.4142 grad_loss: 12695.2041 normal_loss: 0.6928
[epoch 14][iter  250] loss: 115646.4766 RMSElog: 8.5353 grad_loss: 11555.3809 normal_loss: 0.7312
[epoch 14][iter  260] loss: 185755.5312 RMSElog: 8.9251 grad_loss: 18565.9141 normal_loss: 0.7127
[epoch 14][iter  270] loss: 211516.8438 RMSElog: 8.8383 grad_loss: 21142.1855 normal_loss: 0.6603
[epoch 14][iter  280] loss: 215933.7188 RMSElog: 8.9224 grad_loss: 21583.7988 normal_loss: 0.6496
[epoch 14][iter  290] loss: 178766.4688 RMSElog: 8.8823 grad_loss: 17867.0625 normal_loss: 0.7007
[epoch 14][iter  300] loss: 196656.5469 RMSElog: 8.7299 grad_loss: 19656.2637 normal_loss: 0.6596
[epoch 14][iter  310] loss: 165557.5312 RMSElog: 8.7978 grad_loss: 16546.2734 normal_loss: 0.6829
[epoch 14][iter  320] loss: 122894.3594 RMSElog: 8.6538 grad_loss: 12280.1016 normal_loss: 0.6802
[epoch 14][iter  330] loss: 133005.2812 RMSElog: 8.5115 grad_loss: 13291.3809 normal_loss: 0.6348
[epoch 14][iter  340] loss: 133025.9688 RMSElog: 8.6303 grad_loss: 13293.3125 normal_loss: 0.6551
[epoch 14][iter  350] loss: 123514.8828 RMSElog: 8.6978 grad_loss: 12342.0312 normal_loss: 0.7584
[epoch 14][iter  360] loss: 173947.8438 RMSElog: 8.7614 grad_loss: 17385.3262 normal_loss: 0.6979
[epoch 14][iter  370] loss: 172739.7656 RMSElog: 8.9972 grad_loss: 17264.2676 normal_loss: 0.7102
[epoch 14][iter  380] loss: 95986.4453 RMSElog: 8.3192 grad_loss: 9589.6846 normal_loss: 0.6405
[epoch 14][iter  390] loss: 160727.8438 RMSElog: 8.9889 grad_loss: 16063.0938 normal_loss: 0.7024
[epoch 14][iter  400] loss: 165632.8906 RMSElog: 8.7824 grad_loss: 16553.8047 normal_loss: 0.7013
[epoch 14][iter  410] loss: 114903.2031 RMSElog: 8.2717 grad_loss: 11481.3828 normal_loss: 0.6665
[epoch 14][iter  420] loss: 206505.7969 RMSElog: 8.8503 grad_loss: 20641.0762 normal_loss: 0.6545
[epoch 14][iter  430] loss: 185127.0469 RMSElog: 8.9029 grad_loss: 18503.0625 normal_loss: 0.7409
[epoch 14][iter  440] loss: 198014.2969 RMSElog: 8.8373 grad_loss: 19791.9258 normal_loss: 0.6654
[epoch 14][iter  450] loss: 103486.1562 RMSElog: 8.3666 grad_loss: 10339.5879 normal_loss: 0.6608
[epoch 14][iter  460] loss: 72273.2969 RMSElog: 8.4745 grad_loss: 7218.1924 normal_loss: 0.6627
[epoch 14][iter  470] loss: 177043.3594 RMSElog: 8.9488 grad_loss: 17694.7344 normal_loss: 0.6519
[epoch 14][iter  480] loss: 154539.2812 RMSElog: 8.9228 grad_loss: 15444.3154 normal_loss: 0.6890
[epoch 14][iter  490] loss: 114363.7500 RMSElog: 8.5957 grad_loss: 11427.0527 normal_loss: 0.7263
[epoch 14][iter  500] loss: 182845.3438 RMSElog: 8.9947 grad_loss: 18274.8086 normal_loss: 0.7317
[epoch 14][iter  510] loss: 157792.9844 RMSElog: 8.7550 grad_loss: 15769.8340 normal_loss: 0.7091
[epoch 14][iter  520] loss: 195393.8125 RMSElog: 8.9382 grad_loss: 19529.7793 normal_loss: 0.6639
[epoch 14][iter  530] loss: 164827.5156 RMSElog: 8.7576 grad_loss: 16473.3105 normal_loss: 0.6843
[epoch 14][iter  540] loss: 228318.4688 RMSElog: 9.0047 grad_loss: 22822.1797 normal_loss: 0.6632
[epoch 14][iter  550] loss: 151386.5781 RMSElog: 8.5011 grad_loss: 15129.4385 normal_loss: 0.7179
[epoch 14][iter  560] loss: 140260.8750 RMSElog: 8.5601 grad_loss: 14016.8750 normal_loss: 0.6528
[epoch 14][iter  570] loss: 200447.7969 RMSElog: 8.7678 grad_loss: 20035.3613 normal_loss: 0.6510
[epoch 14][iter  580] loss: 197694.9375 RMSElog: 9.1366 grad_loss: 19759.6895 normal_loss: 0.6678
[epoch 14][iter  590] loss: 181273.1094 RMSElog: 8.7464 grad_loss: 18117.8926 normal_loss: 0.6720
[epoch 15][iter    0] loss: 172667.6719 RMSElog: 8.9281 grad_loss: 17257.1445 normal_loss: 0.6962
[epoch 15][iter   10] loss: 166070.9219 RMSElog: 8.9520 grad_loss: 16597.4805 normal_loss: 0.6592
[epoch 15][iter   20] loss: 182296.0781 RMSElog: 8.9390 grad_loss: 18220.0156 normal_loss: 0.6521
[epoch 15][iter   30] loss: 194556.5938 RMSElog: 8.7998 grad_loss: 19446.1992 normal_loss: 0.6621
[epoch 15][iter   40] loss: 106493.6875 RMSElog: 8.0558 grad_loss: 10640.6465 normal_loss: 0.6670
[epoch 15][iter   50] loss: 140261.3594 RMSElog: 8.5881 grad_loss: 14016.8896 normal_loss: 0.6579
[epoch 15][iter   60] loss: 122661.7656 RMSElog: 8.7036 grad_loss: 12256.6172 normal_loss: 0.8554
[epoch 15][iter   70] loss: 161614.2500 RMSElog: 8.9002 grad_loss: 16151.8662 normal_loss: 0.6594
[epoch 15][iter   80] loss: 103486.1328 RMSElog: 8.3680 grad_loss: 10339.5859 normal_loss: 0.6594
[epoch 15][iter   90] loss: 121849.1406 RMSElog: 8.5327 grad_loss: 12175.6592 normal_loss: 0.7229
[epoch 15][iter  100] loss: 160767.9375 RMSElog: 8.8132 grad_loss: 16067.2607 normal_loss: 0.7195
[epoch 15][iter  110] loss: 119637.5078 RMSElog: 8.5607 grad_loss: 11954.5459 normal_loss: 0.6443
[epoch 15][iter  120] loss: 174331.3906 RMSElog: 8.7529 grad_loss: 17423.6973 normal_loss: 0.6885
[epoch 15][iter  130] loss: 155892.5469 RMSElog: 8.6509 grad_loss: 15579.9492 normal_loss: 0.6545
[epoch 15][iter  140] loss: 162875.6875 RMSElog: 8.8551 grad_loss: 16278.0391 normal_loss: 0.6744
[epoch 15][iter  150] loss: 211905.6406 RMSElog: 8.8657 grad_loss: 21181.0371 normal_loss: 0.6626
[epoch 15][iter  160] loss: 103935.7891 RMSElog: 8.3438 grad_loss: 10384.5518 normal_loss: 0.6836
[epoch 15][iter  170] loss: 160862.9531 RMSElog: 8.8422 grad_loss: 16076.7881 normal_loss: 0.6656
[epoch 15][iter  180] loss: 198424.0312 RMSElog: 8.9044 grad_loss: 19832.8262 normal_loss: 0.6717
[epoch 15][iter  190] loss: 175282.4219 RMSElog: 8.6144 grad_loss: 17518.9375 normal_loss: 0.6900
[epoch 15][iter  200] loss: 149352.0625 RMSElog: 8.7272 grad_loss: 14925.7373 normal_loss: 0.7416
[epoch 15][iter  210] loss: 158908.4219 RMSElog: 8.7991 grad_loss: 15881.3486 normal_loss: 0.6947
[epoch 15][iter  220] loss: 208165.0156 RMSElog: 9.1423 grad_loss: 20806.6797 normal_loss: 0.6805
[epoch 15][iter  230] loss: 217153.6094 RMSElog: 8.9233 grad_loss: 21705.7793 normal_loss: 0.6582
[epoch 15][iter  240] loss: 152500.6875 RMSElog: 8.7250 grad_loss: 15240.6426 normal_loss: 0.7014
[epoch 15][iter  250] loss: 160034.2656 RMSElog: 8.8068 grad_loss: 15993.9199 normal_loss: 0.6999
[epoch 15][iter  260] loss: 224057.1875 RMSElog: 9.0583 grad_loss: 22395.9746 normal_loss: 0.6848
[epoch 15][iter  270] loss: 146196.0000 RMSElog: 8.7449 grad_loss: 14610.1768 normal_loss: 0.6781
[epoch 15][iter  280] loss: 199053.1094 RMSElog: 8.9062 grad_loss: 19895.7012 normal_loss: 0.7022
[epoch 15][iter  290] loss: 160010.4062 RMSElog: 8.8236 grad_loss: 15991.4756 normal_loss: 0.7414
[epoch 15][iter  300] loss: 239747.5312 RMSElog: 8.9358 grad_loss: 23965.1543 normal_loss: 0.6635
[epoch 15][iter  310] loss: 181446.1562 RMSElog: 8.8763 grad_loss: 18135.0469 normal_loss: 0.6923
[epoch 15][iter  320] loss: 146764.4062 RMSElog: 8.7690 grad_loss: 14666.9785 normal_loss: 0.6937
[epoch 15][iter  330] loss: 116051.5312 RMSElog: 8.2492 grad_loss: 11596.2393 normal_loss: 0.6646
[epoch 15][iter  340] loss: 160649.1719 RMSElog: 8.8642 grad_loss: 16055.3896 normal_loss: 0.6627
[epoch 15][iter  350] loss: 203071.5781 RMSElog: 8.7381 grad_loss: 20297.7695 normal_loss: 0.6503
[epoch 15][iter  360] loss: 122909.7969 RMSElog: 8.5439 grad_loss: 12281.7139 normal_loss: 0.7213
[epoch 15][iter  370] loss: 161267.1406 RMSElog: 8.7761 grad_loss: 16117.2793 normal_loss: 0.6579
[epoch 15][iter  380] loss: 194387.0000 RMSElog: 8.8345 grad_loss: 19429.1953 normal_loss: 0.6699
[epoch 15][iter  390] loss: 127445.5859 RMSElog: 8.4088 grad_loss: 12735.4844 normal_loss: 0.6648
[epoch 15][iter  400] loss: 160727.2188 RMSElog: 8.9459 grad_loss: 16063.0752 normal_loss: 0.7015
[epoch 15][iter  410] loss: 173145.7812 RMSElog: 8.6024 grad_loss: 17305.2754 normal_loss: 0.7011
[epoch 15][iter  420] loss: 201483.0625 RMSElog: 9.0032 grad_loss: 20138.6289 normal_loss: 0.6741
[epoch 15][iter  430] loss: 148118.4375 RMSElog: 8.7487 grad_loss: 14802.3926 normal_loss: 0.7023
[epoch 15][iter  440] loss: 172739.2031 RMSElog: 8.9668 grad_loss: 17264.2500 normal_loss: 0.7029
[epoch 15][iter  450] loss: 203540.6562 RMSElog: 8.7428 grad_loss: 20344.6699 normal_loss: 0.6549
[epoch 15][iter  460] loss: 131415.9688 RMSElog: 8.4647 grad_loss: 13132.4561 normal_loss: 0.6771
[epoch 15][iter  470] loss: 164750.3281 RMSElog: 8.8245 grad_loss: 16465.4980 normal_loss: 0.7104
[epoch 15][iter  480] loss: 109082.9297 RMSElog: 8.5145 grad_loss: 10899.0967 normal_loss: 0.6812
[epoch 15][iter  490] loss: 172949.9688 RMSElog: 8.8987 grad_loss: 17285.4180 normal_loss: 0.6801
[epoch 15][iter  500] loss: 165937.0312 RMSElog: 8.8814 grad_loss: 16584.1152 normal_loss: 0.7066
[epoch 15][iter  510] loss: 176477.0000 RMSElog: 8.8034 grad_loss: 17638.2051 normal_loss: 0.6906
[epoch 15][iter  520] loss: 134656.9375 RMSElog: 8.5344 grad_loss: 13456.4941 normal_loss: 0.6664
[epoch 15][iter  530] loss: 197500.1719 RMSElog: 8.9175 grad_loss: 19740.4414 normal_loss: 0.6588
[epoch 15][iter  540] loss: 115325.8516 RMSElog: 8.2718 grad_loss: 11523.6484 normal_loss: 0.6651
[epoch 15][iter  550] loss: 167723.1875 RMSElog: 8.8413 grad_loss: 16762.7812 normal_loss: 0.6958
[epoch 15][iter  560] loss: 163758.2344 RMSElog: 8.6696 grad_loss: 16366.4443 normal_loss: 0.7089
[epoch 15][iter  570] loss: 121816.2891 RMSElog: 8.2718 grad_loss: 12172.6816 normal_loss: 0.6757
[epoch 15][iter  580] loss: 108399.2500 RMSElog: 8.5990 grad_loss: 10830.5977 normal_loss: 0.7284
[epoch 15][iter  590] loss: 206741.2812 RMSElog: 8.7868 grad_loss: 20664.6836 normal_loss: 0.6574
[epoch 16][iter    0] loss: 151349.9688 RMSElog: 8.5962 grad_loss: 15125.7090 normal_loss: 0.6915
[epoch 16][iter   10] loss: 124228.9766 RMSElog: 8.6086 grad_loss: 12413.6055 normal_loss: 0.6837
[epoch 16][iter   20] loss: 129689.1328 RMSElog: 8.4822 grad_loss: 12959.7559 normal_loss: 0.6749
[epoch 16][iter   30] loss: 102075.9688 RMSElog: 8.4047 grad_loss: 10198.5273 normal_loss: 0.6653
[epoch 16][iter   40] loss: 144174.5781 RMSElog: 8.6181 grad_loss: 14408.1641 normal_loss: 0.6759
[epoch 16][iter   50] loss: 135094.0156 RMSElog: 8.6152 grad_loss: 13500.1348 normal_loss: 0.6517
[epoch 16][iter   60] loss: 183994.7031 RMSElog: 8.5626 grad_loss: 18390.2168 normal_loss: 0.6922
[epoch 16][iter   70] loss: 148035.5312 RMSElog: 8.6579 grad_loss: 14794.2461 normal_loss: 0.6490
[epoch 16][iter   80] loss: 207666.5312 RMSElog: 8.8813 grad_loss: 20757.0703 normal_loss: 0.7015
[epoch 16][iter   90] loss: 220675.8594 RMSElog: 8.8768 grad_loss: 22058.0195 normal_loss: 0.6900
[epoch 16][iter  100] loss: 158908.4219 RMSElog: 8.7990 grad_loss: 15881.3486 normal_loss: 0.6951
[epoch 16][iter  110] loss: 135448.4688 RMSElog: 8.7803 grad_loss: 13535.3926 normal_loss: 0.6746
[epoch 16][iter  120] loss: 104316.5312 RMSElog: 8.0535 grad_loss: 10422.9385 normal_loss: 0.6614
[epoch 16][iter  130] loss: 108776.7188 RMSElog: 8.1169 grad_loss: 10868.8848 normal_loss: 0.6696
[epoch 16][iter  140] loss: 175528.9688 RMSElog: 8.8619 grad_loss: 17543.3555 normal_loss: 0.6789
[epoch 16][iter  150] loss: 229061.6250 RMSElog: 9.0453 grad_loss: 22896.4453 normal_loss: 0.6718
[epoch 16][iter  160] loss: 160419.6250 RMSElog: 8.8807 grad_loss: 16032.4277 normal_loss: 0.6538
[epoch 16][iter  170] loss: 191673.2188 RMSElog: 8.9318 grad_loss: 19157.6992 normal_loss: 0.6908
[epoch 16][iter  180] loss: 151703.7656 RMSElog: 8.7516 grad_loss: 15160.9805 normal_loss: 0.6439
[epoch 16][iter  190] loss: 143822.8906 RMSElog: 8.7403 grad_loss: 14372.8730 normal_loss: 0.6756
[epoch 16][iter  200] loss: 106157.8203 RMSElog: 8.0439 grad_loss: 10607.0791 normal_loss: 0.6594
[epoch 16][iter  210] loss: 138915.3281 RMSElog: 8.6295 grad_loss: 13882.2441 normal_loss: 0.6580
[epoch 16][iter  220] loss: 129143.3750 RMSElog: 8.6826 grad_loss: 12904.9668 normal_loss: 0.6888
[epoch 16][iter  230] loss: 120269.9297 RMSElog: 8.2877 grad_loss: 12018.0381 normal_loss: 0.6668
[epoch 16][iter  240] loss: 149789.4062 RMSElog: 8.7779 grad_loss: 14969.4648 normal_loss: 0.6978
[epoch 16][iter  250] loss: 112693.5156 RMSElog: 8.1237 grad_loss: 11260.5488 normal_loss: 0.6788
[epoch 16][iter  260] loss: 182845.8125 RMSElog: 9.0188 grad_loss: 18274.8281 normal_loss: 0.7339
[epoch 16][iter  270] loss: 130124.6875 RMSElog: 8.3252 grad_loss: 13003.4717 normal_loss: 0.6719
[epoch 16][iter  280] loss: 103332.5859 RMSElog: 8.1088 grad_loss: 10324.4961 normal_loss: 0.6544
[epoch 16][iter  290] loss: 167191.7031 RMSElog: 8.7906 grad_loss: 16709.6992 normal_loss: 0.6805
[epoch 16][iter  300] loss: 196899.1406 RMSElog: 8.9420 grad_loss: 19680.3164 normal_loss: 0.6569
[epoch 16][iter  310] loss: 175282.4219 RMSElog: 8.6134 grad_loss: 17518.9375 normal_loss: 0.6905
[epoch 16][iter  320] loss: 100625.4062 RMSElog: 8.0334 grad_loss: 10053.8691 normal_loss: 0.6390
[epoch 16][iter  330] loss: 163234.3438 RMSElog: 8.7252 grad_loss: 16314.0410 normal_loss: 0.6684
[epoch 16][iter  340] loss: 154289.1250 RMSElog: 8.6206 grad_loss: 15419.6436 normal_loss: 0.6498
[epoch 16][iter  350] loss: 122427.3516 RMSElog: 8.3552 grad_loss: 12233.6895 normal_loss: 0.6906
[epoch 16][iter  360] loss: 195650.6250 RMSElog: 8.7659 grad_loss: 19555.6211 normal_loss: 0.6754
[epoch 16][iter  370] loss: 161794.1250 RMSElog: 8.8732 grad_loss: 16169.8848 normal_loss: 0.6548
[epoch 16][iter  380] loss: 138041.4844 RMSElog: 8.5296 grad_loss: 13794.9404 normal_loss: 0.6782
[epoch 16][iter  390] loss: 166072.2812 RMSElog: 9.0294 grad_loss: 16597.5312 normal_loss: 0.6686
[epoch 16][iter  400] loss: 107882.7656 RMSElog: 8.0581 grad_loss: 10779.5625 normal_loss: 0.6556
[epoch 16][iter  410] loss: 100729.4688 RMSElog: 8.6357 grad_loss: 10063.6436 normal_loss: 0.6681
[epoch 16][iter  420] loss: 218930.3906 RMSElog: 9.1557 grad_loss: 21883.2051 normal_loss: 0.6775
[epoch 16][iter  430] loss: 183462.1875 RMSElog: 8.8545 grad_loss: 18336.6855 normal_loss: 0.6781
[epoch 16][iter  440] loss: 198424.0312 RMSElog: 8.9034 grad_loss: 19832.8262 normal_loss: 0.6724
[epoch 16][iter  450] loss: 172739.2344 RMSElog: 8.9666 grad_loss: 17264.2539 normal_loss: 0.7028
[epoch 16][iter  460] loss: 90467.2656 RMSElog: 8.3474 grad_loss: 9037.6865 normal_loss: 0.6924
[epoch 16][iter  470] loss: 104433.9219 RMSElog: 8.3996 grad_loss: 10434.3340 normal_loss: 0.6587
[epoch 16][iter  480] loss: 191802.7344 RMSElog: 8.8166 grad_loss: 19170.7988 normal_loss: 0.6579
[epoch 16][iter  490] loss: 112673.8594 RMSElog: 8.1476 grad_loss: 11258.5752 normal_loss: 0.6633
[epoch 16][iter  500] loss: 146141.9844 RMSElog: 8.5806 grad_loss: 14604.8838 normal_loss: 0.7334
[epoch 16][iter  510] loss: 199586.9062 RMSElog: 8.8736 grad_loss: 19949.1504 normal_loss: 0.6687
[epoch 16][iter  520] loss: 149114.0312 RMSElog: 8.7798 grad_loss: 14901.9551 normal_loss: 0.6679
[epoch 16][iter  530] loss: 115480.5156 RMSElog: 8.5633 grad_loss: 11538.8145 normal_loss: 0.6743
[epoch 16][iter  540] loss: 127755.9531 RMSElog: 8.6391 grad_loss: 12766.2754 normal_loss: 0.6815
[epoch 16][iter  550] loss: 154538.2188 RMSElog: 8.8579 grad_loss: 15444.2832 normal_loss: 0.6810
[epoch 16][iter  560] loss: 137237.0000 RMSElog: 8.9378 grad_loss: 13714.0332 normal_loss: 0.7281
[epoch 16][iter  570] loss: 189721.9688 RMSElog: 8.8330 grad_loss: 18962.7051 normal_loss: 0.6587
[epoch 16][iter  580] loss: 180642.4844 RMSElog: 8.9093 grad_loss: 18054.6523 normal_loss: 0.6856
[epoch 16][iter  590] loss: 161266.5312 RMSElog: 8.7469 grad_loss: 16117.2510 normal_loss: 0.6558
[epoch 17][iter    0] loss: 202609.5312 RMSElog: 8.7483 grad_loss: 20251.5391 normal_loss: 0.6655
[epoch 17][iter   10] loss: 105770.4688 RMSElog: 8.0808 grad_loss: 10568.3213 normal_loss: 0.6441
[epoch 17][iter   20] loss: 198424.0312 RMSElog: 8.9030 grad_loss: 19832.8262 normal_loss: 0.6732
[epoch 17][iter   30] loss: 163759.1719 RMSElog: 8.7171 grad_loss: 16366.4805 normal_loss: 0.7193
[epoch 17][iter   40] loss: 109237.2734 RMSElog: 8.1297 grad_loss: 10914.9277 normal_loss: 0.6699
[epoch 17][iter   50] loss: 129149.6094 RMSElog: 8.7458 grad_loss: 12905.5508 normal_loss: 0.6637
[epoch 17][iter   60] loss: 154289.1406 RMSElog: 8.6212 grad_loss: 15419.6436 normal_loss: 0.6497
[epoch 17][iter   70] loss: 199052.5625 RMSElog: 8.8702 grad_loss: 19895.6797 normal_loss: 0.7056
[epoch 17][iter   80] loss: 216489.4375 RMSElog: 8.9428 grad_loss: 21639.3438 normal_loss: 0.6567
[epoch 17][iter   90] loss: 138915.9531 RMSElog: 8.6717 grad_loss: 13882.2598 normal_loss: 0.6627
[epoch 17][iter  100] loss: 176780.8750 RMSElog: 8.7703 grad_loss: 17668.6289 normal_loss: 0.6885
[epoch 17][iter  110] loss: 104110.5469 RMSElog: 8.5507 grad_loss: 10401.8262 normal_loss: 0.6782
[epoch 17][iter  120] loss: 110210.7734 RMSElog: 8.0520 grad_loss: 11012.3691 normal_loss: 0.6567
[epoch 17][iter  130] loss: 174612.8438 RMSElog: 8.8098 grad_loss: 17451.7617 normal_loss: 0.7134
[epoch 17][iter  140] loss: 178453.2812 RMSElog: 8.9124 grad_loss: 17835.7051 normal_loss: 0.7108
[epoch 17][iter  150] loss: 198724.3438 RMSElog: 8.8911 grad_loss: 19862.8418 normal_loss: 0.7007
[epoch 17][iter  160] loss: 135093.4531 RMSElog: 8.5742 grad_loss: 13500.1182 normal_loss: 0.6538
[epoch 17][iter  170] loss: 153703.5312 RMSElog: 8.7528 grad_loss: 15360.9609 normal_loss: 0.6391
[epoch 17][iter  180] loss: 163234.3438 RMSElog: 8.7235 grad_loss: 16314.0410 normal_loss: 0.6688
[epoch 17][iter  190] loss: 170040.0156 RMSElog: 8.7741 grad_loss: 16994.5469 normal_loss: 0.6812
[epoch 17][iter  200] loss: 172667.6719 RMSElog: 8.9287 grad_loss: 17257.1445 normal_loss: 0.6950
[epoch 17][iter  210] loss: 142575.3125 RMSElog: 8.5657 grad_loss: 14248.3086 normal_loss: 0.6577
[epoch 17][iter  220] loss: 106747.5312 RMSElog: 8.3093 grad_loss: 10665.7656 normal_loss: 0.6778
[epoch 17][iter  230] loss: 176477.0000 RMSElog: 8.8020 grad_loss: 17638.2051 normal_loss: 0.6923
[epoch 17][iter  240] loss: 138589.8750 RMSElog: 8.5954 grad_loss: 13849.7012 normal_loss: 0.6915
[epoch 17][iter  250] loss: 109914.5625 RMSElog: 8.4563 grad_loss: 10982.3086 normal_loss: 0.6914
[epoch 17][iter  260] loss: 137308.1562 RMSElog: 8.5531 grad_loss: 13721.6094 normal_loss: 0.6544
[epoch 17][iter  270] loss: 228033.6719 RMSElog: 8.9463 grad_loss: 22793.7383 normal_loss: 0.6809
[epoch 17][iter  280] loss: 105872.9688 RMSElog: 8.0900 grad_loss: 10578.5488 normal_loss: 0.6583
[epoch 17][iter  290] loss: 100729.3672 RMSElog: 8.6332 grad_loss: 10063.6377 normal_loss: 0.6663
[epoch 17][iter  300] loss: 212217.5000 RMSElog: 8.9106 grad_loss: 21212.1914 normal_loss: 0.6476
[epoch 17][iter  310] loss: 220567.6562 RMSElog: 9.0005 grad_loss: 22047.0859 normal_loss: 0.6797
[epoch 17][iter  320] loss: 201482.3750 RMSElog: 8.9608 grad_loss: 20138.6055 normal_loss: 0.6714
[epoch 17][iter  330] loss: 118723.9922 RMSElog: 8.2591 grad_loss: 11863.4707 normal_loss: 0.6702
[epoch 17][iter  340] loss: 211618.0000 RMSElog: 8.8847 grad_loss: 21152.2656 normal_loss: 0.6509
[epoch 17][iter  350] loss: 109123.3125 RMSElog: 8.2898 grad_loss: 10903.3750 normal_loss: 0.6657
[epoch 17][iter  360] loss: 135021.7500 RMSElog: 8.3260 grad_loss: 13493.1689 normal_loss: 0.6800
[epoch 17][iter  370] loss: 139079.5312 RMSElog: 8.6950 grad_loss: 13898.5928 normal_loss: 0.6649
[epoch 17][iter  380] loss: 139415.8438 RMSElog: 8.6706 grad_loss: 13932.2422 normal_loss: 0.6718
[epoch 17][iter  390] loss: 114487.7812 RMSElog: 8.2863 grad_loss: 11439.8145 normal_loss: 0.6775
[epoch 17][iter  400] loss: 72273.2812 RMSElog: 8.4739 grad_loss: 7218.1924 normal_loss: 0.6618
[epoch 17][iter  410] loss: 116562.5312 RMSElog: 8.4485 grad_loss: 11647.1299 normal_loss: 0.6750
[epoch 17][iter  420] loss: 153431.5312 RMSElog: 8.8747 grad_loss: 15333.5820 normal_loss: 0.6958
[epoch 17][iter  430] loss: 123073.1953 RMSElog: 8.2869 grad_loss: 12298.3486 normal_loss: 0.6831
[epoch 17][iter  440] loss: 102075.1406 RMSElog: 8.3459 grad_loss: 10198.5049 normal_loss: 0.6634
[epoch 17][iter  450] loss: 210500.4531 RMSElog: 8.9483 grad_loss: 21040.4512 normal_loss: 0.6449
[epoch 17][iter  460] loss: 175983.2031 RMSElog: 9.1484 grad_loss: 17588.2969 normal_loss: 0.8746
[epoch 17][iter  470] loss: 241952.2656 RMSElog: 9.0177 grad_loss: 24185.5312 normal_loss: 0.6785
[epoch 17][iter  480] loss: 116052.2578 RMSElog: 8.2987 grad_loss: 11596.2676 normal_loss: 0.6588
[epoch 17][iter  490] loss: 119637.5000 RMSElog: 8.5619 grad_loss: 11954.5459 normal_loss: 0.6423
[epoch 17][iter  500] loss: 128302.1094 RMSElog: 8.6103 grad_loss: 12820.9326 normal_loss: 0.6684
[epoch 17][iter  510] loss: 183073.6250 RMSElog: 8.6287 grad_loss: 18298.0430 normal_loss: 0.6907
[epoch 17][iter  520] loss: 144568.9219 RMSElog: 8.0976 grad_loss: 14448.0664 normal_loss: 0.7290
[epoch 17][iter  530] loss: 104457.1406 RMSElog: 8.1460 grad_loss: 10436.9229 normal_loss: 0.6454
[epoch 17][iter  540] loss: 233376.3281 RMSElog: 9.0005 grad_loss: 23327.9648 normal_loss: 0.6686
[epoch 17][iter  550] loss: 167191.6875 RMSElog: 8.7865 grad_loss: 16709.6992 normal_loss: 0.6822
[epoch 17][iter  560] loss: 112835.5391 RMSElog: 8.4678 grad_loss: 11274.4043 normal_loss: 0.6813
[epoch 17][iter  570] loss: 157043.0156 RMSElog: 8.8617 grad_loss: 15694.7832 normal_loss: 0.6573
[epoch 17][iter  580] loss: 156154.1875 RMSElog: 8.8532 grad_loss: 15605.9229 normal_loss: 0.6417
[epoch 17][iter  590] loss: 176892.2031 RMSElog: 8.9621 grad_loss: 17679.6016 normal_loss: 0.6566
[epoch 18][iter    0] loss: 137244.2344 RMSElog: 8.8836 grad_loss: 13714.7793 normal_loss: 0.7594
[epoch 18][iter   10] loss: 156154.1875 RMSElog: 8.8531 grad_loss: 15605.9229 normal_loss: 0.6417
[epoch 18][iter   20] loss: 165732.1719 RMSElog: 8.8410 grad_loss: 16563.7129 normal_loss: 0.6615
[epoch 18][iter   30] loss: 218748.1562 RMSElog: 9.3937 grad_loss: 21864.5273 normal_loss: 0.8937
[epoch 18][iter   40] loss: 154289.4062 RMSElog: 8.6400 grad_loss: 15419.6543 normal_loss: 0.6475
[epoch 18][iter   50] loss: 138589.8438 RMSElog: 8.5968 grad_loss: 13849.6982 normal_loss: 0.6894
[epoch 18][iter   60] loss: 124615.0000 RMSElog: 8.5033 grad_loss: 12452.3281 normal_loss: 0.6689
[epoch 18][iter   70] loss: 141942.3281 RMSElog: 8.4999 grad_loss: 14185.0547 normal_loss: 0.6779
[epoch 18][iter   80] loss: 139415.3750 RMSElog: 8.6540 grad_loss: 13932.2285 normal_loss: 0.6543
[epoch 18][iter   90] loss: 106928.9219 RMSElog: 8.3336 grad_loss: 10683.8945 normal_loss: 0.6642
[epoch 18][iter  100] loss: 111645.6172 RMSElog: 8.6174 grad_loss: 11155.2041 normal_loss: 0.7406
[epoch 18][iter  110] loss: 142523.0156 RMSElog: 8.8151 grad_loss: 14242.8330 normal_loss: 0.6536
[epoch 18][iter  120] loss: 176892.1875 RMSElog: 8.9610 grad_loss: 17679.6016 normal_loss: 0.6566
[epoch 18][iter  130] loss: 146764.3906 RMSElog: 8.7671 grad_loss: 14666.9775 normal_loss: 0.6934
[epoch 18][iter  140] loss: 139858.0469 RMSElog: 8.2703 grad_loss: 13976.7832 normal_loss: 0.7512
[epoch 18][iter  150] loss: 180962.8750 RMSElog: 8.9812 grad_loss: 18086.6191 normal_loss: 0.6870
[epoch 18][iter  160] loss: 112368.8672 RMSElog: 8.1199 grad_loss: 11228.0977 normal_loss: 0.6692
[epoch 18][iter  170] loss: 111900.7656 RMSElog: 8.4361 grad_loss: 11180.9336 normal_loss: 0.7059
[epoch 18][iter  180] loss: 121168.3906 RMSElog: 8.7411 grad_loss: 12107.3525 normal_loss: 0.7452
[epoch 18][iter  190] loss: 100646.2891 RMSElog: 8.7663 grad_loss: 10055.1777 normal_loss: 0.6849
[epoch 18][iter  200] loss: 161068.3281 RMSElog: 8.6725 grad_loss: 16097.5000 normal_loss: 0.6600
[epoch 18][iter  210] loss: 104316.4922 RMSElog: 8.0507 grad_loss: 10422.9375 normal_loss: 0.6613
[epoch 18][iter  220] loss: 210634.8594 RMSElog: 9.1791 grad_loss: 21053.6172 normal_loss: 0.6901
[epoch 18][iter  230] loss: 137275.7188 RMSElog: 8.5628 grad_loss: 13718.3311 normal_loss: 0.6773
[epoch 18][iter  240] loss: 158614.6562 RMSElog: 8.8493 grad_loss: 15851.9229 normal_loss: 0.6932
[epoch 18][iter  250] loss: 181446.7344 RMSElog: 8.8961 grad_loss: 18135.0762 normal_loss: 0.7015
[epoch 18][iter  260] loss: 165633.4531 RMSElog: 8.8099 grad_loss: 16553.8262 normal_loss: 0.7097
[epoch 18][iter  270] loss: 167728.5000 RMSElog: 8.8758 grad_loss: 16763.2734 normal_loss: 0.7008
[epoch 18][iter  280] loss: 166054.3125 RMSElog: 8.7677 grad_loss: 16595.9648 normal_loss: 0.6991
[epoch 18][iter  290] loss: 150132.2031 RMSElog: 8.7519 grad_loss: 15003.8066 normal_loss: 0.6608
[epoch 18][iter  300] loss: 95206.3984 RMSElog: 8.3174 grad_loss: 9511.6543 normal_loss: 0.6678
[epoch 18][iter  310] loss: 128257.8750 RMSElog: 8.5072 grad_loss: 12816.6299 normal_loss: 0.6507
[epoch 18][iter  320] loss: 113898.4297 RMSElog: 8.0929 grad_loss: 11381.0732 normal_loss: 0.6770
[epoch 18][iter  330] loss: 147441.0312 RMSElog: 8.4963 grad_loss: 14734.9131 normal_loss: 0.6934
[epoch 18][iter  340] loss: 114903.1953 RMSElog: 8.2716 grad_loss: 11481.3818 normal_loss: 0.6658
[epoch 18][iter  350] loss: 214470.3906 RMSElog: 8.8807 grad_loss: 21437.5000 normal_loss: 0.6587
[epoch 18][iter  360] loss: 175102.8906 RMSElog: 8.7097 grad_loss: 17500.8945 normal_loss: 0.6849
[epoch 18][iter  370] loss: 142242.1562 RMSElog: 8.4496 grad_loss: 14215.0625 normal_loss: 0.7045
[epoch 18][iter  380] loss: 145597.8281 RMSElog: 8.8225 grad_loss: 14550.2988 normal_loss: 0.6613
[epoch 18][iter  390] loss: 133026.5312 RMSElog: 8.6615 grad_loss: 13293.3359 normal_loss: 0.6565
[epoch 18][iter  400] loss: 120269.0938 RMSElog: 8.2399 grad_loss: 12018.0039 normal_loss: 0.6649
[epoch 18][iter  410] loss: 103500.0312 RMSElog: 8.5433 grad_loss: 10340.7930 normal_loss: 0.6670
[epoch 18][iter  420] loss: 150441.7344 RMSElog: 8.7145 grad_loss: 15034.7461 normal_loss: 0.7121
[epoch 18][iter  430] loss: 136045.2188 RMSElog: 8.3149 grad_loss: 13595.5195 normal_loss: 0.6889
[epoch 18][iter  440] loss: 224056.5000 RMSElog: 9.0302 grad_loss: 22395.9473 normal_loss: 0.6732
[epoch 18][iter  450] loss: 164750.1875 RMSElog: 8.7531 grad_loss: 16465.5742 normal_loss: 0.6921
[epoch 18][iter  460] loss: 153480.7656 RMSElog: 8.8323 grad_loss: 15338.5986 normal_loss: 0.6457
[epoch 18][iter  470] loss: 213396.0938 RMSElog: 8.9660 grad_loss: 21329.9590 normal_loss: 0.6833
[epoch 18][iter  480] loss: 125490.4609 RMSElog: 8.8237 grad_loss: 12539.5156 normal_loss: 0.7056
[epoch 18][iter  490] loss: 211905.6406 RMSElog: 8.8647 grad_loss: 21181.0371 normal_loss: 0.6625
[epoch 18][iter  500] loss: 144568.9219 RMSElog: 8.0961 grad_loss: 14448.0664 normal_loss: 0.7292
[epoch 18][iter  510] loss: 140919.0156 RMSElog: 8.4683 grad_loss: 14082.7637 normal_loss: 0.6687
[epoch 18][iter  520] loss: 167723.1562 RMSElog: 8.8399 grad_loss: 16762.7812 normal_loss: 0.6955
[epoch 18][iter  530] loss: 180730.4844 RMSElog: 8.8802 grad_loss: 18063.4980 normal_loss: 0.6696
[epoch 18][iter  540] loss: 214753.3125 RMSElog: 8.8272 grad_loss: 21465.8496 normal_loss: 0.6540
[epoch 18][iter  550] loss: 191801.6406 RMSElog: 8.7741 grad_loss: 19170.7500 normal_loss: 0.6414
[epoch 18][iter  560] loss: 174612.8438 RMSElog: 8.8087 grad_loss: 17451.7617 normal_loss: 0.7139
[epoch 18][iter  570] loss: 200933.8750 RMSElog: 8.8635 grad_loss: 20083.8320 normal_loss: 0.6921
[epoch 18][iter  580] loss: 160806.4375 RMSElog: 8.8164 grad_loss: 16071.1807 normal_loss: 0.6461
[epoch 18][iter  590] loss: 161266.5312 RMSElog: 8.7470 grad_loss: 16117.2510 normal_loss: 0.6549
[epoch 19][iter    0] loss: 147525.3594 RMSElog: 8.7397 grad_loss: 14743.1357 normal_loss: 0.6616
[epoch 19][iter   10] loss: 183994.6719 RMSElog: 8.5617 grad_loss: 18390.2129 normal_loss: 0.6911
[epoch 19][iter   20] loss: 138041.0000 RMSElog: 8.4986 grad_loss: 13794.9229 normal_loss: 0.6790
[epoch 19][iter   30] loss: 200934.3750 RMSElog: 8.9082 grad_loss: 20083.8418 normal_loss: 0.6874
[epoch 19][iter   40] loss: 148773.9688 RMSElog: 8.8061 grad_loss: 14867.9062 normal_loss: 0.6845
[epoch 19][iter   50] loss: 165733.4375 RMSElog: 8.8889 grad_loss: 16563.7637 normal_loss: 0.6910
[epoch 19][iter   60] loss: 135093.4531 RMSElog: 8.5730 grad_loss: 13500.1172 normal_loss: 0.6543
[epoch 19][iter   70] loss: 105682.3906 RMSElog: 8.0518 grad_loss: 10559.5273 normal_loss: 0.6604
[epoch 19][iter   80] loss: 173145.7812 RMSElog: 8.6008 grad_loss: 17305.2754 normal_loss: 0.7006
[epoch 19][iter   90] loss: 125808.1641 RMSElog: 8.3699 grad_loss: 12571.7686 normal_loss: 0.6776
[epoch 19][iter  100] loss: 105075.4062 RMSElog: 8.1074 grad_loss: 10498.7646 normal_loss: 0.6688
[epoch 19][iter  110] loss: 217892.0156 RMSElog: 8.8634 grad_loss: 21779.6914 normal_loss: 0.6458
[epoch 19][iter  120] loss: 114487.0469 RMSElog: 8.2421 grad_loss: 11439.7871 normal_loss: 0.6756
[epoch 19][iter  130] loss: 115479.1484 RMSElog: 8.4971 grad_loss: 11538.7549 normal_loss: 0.6630
[epoch 19][iter  140] loss: 145303.0156 RMSElog: 8.6264 grad_loss: 14521.0205 normal_loss: 0.6553
[epoch 19][iter  150] loss: 198272.0156 RMSElog: 8.8019 grad_loss: 19817.7402 normal_loss: 0.6587
[epoch 19][iter  160] loss: 153978.8281 RMSElog: 8.6078 grad_loss: 15388.6279 normal_loss: 0.6479
[epoch 19][iter  170] loss: 204628.5781 RMSElog: 8.8828 grad_loss: 20453.3184 normal_loss: 0.6557
[epoch 19][iter  180] loss: 190917.3125 RMSElog: 9.0334 grad_loss: 19082.0293 normal_loss: 0.6689
[epoch 19][iter  190] loss: 129149.1875 RMSElog: 8.7090 grad_loss: 12905.5381 normal_loss: 0.6723
[epoch 19][iter  200] loss: 227059.7188 RMSElog: 9.0941 grad_loss: 22696.2207 normal_loss: 0.6575
[epoch 19][iter  210] loss: 158014.0938 RMSElog: 8.7556 grad_loss: 15792.0020 normal_loss: 0.6527
[epoch 19][iter  220] loss: 170340.5000 RMSElog: 8.9567 grad_loss: 17024.4121 normal_loss: 0.6808
[epoch 19][iter  230] loss: 179630.0938 RMSElog: 8.9633 grad_loss: 17953.3555 normal_loss: 0.6906
[epoch 19][iter  240] loss: 179884.8438 RMSElog: 8.8189 grad_loss: 17978.9629 normal_loss: 0.7034
[epoch 19][iter  250] loss: 178062.0156 RMSElog: 8.8829 grad_loss: 17796.5879 normal_loss: 0.7305
[epoch 19][iter  260] loss: 164750.6094 RMSElog: 8.7747 grad_loss: 16465.5879 normal_loss: 0.6965
[epoch 19][iter  270] loss: 142242.1719 RMSElog: 8.4493 grad_loss: 14215.0625 normal_loss: 0.7048
[epoch 19][iter  280] loss: 130725.8594 RMSElog: 8.7316 grad_loss: 13063.1260 normal_loss: 0.7282
[epoch 19][iter  290] loss: 112835.5156 RMSElog: 8.4669 grad_loss: 11274.4043 normal_loss: 0.6809
[epoch 19][iter  300] loss: 131196.7344 RMSElog: 8.5790 grad_loss: 13110.3828 normal_loss: 0.7111
[epoch 19][iter  310] loss: 107882.7422 RMSElog: 8.0593 grad_loss: 10779.5605 normal_loss: 0.6544
[epoch 19][iter  320] loss: 167398.9219 RMSElog: 8.8027 grad_loss: 16730.3594 normal_loss: 0.7314
[epoch 19][iter  330] loss: 163249.8750 RMSElog: 8.8312 grad_loss: 16315.4824 normal_loss: 0.6743
[epoch 19][iter  340] loss: 121848.8984 RMSElog: 8.5166 grad_loss: 12175.6533 normal_loss: 0.7193
[epoch 19][iter  350] loss: 163235.8281 RMSElog: 8.8212 grad_loss: 16314.0762 normal_loss: 0.6856
[epoch 19][iter  360] loss: 175282.4219 RMSElog: 8.6128 grad_loss: 17518.9375 normal_loss: 0.6906
[epoch 19][iter  370] loss: 123515.1484 RMSElog: 8.7098 grad_loss: 12342.0430 normal_loss: 0.7614
[epoch 19][iter  380] loss: 203000.4844 RMSElog: 8.8288 grad_loss: 20290.5684 normal_loss: 0.6527
[epoch 19][iter  390] loss: 161267.0938 RMSElog: 8.7757 grad_loss: 16117.2773 normal_loss: 0.6570
[epoch 19][iter  400] loss: 162560.7812 RMSElog: 8.9154 grad_loss: 16246.4639 normal_loss: 0.6991
[epoch 19][iter  410] loss: 130410.0391 RMSElog: 8.5277 grad_loss: 13031.8184 normal_loss: 0.6582
[epoch 19][iter  420] loss: 210500.9375 RMSElog: 8.9675 grad_loss: 21040.4766 normal_loss: 0.6502
[epoch 19][iter  430] loss: 163681.8125 RMSElog: 8.8063 grad_loss: 16358.6289 normal_loss: 0.7462
[epoch 19][iter  440] loss: 136045.2344 RMSElog: 8.3150 grad_loss: 13595.5195 normal_loss: 0.6887
[epoch 19][iter  450] loss: 107923.9922 RMSElog: 8.0551 grad_loss: 10783.6826 normal_loss: 0.6620
[epoch 19][iter  460] loss: 232751.6406 RMSElog: 9.0185 grad_loss: 23265.4766 normal_loss: 0.6701
[epoch 19][iter  470] loss: 166190.8438 RMSElog: 8.8382 grad_loss: 16609.5586 normal_loss: 0.6867
[epoch 19][iter  480] loss: 120426.6797 RMSElog: 8.3734 grad_loss: 12033.6084 normal_loss: 0.6870
[epoch 19][iter  490] loss: 167777.8750 RMSElog: 8.8634 grad_loss: 16768.2324 normal_loss: 0.6909
[epoch 19][iter  500] loss: 197694.9062 RMSElog: 9.1330 grad_loss: 19759.6895 normal_loss: 0.6681
[epoch 19][iter  510] loss: 153481.7656 RMSElog: 8.8760 grad_loss: 15338.6426 normal_loss: 0.6577
[epoch 19][iter  520] loss: 100093.3203 RMSElog: 8.2967 grad_loss: 10000.3711 normal_loss: 0.6636
[epoch 19][iter  530] loss: 188998.9219 RMSElog: 8.9417 grad_loss: 18890.2578 normal_loss: 0.6930
[epoch 19][iter  540] loss: 214787.4062 RMSElog: 8.8489 grad_loss: 21469.2344 normal_loss: 0.6555
[epoch 19][iter  550] loss: 112673.8281 RMSElog: 8.1485 grad_loss: 11258.5732 normal_loss: 0.6616
[epoch 19][iter  560] loss: 111900.7500 RMSElog: 8.4357 grad_loss: 11180.9336 normal_loss: 0.7058
[epoch 19][iter  570] loss: 124228.9141 RMSElog: 8.6064 grad_loss: 12413.6025 normal_loss: 0.6831
[epoch 19][iter  580] loss: 122661.7812 RMSElog: 8.7050 grad_loss: 12256.6172 normal_loss: 0.8551
[epoch 19][iter  590] loss: 133005.2344 RMSElog: 8.5094 grad_loss: 13291.3789 normal_loss: 0.6343
[epoch 20][iter    0] loss: 106157.8125 RMSElog: 8.0429 grad_loss: 10607.0791 normal_loss: 0.6589
[epoch 20][iter   10] loss: 173836.4688 RMSElog: 8.8775 grad_loss: 17374.0723 normal_loss: 0.6980
[epoch 20][iter   20] loss: 143594.6875 RMSElog: 8.5870 grad_loss: 14350.1875 normal_loss: 0.6942
[epoch 20][iter   30] loss: 110864.7656 RMSElog: 8.6914 grad_loss: 11077.0518 normal_loss: 0.7332
[epoch 20][iter   40] loss: 142575.9531 RMSElog: 8.6049 grad_loss: 14248.3340 normal_loss: 0.6573
[epoch 20][iter   50] loss: 112693.4688 RMSElog: 8.1198 grad_loss: 11260.5459 normal_loss: 0.6804
[epoch 20][iter   60] loss: 129143.2812 RMSElog: 8.6660 grad_loss: 12904.9668 normal_loss: 0.6951
[epoch 20][iter   70] loss: 163235.8281 RMSElog: 8.8211 grad_loss: 16314.0762 normal_loss: 0.6855
[epoch 20][iter   80] loss: 162415.7344 RMSElog: 8.8348 grad_loss: 16232.0723 normal_loss: 0.6661
[epoch 20][iter   90] loss: 161794.1250 RMSElog: 8.8742 grad_loss: 16169.8848 normal_loss: 0.6530
[epoch 20][iter  100] loss: 72273.2734 RMSElog: 8.4746 grad_loss: 7218.1924 normal_loss: 0.6604
[epoch 20][iter  110] loss: 100958.6641 RMSElog: 8.1503 grad_loss: 10087.0684 normal_loss: 0.6470
[epoch 20][iter  120] loss: 150132.2031 RMSElog: 8.7516 grad_loss: 15003.8066 normal_loss: 0.6609
[epoch 20][iter  130] loss: 142523.0000 RMSElog: 8.8147 grad_loss: 14242.8330 normal_loss: 0.6536
[epoch 20][iter  140] loss: 113404.2031 RMSElog: 8.1836 grad_loss: 11331.5605 normal_loss: 0.6756
[epoch 20][iter  150] loss: 176244.5625 RMSElog: 9.0361 grad_loss: 17614.7246 normal_loss: 0.6963
[epoch 20][iter  160] loss: 120426.5547 RMSElog: 8.3581 grad_loss: 12033.6055 normal_loss: 0.6916
[epoch 20][iter  170] loss: 159323.0312 RMSElog: 8.8833 grad_loss: 15922.7256 normal_loss: 0.6941
[epoch 20][iter  180] loss: 201353.6875 RMSElog: 9.0794 grad_loss: 20125.6133 normal_loss: 0.6749
[epoch 20][iter  190] loss: 105872.1094 RMSElog: 8.0501 grad_loss: 10578.5137 normal_loss: 0.6472
[epoch 20][iter  200] loss: 125265.6875 RMSElog: 8.4421 grad_loss: 12517.3936 normal_loss: 0.7322
[epoch 20][iter  210] loss: 162874.9062 RMSElog: 8.8290 grad_loss: 16278.0000 normal_loss: 0.6623
[epoch 20][iter  220] loss: 160449.9375 RMSElog: 8.8725 grad_loss: 16035.4414 normal_loss: 0.6793
[epoch 20][iter  230] loss: 112518.0391 RMSElog: 8.5107 grad_loss: 11242.6270 normal_loss: 0.6663
[epoch 20][iter  240] loss: 190952.1250 RMSElog: 8.8476 grad_loss: 19085.6953 normal_loss: 0.6692
[epoch 20][iter  250] loss: 163759.1562 RMSElog: 8.7172 grad_loss: 16366.4795 normal_loss: 0.7191
[epoch 20][iter  260] loss: 165290.2969 RMSElog: 8.8961 grad_loss: 16519.4277 normal_loss: 0.7056
[epoch 20][iter  270] loss: 193003.2031 RMSElog: 8.6328 grad_loss: 19290.9941 normal_loss: 0.6933
[epoch 20][iter  280] loss: 194386.9531 RMSElog: 8.8334 grad_loss: 19429.1914 normal_loss: 0.6696
[epoch 20][iter  290] loss: 107049.5938 RMSElog: 8.0694 grad_loss: 10696.2256 normal_loss: 0.6642
[epoch 20][iter  300] loss: 160806.4219 RMSElog: 8.8165 grad_loss: 16071.1807 normal_loss: 0.6460
[epoch 20][iter  310] loss: 115641.2578 RMSElog: 8.5842 grad_loss: 11554.8145 normal_loss: 0.7277
[epoch 20][iter  320] loss: 123073.1953 RMSElog: 8.2881 grad_loss: 12298.3486 normal_loss: 0.6828
[epoch 20][iter  330] loss: 104725.2266 RMSElog: 8.0866 grad_loss: 10463.7803 normal_loss: 0.6550
[epoch 20][iter  340] loss: 162355.8281 RMSElog: 8.8226 grad_loss: 16226.0605 normal_loss: 0.7002
[epoch 20][iter  350] loss: 128958.4688 RMSElog: 8.3037 grad_loss: 12886.8594 normal_loss: 0.6834
[epoch 20][iter  360] loss: 170339.7500 RMSElog: 8.9149 grad_loss: 17024.3867 normal_loss: 0.6747
[epoch 20][iter  370] loss: 174986.3281 RMSElog: 8.8613 grad_loss: 17489.0605 normal_loss: 0.7118
[epoch 20][iter  380] loss: 141846.2188 RMSElog: 8.4371 grad_loss: 14175.4834 normal_loss: 0.7000
[epoch 20][iter  390] loss: 130410.4219 RMSElog: 8.5526 grad_loss: 13031.8320 normal_loss: 0.6568
[epoch 20][iter  400] loss: 177688.0938 RMSElog: 8.8194 grad_loss: 17759.2461 normal_loss: 0.7423
[epoch 20][iter  410] loss: 170471.5312 RMSElog: 8.7744 grad_loss: 17037.7109 normal_loss: 0.6664
[epoch 20][iter  420] loss: 109417.8438 RMSElog: 8.0673 grad_loss: 10933.0430 normal_loss: 0.6740
[epoch 20][iter  430] loss: 100625.3828 RMSElog: 8.0308 grad_loss: 10053.8682 normal_loss: 0.6388
[epoch 20][iter  440] loss: 186032.5625 RMSElog: 8.8528 grad_loss: 18593.7266 normal_loss: 0.6755
[epoch 20][iter  450] loss: 226929.5469 RMSElog: 8.9595 grad_loss: 22683.3359 normal_loss: 0.6610
[epoch 20][iter  460] loss: 178452.7969 RMSElog: 8.8895 grad_loss: 17835.6836 normal_loss: 0.7068
[epoch 20][iter  470] loss: 212217.5156 RMSElog: 8.9113 grad_loss: 21212.1914 normal_loss: 0.6480
[epoch 20][iter  480] loss: 175103.5312 RMSElog: 8.7374 grad_loss: 17500.9219 normal_loss: 0.6940
[epoch 20][iter  490] loss: 157043.0156 RMSElog: 8.8614 grad_loss: 15694.7832 normal_loss: 0.6573
[epoch 20][iter  500] loss: 165632.8750 RMSElog: 8.7815 grad_loss: 16553.8047 normal_loss: 0.7009
[epoch 20][iter  510] loss: 174548.3750 RMSElog: 8.7424 grad_loss: 17445.4062 normal_loss: 0.6887
[epoch 20][iter  520] loss: 214753.3125 RMSElog: 8.8272 grad_loss: 21465.8496 normal_loss: 0.6538
[epoch 20][iter  530] loss: 175917.2500 RMSElog: 9.0507 grad_loss: 17581.9629 normal_loss: 0.7113
[epoch 20][iter  540] loss: 103289.8281 RMSElog: 8.5838 grad_loss: 10319.7227 normal_loss: 0.6755
[epoch 20][iter  550] loss: 196819.8125 RMSElog: 8.7076 grad_loss: 19672.6211 normal_loss: 0.6519
[epoch 20][iter  560] loss: 202096.9688 RMSElog: 8.7439 grad_loss: 20200.3008 normal_loss: 0.6530
[epoch 20][iter  570] loss: 154145.9219 RMSElog: 8.8672 grad_loss: 15405.0693 normal_loss: 0.6555
[epoch 20][iter  580] loss: 105075.4062 RMSElog: 8.1071 grad_loss: 10498.7646 normal_loss: 0.6689
[epoch 20][iter  590] loss: 150440.8125 RMSElog: 8.6557 grad_loss: 15034.7168 normal_loss: 0.7099
[epoch 21][iter    0] loss: 163375.4219 RMSElog: 8.8311 grad_loss: 16327.9795 normal_loss: 0.7312
[epoch 21][iter   10] loss: 147747.3125 RMSElog: 8.6398 grad_loss: 14765.3564 normal_loss: 0.7351
[epoch 21][iter   20] loss: 188696.6562 RMSElog: 8.7152 grad_loss: 18860.2715 normal_loss: 0.6793
[epoch 21][iter   30] loss: 196003.9688 RMSElog: 8.8262 grad_loss: 19590.9082 normal_loss: 0.6629
[epoch 21][iter   40] loss: 172739.7188 RMSElog: 8.9944 grad_loss: 17264.2676 normal_loss: 0.7100
[epoch 21][iter   50] loss: 167192.5156 RMSElog: 8.8179 grad_loss: 16709.7441 normal_loss: 0.6889
[epoch 21][iter   60] loss: 100729.4141 RMSElog: 8.6347 grad_loss: 10063.6396 normal_loss: 0.6668
[epoch 21][iter   70] loss: 199052.5312 RMSElog: 8.8682 grad_loss: 19895.6797 normal_loss: 0.7062
[epoch 21][iter   80] loss: 161266.5312 RMSElog: 8.7469 grad_loss: 16117.2510 normal_loss: 0.6549
[epoch 21][iter   90] loss: 140447.2188 RMSElog: 8.7898 grad_loss: 14035.1064 normal_loss: 0.8257
[epoch 21][iter  100] loss: 112297.4219 RMSElog: 8.2072 grad_loss: 11220.8594 normal_loss: 0.6755
[epoch 21][iter  110] loss: 130410.0391 RMSElog: 8.5275 grad_loss: 13031.8184 normal_loss: 0.6584
[epoch 21][iter  120] loss: 177919.3438 RMSElog: 8.9593 grad_loss: 17782.2617 normal_loss: 0.7139
[epoch 21][iter  130] loss: 117673.9922 RMSElog: 8.3549 grad_loss: 11758.3711 normal_loss: 0.6738
[epoch 21][iter  140] loss: 124542.1094 RMSElog: 8.5168 grad_loss: 12445.0342 normal_loss: 0.6598
[epoch 21][iter  150] loss: 211617.9844 RMSElog: 8.8839 grad_loss: 21152.2637 normal_loss: 0.6512
[epoch 21][iter  160] loss: 112517.4922 RMSElog: 8.4823 grad_loss: 11242.6064 normal_loss: 0.6601
[epoch 21][iter  170] loss: 215522.2188 RMSElog: 9.1081 grad_loss: 21542.4395 normal_loss: 0.6749
[epoch 21][iter  180] loss: 140035.8750 RMSElog: 8.6432 grad_loss: 13994.2881 normal_loss: 0.6550
[epoch 21][iter  190] loss: 178452.7969 RMSElog: 8.8894 grad_loss: 17835.6836 normal_loss: 0.7067
[epoch 21][iter  200] loss: 103935.7656 RMSElog: 8.3432 grad_loss: 10384.5508 normal_loss: 0.6828
[epoch 21][iter  210] loss: 125664.1719 RMSElog: 8.5535 grad_loss: 12557.1719 normal_loss: 0.6913
[epoch 21][iter  220] loss: 193959.2188 RMSElog: 9.0665 grad_loss: 19386.1738 normal_loss: 0.6823
[epoch 21][iter  230] loss: 170340.5000 RMSElog: 8.9568 grad_loss: 17024.4121 normal_loss: 0.6808
[epoch 21][iter  240] loss: 133267.8438 RMSElog: 8.6645 grad_loss: 13317.4697 normal_loss: 0.6514
[epoch 21][iter  250] loss: 172667.9062 RMSElog: 8.9451 grad_loss: 17257.1504 normal_loss: 0.6954
[epoch 21][iter  260] loss: 104111.6562 RMSElog: 8.6245 grad_loss: 10401.8545 normal_loss: 0.6865
[epoch 21][iter  270] loss: 176476.9531 RMSElog: 8.8026 grad_loss: 17638.2012 normal_loss: 0.6911
[epoch 21][iter  280] loss: 166526.6562 RMSElog: 8.9622 grad_loss: 16643.0117 normal_loss: 0.6905
[epoch 21][iter  290] loss: 127096.7031 RMSElog: 8.6422 grad_loss: 12700.2891 normal_loss: 0.7387
[epoch 21][iter  300] loss: 125489.9219 RMSElog: 8.7874 grad_loss: 12539.5010 normal_loss: 0.7045
[epoch 21][iter  310] loss: 105877.3906 RMSElog: 8.4264 grad_loss: 10578.6348 normal_loss: 0.6781
[epoch 21][iter  320] loss: 126949.7734 RMSElog: 8.4499 grad_loss: 12685.8584 normal_loss: 0.6690
[epoch 21][iter  330] loss: 228033.1406 RMSElog: 8.9206 grad_loss: 22793.7188 normal_loss: 0.6767
[epoch 21][iter  340] loss: 151334.6562 RMSElog: 8.6861 grad_loss: 15124.1318 normal_loss: 0.6469
[epoch 21][iter  350] loss: 144638.3438 RMSElog: 8.7167 grad_loss: 14454.4873 normal_loss: 0.6298
[epoch 21][iter  360] loss: 120722.7344 RMSElog: 8.2590 grad_loss: 12063.3574 normal_loss: 0.6572
[epoch 21][iter  370] loss: 138589.8438 RMSElog: 8.5968 grad_loss: 13849.6982 normal_loss: 0.6895
[epoch 21][iter  380] loss: 187216.7812 RMSElog: 8.8463 grad_loss: 18712.1602 normal_loss: 0.6724
[epoch 21][iter  390] loss: 155464.4375 RMSElog: 8.9915 grad_loss: 15536.7920 normal_loss: 0.6608
[epoch 21][iter  400] loss: 115342.8828 RMSElog: 8.5145 grad_loss: 11525.0703 normal_loss: 0.7027
[epoch 21][iter  410] loss: 175528.5938 RMSElog: 8.8321 grad_loss: 17543.3457 normal_loss: 0.6811
[epoch 21][iter  420] loss: 133448.0000 RMSElog: 8.6459 grad_loss: 13335.4834 normal_loss: 0.6716
[epoch 21][iter  430] loss: 150347.3125 RMSElog: 8.8547 grad_loss: 15025.1875 normal_loss: 0.6895
[epoch 21][iter  440] loss: 174331.3438 RMSElog: 8.7536 grad_loss: 17423.6934 normal_loss: 0.6872
[epoch 21][iter  450] loss: 100625.3828 RMSElog: 8.0311 grad_loss: 10053.8682 normal_loss: 0.6386
[epoch 21][iter  460] loss: 144568.9219 RMSElog: 8.0966 grad_loss: 14448.0664 normal_loss: 0.7288
[epoch 21][iter  470] loss: 196255.0156 RMSElog: 8.7686 grad_loss: 19616.0762 normal_loss: 0.6568
[epoch 21][iter  480] loss: 173703.9062 RMSElog: 8.9514 grad_loss: 17360.7305 normal_loss: 0.7092
[epoch 21][iter  490] loss: 120426.5547 RMSElog: 8.3583 grad_loss: 12033.6055 normal_loss: 0.6916
[epoch 21][iter  500] loss: 128471.1719 RMSElog: 8.6923 grad_loss: 12837.7480 normal_loss: 0.6770
[epoch 21][iter  510] loss: 126854.5234 RMSElog: 8.5381 grad_loss: 12676.2705 normal_loss: 0.6433
[epoch 21][iter  520] loss: 190951.1875 RMSElog: 8.7963 grad_loss: 19085.6562 normal_loss: 0.6657
[epoch 21][iter  530] loss: 167765.9219 RMSElog: 8.7633 grad_loss: 16767.1113 normal_loss: 0.7167
[epoch 21][iter  540] loss: 119904.8594 RMSElog: 8.4955 grad_loss: 11981.3525 normal_loss: 0.6383
[epoch 21][iter  550] loss: 156154.1719 RMSElog: 8.8530 grad_loss: 15605.9229 normal_loss: 0.6416
[epoch 21][iter  560] loss: 191187.3594 RMSElog: 8.8388 grad_loss: 19109.1758 normal_loss: 0.7231
[epoch 21][iter  570] loss: 145597.5156 RMSElog: 8.7971 grad_loss: 14550.2881 normal_loss: 0.6671
[epoch 21][iter  580] loss: 148118.4062 RMSElog: 8.7471 grad_loss: 14802.3916 normal_loss: 0.7019
[epoch 21][iter  590] loss: 127482.6406 RMSElog: 8.2794 grad_loss: 12739.3027 normal_loss: 0.6821
[epoch 22][iter    0] loss: 131922.2031 RMSElog: 8.5440 grad_loss: 13183.0234 normal_loss: 0.6533
[epoch 22][iter   10] loss: 112835.5156 RMSElog: 8.4668 grad_loss: 11274.4043 normal_loss: 0.6810
[epoch 22][iter   20] loss: 149524.8281 RMSElog: 8.8364 grad_loss: 14942.9590 normal_loss: 0.6888
[epoch 22][iter   30] loss: 133448.0000 RMSElog: 8.6455 grad_loss: 13335.4824 normal_loss: 0.6718
[epoch 22][iter   40] loss: 159807.5625 RMSElog: 8.8447 grad_loss: 15971.2256 normal_loss: 0.6859
[epoch 22][iter   50] loss: 171571.7188 RMSElog: 8.7124 grad_loss: 17147.7383 normal_loss: 0.7209
[epoch 22][iter   60] loss: 185051.6406 RMSElog: 8.7494 grad_loss: 18495.7168 normal_loss: 0.6965
[epoch 22][iter   70] loss: 198724.3438 RMSElog: 8.8911 grad_loss: 19862.8418 normal_loss: 0.7003
[epoch 22][iter   80] loss: 164163.1562 RMSElog: 8.8566 grad_loss: 16406.7852 normal_loss: 0.6747
[epoch 22][iter   90] loss: 139858.0312 RMSElog: 8.2698 grad_loss: 13976.7832 normal_loss: 0.7513
[epoch 22][iter  100] loss: 155463.4688 RMSElog: 8.9289 grad_loss: 15536.7656 normal_loss: 0.6530
[epoch 22][iter  110] loss: 146195.5312 RMSElog: 8.7193 grad_loss: 14610.1611 normal_loss: 0.6728
[epoch 22][iter  120] loss: 139000.0938 RMSElog: 8.6245 grad_loss: 13890.7109 normal_loss: 0.6742
[epoch 22][iter  130] loss: 177272.4688 RMSElog: 8.8745 grad_loss: 17717.6758 normal_loss: 0.6961
[epoch 22][iter  140] loss: 140447.2188 RMSElog: 8.7897 grad_loss: 14035.1064 normal_loss: 0.8255
[epoch 22][iter  150] loss: 224923.8906 RMSElog: 8.8167 grad_loss: 22482.8867 normal_loss: 0.6848
[epoch 22][iter  160] loss: 110566.8281 RMSElog: 8.6099 grad_loss: 11047.3691 normal_loss: 0.7029
[epoch 22][iter  170] loss: 154270.8438 RMSElog: 8.6615 grad_loss: 15417.7725 normal_loss: 0.6512
[epoch 22][iter  180] loss: 154687.2500 RMSElog: 8.8054 grad_loss: 15459.2461 normal_loss: 0.6743
[epoch 22][iter  190] loss: 126004.6562 RMSElog: 8.4298 grad_loss: 12591.3623 normal_loss: 0.6741
[epoch 22][iter  200] loss: 155892.4844 RMSElog: 8.6518 grad_loss: 15579.9434 normal_loss: 0.6528
[epoch 22][iter  210] loss: 120269.0781 RMSElog: 8.2398 grad_loss: 12018.0039 normal_loss: 0.6645
[epoch 22][iter  220] loss: 115641.6406 RMSElog: 8.5962 grad_loss: 11554.8330 normal_loss: 0.7340
[epoch 22][iter  230] loss: 129724.5781 RMSElog: 8.7336 grad_loss: 12963.0586 normal_loss: 0.6661
[epoch 22][iter  240] loss: 105877.9375 RMSElog: 8.4748 grad_loss: 10578.6416 normal_loss: 0.6773
[epoch 22][iter  250] loss: 191952.9844 RMSElog: 8.8938 grad_loss: 19185.7090 normal_loss: 0.6955
[epoch 22][iter  260] loss: 156963.2500 RMSElog: 8.8586 grad_loss: 15686.8184 normal_loss: 0.6488
[epoch 22][iter  270] loss: 176476.9531 RMSElog: 8.8025 grad_loss: 17638.2012 normal_loss: 0.6912
[epoch 22][iter  280] loss: 191539.4375 RMSElog: 8.6708 grad_loss: 19144.5820 normal_loss: 0.6909
[epoch 22][iter  290] loss: 158908.4062 RMSElog: 8.7985 grad_loss: 15881.3477 normal_loss: 0.6941
[epoch 22][iter  300] loss: 106157.8047 RMSElog: 8.0433 grad_loss: 10607.0791 normal_loss: 0.6585
[epoch 22][iter  310] loss: 112297.4219 RMSElog: 8.2075 grad_loss: 11220.8604 normal_loss: 0.6752
[epoch 22][iter  320] loss: 193958.5312 RMSElog: 9.0228 grad_loss: 19386.1504 normal_loss: 0.6805
[epoch 22][iter  330] loss: 146764.3750 RMSElog: 8.7666 grad_loss: 14666.9775 normal_loss: 0.6933
[epoch 22][iter  340] loss: 127445.1094 RMSElog: 8.3838 grad_loss: 12735.4648 normal_loss: 0.6625
[epoch 22][iter  350] loss: 208164.4531 RMSElog: 9.1080 grad_loss: 20806.6582 normal_loss: 0.6797
[epoch 22][iter  360] loss: 160649.1406 RMSElog: 8.8636 grad_loss: 16055.3887 normal_loss: 0.6623
[epoch 22][iter  370] loss: 116052.2578 RMSElog: 8.2968 grad_loss: 11596.2686 normal_loss: 0.6600
[epoch 22][iter  380] loss: 178577.7344 RMSElog: 8.9075 grad_loss: 17848.1367 normal_loss: 0.7276
[epoch 22][iter  390] loss: 121303.1875 RMSElog: 8.6188 grad_loss: 12120.9570 normal_loss: 0.7421
[epoch 22][iter  400] loss: 141426.1250 RMSElog: 8.6849 grad_loss: 14133.2441 normal_loss: 0.6834
[epoch 22][iter  410] loss: 165937.0156 RMSElog: 8.8791 grad_loss: 16584.1152 normal_loss: 0.7063
[epoch 22][iter  420] loss: 114808.5078 RMSElog: 8.4930 grad_loss: 11471.6719 normal_loss: 0.6858
[epoch 22][iter  430] loss: 175507.2031 RMSElog: 9.0954 grad_loss: 17540.9023 normal_loss: 0.7228
[epoch 22][iter  440] loss: 103935.7734 RMSElog: 8.3433 grad_loss: 10384.5508 normal_loss: 0.6827
[epoch 22][iter  450] loss: 163710.1875 RMSElog: 8.6189 grad_loss: 16361.7002 normal_loss: 0.7001
[epoch 22][iter  460] loss: 202609.5156 RMSElog: 8.7488 grad_loss: 20251.5391 normal_loss: 0.6645
[epoch 22][iter  470] loss: 163235.8281 RMSElog: 8.8212 grad_loss: 16314.0762 normal_loss: 0.6854
[epoch 22][iter  480] loss: 153948.1719 RMSElog: 9.0119 grad_loss: 15385.0498 normal_loss: 0.7556
[epoch 22][iter  490] loss: 194555.7656 RMSElog: 8.7647 grad_loss: 19446.1582 normal_loss: 0.6515
[epoch 22][iter  500] loss: 142676.5938 RMSElog: 8.6456 grad_loss: 14258.3359 normal_loss: 0.6780
[epoch 22][iter  510] loss: 153575.7969 RMSElog: 8.6901 grad_loss: 15348.2373 normal_loss: 0.6523
[epoch 22][iter  520] loss: 125265.6719 RMSElog: 8.4421 grad_loss: 12517.3926 normal_loss: 0.7321
[epoch 22][iter  530] loss: 145303.0312 RMSElog: 8.6270 grad_loss: 14521.0215 normal_loss: 0.6549
[epoch 22][iter  540] loss: 148004.8750 RMSElog: 8.7203 grad_loss: 14791.1074 normal_loss: 0.6605
[epoch 22][iter  550] loss: 152574.4688 RMSElog: 8.5667 grad_loss: 15248.1797 normal_loss: 0.7005
[epoch 22][iter  560] loss: 166989.1875 RMSElog: 8.8055 grad_loss: 16689.4297 normal_loss: 0.6838
[epoch 22][iter  570] loss: 114139.3828 RMSElog: 8.6647 grad_loss: 11404.5322 normal_loss: 0.7407
[epoch 22][iter  580] loss: 118724.0000 RMSElog: 8.2583 grad_loss: 11863.4717 normal_loss: 0.6707
[epoch 22][iter  590] loss: 206381.3438 RMSElog: 9.0255 grad_loss: 20628.4258 normal_loss: 0.6840
[epoch 23][iter    0] loss: 176937.9688 RMSElog: 9.0212 grad_loss: 17684.0703 normal_loss: 0.7055
[epoch 23][iter   10] loss: 158014.0938 RMSElog: 8.7556 grad_loss: 15792.0020 normal_loss: 0.6527
[epoch 23][iter   20] loss: 109236.6250 RMSElog: 8.0865 grad_loss: 10914.9082 normal_loss: 0.6667
[epoch 23][iter   30] loss: 104420.5391 RMSElog: 8.3000 grad_loss: 10433.0898 normal_loss: 0.6639
[epoch 23][iter   40] loss: 153081.2656 RMSElog: 8.6014 grad_loss: 15298.8145 normal_loss: 0.7099
[epoch 23][iter   50] loss: 100646.6719 RMSElog: 8.7976 grad_loss: 10055.1895 normal_loss: 0.6802
[epoch 23][iter   60] loss: 121968.6016 RMSElog: 8.4452 grad_loss: 12187.6816 normal_loss: 0.7335
[epoch 23][iter   70] loss: 129148.3203 RMSElog: 8.8699 grad_loss: 12905.2852 normal_loss: 0.6772
[epoch 23][iter   80] loss: 204628.5781 RMSElog: 8.8827 grad_loss: 20453.3184 normal_loss: 0.6556
[epoch 23][iter   90] loss: 180302.5312 RMSElog: 8.9001 grad_loss: 18020.6484 normal_loss: 0.7053
[epoch 23][iter  100] loss: 182845.3125 RMSElog: 8.9946 grad_loss: 18274.8066 normal_loss: 0.7309
[epoch 23][iter  110] loss: 105717.3906 RMSElog: 7.9983 grad_loss: 10563.0771 normal_loss: 0.6640
[epoch 23][iter  120] loss: 194386.1094 RMSElog: 8.7980 grad_loss: 19429.1543 normal_loss: 0.6582
[epoch 23][iter  130] loss: 200447.7500 RMSElog: 8.7662 grad_loss: 20035.3594 normal_loss: 0.6513
[epoch 23][iter  140] loss: 152521.7031 RMSElog: 8.7277 grad_loss: 15242.7617 normal_loss: 0.6816
[epoch 23][iter  150] loss: 148118.4219 RMSElog: 8.7472 grad_loss: 14802.3926 normal_loss: 0.7018
[epoch 23][iter  160] loss: 127613.0391 RMSElog: 8.4663 grad_loss: 12752.0918 normal_loss: 0.7457
[epoch 23][iter  170] loss: 241952.2500 RMSElog: 9.0134 grad_loss: 24185.5312 normal_loss: 0.6794
[epoch 23][iter  180] loss: 217892.0156 RMSElog: 8.8634 grad_loss: 21779.6914 normal_loss: 0.6456
[epoch 23][iter  190] loss: 196495.8125 RMSElog: 8.6938 grad_loss: 19640.1992 normal_loss: 0.6891
[epoch 23][iter  200] loss: 221068.8906 RMSElog: 9.0495 grad_loss: 22097.1836 normal_loss: 0.6561
[epoch 23][iter  210] loss: 147747.3125 RMSElog: 8.6400 grad_loss: 14765.3564 normal_loss: 0.7349
[epoch 23][iter  220] loss: 167765.9219 RMSElog: 8.7631 grad_loss: 16767.1113 normal_loss: 0.7169
[epoch 23][iter  230] loss: 173949.0469 RMSElog: 8.8486 grad_loss: 17385.3496 normal_loss: 0.7052
[epoch 23][iter  240] loss: 162356.2656 RMSElog: 8.8635 grad_loss: 16226.0645 normal_loss: 0.6982
[epoch 23][iter  250] loss: 211618.7656 RMSElog: 8.9303 grad_loss: 21152.2871 normal_loss: 0.6610
[epoch 23][iter  260] loss: 160449.9375 RMSElog: 8.8721 grad_loss: 16035.4414 normal_loss: 0.6796
[epoch 23][iter  270] loss: 141943.3125 RMSElog: 8.5607 grad_loss: 14185.0801 normal_loss: 0.6918
[epoch 23][iter  280] loss: 108399.6562 RMSElog: 8.6209 grad_loss: 10830.6143 normal_loss: 0.7305
[epoch 23][iter  290] loss: 165436.8594 RMSElog: 8.9550 grad_loss: 16534.0117 normal_loss: 0.7190
[epoch 23][iter  300] loss: 211905.6406 RMSElog: 8.8647 grad_loss: 21181.0371 normal_loss: 0.6625
[epoch 23][iter  310] loss: 134386.5625 RMSElog: 8.7381 grad_loss: 13429.2480 normal_loss: 0.6704
[epoch 23][iter  320] loss: 132686.7500 RMSElog: 8.4944 grad_loss: 13259.5225 normal_loss: 0.6590
[epoch 23][iter  330] loss: 104110.5547 RMSElog: 8.5506 grad_loss: 10401.8262 normal_loss: 0.6783
[epoch 23][iter  340] loss: 135797.0625 RMSElog: 8.4421 grad_loss: 13570.5811 normal_loss: 0.6830
[epoch 23][iter  350] loss: 163768.9531 RMSElog: 8.7484 grad_loss: 16367.4795 normal_loss: 0.6684
[epoch 23][iter  360] loss: 143822.8750 RMSElog: 8.7400 grad_loss: 14372.8730 normal_loss: 0.6750
[epoch 23][iter  370] loss: 149525.4062 RMSElog: 8.8721 grad_loss: 14942.9727 normal_loss: 0.6949
[epoch 23][iter  380] loss: 162561.6875 RMSElog: 8.9569 grad_loss: 16246.4980 normal_loss: 0.7132
[epoch 23][iter  390] loss: 138694.4844 RMSElog: 8.5622 grad_loss: 13860.1514 normal_loss: 0.7346
[epoch 23][iter  400] loss: 72273.2734 RMSElog: 8.4746 grad_loss: 7218.1924 normal_loss: 0.6603
[epoch 23][iter  410] loss: 127445.1094 RMSElog: 8.3838 grad_loss: 12735.4648 normal_loss: 0.6624
[epoch 23][iter  420] loss: 180188.6875 RMSElog: 8.7637 grad_loss: 18009.4102 normal_loss: 0.6952
[epoch 23][iter  430] loss: 106181.8281 RMSElog: 8.4118 grad_loss: 10609.0713 normal_loss: 0.6993
[epoch 23][iter  440] loss: 105603.9844 RMSElog: 8.3317 grad_loss: 10551.3975 normal_loss: 0.6690
[epoch 23][iter  450] loss: 151386.5469 RMSElog: 8.5004 grad_loss: 15129.4385 normal_loss: 0.7169
[epoch 23][iter  460] loss: 150440.8125 RMSElog: 8.6563 grad_loss: 15034.7168 normal_loss: 0.7094
[epoch 23][iter  470] loss: 138589.6094 RMSElog: 8.5774 grad_loss: 13849.6934 normal_loss: 0.6904
[epoch 23][iter  480] loss: 138041.4688 RMSElog: 8.5314 grad_loss: 13794.9395 normal_loss: 0.6764
[epoch 23][iter  490] loss: 196002.9062 RMSElog: 8.7741 grad_loss: 19590.8633 normal_loss: 0.6537
[epoch 23][iter  500] loss: 198724.3125 RMSElog: 8.8912 grad_loss: 19862.8418 normal_loss: 0.7000
[epoch 23][iter  510] loss: 228033.6562 RMSElog: 8.9476 grad_loss: 22793.7383 normal_loss: 0.6792
[epoch 23][iter  520] loss: 167664.1406 RMSElog: 8.9648 grad_loss: 16756.7070 normal_loss: 0.7423
[epoch 23][iter  530] loss: 121303.1875 RMSElog: 8.6190 grad_loss: 12120.9570 normal_loss: 0.7419
[epoch 23][iter  540] loss: 101431.1250 RMSElog: 8.6134 grad_loss: 10133.8242 normal_loss: 0.6750
[epoch 23][iter  550] loss: 193958.5312 RMSElog: 9.0230 grad_loss: 19386.1504 normal_loss: 0.6804
[epoch 23][iter  560] loss: 159806.8906 RMSElog: 8.8102 grad_loss: 15971.1992 normal_loss: 0.6789
[epoch 23][iter  570] loss: 143514.0938 RMSElog: 8.4539 grad_loss: 14342.2578 normal_loss: 0.6972
[epoch 23][iter  580] loss: 143884.8438 RMSElog: 8.7168 grad_loss: 14379.0879 normal_loss: 0.6799
[epoch 23][iter  590] loss: 147525.3594 RMSElog: 8.7394 grad_loss: 14743.1357 normal_loss: 0.6612
[epoch 24][iter    0] loss: 142575.2969 RMSElog: 8.5646 grad_loss: 14248.3066 normal_loss: 0.6581
[epoch 24][iter   10] loss: 177915.9062 RMSElog: 8.7646 grad_loss: 17782.1543 normal_loss: 0.6712
[epoch 24][iter   20] loss: 122366.7656 RMSElog: 8.5424 grad_loss: 12227.4893 normal_loss: 0.6458
[epoch 24][iter   30] loss: 175917.2500 RMSElog: 9.0509 grad_loss: 17581.9629 normal_loss: 0.7112
[epoch 24][iter   40] loss: 144423.4062 RMSElog: 8.8214 grad_loss: 14432.8564 normal_loss: 0.6620
[epoch 24][iter   50] loss: 115646.4141 RMSElog: 8.5316 grad_loss: 11555.3799 normal_loss: 0.7305
[epoch 24][iter   60] loss: 231955.0312 RMSElog: 9.0412 grad_loss: 23185.7812 normal_loss: 0.6823
[epoch 24][iter   70] loss: 133005.2031 RMSElog: 8.5097 grad_loss: 13291.3770 normal_loss: 0.6339
[epoch 24][iter   80] loss: 141845.6719 RMSElog: 8.4052 grad_loss: 14175.4629 normal_loss: 0.6989
[epoch 24][iter   90] loss: 195651.3438 RMSElog: 8.8066 grad_loss: 19555.6504 normal_loss: 0.6769
[epoch 24][iter  100] loss: 124541.4141 RMSElog: 8.4793 grad_loss: 12445.0098 normal_loss: 0.6523
[epoch 24][iter  110] loss: 129149.1875 RMSElog: 8.7091 grad_loss: 12905.5381 normal_loss: 0.6719
[epoch 24][iter  120] loss: 131922.2031 RMSElog: 8.5440 grad_loss: 13183.0234 normal_loss: 0.6532
[epoch 24][iter  130] loss: 141426.1250 RMSElog: 8.6849 grad_loss: 14133.2441 normal_loss: 0.6833
[epoch 24][iter  140] loss: 110579.6172 RMSElog: 8.1406 grad_loss: 11049.1465 normal_loss: 0.6747
[epoch 24][iter  150] loss: 105877.3828 RMSElog: 8.4259 grad_loss: 10578.6348 normal_loss: 0.6782
[epoch 24][iter  160] loss: 131415.9531 RMSElog: 8.4629 grad_loss: 13132.4561 normal_loss: 0.6767
[epoch 24][iter  170] loss: 172667.6719 RMSElog: 8.9278 grad_loss: 17257.1445 normal_loss: 0.6954
[epoch 24][iter  180] loss: 131196.7188 RMSElog: 8.5779 grad_loss: 13110.3828 normal_loss: 0.7111
[epoch 24][iter  190] loss: 224056.5000 RMSElog: 9.0296 grad_loss: 22395.9473 normal_loss: 0.6729
[epoch 24][iter  200] loss: 114139.3750 RMSElog: 8.6648 grad_loss: 11404.5322 normal_loss: 0.7407
[epoch 24][iter  210] loss: 204628.5781 RMSElog: 8.8829 grad_loss: 20453.3184 normal_loss: 0.6555
[epoch 24][iter  220] loss: 103778.7891 RMSElog: 8.3415 grad_loss: 10368.8887 normal_loss: 0.6484
[epoch 24][iter  230] loss: 125297.1016 RMSElog: 8.6319 grad_loss: 12520.4395 normal_loss: 0.6386
[epoch 24][iter  240] loss: 198015.1719 RMSElog: 8.8927 grad_loss: 19791.9590 normal_loss: 0.6663
[epoch 24][iter  250] loss: 217892.9062 RMSElog: 8.9099 grad_loss: 21779.7227 normal_loss: 0.6575
[epoch 24][iter  260] loss: 137238.1562 RMSElog: 9.0285 grad_loss: 13714.0615 normal_loss: 0.7255
[epoch 24][iter  270] loss: 163710.5781 RMSElog: 8.6419 grad_loss: 16361.7100 normal_loss: 0.7057
[epoch 24][iter  280] loss: 158520.1250 RMSElog: 8.7412 grad_loss: 15842.5625 normal_loss: 0.7092
[epoch 24][iter  290] loss: 127096.7031 RMSElog: 8.6422 grad_loss: 12700.2891 normal_loss: 0.7387
[epoch 24][iter  300] loss: 121942.8125 RMSElog: 8.7030 grad_loss: 12184.9111 normal_loss: 0.6674
[epoch 24][iter  310] loss: 134795.4844 RMSElog: 8.3212 grad_loss: 13470.5449 normal_loss: 0.6816
[epoch 24][iter  320] loss: 155463.4688 RMSElog: 8.9288 grad_loss: 15536.7656 normal_loss: 0.6529
[epoch 24][iter  330] loss: 175277.6406 RMSElog: 8.7897 grad_loss: 17518.3125 normal_loss: 0.6628
[epoch 24][iter  340] loss: 213785.9219 RMSElog: 8.8518 grad_loss: 21369.0840 normal_loss: 0.6562
[epoch 24][iter  350] loss: 206381.3438 RMSElog: 9.0256 grad_loss: 20628.4258 normal_loss: 0.6839
[epoch 24][iter  360] loss: 142526.8125 RMSElog: 9.0244 grad_loss: 14242.9805 normal_loss: 0.6770
[epoch 24][iter  370] loss: 137275.7188 RMSElog: 8.5621 grad_loss: 13718.3311 normal_loss: 0.6778
[epoch 24][iter  380] loss: 228319.1562 RMSElog: 9.0375 grad_loss: 22822.2070 normal_loss: 0.6720
[epoch 24][iter  390] loss: 142242.1719 RMSElog: 8.4489 grad_loss: 14215.0635 normal_loss: 0.7049
[epoch 24][iter  400] loss: 181990.6094 RMSElog: 9.0908 grad_loss: 18189.2422 normal_loss: 0.7290
[epoch 24][iter  410] loss: 150132.1875 RMSElog: 8.7514 grad_loss: 15003.8066 normal_loss: 0.6609
[epoch 24][iter  420] loss: 179884.8438 RMSElog: 8.8188 grad_loss: 17978.9629 normal_loss: 0.7034
[epoch 24][iter  430] loss: 135448.4062 RMSElog: 8.7755 grad_loss: 13535.3906 normal_loss: 0.6746
[epoch 24][iter  440] loss: 147353.8438 RMSElog: 8.5689 grad_loss: 14726.1250 normal_loss: 0.6903
[epoch 24][iter  450] loss: 210634.3594 RMSElog: 9.1498 grad_loss: 21053.5957 normal_loss: 0.6894
[epoch 24][iter  460] loss: 178061.5938 RMSElog: 8.8634 grad_loss: 17796.5684 normal_loss: 0.7277
[epoch 24][iter  470] loss: 149524.8281 RMSElog: 8.8363 grad_loss: 14942.9590 normal_loss: 0.6886
[epoch 24][iter  480] loss: 191187.8438 RMSElog: 8.8699 grad_loss: 19109.1973 normal_loss: 0.7195
[epoch 24][iter  490] loss: 148004.8750 RMSElog: 8.7201 grad_loss: 14791.1074 normal_loss: 0.6606
[epoch 24][iter  500] loss: 112835.5156 RMSElog: 8.4665 grad_loss: 11274.4043 normal_loss: 0.6809
[epoch 24][iter  510] loss: 101078.7812 RMSElog: 8.3859 grad_loss: 10098.8496 normal_loss: 0.6423
[epoch 24][iter  520] loss: 196899.1406 RMSElog: 8.9397 grad_loss: 19680.3164 normal_loss: 0.6575
[epoch 24][iter  530] loss: 129724.5781 RMSElog: 8.7332 grad_loss: 12963.0586 normal_loss: 0.6663
[epoch 24][iter  540] loss: 218437.8750 RMSElog: 8.8759 grad_loss: 21834.2578 normal_loss: 0.6536
[epoch 24][iter  550] loss: 161793.4688 RMSElog: 8.8440 grad_loss: 16169.8525 normal_loss: 0.6506
[epoch 24][iter  560] loss: 153978.8125 RMSElog: 8.6079 grad_loss: 15388.6270 normal_loss: 0.6475
[epoch 24][iter  570] loss: 189563.4062 RMSElog: 8.7904 grad_loss: 18946.8594 normal_loss: 0.6894
[epoch 24][iter  580] loss: 124301.6797 RMSElog: 8.2778 grad_loss: 12421.2158 normal_loss: 0.6736
[epoch 24][iter  590] loss: 145302.6094 RMSElog: 8.5927 grad_loss: 14521.0078 normal_loss: 0.6605
[epoch 25][iter    0] loss: 135951.2969 RMSElog: 8.7094 grad_loss: 13585.6992 normal_loss: 0.7213
[epoch 25][iter   10] loss: 117385.6641 RMSElog: 8.3820 grad_loss: 11729.5254 normal_loss: 0.6594
[epoch 25][iter   20] loss: 137236.9688 RMSElog: 8.9351 grad_loss: 13714.0332 normal_loss: 0.7276
[epoch 25][iter   30] loss: 112518.0391 RMSElog: 8.5104 grad_loss: 11242.6270 normal_loss: 0.6664
[epoch 25][iter   40] loss: 233377.1875 RMSElog: 9.0379 grad_loss: 23328.0039 normal_loss: 0.6774
[epoch 25][iter   50] loss: 241952.8906 RMSElog: 9.0355 grad_loss: 24185.5645 normal_loss: 0.6886
[epoch 25][iter   60] loss: 182548.6562 RMSElog: 8.9015 grad_loss: 18245.2715 normal_loss: 0.6922
[epoch 25][iter   70] loss: 174331.3438 RMSElog: 8.7535 grad_loss: 17423.6934 normal_loss: 0.6873
[epoch 25][iter   80] loss: 176937.9688 RMSElog: 9.0213 grad_loss: 17684.0703 normal_loss: 0.7054
[epoch 25][iter   90] loss: 164750.6094 RMSElog: 8.7746 grad_loss: 16465.5879 normal_loss: 0.6965
[epoch 25][iter  100] loss: 175507.2031 RMSElog: 9.0954 grad_loss: 17540.9023 normal_loss: 0.7227
[epoch 25][iter  110] loss: 164579.5469 RMSElog: 8.8200 grad_loss: 16448.4590 normal_loss: 0.6766
[epoch 25][iter  120] loss: 162503.5625 RMSElog: 8.9003 grad_loss: 16240.7998 normal_loss: 0.6559
[epoch 25][iter  130] loss: 138915.2969 RMSElog: 8.6291 grad_loss: 13882.2422 normal_loss: 0.6579
[epoch 25][iter  140] loss: 107883.7188 RMSElog: 8.0994 grad_loss: 10779.6104 normal_loss: 0.6625
[epoch 25][iter  150] loss: 110210.7812 RMSElog: 8.0511 grad_loss: 11012.3711 normal_loss: 0.6567
[epoch 25][iter  160] loss: 213785.9219 RMSElog: 8.8518 grad_loss: 21369.0840 normal_loss: 0.6562
[epoch 25][iter  170] loss: 103500.0312 RMSElog: 8.5433 grad_loss: 10340.7930 normal_loss: 0.6669
[epoch 25][iter  180] loss: 141149.5000 RMSElog: 8.3741 grad_loss: 14105.8799 normal_loss: 0.6951
[epoch 25][iter  190] loss: 129148.3203 RMSElog: 8.8700 grad_loss: 12905.2852 normal_loss: 0.6770
[epoch 25][iter  200] loss: 145391.8906 RMSElog: 8.7154 grad_loss: 14529.7861 normal_loss: 0.6876
[epoch 25][iter  210] loss: 215522.2031 RMSElog: 9.1083 grad_loss: 21542.4395 normal_loss: 0.6745
[epoch 25][iter  220] loss: 216490.1250 RMSElog: 8.9768 grad_loss: 21639.3730 normal_loss: 0.6615
[epoch 25][iter  230] loss: 208164.9844 RMSElog: 9.1407 grad_loss: 20806.6797 normal_loss: 0.6787
[epoch 25][iter  240] loss: 160772.1719 RMSElog: 8.7993 grad_loss: 16067.7324 normal_loss: 0.6866
[epoch 25][iter  250] loss: 178767.1562 RMSElog: 8.9310 grad_loss: 17867.0801 normal_loss: 0.7023
[epoch 25][iter  260] loss: 115715.6953 RMSElog: 8.1545 grad_loss: 11562.7383 normal_loss: 0.6770
[epoch 25][iter  270] loss: 151350.6719 RMSElog: 8.6274 grad_loss: 15125.7402 normal_loss: 0.6997
[epoch 25][iter  280] loss: 145303.0312 RMSElog: 8.6267 grad_loss: 14521.0215 normal_loss: 0.6553
[epoch 25][iter  290] loss: 196899.1406 RMSElog: 8.9397 grad_loss: 19680.3164 normal_loss: 0.6575
[epoch 25][iter  300] loss: 172098.5000 RMSElog: 8.7346 grad_loss: 17200.4180 normal_loss: 0.6982
[epoch 25][iter  310] loss: 122312.4844 RMSElog: 8.5845 grad_loss: 12222.0029 normal_loss: 0.6599
[epoch 25][iter  320] loss: 202096.9375 RMSElog: 8.7442 grad_loss: 20200.2969 normal_loss: 0.6525
[epoch 25][iter  330] loss: 148227.0625 RMSElog: 8.7199 grad_loss: 14813.2959 normal_loss: 0.6902
[epoch 25][iter  340] loss: 150302.5938 RMSElog: 8.7215 grad_loss: 15020.8740 normal_loss: 0.6630
[epoch 25][iter  350] loss: 206505.1875 RMSElog: 8.8231 grad_loss: 20641.0469 normal_loss: 0.6503
[epoch 25][iter  360] loss: 145312.2031 RMSElog: 8.7563 grad_loss: 14521.8047 normal_loss: 0.6594
[epoch 25][iter  370] loss: 163769.6094 RMSElog: 8.7820 grad_loss: 16367.5010 normal_loss: 0.6775
[epoch 25][iter  380] loss: 144569.1875 RMSElog: 8.1139 grad_loss: 14448.0742 normal_loss: 0.7300
[epoch 25][iter  390] loss: 198424.2969 RMSElog: 8.9208 grad_loss: 19832.8379 normal_loss: 0.6712
[epoch 25][iter  400] loss: 176780.8594 RMSElog: 8.7698 grad_loss: 17668.6289 normal_loss: 0.6883
[epoch 25][iter  410] loss: 234926.2656 RMSElog: 8.7518 grad_loss: 23483.1641 normal_loss: 0.7100
[epoch 25][iter  420] loss: 139045.9219 RMSElog: 8.6423 grad_loss: 13895.2441 normal_loss: 0.7051
[epoch 25][iter  430] loss: 175282.4219 RMSElog: 8.6126 grad_loss: 17518.9375 normal_loss: 0.6904
[epoch 25][iter  440] loss: 165937.0156 RMSElog: 8.8791 grad_loss: 16584.1152 normal_loss: 0.7062
[epoch 25][iter  450] loss: 212217.5156 RMSElog: 8.9112 grad_loss: 21212.1914 normal_loss: 0.6478
[epoch 25][iter  460] loss: 162560.7812 RMSElog: 8.9152 grad_loss: 16246.4639 normal_loss: 0.6989
[epoch 25][iter  470] loss: 149352.0469 RMSElog: 8.7252 grad_loss: 14925.7373 normal_loss: 0.7420
[epoch 25][iter  480] loss: 154271.7031 RMSElog: 8.6992 grad_loss: 15417.8115 normal_loss: 0.6597
[epoch 25][iter  490] loss: 136780.4219 RMSElog: 8.6606 grad_loss: 13668.6816 normal_loss: 0.7005
[epoch 25][iter  500] loss: 119904.8594 RMSElog: 8.4954 grad_loss: 11981.3525 normal_loss: 0.6382
[epoch 25][iter  510] loss: 100959.4531 RMSElog: 8.1927 grad_loss: 10087.0986 normal_loss: 0.6546
[epoch 25][iter  520] loss: 155463.4688 RMSElog: 8.9288 grad_loss: 15536.7656 normal_loss: 0.6529
[epoch 25][iter  530] loss: 176245.0938 RMSElog: 9.0638 grad_loss: 17614.7422 normal_loss: 0.7039
[epoch 25][iter  540] loss: 167067.6562 RMSElog: 8.8305 grad_loss: 16697.2363 normal_loss: 0.7000
[epoch 25][iter  550] loss: 239432.7344 RMSElog: 9.0520 grad_loss: 23933.5430 normal_loss: 0.6769
[epoch 25][iter  560] loss: 149524.8281 RMSElog: 8.8363 grad_loss: 14942.9590 normal_loss: 0.6887
[epoch 25][iter  570] loss: 185127.0469 RMSElog: 8.9024 grad_loss: 18503.0625 normal_loss: 0.7405
[epoch 25][iter  580] loss: 131991.5156 RMSElog: 8.2599 grad_loss: 13190.2041 normal_loss: 0.6873
[epoch 25][iter  590] loss: 105603.9766 RMSElog: 8.3314 grad_loss: 10551.3975 normal_loss: 0.6691
[epoch 26][iter    0] loss: 215933.5312 RMSElog: 8.9020 grad_loss: 21583.8008 normal_loss: 0.6498
[epoch 26][iter   10] loss: 135873.4688 RMSElog: 8.6277 grad_loss: 13578.0713 normal_loss: 0.6474
[epoch 26][iter   20] loss: 167777.8750 RMSElog: 8.8635 grad_loss: 16768.2324 normal_loss: 0.6908
[epoch 26][iter   30] loss: 156853.5000 RMSElog: 8.8068 grad_loss: 15675.8613 normal_loss: 0.6817
[epoch 26][iter   40] loss: 178062.0156 RMSElog: 8.8827 grad_loss: 17796.5879 normal_loss: 0.7304
[epoch 26][iter   50] loss: 170525.0312 RMSElog: 8.6811 grad_loss: 17043.1016 normal_loss: 0.7211
[epoch 26][iter   60] loss: 217152.7812 RMSElog: 8.8756 grad_loss: 21705.7500 normal_loss: 0.6529
[epoch 26][iter   70] loss: 139415.3594 RMSElog: 8.6529 grad_loss: 13932.2285 normal_loss: 0.6541
[epoch 26][iter   80] loss: 105717.3906 RMSElog: 7.9984 grad_loss: 10563.0771 normal_loss: 0.6636
[epoch 26][iter   90] loss: 129724.5781 RMSElog: 8.7332 grad_loss: 12963.0586 normal_loss: 0.6662
[epoch 26][iter  100] loss: 136486.5938 RMSElog: 8.6966 grad_loss: 13639.3066 normal_loss: 0.6565
[epoch 26][iter  110] loss: 181273.0625 RMSElog: 8.7435 grad_loss: 18117.8906 normal_loss: 0.6717
[epoch 26][iter  120] loss: 203071.5781 RMSElog: 8.7358 grad_loss: 20297.7715 normal_loss: 0.6497
[epoch 26][iter  130] loss: 177915.9062 RMSElog: 8.7646 grad_loss: 17782.1543 normal_loss: 0.6712
[epoch 26][iter  140] loss: 110579.6406 RMSElog: 8.1406 grad_loss: 11049.1484 normal_loss: 0.6746
[epoch 26][iter  150] loss: 138929.5312 RMSElog: 8.6596 grad_loss: 13883.6406 normal_loss: 0.6537
[epoch 26][iter  160] loss: 146195.5312 RMSElog: 8.7192 grad_loss: 14610.1611 normal_loss: 0.6727
[epoch 26][iter  170] loss: 155951.7969 RMSElog: 8.6891 grad_loss: 15585.7510 normal_loss: 0.7393
[epoch 26][iter  180] loss: 161068.3125 RMSElog: 8.6718 grad_loss: 16097.5000 normal_loss: 0.6598
[epoch 26][iter  190] loss: 172098.5000 RMSElog: 8.7346 grad_loss: 17200.4180 normal_loss: 0.6982
[epoch 26][iter  200] loss: 130725.7109 RMSElog: 8.7210 grad_loss: 13063.1191 normal_loss: 0.7313
[epoch 26][iter  210] loss: 121168.3906 RMSElog: 8.7411 grad_loss: 12107.3525 normal_loss: 0.7451
[epoch 26][iter  220] loss: 106493.6875 RMSElog: 8.0595 grad_loss: 10640.6445 normal_loss: 0.6646
[epoch 26][iter  230] loss: 157043.5781 RMSElog: 8.8856 grad_loss: 15694.8027 normal_loss: 0.6698
[epoch 26][iter  240] loss: 139858.0312 RMSElog: 8.2697 grad_loss: 13976.7832 normal_loss: 0.7512
[epoch 26][iter  250] loss: 182845.7812 RMSElog: 9.0167 grad_loss: 18274.8262 normal_loss: 0.7340
[epoch 26][iter  260] loss: 100729.3047 RMSElog: 8.6337 grad_loss: 10063.6318 normal_loss: 0.6646
[epoch 26][iter  270] loss: 141426.5000 RMSElog: 8.6983 grad_loss: 14133.2568 normal_loss: 0.6947
[epoch 26][iter  280] loss: 201145.2188 RMSElog: 8.8705 grad_loss: 20104.9492 normal_loss: 0.7008
[epoch 26][iter  290] loss: 190951.1875 RMSElog: 8.7964 grad_loss: 19085.6562 normal_loss: 0.6655
[epoch 26][iter  300] loss: 135951.3125 RMSElog: 8.7094 grad_loss: 13585.7012 normal_loss: 0.7213
[epoch 26][iter  310] loss: 164750.1875 RMSElog: 8.7531 grad_loss: 16465.5742 normal_loss: 0.6916
[epoch 26][iter  320] loss: 117385.6641 RMSElog: 8.3820 grad_loss: 11729.5254 normal_loss: 0.6594
[epoch 26][iter  330] loss: 128471.1719 RMSElog: 8.6920 grad_loss: 12837.7480 normal_loss: 0.6768
[epoch 26][iter  340] loss: 145302.5938 RMSElog: 8.5927 grad_loss: 14521.0068 normal_loss: 0.6605
[epoch 26][iter  350] loss: 151349.9688 RMSElog: 8.5966 grad_loss: 15125.7090 normal_loss: 0.6905
[epoch 26][iter  360] loss: 103790.7656 RMSElog: 8.0553 grad_loss: 10370.3721 normal_loss: 0.6484
[epoch 26][iter  370] loss: 148163.2188 RMSElog: 8.7170 grad_loss: 14806.9453 normal_loss: 0.6604
[epoch 26][iter  380] loss: 179884.8438 RMSElog: 8.8188 grad_loss: 17978.9629 normal_loss: 0.7034
[epoch 26][iter  390] loss: 131991.9844 RMSElog: 8.2839 grad_loss: 13190.2236 normal_loss: 0.6905
[epoch 26][iter  400] loss: 105682.3906 RMSElog: 8.0519 grad_loss: 10559.5273 normal_loss: 0.6600
[epoch 26][iter  410] loss: 218437.8750 RMSElog: 8.8759 grad_loss: 21834.2578 normal_loss: 0.6536
[epoch 26][iter  420] loss: 146764.7188 RMSElog: 8.7850 grad_loss: 14666.9883 normal_loss: 0.6985
[epoch 26][iter  430] loss: 115479.1484 RMSElog: 8.4971 grad_loss: 11538.7549 normal_loss: 0.6628
[epoch 26][iter  440] loss: 142526.8125 RMSElog: 9.0244 grad_loss: 14242.9795 normal_loss: 0.6770
[epoch 26][iter  450] loss: 208164.4531 RMSElog: 9.1080 grad_loss: 20806.6582 normal_loss: 0.6796
[epoch 26][iter  460] loss: 129143.2734 RMSElog: 8.6659 grad_loss: 12904.9658 normal_loss: 0.6950
[epoch 26][iter  470] loss: 109417.1562 RMSElog: 8.0383 grad_loss: 10933.0166 normal_loss: 0.6616
[epoch 26][iter  480] loss: 156154.8594 RMSElog: 8.8881 grad_loss: 15605.9492 normal_loss: 0.6486
[epoch 26][iter  490] loss: 116051.4766 RMSElog: 8.2478 grad_loss: 11596.2354 normal_loss: 0.6636
[epoch 26][iter  500] loss: 124301.6797 RMSElog: 8.2779 grad_loss: 12421.2158 normal_loss: 0.6736
[epoch 26][iter  510] loss: 162961.3750 RMSElog: 8.6660 grad_loss: 16286.7773 normal_loss: 0.6933
[epoch 26][iter  520] loss: 160449.1094 RMSElog: 8.8204 grad_loss: 16035.4121 normal_loss: 0.6785
[epoch 26][iter  530] loss: 134657.4219 RMSElog: 8.5731 grad_loss: 13456.5059 normal_loss: 0.6631
[epoch 26][iter  540] loss: 90467.2500 RMSElog: 8.3458 grad_loss: 9037.6865 normal_loss: 0.6923
[epoch 26][iter  550] loss: 142676.5938 RMSElog: 8.6454 grad_loss: 14258.3359 normal_loss: 0.6780
[epoch 26][iter  560] loss: 150302.5938 RMSElog: 8.7215 grad_loss: 15020.8740 normal_loss: 0.6630
[epoch 26][iter  570] loss: 182170.7812 RMSElog: 8.9656 grad_loss: 18207.4062 normal_loss: 0.7071
[epoch 26][iter  580] loss: 137236.9688 RMSElog: 8.9351 grad_loss: 13714.0332 normal_loss: 0.7276
[epoch 26][iter  590] loss: 176476.6250 RMSElog: 8.7873 grad_loss: 17638.1875 normal_loss: 0.6883
[epoch 27][iter    0] loss: 135193.3906 RMSElog: 8.5547 grad_loss: 13510.1260 normal_loss: 0.6583
[epoch 27][iter   10] loss: 158211.1406 RMSElog: 8.7875 grad_loss: 15811.6689 normal_loss: 0.6583
[epoch 27][iter   20] loss: 106181.8281 RMSElog: 8.4117 grad_loss: 10609.0713 normal_loss: 0.6993
[epoch 27][iter   30] loss: 106493.6875 RMSElog: 8.0595 grad_loss: 10640.6445 normal_loss: 0.6646
[epoch 27][iter   40] loss: 173064.2812 RMSElog: 9.0394 grad_loss: 17296.7324 normal_loss: 0.6554
[epoch 27][iter   50] loss: 231678.4375 RMSElog: 9.1656 grad_loss: 23157.9922 normal_loss: 0.6861
[epoch 27][iter   60] loss: 204628.5781 RMSElog: 8.8829 grad_loss: 20453.3184 normal_loss: 0.6555
[epoch 27][iter   70] loss: 119450.1953 RMSElog: 8.2963 grad_loss: 11936.0488 normal_loss: 0.6748
[epoch 27][iter   80] loss: 182170.7812 RMSElog: 8.9656 grad_loss: 18207.4062 normal_loss: 0.7071
[epoch 27][iter   90] loss: 104434.6094 RMSElog: 8.4308 grad_loss: 10434.3652 normal_loss: 0.6652
[epoch 27][iter  100] loss: 144568.9062 RMSElog: 8.0962 grad_loss: 14448.0664 normal_loss: 0.7288
[epoch 27][iter  110] loss: 217891.9688 RMSElog: 8.8632 grad_loss: 21779.6895 normal_loss: 0.6455
[epoch 27][iter  120] loss: 159806.8750 RMSElog: 8.8100 grad_loss: 15971.1992 normal_loss: 0.6790
[epoch 27][iter  130] loss: 139078.5625 RMSElog: 8.6300 grad_loss: 13898.5605 normal_loss: 0.6652
[epoch 27][iter  140] loss: 241952.8906 RMSElog: 9.0356 grad_loss: 24185.5645 normal_loss: 0.6886
[epoch 27][iter  150] loss: 127755.9297 RMSElog: 8.6384 grad_loss: 12766.2734 normal_loss: 0.6807
[epoch 27][iter  160] loss: 138589.6094 RMSElog: 8.5773 grad_loss: 13849.6934 normal_loss: 0.6904
[epoch 27][iter  170] loss: 132686.7500 RMSElog: 8.4945 grad_loss: 13259.5225 normal_loss: 0.6588
[epoch 27][iter  180] loss: 200933.8750 RMSElog: 8.8635 grad_loss: 20083.8320 normal_loss: 0.6916
[epoch 27][iter  190] loss: 135093.4531 RMSElog: 8.5732 grad_loss: 13500.1172 normal_loss: 0.6539
[epoch 27][iter  200] loss: 214470.3906 RMSElog: 8.8802 grad_loss: 21437.5000 normal_loss: 0.6586
[epoch 27][iter  210] loss: 133005.2031 RMSElog: 8.5097 grad_loss: 13291.3770 normal_loss: 0.6338
[epoch 27][iter  220] loss: 142677.3125 RMSElog: 8.6913 grad_loss: 14258.3604 normal_loss: 0.6791
[epoch 27][iter  230] loss: 133026.5312 RMSElog: 8.6611 grad_loss: 13293.3359 normal_loss: 0.6567
[epoch 27][iter  240] loss: 208164.9844 RMSElog: 9.1406 grad_loss: 20806.6797 normal_loss: 0.6787
[epoch 27][iter  250] loss: 188482.6406 RMSElog: 8.9565 grad_loss: 18838.6367 normal_loss: 0.6692
[epoch 27][iter  260] loss: 129149.9922 RMSElog: 8.9762 grad_loss: 12905.3281 normal_loss: 0.6944
[epoch 27][iter  270] loss: 188998.9219 RMSElog: 8.9417 grad_loss: 18890.2578 normal_loss: 0.6930
[epoch 27][iter  280] loss: 140919.0156 RMSElog: 8.4684 grad_loss: 14082.7637 normal_loss: 0.6689
[epoch 27][iter  290] loss: 156980.5000 RMSElog: 9.2217 grad_loss: 15687.9600 normal_loss: 0.8683
[epoch 27][iter  300] loss: 215933.5312 RMSElog: 8.9020 grad_loss: 21583.8008 normal_loss: 0.6498
[epoch 27][iter  310] loss: 101431.1250 RMSElog: 8.6133 grad_loss: 10133.8242 normal_loss: 0.6750
[epoch 27][iter  320] loss: 175983.2500 RMSElog: 9.1518 grad_loss: 17588.2969 normal_loss: 0.8753
[epoch 27][iter  330] loss: 121816.2812 RMSElog: 8.2713 grad_loss: 12172.6816 normal_loss: 0.6744
[epoch 27][iter  340] loss: 139000.0625 RMSElog: 8.6245 grad_loss: 13890.7090 normal_loss: 0.6741
[epoch 27][iter  350] loss: 167191.6875 RMSElog: 8.7871 grad_loss: 16709.6992 normal_loss: 0.6813
[epoch 27][iter  360] loss: 106928.3438 RMSElog: 8.3060 grad_loss: 10683.8730 normal_loss: 0.6550
[epoch 27][iter  370] loss: 191539.4375 RMSElog: 8.6705 grad_loss: 19144.5820 normal_loss: 0.6910
[epoch 27][iter  380] loss: 163236.4062 RMSElog: 8.8368 grad_loss: 16314.1035 normal_loss: 0.7006
[epoch 27][iter  390] loss: 114903.7969 RMSElog: 8.3035 grad_loss: 11481.4111 normal_loss: 0.6651
[epoch 27][iter  400] loss: 165956.8906 RMSElog: 8.7471 grad_loss: 16586.2930 normal_loss: 0.6481
[epoch 27][iter  410] loss: 173703.1094 RMSElog: 8.9012 grad_loss: 17360.7109 normal_loss: 0.6997
[epoch 27][iter  420] loss: 109237.2500 RMSElog: 8.1283 grad_loss: 10914.9268 normal_loss: 0.6700
[epoch 27][iter  430] loss: 102075.1406 RMSElog: 8.3446 grad_loss: 10198.5049 normal_loss: 0.6644
[epoch 27][iter  440] loss: 107923.9844 RMSElog: 8.0546 grad_loss: 10783.6816 normal_loss: 0.6619
[epoch 27][iter  450] loss: 100958.6328 RMSElog: 8.1501 grad_loss: 10087.0664 normal_loss: 0.6469
[epoch 27][iter  460] loss: 167714.5469 RMSElog: 8.9870 grad_loss: 16761.7891 normal_loss: 0.6795
[epoch 27][iter  470] loss: 181446.1250 RMSElog: 8.8744 grad_loss: 18135.0469 normal_loss: 0.6917
[epoch 27][iter  480] loss: 164580.2500 RMSElog: 8.8475 grad_loss: 16448.4883 normal_loss: 0.6903
[epoch 27][iter  490] loss: 114363.7188 RMSElog: 8.5953 grad_loss: 11427.0518 normal_loss: 0.7248
[epoch 27][iter  500] loss: 207666.5312 RMSElog: 8.8811 grad_loss: 20757.0703 normal_loss: 0.7011
[epoch 27][iter  510] loss: 165290.2812 RMSElog: 8.8957 grad_loss: 16519.4258 normal_loss: 0.7057
[epoch 27][iter  520] loss: 203540.5938 RMSElog: 8.7406 grad_loss: 20344.6660 normal_loss: 0.6531
[epoch 27][iter  530] loss: 167728.5000 RMSElog: 8.8754 grad_loss: 16763.2734 normal_loss: 0.7013
[epoch 27][iter  540] loss: 125489.9219 RMSElog: 8.7870 grad_loss: 12539.5010 normal_loss: 0.7045
[epoch 27][iter  550] loss: 166475.3438 RMSElog: 8.8007 grad_loss: 16638.0449 normal_loss: 0.6888
[epoch 27][iter  560] loss: 104455.6875 RMSElog: 8.0465 grad_loss: 10436.8838 normal_loss: 0.6373
[epoch 27][iter  570] loss: 190917.3125 RMSElog: 9.0337 grad_loss: 19082.0293 normal_loss: 0.6686
[epoch 27][iter  580] loss: 137745.4219 RMSElog: 8.6268 grad_loss: 13765.2588 normal_loss: 0.6563
[epoch 27][iter  590] loss: 137236.9688 RMSElog: 8.9351 grad_loss: 13714.0332 normal_loss: 0.7277
[epoch 28][iter    0] loss: 142118.3125 RMSElog: 8.4643 grad_loss: 14202.6797 normal_loss: 0.6879
[epoch 28][iter   10] loss: 160649.1406 RMSElog: 8.8637 grad_loss: 16055.3887 normal_loss: 0.6621
[epoch 28][iter   20] loss: 172236.6250 RMSElog: 8.8302 grad_loss: 17214.0859 normal_loss: 0.7463
[epoch 28][iter   30] loss: 175528.9375 RMSElog: 8.8611 grad_loss: 17543.3555 normal_loss: 0.6781
[epoch 28][iter   40] loss: 182845.7812 RMSElog: 9.0167 grad_loss: 18274.8262 normal_loss: 0.7340
[epoch 28][iter   50] loss: 165290.2812 RMSElog: 8.8957 grad_loss: 16519.4258 normal_loss: 0.7056
[epoch 28][iter   60] loss: 118723.9922 RMSElog: 8.2582 grad_loss: 11863.4707 normal_loss: 0.6706
[epoch 28][iter   70] loss: 139000.0625 RMSElog: 8.6245 grad_loss: 13890.7090 normal_loss: 0.6741
[epoch 28][iter   80] loss: 188481.8594 RMSElog: 8.9086 grad_loss: 18838.6172 normal_loss: 0.6598
[epoch 28][iter   90] loss: 148163.2188 RMSElog: 8.7169 grad_loss: 14806.9453 normal_loss: 0.6604
[epoch 28][iter  100] loss: 114883.1250 RMSElog: 8.6509 grad_loss: 11478.9268 normal_loss: 0.7339
[epoch 28][iter  110] loss: 112835.5156 RMSElog: 8.4665 grad_loss: 11274.4043 normal_loss: 0.6809
[epoch 28][iter  120] loss: 166475.3438 RMSElog: 8.8007 grad_loss: 16638.0449 normal_loss: 0.6888
[epoch 28][iter  130] loss: 167327.2188 RMSElog: 8.7888 grad_loss: 16723.2402 normal_loss: 0.6942
[epoch 28][iter  140] loss: 156154.8594 RMSElog: 8.8881 grad_loss: 15605.9492 normal_loss: 0.6486
[epoch 28][iter  150] loss: 163681.8125 RMSElog: 8.8063 grad_loss: 16358.6289 normal_loss: 0.7460
[epoch 28][iter  160] loss: 134614.5000 RMSElog: 8.7124 grad_loss: 13452.0605 normal_loss: 0.6774
[epoch 28][iter  170] loss: 167727.9531 RMSElog: 8.8459 grad_loss: 16763.2598 normal_loss: 0.6896
[epoch 28][iter  180] loss: 140035.8594 RMSElog: 8.6433 grad_loss: 13994.2881 normal_loss: 0.6547
[epoch 28][iter  190] loss: 193958.5312 RMSElog: 9.0228 grad_loss: 19386.1504 normal_loss: 0.6804
[epoch 28][iter  200] loss: 181273.0625 RMSElog: 8.7434 grad_loss: 18117.8906 normal_loss: 0.6717
[epoch 28][iter  210] loss: 176244.5469 RMSElog: 9.0361 grad_loss: 17614.7246 normal_loss: 0.6962
[epoch 28][iter  220] loss: 196899.7656 RMSElog: 8.9802 grad_loss: 19680.3359 normal_loss: 0.6595
[epoch 28][iter  230] loss: 180302.5312 RMSElog: 8.9003 grad_loss: 18020.6484 normal_loss: 0.7053
[epoch 28][iter  240] loss: 162504.4375 RMSElog: 8.9399 grad_loss: 16240.8340 normal_loss: 0.6701
[epoch 28][iter  250] loss: 167765.9219 RMSElog: 8.7633 grad_loss: 16767.1113 normal_loss: 0.7168
[epoch 28][iter  260] loss: 202609.9844 RMSElog: 8.7789 grad_loss: 20251.5527 normal_loss: 0.6655
[epoch 28][iter  270] loss: 105877.9375 RMSElog: 8.4742 grad_loss: 10578.6416 normal_loss: 0.6774
[epoch 28][iter  280] loss: 156963.2656 RMSElog: 8.8586 grad_loss: 15686.8203 normal_loss: 0.6489
[epoch 28][iter  290] loss: 105804.9609 RMSElog: 8.3606 grad_loss: 10571.4668 normal_loss: 0.6689
[epoch 28][iter  300] loss: 164750.1875 RMSElog: 8.7531 grad_loss: 16465.5742 normal_loss: 0.6916
[epoch 28][iter  310] loss: 145391.8906 RMSElog: 8.7154 grad_loss: 14529.7861 normal_loss: 0.6875
[epoch 28][iter  320] loss: 167723.1562 RMSElog: 8.8400 grad_loss: 16762.7812 normal_loss: 0.6950
[epoch 28][iter  330] loss: 162355.8438 RMSElog: 8.8228 grad_loss: 16226.0605 normal_loss: 0.7000
[epoch 28][iter  340] loss: 135448.4062 RMSElog: 8.7754 grad_loss: 13535.3906 normal_loss: 0.6746
[epoch 28][iter  350] loss: 150303.8906 RMSElog: 8.8670 grad_loss: 15020.8398 normal_loss: 0.6828
[epoch 28][iter  360] loss: 177648.7188 RMSElog: 8.7827 grad_loss: 17755.3828 normal_loss: 0.7044
[epoch 28][iter  370] loss: 166054.3125 RMSElog: 8.7676 grad_loss: 16595.9648 normal_loss: 0.6993
[epoch 28][iter  380] loss: 122427.9609 RMSElog: 8.3860 grad_loss: 12233.7168 normal_loss: 0.6929
[epoch 28][iter  390] loss: 140623.7344 RMSElog: 8.6447 grad_loss: 14053.0684 normal_loss: 0.6608
[epoch 28][iter  400] loss: 170040.0156 RMSElog: 8.7737 grad_loss: 16994.5469 normal_loss: 0.6816
[epoch 28][iter  410] loss: 189563.4062 RMSElog: 8.7904 grad_loss: 18946.8594 normal_loss: 0.6894
[epoch 28][iter  420] loss: 186028.9688 RMSElog: 8.7860 grad_loss: 18593.4336 normal_loss: 0.6772
[epoch 28][iter  430] loss: 122894.3438 RMSElog: 8.6533 grad_loss: 12280.1016 normal_loss: 0.6801
[epoch 28][iter  440] loss: 150282.3125 RMSElog: 8.6605 grad_loss: 15018.9150 normal_loss: 0.6554
[epoch 28][iter  450] loss: 141210.3594 RMSElog: 8.7946 grad_loss: 14111.5762 normal_loss: 0.6652
[epoch 28][iter  460] loss: 104957.1172 RMSElog: 8.5603 grad_loss: 10486.4941 normal_loss: 0.6569
[epoch 28][iter  470] loss: 191187.3750 RMSElog: 8.8389 grad_loss: 19109.1758 normal_loss: 0.7229
[epoch 28][iter  480] loss: 131198.2500 RMSElog: 8.6984 grad_loss: 13110.4150 normal_loss: 0.7119
[epoch 28][iter  490] loss: 148222.1562 RMSElog: 8.7880 grad_loss: 14812.7676 normal_loss: 0.6593
[epoch 28][iter  500] loss: 162415.7344 RMSElog: 8.8347 grad_loss: 16232.0723 normal_loss: 0.6660
[epoch 28][iter  510] loss: 136046.1250 RMSElog: 8.3679 grad_loss: 13595.5449 normal_loss: 0.6991
[epoch 28][iter  520] loss: 200933.8750 RMSElog: 8.8635 grad_loss: 20083.8320 normal_loss: 0.6916
[epoch 28][iter  530] loss: 191802.6875 RMSElog: 8.8167 grad_loss: 19170.7969 normal_loss: 0.6562
[epoch 28][iter  540] loss: 227059.6875 RMSElog: 9.0943 grad_loss: 22696.2188 normal_loss: 0.6571
[epoch 28][iter  550] loss: 138041.0000 RMSElog: 8.4987 grad_loss: 13794.9229 normal_loss: 0.6785
[epoch 28][iter  560] loss: 127096.7031 RMSElog: 8.6423 grad_loss: 12700.2891 normal_loss: 0.7386
[epoch 28][iter  570] loss: 154687.2500 RMSElog: 8.8054 grad_loss: 15459.2461 normal_loss: 0.6742
[epoch 28][iter  580] loss: 202096.9375 RMSElog: 8.7443 grad_loss: 20200.2969 normal_loss: 0.6525
[epoch 28][iter  590] loss: 161614.2344 RMSElog: 8.8986 grad_loss: 16151.8662 normal_loss: 0.6590
[epoch 29][iter    0] loss: 195979.2500 RMSElog: 8.9566 grad_loss: 19588.3105 normal_loss: 0.6586
[epoch 29][iter   10] loss: 103500.0312 RMSElog: 8.5433 grad_loss: 10340.7930 normal_loss: 0.6669
[epoch 29][iter   20] loss: 143822.8750 RMSElog: 8.7399 grad_loss: 14372.8730 normal_loss: 0.6749
[epoch 29][iter   30] loss: 104456.9688 RMSElog: 8.1339 grad_loss: 10436.9189 normal_loss: 0.6441
[epoch 29][iter   40] loss: 227303.7812 RMSElog: 9.1408 grad_loss: 22720.5781 normal_loss: 0.6594
[epoch 29][iter   50] loss: 132023.8125 RMSElog: 8.8458 grad_loss: 13192.8525 normal_loss: 0.6835
[epoch 29][iter   60] loss: 112835.5156 RMSElog: 8.4664 grad_loss: 11274.4043 normal_loss: 0.6809
[epoch 29][iter   70] loss: 165557.5000 RMSElog: 8.7976 grad_loss: 16546.2715 normal_loss: 0.6824
[epoch 29][iter   80] loss: 140918.5000 RMSElog: 8.4399 grad_loss: 14082.7441 normal_loss: 0.6668
[epoch 29][iter   90] loss: 196004.0312 RMSElog: 8.8267 grad_loss: 19590.9141 normal_loss: 0.6630
[epoch 29][iter  100] loss: 175282.4062 RMSElog: 8.6126 grad_loss: 17518.9375 normal_loss: 0.6904
[epoch 29][iter  110] loss: 138041.0000 RMSElog: 8.4987 grad_loss: 13794.9229 normal_loss: 0.6785
[epoch 29][iter  120] loss: 205340.7656 RMSElog: 8.8006 grad_loss: 20524.6289 normal_loss: 0.6465
[epoch 29][iter  130] loss: 135448.4062 RMSElog: 8.7754 grad_loss: 13535.3906 normal_loss: 0.6746
[epoch 29][iter  140] loss: 174746.0000 RMSElog: 8.7799 grad_loss: 17465.1094 normal_loss: 0.7117
[epoch 29][iter  150] loss: 199052.5312 RMSElog: 8.8685 grad_loss: 19895.6797 normal_loss: 0.7057
[epoch 29][iter  160] loss: 147525.3594 RMSElog: 8.7392 grad_loss: 14743.1357 normal_loss: 0.6611
[epoch 29][iter  170] loss: 148227.0625 RMSElog: 8.7199 grad_loss: 14813.2959 normal_loss: 0.6902
[epoch 29][iter  180] loss: 183073.2031 RMSElog: 8.5994 grad_loss: 18298.0312 normal_loss: 0.6896
[epoch 29][iter  190] loss: 127482.6406 RMSElog: 8.2795 grad_loss: 12739.3027 normal_loss: 0.6818
[epoch 29][iter  200] loss: 182460.7500 RMSElog: 8.9574 grad_loss: 18236.4102 normal_loss: 0.7078
[epoch 29][iter  210] loss: 148118.4062 RMSElog: 8.7473 grad_loss: 14802.3926 normal_loss: 0.7016
[epoch 29][iter  220] loss: 133026.5312 RMSElog: 8.6611 grad_loss: 13293.3359 normal_loss: 0.6567
[epoch 29][iter  230] loss: 239748.2031 RMSElog: 8.9687 grad_loss: 23965.1797 normal_loss: 0.6712
[epoch 29][iter  240] loss: 109914.5469 RMSElog: 8.4566 grad_loss: 10982.3086 normal_loss: 0.6897
[epoch 29][iter  250] loss: 104434.6094 RMSElog: 8.4308 grad_loss: 10434.3652 normal_loss: 0.6651
[epoch 29][iter  260] loss: 218527.2031 RMSElog: 9.1198 grad_loss: 21842.9141 normal_loss: 0.6881
[epoch 29][iter  270] loss: 165290.2812 RMSElog: 8.8957 grad_loss: 16519.4258 normal_loss: 0.7057
[epoch 29][iter  280] loss: 117090.5391 RMSElog: 8.2817 grad_loss: 11700.1055 normal_loss: 0.6671
[epoch 29][iter  290] loss: 154538.2031 RMSElog: 8.8582 grad_loss: 15444.2822 normal_loss: 0.6795
[epoch 29][iter  300] loss: 135951.2969 RMSElog: 8.7095 grad_loss: 13585.6992 normal_loss: 0.7213
[epoch 29][iter  310] loss: 115325.8125 RMSElog: 8.2683 grad_loss: 11523.6465 normal_loss: 0.6656
[epoch 29][iter  320] loss: 124614.9922 RMSElog: 8.5019 grad_loss: 12452.3281 normal_loss: 0.6689
[epoch 29][iter  330] loss: 129149.1875 RMSElog: 8.7091 grad_loss: 12905.5381 normal_loss: 0.6718
[epoch 29][iter  340] loss: 232751.5938 RMSElog: 9.0182 grad_loss: 23265.4727 normal_loss: 0.6699
[epoch 29][iter  350] loss: 208800.7188 RMSElog: 8.8111 grad_loss: 20870.6094 normal_loss: 0.6522
[epoch 29][iter  360] loss: 164750.1875 RMSElog: 8.7531 grad_loss: 16465.5742 normal_loss: 0.6916
[epoch 29][iter  370] loss: 105805.7969 RMSElog: 8.4183 grad_loss: 10571.4883 normal_loss: 0.6734
[epoch 29][iter  380] loss: 126005.3281 RMSElog: 8.4625 grad_loss: 12591.3906 normal_loss: 0.6795
[epoch 29][iter  390] loss: 213396.6406 RMSElog: 9.0003 grad_loss: 21329.9805 normal_loss: 0.6841
[epoch 29][iter  400] loss: 183854.5000 RMSElog: 9.0350 grad_loss: 18375.7051 normal_loss: 0.7092
[epoch 29][iter  410] loss: 195755.9062 RMSElog: 8.8273 grad_loss: 19566.0938 normal_loss: 0.6677
[epoch 29][iter  420] loss: 153979.6094 RMSElog: 8.6388 grad_loss: 15388.6641 normal_loss: 0.6585
[epoch 29][iter  430] loss: 122312.4844 RMSElog: 8.5845 grad_loss: 12222.0029 normal_loss: 0.6599
[epoch 29][iter  440] loss: 103331.7656 RMSElog: 8.0592 grad_loss: 10324.4668 normal_loss: 0.6503
[epoch 29][iter  450] loss: 196899.1406 RMSElog: 8.9398 grad_loss: 19680.3164 normal_loss: 0.6575
[epoch 29][iter  460] loss: 130507.1016 RMSElog: 8.5754 grad_loss: 13041.4688 normal_loss: 0.6662
[epoch 29][iter  470] loss: 218604.3594 RMSElog: 8.8691 grad_loss: 21850.8965 normal_loss: 0.6700
[epoch 29][iter  480] loss: 162416.4375 RMSElog: 8.8700 grad_loss: 16232.0947 normal_loss: 0.6794
[epoch 29][iter  490] loss: 163574.9688 RMSElog: 8.7480 grad_loss: 16348.0811 normal_loss: 0.6672
[epoch 29][iter  500] loss: 170524.2188 RMSElog: 8.6305 grad_loss: 17043.0781 normal_loss: 0.7125
[epoch 29][iter  510] loss: 163759.1719 RMSElog: 8.7170 grad_loss: 16366.4805 normal_loss: 0.7192
[epoch 29][iter  520] loss: 122366.7656 RMSElog: 8.5424 grad_loss: 12227.4893 normal_loss: 0.6458
[epoch 29][iter  530] loss: 203000.4844 RMSElog: 8.8285 grad_loss: 20290.5684 normal_loss: 0.6530
[epoch 29][iter  540] loss: 210500.4375 RMSElog: 8.9463 grad_loss: 21040.4512 normal_loss: 0.6458
[epoch 29][iter  550] loss: 106157.8047 RMSElog: 8.0432 grad_loss: 10607.0791 normal_loss: 0.6584
[epoch 29][iter  560] loss: 100625.3750 RMSElog: 8.0304 grad_loss: 10053.8682 normal_loss: 0.6387
[epoch 29][iter  570] loss: 170471.5312 RMSElog: 8.7745 grad_loss: 17037.7109 normal_loss: 0.6661
[epoch 29][iter  580] loss: 107049.5938 RMSElog: 8.0690 grad_loss: 10696.2256 normal_loss: 0.6642
[epoch 29][iter  590] loss: 135679.7031 RMSElog: 8.3691 grad_loss: 13558.9014 normal_loss: 0.6988
###############
#epochs=80
###############
[epoch  0][iter    0] loss: 96.6826 RMSElog: 9.6683 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   10] loss: 101.8512 RMSElog: 10.1851 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   20] loss: 102.7256 RMSElog: 10.2726 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   30] loss: 102.5333 RMSElog: 10.2533 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   40] loss: 103.4060 RMSElog: 10.3406 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   50] loss: 101.7941 RMSElog: 10.1794 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   60] loss: 99.4623 RMSElog: 9.9462 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   70] loss: 105.6677 RMSElog: 10.5668 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   80] loss: 104.6128 RMSElog: 10.4613 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   90] loss: 102.0681 RMSElog: 10.2068 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  100] loss: 103.5810 RMSElog: 10.3581 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  110] loss: 99.6793 RMSElog: 9.9679 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  120] loss: 106.1550 RMSElog: 10.6155 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  130] loss: 98.8509 RMSElog: 9.8851 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  140] loss: 102.4039 RMSElog: 10.2404 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  150] loss: 102.1226 RMSElog: 10.2123 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  160] loss: 99.4914 RMSElog: 9.9491 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  170] loss: 101.0637 RMSElog: 10.1064 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  180] loss: 102.0280 RMSElog: 10.2028 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  190] loss: 99.5242 RMSElog: 9.9524 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  200] loss: 96.0814 RMSElog: 9.6081 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  210] loss: 95.7316 RMSElog: 9.5732 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  220] loss: 101.7287 RMSElog: 10.1729 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  230] loss: 104.1326 RMSElog: 10.4133 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  240] loss: 103.4952 RMSElog: 10.3495 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  250] loss: 99.1753 RMSElog: 9.9175 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  260] loss: 99.6551 RMSElog: 9.9655 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  270] loss: 97.4319 RMSElog: 9.7432 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  280] loss: 99.7375 RMSElog: 9.9738 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  290] loss: 97.1322 RMSElog: 9.7132 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  300] loss: 102.8102 RMSElog: 10.2810 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  310] loss: 100.0774 RMSElog: 10.0077 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  320] loss: 96.2130 RMSElog: 9.6213 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  330] loss: 92.7374 RMSElog: 9.2737 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  340] loss: 97.4844 RMSElog: 9.7484 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  350] loss: 97.9433 RMSElog: 9.7943 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  360] loss: 96.9446 RMSElog: 9.6945 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  370] loss: 103.4173 RMSElog: 10.3417 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  380] loss: 99.2293 RMSElog: 9.9229 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  390] loss: 98.8696 RMSElog: 9.8870 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  400] loss: 100.6011 RMSElog: 10.0601 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  410] loss: 97.2120 RMSElog: 9.7212 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  420] loss: 102.2770 RMSElog: 10.2277 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  430] loss: 100.2353 RMSElog: 10.0235 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  440] loss: 101.7422 RMSElog: 10.1742 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  450] loss: 101.1643 RMSElog: 10.1164 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  460] loss: 98.5979 RMSElog: 9.8598 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  470] loss: 97.4061 RMSElog: 9.7406 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  480] loss: 100.1776 RMSElog: 10.0178 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  490] loss: 102.7446 RMSElog: 10.2745 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  500] loss: 97.5966 RMSElog: 9.7597 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  510] loss: 97.5013 RMSElog: 9.7501 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  520] loss: 98.3133 RMSElog: 9.8313 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  530] loss: 97.4836 RMSElog: 9.7484 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  540] loss: 97.4750 RMSElog: 9.7475 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  550] loss: 98.9282 RMSElog: 9.8928 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  560] loss: 97.4285 RMSElog: 9.7429 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  570] loss: 97.7570 RMSElog: 9.7757 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  580] loss: 101.8018 RMSElog: 10.1802 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  590] loss: 103.8059 RMSElog: 10.3806 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter    0] loss: 99.1613 RMSElog: 9.9161 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   10] loss: 97.7528 RMSElog: 9.7753 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   20] loss: 99.0620 RMSElog: 9.9062 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   30] loss: 97.7919 RMSElog: 9.7792 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   40] loss: 97.9029 RMSElog: 9.7903 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   50] loss: 99.7147 RMSElog: 9.9715 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   60] loss: 99.1545 RMSElog: 9.9155 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   70] loss: 97.6675 RMSElog: 9.7667 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   80] loss: 99.8294 RMSElog: 9.9829 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   90] loss: 96.8697 RMSElog: 9.6870 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  100] loss: 98.5712 RMSElog: 9.8571 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  110] loss: 96.6516 RMSElog: 9.6652 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  120] loss: 100.8189 RMSElog: 10.0819 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  130] loss: 91.8050 RMSElog: 9.1805 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  140] loss: 102.7508 RMSElog: 10.2751 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  150] loss: 97.4671 RMSElog: 9.7467 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  160] loss: 99.8099 RMSElog: 9.9810 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  170] loss: 94.3540 RMSElog: 9.4354 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  180] loss: 100.2277 RMSElog: 10.0228 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  190] loss: 101.0172 RMSElog: 10.1017 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  200] loss: 101.6594 RMSElog: 10.1659 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  210] loss: 99.7231 RMSElog: 9.9723 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  220] loss: 98.6099 RMSElog: 9.8610 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  230] loss: 100.0386 RMSElog: 10.0039 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  240] loss: 101.7815 RMSElog: 10.1781 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  250] loss: 94.2204 RMSElog: 9.4220 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  260] loss: 97.8211 RMSElog: 9.7821 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  270] loss: 93.2694 RMSElog: 9.3269 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  280] loss: 95.1448 RMSElog: 9.5145 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  290] loss: 99.9740 RMSElog: 9.9974 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  300] loss: 100.9375 RMSElog: 10.0938 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  310] loss: 99.4847 RMSElog: 9.9485 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  320] loss: 99.4786 RMSElog: 9.9479 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  330] loss: 96.8769 RMSElog: 9.6877 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  340] loss: 93.9718 RMSElog: 9.3972 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  350] loss: 99.2918 RMSElog: 9.9292 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  360] loss: 98.8900 RMSElog: 9.8890 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  370] loss: 100.2438 RMSElog: 10.0244 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  380] loss: 101.0081 RMSElog: 10.1008 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  390] loss: 102.4852 RMSElog: 10.2485 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  400] loss: 98.8006 RMSElog: 9.8801 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  410] loss: 98.2220 RMSElog: 9.8222 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  420] loss: 98.1105 RMSElog: 9.8111 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  430] loss: 100.3227 RMSElog: 10.0323 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  440] loss: 101.5933 RMSElog: 10.1593 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  450] loss: 97.3025 RMSElog: 9.7302 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  460] loss: 99.4989 RMSElog: 9.9499 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  470] loss: 99.4001 RMSElog: 9.9400 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  480] loss: 101.3661 RMSElog: 10.1366 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  490] loss: 99.0564 RMSElog: 9.9056 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  500] loss: 97.9668 RMSElog: 9.7967 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  510] loss: 96.6271 RMSElog: 9.6627 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  520] loss: 103.0374 RMSElog: 10.3037 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  530] loss: 96.9751 RMSElog: 9.6975 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  540] loss: 99.1122 RMSElog: 9.9112 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  550] loss: 97.2972 RMSElog: 9.7297 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  560] loss: 102.4609 RMSElog: 10.2461 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  570] loss: 96.9348 RMSElog: 9.6935 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  580] loss: 99.2774 RMSElog: 9.9277 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  590] loss: 99.0421 RMSElog: 9.9042 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter    0] loss: 99.1679 RMSElog: 9.9168 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   10] loss: 103.8317 RMSElog: 10.3832 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   20] loss: 96.1357 RMSElog: 9.6136 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   30] loss: 92.8975 RMSElog: 9.2898 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   40] loss: 94.7136 RMSElog: 9.4714 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   50] loss: 92.2853 RMSElog: 9.2285 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   60] loss: 91.5769 RMSElog: 9.1577 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   70] loss: 102.2206 RMSElog: 10.2221 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   80] loss: 99.3237 RMSElog: 9.9324 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   90] loss: 101.1983 RMSElog: 10.1198 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  100] loss: 97.0622 RMSElog: 9.7062 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  110] loss: 99.7166 RMSElog: 9.9717 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  120] loss: 98.0991 RMSElog: 9.8099 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  130] loss: 97.1192 RMSElog: 9.7119 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  140] loss: 98.4732 RMSElog: 9.8473 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  150] loss: 100.2014 RMSElog: 10.0201 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  160] loss: 97.6003 RMSElog: 9.7600 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  170] loss: 96.7008 RMSElog: 9.6701 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  180] loss: 95.8956 RMSElog: 9.5896 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  190] loss: 96.8870 RMSElog: 9.6887 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  200] loss: 104.0727 RMSElog: 10.4073 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  210] loss: 99.9804 RMSElog: 9.9980 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  220] loss: 96.5481 RMSElog: 9.6548 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  230] loss: 97.1177 RMSElog: 9.7118 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  240] loss: 100.6772 RMSElog: 10.0677 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  250] loss: 98.2893 RMSElog: 9.8289 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  260] loss: 91.1288 RMSElog: 9.1129 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  270] loss: 96.8654 RMSElog: 9.6865 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  280] loss: 98.2969 RMSElog: 9.8297 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  290] loss: 98.4339 RMSElog: 9.8434 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  300] loss: 93.9825 RMSElog: 9.3983 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  310] loss: 100.3815 RMSElog: 10.0381 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  320] loss: 95.5435 RMSElog: 9.5543 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  330] loss: 95.8800 RMSElog: 9.5880 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  340] loss: 102.2537 RMSElog: 10.2254 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  350] loss: 96.9657 RMSElog: 9.6966 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  360] loss: 100.5099 RMSElog: 10.0510 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  370] loss: 97.3420 RMSElog: 9.7342 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  380] loss: 99.3301 RMSElog: 9.9330 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  390] loss: 102.7829 RMSElog: 10.2783 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  400] loss: 102.2882 RMSElog: 10.2288 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  410] loss: 97.4234 RMSElog: 9.7423 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  420] loss: 97.6621 RMSElog: 9.7662 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  430] loss: 97.0313 RMSElog: 9.7031 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  440] loss: 99.1419 RMSElog: 9.9142 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  450] loss: 97.3766 RMSElog: 9.7377 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  460] loss: 96.2759 RMSElog: 9.6276 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  470] loss: 97.5261 RMSElog: 9.7526 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  480] loss: 99.6722 RMSElog: 9.9672 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  490] loss: 100.4557 RMSElog: 10.0456 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  500] loss: 104.1274 RMSElog: 10.4127 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  510] loss: 99.4066 RMSElog: 9.9407 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  520] loss: 97.1062 RMSElog: 9.7106 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  530] loss: 102.9953 RMSElog: 10.2995 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  540] loss: 99.6630 RMSElog: 9.9663 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  550] loss: 92.5311 RMSElog: 9.2531 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  560] loss: 101.2549 RMSElog: 10.1255 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  570] loss: 96.7327 RMSElog: 9.6733 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  580] loss: 98.0348 RMSElog: 9.8035 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  590] loss: 96.9767 RMSElog: 9.6977 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter    0] loss: 99.3848 RMSElog: 9.9385 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   10] loss: 98.8429 RMSElog: 9.8843 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   20] loss: 97.5521 RMSElog: 9.7552 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   30] loss: 96.2185 RMSElog: 9.6219 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   40] loss: 99.1477 RMSElog: 9.9148 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   50] loss: 96.5044 RMSElog: 9.6504 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   60] loss: 99.2346 RMSElog: 9.9235 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   70] loss: 98.0536 RMSElog: 9.8054 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   80] loss: 100.2627 RMSElog: 10.0263 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   90] loss: 98.5399 RMSElog: 9.8540 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  100] loss: 99.7144 RMSElog: 9.9714 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  110] loss: 98.1829 RMSElog: 9.8183 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  120] loss: 97.4644 RMSElog: 9.7464 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  130] loss: 101.4699 RMSElog: 10.1470 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  140] loss: 99.9806 RMSElog: 9.9981 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  150] loss: 102.4138 RMSElog: 10.2414 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  160] loss: 99.4019 RMSElog: 9.9402 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  170] loss: 101.2381 RMSElog: 10.1238 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  180] loss: 102.2882 RMSElog: 10.2288 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  190] loss: 101.9158 RMSElog: 10.1916 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  200] loss: 97.6821 RMSElog: 9.7682 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  210] loss: 100.2848 RMSElog: 10.0285 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  220] loss: 101.4907 RMSElog: 10.1491 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  230] loss: 97.4408 RMSElog: 9.7441 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  240] loss: 104.4796 RMSElog: 10.4480 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  250] loss: 98.2523 RMSElog: 9.8252 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  260] loss: 98.3247 RMSElog: 9.8325 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  270] loss: 97.8632 RMSElog: 9.7863 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  280] loss: 101.5924 RMSElog: 10.1592 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  290] loss: 100.9302 RMSElog: 10.0930 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  300] loss: 95.7654 RMSElog: 9.5765 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  310] loss: 101.2056 RMSElog: 10.1206 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  320] loss: 95.5603 RMSElog: 9.5560 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  330] loss: 101.7185 RMSElog: 10.1719 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  340] loss: 102.3188 RMSElog: 10.2319 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  350] loss: 97.8259 RMSElog: 9.7826 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  360] loss: 100.5099 RMSElog: 10.0510 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  370] loss: 98.3555 RMSElog: 9.8355 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  380] loss: 101.5307 RMSElog: 10.1531 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  390] loss: 98.0169 RMSElog: 9.8017 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  400] loss: 100.1311 RMSElog: 10.0131 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  410] loss: 96.0156 RMSElog: 9.6016 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  420] loss: 99.9277 RMSElog: 9.9928 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  430] loss: 96.7556 RMSElog: 9.6756 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  440] loss: 101.7802 RMSElog: 10.1780 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  450] loss: 94.2154 RMSElog: 9.4215 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  460] loss: 92.6056 RMSElog: 9.2606 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  470] loss: 97.7581 RMSElog: 9.7758 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  480] loss: 97.6624 RMSElog: 9.7662 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  490] loss: 94.4136 RMSElog: 9.4414 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  500] loss: 91.7611 RMSElog: 9.1761 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  510] loss: 99.3281 RMSElog: 9.9328 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  520] loss: 98.6529 RMSElog: 9.8653 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  530] loss: 92.7689 RMSElog: 9.2769 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  540] loss: 91.8944 RMSElog: 9.1894 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  550] loss: 99.5568 RMSElog: 9.9557 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  560] loss: 94.2778 RMSElog: 9.4278 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  570] loss: 101.8982 RMSElog: 10.1898 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  580] loss: 99.4045 RMSElog: 9.9405 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  590] loss: 98.8814 RMSElog: 9.8881 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  4][iter    0] loss: 161275.7500 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.0000
[epoch  4][iter   10] loss: 95212.1016 RMSElog: 9.1894 grad_loss: 9512.0205 normal_loss: 0.0000
[epoch  4][iter   20] loss: 150144.0156 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.0000
[epoch  4][iter   30] loss: 137287.1562 RMSElog: 9.9750 grad_loss: 13718.7412 normal_loss: 0.0000
[epoch  4][iter   40] loss: 188652.9531 RMSElog: 10.2592 grad_loss: 18855.0352 normal_loss: 0.0000
[epoch  4][iter   50] loss: 114817.7734 RMSElog: 9.7767 grad_loss: 11472.0010 normal_loss: 0.0000
[epoch  4][iter   60] loss: 108400.6172 RMSElog: 9.2105 grad_loss: 10830.8506 normal_loss: 0.0000
[epoch  4][iter   70] loss: 172674.3750 RMSElog: 9.9061 grad_loss: 17257.5312 normal_loss: 0.0000
[epoch  4][iter   80] loss: 162423.6719 RMSElog: 9.8183 grad_loss: 16232.5488 normal_loss: 0.0000
[epoch  4][iter   90] loss: 184006.8438 RMSElog: 9.9468 grad_loss: 18390.7363 normal_loss: 0.0000
[epoch  4][iter  100] loss: 163776.9219 RMSElog: 9.7419 grad_loss: 16367.9502 normal_loss: 0.0000
[epoch  4][iter  110] loss: 122376.6562 RMSElog: 9.6688 grad_loss: 12227.9971 normal_loss: 0.0000
[epoch  4][iter  120] loss: 135690.0938 RMSElog: 9.6754 grad_loss: 13559.3340 normal_loss: 0.0000
[epoch  4][iter  130] loss: 161079.5156 RMSElog: 9.9258 grad_loss: 16098.0254 normal_loss: 0.0000
[epoch  4][iter  140] loss: 105887.2734 RMSElog: 9.6983 grad_loss: 10579.0293 normal_loss: 0.0000
[epoch  4][iter  150] loss: 135194.2344 RMSElog: 9.4545 grad_loss: 13509.9697 normal_loss: 0.0000
[epoch  4][iter  160] loss: 172957.4375 RMSElog: 9.9430 grad_loss: 17285.8008 normal_loss: 0.0000
[epoch  4][iter  170] loss: 167075.2344 RMSElog: 9.8660 grad_loss: 16697.6582 normal_loss: 0.0000
[epoch  4][iter  180] loss: 103789.0000 RMSElog: 9.6193 grad_loss: 10369.2812 normal_loss: 0.0000
[epoch  4][iter  190] loss: 115757.1875 RMSElog: 9.7467 grad_loss: 11565.9717 normal_loss: 0.0000
[epoch  4][iter  200] loss: 179730.6562 RMSElog: 10.1206 grad_loss: 17962.9453 normal_loss: 0.0000
[epoch  4][iter  210] loss: 208812.3438 RMSElog: 10.1565 grad_loss: 20871.0781 normal_loss: 0.0000
[epoch  4][iter  220] loss: 104331.3984 RMSElog: 9.7692 grad_loss: 10423.3701 normal_loss: 0.0000
[epoch  4][iter  230] loss: 141856.0938 RMSElog: 9.7199 grad_loss: 14175.8896 normal_loss: 0.0000
[epoch  4][iter  240] loss: 175476.4844 RMSElog: 10.0393 grad_loss: 17537.6094 normal_loss: 0.0000
[epoch  4][iter  250] loss: 106943.6875 RMSElog: 10.0294 grad_loss: 10684.3398 normal_loss: 0.0000
[epoch  4][iter  260] loss: 149531.1562 RMSElog: 9.7408 grad_loss: 14943.3750 normal_loss: 0.0000
[epoch  4][iter  270] loss: 100654.6172 RMSElog: 9.9598 grad_loss: 10055.5020 normal_loss: 0.0000
[epoch  4][iter  280] loss: 113912.4375 RMSElog: 9.7251 grad_loss: 11381.5195 normal_loss: 0.0000
[epoch  4][iter  290] loss: 171578.8438 RMSElog: 9.8325 grad_loss: 17148.0527 normal_loss: 0.0000
[epoch  4][iter  300] loss: 142586.7188 RMSElog: 9.8922 grad_loss: 14248.7793 normal_loss: 0.0000
[epoch  4][iter  310] loss: 114500.0391 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.0000
[epoch  4][iter  320] loss: 160816.1094 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.0000
[epoch  4][iter  330] loss: 226855.7188 RMSElog: 10.2887 grad_loss: 22675.2832 normal_loss: 0.0000
[epoch  4][iter  340] loss: 139051.9688 RMSElog: 9.6201 grad_loss: 13895.5771 normal_loss: 0.0000
[epoch  4][iter  350] loss: 174751.8438 RMSElog: 9.7333 grad_loss: 17465.4512 normal_loss: 0.0000
[epoch  4][iter  360] loss: 215533.2500 RMSElog: 10.4358 grad_loss: 21542.8887 normal_loss: 0.0000
[epoch  4][iter  370] loss: 210645.0156 RMSElog: 10.4982 grad_loss: 21054.0039 normal_loss: 0.0000
[epoch  4][iter  380] loss: 218616.2812 RMSElog: 10.2839 grad_loss: 21851.3457 normal_loss: 0.0000
[epoch  4][iter  390] loss: 114164.8359 RMSElog: 9.3600 grad_loss: 11407.1230 normal_loss: 0.0000
[epoch  4][iter  400] loss: 139089.1250 RMSElog: 9.8619 grad_loss: 13899.0508 normal_loss: 0.0000
[epoch  4][iter  410] loss: 100971.7031 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.0000
[epoch  4][iter  420] loss: 153988.3281 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.0000
[epoch  4][iter  430] loss: 218747.5000 RMSElog: 10.1228 grad_loss: 21864.6270 normal_loss: 0.0000
[epoch  4][iter  440] loss: 103938.9062 RMSElog: 9.7608 grad_loss: 10384.1299 normal_loss: 0.0000
[epoch  4][iter  450] loss: 162547.0312 RMSElog: 9.9091 grad_loss: 16244.7939 normal_loss: 0.0000
[epoch  4][iter  460] loss: 106760.6094 RMSElog: 9.8688 grad_loss: 10666.1914 normal_loss: 0.0000
[epoch  4][iter  470] loss: 196016.1562 RMSElog: 10.2650 grad_loss: 19591.3496 normal_loss: 0.0000
[epoch  4][iter  480] loss: 207875.7500 RMSElog: 10.4422 grad_loss: 20777.1328 normal_loss: 0.0000
[epoch  4][iter  490] loss: 90473.3125 RMSElog: 9.3127 grad_loss: 9038.0186 normal_loss: 0.0000
[epoch  4][iter  500] loss: 154155.7969 RMSElog: 10.0187 grad_loss: 15405.5605 normal_loss: 0.0000
[epoch  4][iter  510] loss: 194399.2500 RMSElog: 10.2924 grad_loss: 19429.6328 normal_loss: 0.0000
[epoch  4][iter  520] loss: 141219.4531 RMSElog: 9.9926 grad_loss: 14111.9531 normal_loss: 0.0000
[epoch  4][iter  530] loss: 161803.7344 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.0000
[epoch  4][iter  540] loss: 221204.0000 RMSElog: 10.1740 grad_loss: 22110.2266 normal_loss: 0.0000
[epoch  4][iter  550] loss: 148784.5000 RMSElog: 10.1047 grad_loss: 14868.3447 normal_loss: 0.0000
[epoch  4][iter  560] loss: 159814.7812 RMSElog: 9.8973 grad_loss: 15971.5811 normal_loss: 0.0000
[epoch  4][iter  570] loss: 174366.1875 RMSElog: 10.0512 grad_loss: 17426.5684 normal_loss: 0.0000
[epoch  4][iter  580] loss: 128970.3984 RMSElog: 9.7049 grad_loss: 12887.3350 normal_loss: 0.0000
[epoch  4][iter  590] loss: 149026.6094 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.0000
[epoch  5][iter    0] loss: 213392.1562 RMSElog: 10.0568 grad_loss: 21329.1582 normal_loss: 0.0000
[epoch  5][iter   10] loss: 126864.5312 RMSElog: 9.7526 grad_loss: 12676.7002 normal_loss: 0.0000
[epoch  5][iter   20] loss: 146932.7656 RMSElog: 9.4227 grad_loss: 14683.8535 normal_loss: 0.0000
[epoch  5][iter   30] loss: 175349.6094 RMSElog: 10.1476 grad_loss: 17524.8125 normal_loss: 0.0000
[epoch  5][iter   40] loss: 214799.3125 RMSElog: 10.1872 grad_loss: 21469.7441 normal_loss: 0.0000
[epoch  5][iter   50] loss: 146567.5625 RMSElog: 9.6520 grad_loss: 14647.1045 normal_loss: 0.0000
[epoch  5][iter   60] loss: 162702.5469 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.0000
[epoch  5][iter   70] loss: 203083.8281 RMSElog: 10.1238 grad_loss: 20298.2598 normal_loss: 0.0000
[epoch  5][iter   80] loss: 106186.2422 RMSElog: 9.2531 grad_loss: 10609.3711 normal_loss: 0.0000
[epoch  5][iter   90] loss: 180415.6875 RMSElog: 10.0354 grad_loss: 18031.5332 normal_loss: 0.0000
[epoch  5][iter  100] loss: 197511.0781 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.0000
[epoch  5][iter  110] loss: 186039.4375 RMSElog: 10.0165 grad_loss: 18593.9277 normal_loss: 0.0000
[epoch  5][iter  120] loss: 214057.7969 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.0000
[epoch  5][iter  130] loss: 132925.8125 RMSElog: 9.9640 grad_loss: 13282.6172 normal_loss: 0.0000
[epoch  5][iter  140] loss: 221204.0000 RMSElog: 10.1740 grad_loss: 22110.2266 normal_loss: 0.0000
[epoch  5][iter  150] loss: 133750.3750 RMSElog: 10.0653 grad_loss: 13364.9717 normal_loss: 0.0000
[epoch  5][iter  160] loss: 191310.4688 RMSElog: 10.0978 grad_loss: 19120.9492 normal_loss: 0.0000
[epoch  5][iter  170] loss: 165443.4219 RMSElog: 9.9262 grad_loss: 16534.4160 normal_loss: 0.0000
[epoch  5][iter  180] loss: 220686.3125 RMSElog: 10.2208 grad_loss: 22058.4102 normal_loss: 0.0000
[epoch  5][iter  190] loss: 106507.5156 RMSElog: 9.6966 grad_loss: 10641.0557 normal_loss: 0.0000
[epoch  5][iter  200] loss: 195662.2031 RMSElog: 10.1080 grad_loss: 19556.1133 normal_loss: 0.0000
[epoch  5][iter  210] loss: 182178.2969 RMSElog: 10.0835 grad_loss: 18207.7461 normal_loss: 0.0000
[epoch  5][iter  220] loss: 130729.9062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.0000
[epoch  5][iter  230] loss: 141109.0625 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.0000
[epoch  5][iter  240] loss: 115525.0469 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.0000
[epoch  5][iter  250] loss: 136860.4375 RMSElog: 9.5771 grad_loss: 13676.4668 normal_loss: 0.0000
[epoch  5][iter  260] loss: 103945.7812 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.0000
[epoch  5][iter  270] loss: 144977.7188 RMSElog: 9.8653 grad_loss: 14487.9062 normal_loss: 0.0000
[epoch  5][iter  280] loss: 205353.2500 RMSElog: 10.1686 grad_loss: 20525.1562 normal_loss: 0.0000
[epoch  5][iter  290] loss: 152540.2188 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.0000
[epoch  5][iter  300] loss: 112526.2812 RMSElog: 9.5823 grad_loss: 11243.0459 normal_loss: 0.0000
[epoch  5][iter  310] loss: 200943.7656 RMSElog: 10.1163 grad_loss: 20084.2598 normal_loss: 0.0000
[epoch  5][iter  320] loss: 104740.0000 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.0000
[epoch  5][iter  330] loss: 133036.2656 RMSElog: 9.8765 grad_loss: 13293.7490 normal_loss: 0.0000
[epoch  5][iter  340] loss: 163263.3125 RMSElog: 10.0261 grad_loss: 16316.3047 normal_loss: 0.0000
[epoch  5][iter  350] loss: 122661.5703 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.0000
[epoch  5][iter  360] loss: 105819.5781 RMSElog: 10.1032 grad_loss: 10571.8545 normal_loss: 0.0000
[epoch  5][iter  370] loss: 167784.5469 RMSElog: 9.8335 grad_loss: 16768.6211 normal_loss: 0.0000
[epoch  5][iter  380] loss: 195403.4531 RMSElog: 10.0493 grad_loss: 19530.2969 normal_loss: 0.0000
[epoch  5][iter  390] loss: 181456.2500 RMSElog: 10.1136 grad_loss: 18135.5117 normal_loss: 0.0000
[epoch  5][iter  400] loss: 113886.5312 RMSElog: 9.2606 grad_loss: 11379.3926 normal_loss: 0.0000
[epoch  5][iter  410] loss: 196428.2188 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.0000
[epoch  5][iter  420] loss: 107064.2031 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.0000
[epoch  5][iter  430] loss: 120431.3594 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.0000
[epoch  5][iter  440] loss: 142535.2188 RMSElog: 10.2185 grad_loss: 14243.3027 normal_loss: 0.0000
[epoch  5][iter  450] loss: 191962.0469 RMSElog: 10.0873 grad_loss: 19186.1172 normal_loss: 0.0000
[epoch  5][iter  460] loss: 156976.2500 RMSElog: 9.5765 grad_loss: 15688.0488 normal_loss: 0.0000
[epoch  5][iter  470] loss: 174555.5938 RMSElog: 9.7759 grad_loss: 17445.7832 normal_loss: 0.0000
[epoch  5][iter  480] loss: 202620.4844 RMSElog: 10.0417 grad_loss: 20252.0078 normal_loss: 0.0000
[epoch  5][iter  490] loss: 127489.9531 RMSElog: 9.2769 grad_loss: 12739.7178 normal_loss: 0.0000
[epoch  5][iter  500] loss: 115728.8125 RMSElog: 9.6968 grad_loss: 11563.1836 normal_loss: 0.0000
[epoch  5][iter  510] loss: 224934.3438 RMSElog: 10.1206 grad_loss: 22483.3125 normal_loss: 0.0000
[epoch  5][iter  520] loss: 177053.9062 RMSElog: 10.1532 grad_loss: 17695.2383 normal_loss: 0.0000
[epoch  5][iter  530] loss: 128874.0469 RMSElog: 9.8798 grad_loss: 12877.5244 normal_loss: 0.0000
[epoch  5][iter  540] loss: 172238.9062 RMSElog: 9.5166 grad_loss: 17214.3730 normal_loss: 0.0000
[epoch  5][iter  550] loss: 154280.7969 RMSElog: 9.8471 grad_loss: 15418.2334 normal_loss: 0.0000
[epoch  5][iter  560] loss: 189734.0625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.0000
[epoch  5][iter  570] loss: 143451.3750 RMSElog: 9.7520 grad_loss: 14335.3848 normal_loss: 0.0000
[epoch  5][iter  580] loss: 111646.4453 RMSElog: 9.2050 grad_loss: 11155.4395 normal_loss: 0.0000
[epoch  5][iter  590] loss: 226940.0781 RMSElog: 10.2029 grad_loss: 22683.8047 normal_loss: 0.0000
[epoch  6][iter    0] loss: 182306.3281 RMSElog: 10.1291 grad_loss: 18220.5039 normal_loss: 0.0000
[epoch  6][iter   10] loss: 197705.4688 RMSElog: 10.4355 grad_loss: 19760.1113 normal_loss: 0.0000
[epoch  6][iter   20] loss: 154020.3750 RMSElog: 9.8645 grad_loss: 15392.1729 normal_loss: 0.0000
[epoch  6][iter   30] loss: 112687.7422 RMSElog: 9.7295 grad_loss: 11259.0449 normal_loss: 0.0000
[epoch  6][iter   40] loss: 114817.7734 RMSElog: 9.7767 grad_loss: 11472.0010 normal_loss: 0.0000
[epoch  6][iter   50] loss: 181283.8125 RMSElog: 10.0009 grad_loss: 18118.3809 normal_loss: 0.0000
[epoch  6][iter   60] loss: 142006.8594 RMSElog: 9.9191 grad_loss: 14190.7676 normal_loss: 0.0000
[epoch  6][iter   70] loss: 165010.7031 RMSElog: 9.7791 grad_loss: 16491.2910 normal_loss: 0.0000
[epoch  6][iter   80] loss: 218616.2812 RMSElog: 10.2839 grad_loss: 21851.3457 normal_loss: 0.0000
[epoch  6][iter   90] loss: 160816.1094 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.0000
[epoch  6][iter  100] loss: 147198.5625 RMSElog: 9.9779 grad_loss: 14709.8789 normal_loss: 0.0000
[epoch  6][iter  110] loss: 102214.2891 RMSElog: 9.4278 grad_loss: 10212.0010 normal_loss: 0.0000
[epoch  6][iter  120] loss: 121857.3828 RMSElog: 9.8422 grad_loss: 12175.8965 normal_loss: 0.0000
[epoch  6][iter  130] loss: 107463.1250 RMSElog: 9.0654 grad_loss: 10737.2471 normal_loss: 0.0000
[epoch  6][iter  140] loss: 144977.7188 RMSElog: 9.8653 grad_loss: 14487.9062 normal_loss: 0.0000
[epoch  6][iter  150] loss: 228043.6094 RMSElog: 10.2288 grad_loss: 22794.1328 normal_loss: 0.0000
[epoch  6][iter  160] loss: 185062.1719 RMSElog: 10.0456 grad_loss: 18496.1719 normal_loss: 0.0000
[epoch  6][iter  170] loss: 140324.4688 RMSElog: 9.8261 grad_loss: 14022.6211 normal_loss: 0.0000
[epoch  6][iter  180] loss: 161275.7500 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.0000
[epoch  6][iter  190] loss: 156163.8750 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.0000
[epoch  6][iter  200] loss: 218940.3750 RMSElog: 10.4462 grad_loss: 21883.5918 normal_loss: 0.0000
[epoch  6][iter  210] loss: 119461.2188 RMSElog: 9.6196 grad_loss: 11936.5020 normal_loss: 0.0000
[epoch  6][iter  220] loss: 161623.7656 RMSElog: 10.0107 grad_loss: 16152.3652 normal_loss: 0.0000
[epoch  6][iter  230] loss: 174751.8438 RMSElog: 9.7333 grad_loss: 17465.4512 normal_loss: 0.0000
[epoch  6][iter  240] loss: 104118.5625 RMSElog: 9.6242 grad_loss: 10402.2324 normal_loss: 0.0000
[epoch  6][iter  250] loss: 177924.8281 RMSElog: 9.8386 grad_loss: 17782.6445 normal_loss: 0.0000
[epoch  6][iter  260] loss: 170533.2656 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.0000
[epoch  6][iter  270] loss: 162569.9688 RMSElog: 10.1223 grad_loss: 16246.8740 normal_loss: 0.0000
[epoch  6][iter  280] loss: 149118.7969 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.0000
[epoch  6][iter  290] loss: 177690.3281 RMSElog: 9.4851 grad_loss: 17759.5488 normal_loss: 0.0000
[epoch  6][iter  300] loss: 149360.6875 RMSElog: 10.0930 grad_loss: 14925.9756 normal_loss: 0.0000
[epoch  6][iter  310] loss: 228329.2812 RMSElog: 10.2936 grad_loss: 22822.6348 normal_loss: 0.0000
[epoch  6][iter  320] loss: 135105.3281 RMSElog: 9.9265 grad_loss: 13500.6055 normal_loss: 0.0000
[epoch  6][iter  330] loss: 109432.2266 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.0000
[epoch  6][iter  340] loss: 125686.2578 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.0000
[epoch  6][iter  350] loss: 136860.4375 RMSElog: 9.5771 grad_loss: 13676.4668 normal_loss: 0.0000
[epoch  6][iter  360] loss: 114915.6172 RMSElog: 9.6925 grad_loss: 11481.8691 normal_loss: 0.0000
[epoch  6][iter  370] loss: 234935.6875 RMSElog: 10.0015 grad_loss: 23483.5664 normal_loss: 0.0000
[epoch  6][iter  380] loss: 160870.2812 RMSElog: 9.7521 grad_loss: 16077.2754 normal_loss: 0.0000
[epoch  6][iter  390] loss: 197511.0781 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.0000
[epoch  6][iter  400] loss: 139051.9688 RMSElog: 9.6201 grad_loss: 13895.5771 normal_loss: 0.0000
[epoch  6][iter  410] loss: 172859.2031 RMSElog: 10.0539 grad_loss: 17275.8652 normal_loss: 0.0000
[epoch  6][iter  420] loss: 115491.1562 RMSElog: 9.9924 grad_loss: 11539.1230 normal_loss: 0.0000
[epoch  6][iter  430] loss: 202620.4844 RMSElog: 10.0417 grad_loss: 20252.0078 normal_loss: 0.0000
[epoch  6][iter  440] loss: 155901.8281 RMSElog: 9.7863 grad_loss: 15580.3965 normal_loss: 0.0000
[epoch  6][iter  450] loss: 106943.6875 RMSElog: 10.0294 grad_loss: 10684.3398 normal_loss: 0.0000
[epoch  6][iter  460] loss: 153988.3281 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.0000
[epoch  6][iter  470] loss: 186950.9219 RMSElog: 10.2468 grad_loss: 18684.8457 normal_loss: 0.0000
[epoch  6][iter  480] loss: 133015.5938 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.0000
[epoch  6][iter  490] loss: 180309.3125 RMSElog: 9.9530 grad_loss: 18020.9785 normal_loss: 0.0000
[epoch  6][iter  500] loss: 164756.8750 RMSElog: 9.6928 grad_loss: 16465.9941 normal_loss: 0.0000
[epoch  6][iter  510] loss: 140929.4375 RMSElog: 9.7483 grad_loss: 14083.1953 normal_loss: 0.0000
[epoch  6][iter  520] loss: 175292.1875 RMSElog: 9.8017 grad_loss: 17519.4180 normal_loss: 0.0000
[epoch  6][iter  530] loss: 176214.0000 RMSElog: 9.9872 grad_loss: 17611.4141 normal_loss: 0.0000
[epoch  6][iter  540] loss: 103505.5547 RMSElog: 9.3451 grad_loss: 10341.2109 normal_loss: 0.0000
[epoch  6][iter  550] loss: 214483.6094 RMSElog: 10.3525 grad_loss: 21438.0078 normal_loss: 0.0000
[epoch  6][iter  560] loss: 223865.8750 RMSElog: 10.3929 grad_loss: 22376.1953 normal_loss: 0.0000
[epoch  6][iter  570] loss: 150311.9062 RMSElog: 9.9248 grad_loss: 15021.2656 normal_loss: 0.0000
[epoch  6][iter  580] loss: 146567.5625 RMSElog: 9.6520 grad_loss: 14647.1045 normal_loss: 0.0000
[epoch  6][iter  590] loss: 90473.3125 RMSElog: 9.3127 grad_loss: 9038.0186 normal_loss: 0.0000
[epoch  7][iter    0] loss: 177804.7500 RMSElog: 10.0854 grad_loss: 17770.3887 normal_loss: 0.0000
[epoch  7][iter   10] loss: 150599.4375 RMSElog: 10.0680 grad_loss: 15049.8750 normal_loss: 0.0000
[epoch  7][iter   20] loss: 99098.6641 RMSElog: 9.5230 grad_loss: 9900.3428 normal_loss: 0.0000
[epoch  7][iter   30] loss: 165967.0938 RMSElog: 9.9385 grad_loss: 16586.7695 normal_loss: 0.0000
[epoch  7][iter   40] loss: 103505.5469 RMSElog: 9.3451 grad_loss: 10341.2100 normal_loss: 0.0000
[epoch  7][iter   50] loss: 176788.5000 RMSElog: 9.8176 grad_loss: 17669.0312 normal_loss: 0.0000
[epoch  7][iter   60] loss: 148229.7500 RMSElog: 9.8055 grad_loss: 14813.1689 normal_loss: 0.0000
[epoch  7][iter   70] loss: 182309.4062 RMSElog: 10.1008 grad_loss: 18220.8398 normal_loss: 0.0000
[epoch  7][iter   80] loss: 127101.3359 RMSElog: 9.5273 grad_loss: 12700.6064 normal_loss: 0.0000
[epoch  7][iter   90] loss: 122661.5703 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.0000
[epoch  7][iter  100] loss: 157265.0000 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.0000
[epoch  7][iter  110] loss: 195431.3281 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.0000
[epoch  7][iter  120] loss: 176251.3438 RMSElog: 10.0638 grad_loss: 17615.0703 normal_loss: 0.0000
[epoch  7][iter  130] loss: 170533.2656 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.0000
[epoch  7][iter  140] loss: 227314.3594 RMSElog: 10.4159 grad_loss: 22721.0195 normal_loss: 0.0000
[epoch  7][iter  150] loss: 120431.3594 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.0000
[epoch  7][iter  160] loss: 179730.6562 RMSElog: 10.1206 grad_loss: 17962.9453 normal_loss: 0.0000
[epoch  7][iter  170] loss: 152762.9844 RMSElog: 9.8249 grad_loss: 15266.4736 normal_loss: 0.0000
[epoch  7][iter  180] loss: 113912.4375 RMSElog: 9.7251 grad_loss: 11381.5195 normal_loss: 0.0000
[epoch  7][iter  190] loss: 100980.9375 RMSElog: 9.7350 grad_loss: 10088.3584 normal_loss: 0.0000
[epoch  7][iter  200] loss: 133015.5938 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.0000
[epoch  7][iter  210] loss: 111646.4453 RMSElog: 9.2050 grad_loss: 11155.4395 normal_loss: 0.0000
[epoch  7][iter  220] loss: 183085.4688 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.0000
[epoch  7][iter  230] loss: 118736.9062 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.0000
[epoch  7][iter  240] loss: 159789.3438 RMSElog: 9.8075 grad_loss: 15969.1260 normal_loss: 0.0000
[epoch  7][iter  250] loss: 157800.9062 RMSElog: 9.9254 grad_loss: 15770.1641 normal_loss: 0.0000
[epoch  7][iter  260] loss: 172105.9219 RMSElog: 9.7682 grad_loss: 17200.8242 normal_loss: 0.0000
[epoch  7][iter  270] loss: 177186.0312 RMSElog: 10.1516 grad_loss: 17708.4512 normal_loss: 0.0000
[epoch  7][iter  280] loss: 114140.2969 RMSElog: 9.2655 grad_loss: 11404.7637 normal_loss: 0.0000
[epoch  7][iter  290] loss: 100971.7031 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.0000
[epoch  7][iter  300] loss: 146950.9219 RMSElog: 10.0979 grad_loss: 14684.9941 normal_loss: 0.0000
[epoch  7][iter  310] loss: 182849.3594 RMSElog: 9.8110 grad_loss: 18275.1250 normal_loss: 0.0000
[epoch  7][iter  320] loss: 108790.9062 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.0000
[epoch  7][iter  330] loss: 103945.7812 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.0000
[epoch  7][iter  340] loss: 196428.2188 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.0000
[epoch  7][iter  350] loss: 100740.3125 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.0000
[epoch  7][iter  360] loss: 150689.8906 RMSElog: 9.8567 grad_loss: 15059.1328 normal_loss: 0.0000
[epoch  7][iter  370] loss: 167730.8750 RMSElog: 9.8540 grad_loss: 16763.2344 normal_loss: 0.0000
[epoch  7][iter  380] loss: 128268.4531 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.0000
[epoch  7][iter  390] loss: 133276.7656 RMSElog: 9.7900 grad_loss: 13317.8867 normal_loss: 0.0000
[epoch  7][iter  400] loss: 129157.1406 RMSElog: 9.7364 grad_loss: 12905.9775 normal_loss: 0.0000
[epoch  7][iter  410] loss: 122350.0859 RMSElog: 9.7683 grad_loss: 12225.2402 normal_loss: 0.0000
[epoch  7][iter  420] loss: 112706.4375 RMSElog: 9.6867 grad_loss: 11260.9570 normal_loss: 0.0000
[epoch  7][iter  430] loss: 156163.8750 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.0000
[epoch  7][iter  440] loss: 128970.3984 RMSElog: 9.7049 grad_loss: 12887.3350 normal_loss: 0.0000
[epoch  7][iter  450] loss: 151392.3438 RMSElog: 9.4414 grad_loss: 15129.7930 normal_loss: 0.0000
[epoch  7][iter  460] loss: 106186.2422 RMSElog: 9.2531 grad_loss: 10609.3711 normal_loss: 0.0000
[epoch  7][iter  470] loss: 100107.2344 RMSElog: 9.9235 grad_loss: 10000.7998 normal_loss: 0.0000
[epoch  7][iter  480] loss: 132003.3906 RMSElog: 9.6802 grad_loss: 13190.6582 normal_loss: 0.0000
[epoch  7][iter  490] loss: 164834.3438 RMSElog: 9.7972 grad_loss: 16473.6367 normal_loss: 0.0000
[epoch  7][iter  500] loss: 191361.9375 RMSElog: 10.1918 grad_loss: 19126.0020 normal_loss: 0.0000
[epoch  7][iter  510] loss: 129150.1562 RMSElog: 9.6889 grad_loss: 12905.3271 normal_loss: 0.0000
[epoch  7][iter  520] loss: 227071.1094 RMSElog: 10.4127 grad_loss: 22696.6992 normal_loss: 0.0000
[epoch  7][iter  530] loss: 142535.0938 RMSElog: 10.1645 grad_loss: 14243.3457 normal_loss: 0.0000
[epoch  7][iter  540] loss: 191310.4688 RMSElog: 10.0978 grad_loss: 19120.9492 normal_loss: 0.0000
[epoch  7][iter  550] loss: 198733.7656 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.0000
[epoch  7][iter  560] loss: 177690.3281 RMSElog: 9.4851 grad_loss: 17759.5488 normal_loss: 0.0000
[epoch  7][iter  570] loss: 148047.6875 RMSElog: 9.9895 grad_loss: 14794.7803 normal_loss: 0.0000
[epoch  7][iter  580] loss: 162532.5156 RMSElog: 9.9393 grad_loss: 16243.3115 normal_loss: 0.0000
[epoch  7][iter  590] loss: 134396.6562 RMSElog: 9.9402 grad_loss: 13429.7256 normal_loss: 0.0000
[epoch  8][iter    0] loss: 181465.8125 RMSElog: 10.1136 grad_loss: 18135.5117 normal_loss: 0.9572
[epoch  8][iter   10] loss: 152540.7500 RMSElog: 9.9175 grad_loss: 15243.2090 normal_loss: 0.9474
[epoch  8][iter   20] loss: 144987.0938 RMSElog: 9.8653 grad_loss: 14487.9062 normal_loss: 0.9378
[epoch  8][iter   30] loss: 135966.2969 RMSElog: 9.6504 grad_loss: 13586.0273 normal_loss: 0.9522
[epoch  8][iter   40] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch  8][iter   50] loss: 114924.9844 RMSElog: 9.6925 grad_loss: 11481.8691 normal_loss: 0.9360
[epoch  8][iter   60] loss: 178076.4688 RMSElog: 9.8778 grad_loss: 17796.8457 normal_loss: 0.9233
[epoch  8][iter   70] loss: 159422.2500 RMSElog: 9.7010 grad_loss: 15931.5938 normal_loss: 0.9299
[epoch  8][iter   80] loss: 122912.0625 RMSElog: 9.7328 grad_loss: 12280.5225 normal_loss: 0.9509
[epoch  8][iter   90] loss: 106769.7500 RMSElog: 9.8688 grad_loss: 10666.1914 normal_loss: 0.9140
[epoch  8][iter  100] loss: 139830.9062 RMSElog: 9.7552 grad_loss: 13972.3770 normal_loss: 0.9585
[epoch  8][iter  110] loss: 185495.4062 RMSElog: 9.9310 grad_loss: 18538.6641 normal_loss: 0.9455
[epoch  8][iter  120] loss: 115738.1953 RMSElog: 9.6968 grad_loss: 11563.1836 normal_loss: 0.9382
[epoch  8][iter  130] loss: 157119.7500 RMSElog: 9.8959 grad_loss: 15701.1318 normal_loss: 0.9480
[epoch  8][iter  140] loss: 164767.1875 RMSElog: 9.8398 grad_loss: 16465.9102 normal_loss: 0.9691
[epoch  8][iter  150] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch  8][iter  160] loss: 148239.1406 RMSElog: 9.8055 grad_loss: 14813.1689 normal_loss: 0.9395
[epoch  8][iter  170] loss: 124246.3594 RMSElog: 9.7165 grad_loss: 12413.9834 normal_loss: 0.9360
[epoch  8][iter  180] loss: 150459.7656 RMSElog: 9.9429 grad_loss: 15035.0986 normal_loss: 0.9347
[epoch  8][iter  190] loss: 229081.2812 RMSElog: 10.2778 grad_loss: 22896.9102 normal_loss: 0.9420
[epoch  8][iter  200] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch  8][iter  210] loss: 203093.2969 RMSElog: 10.1238 grad_loss: 20298.2598 normal_loss: 0.9478
[epoch  8][iter  220] loss: 194987.6250 RMSElog: 9.8416 grad_loss: 19487.9453 normal_loss: 0.9748
[epoch  8][iter  230] loss: 115766.5312 RMSElog: 9.7467 grad_loss: 11565.9717 normal_loss: 0.9344
[epoch  8][iter  240] loss: 199607.1562 RMSElog: 10.1504 grad_loss: 19949.6133 normal_loss: 0.9517
[epoch  8][iter  250] loss: 144657.9844 RMSElog: 9.9197 grad_loss: 14454.9258 normal_loss: 0.9518
[epoch  8][iter  260] loss: 155762.3594 RMSElog: 9.8487 grad_loss: 15565.4414 normal_loss: 0.9448
[epoch  8][iter  270] loss: 177699.9688 RMSElog: 9.4851 grad_loss: 17759.5488 normal_loss: 0.9621
[epoch  8][iter  280] loss: 163389.5625 RMSElog: 9.7702 grad_loss: 16328.2656 normal_loss: 0.9208
[epoch  8][iter  290] loss: 145409.6719 RMSElog: 9.8330 grad_loss: 14530.1904 normal_loss: 0.9445
[epoch  8][iter  300] loss: 177814.3125 RMSElog: 10.0854 grad_loss: 17770.3887 normal_loss: 0.9571
[epoch  8][iter  310] loss: 103514.7812 RMSElog: 9.3451 grad_loss: 10341.2109 normal_loss: 0.9229
[epoch  8][iter  320] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch  8][iter  330] loss: 166207.1094 RMSElog: 9.7947 grad_loss: 16609.9668 normal_loss: 0.9492
[epoch  8][iter  340] loss: 120765.1875 RMSElog: 9.5441 grad_loss: 12066.0400 normal_loss: 0.9348
[epoch  8][iter  350] loss: 189017.5781 RMSElog: 10.1390 grad_loss: 18890.6602 normal_loss: 0.9589
[epoch  8][iter  360] loss: 167345.2500 RMSElog: 9.8843 grad_loss: 16723.6777 normal_loss: 0.9620
[epoch  8][iter  370] loss: 174629.2812 RMSElog: 9.9405 grad_loss: 17452.0625 normal_loss: 0.9229
[epoch  8][iter  380] loss: 184374.2188 RMSElog: 10.2641 grad_loss: 18426.1992 normal_loss: 0.9596
[epoch  8][iter  390] loss: 179740.0625 RMSElog: 10.1206 grad_loss: 17962.9453 normal_loss: 0.9397
[epoch  8][iter  400] loss: 185772.2500 RMSElog: 9.9702 grad_loss: 18566.2969 normal_loss: 0.9567
[epoch  8][iter  410] loss: 142138.5156 RMSElog: 9.7967 grad_loss: 14203.1260 normal_loss: 0.9291
[epoch  8][iter  420] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch  8][iter  430] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch  8][iter  440] loss: 160595.2188 RMSElog: 9.9514 grad_loss: 16048.6191 normal_loss: 0.9518
[epoch  8][iter  450] loss: 154029.7812 RMSElog: 9.8645 grad_loss: 15392.1729 normal_loss: 0.9405
[epoch  8][iter  460] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch  8][iter  470] loss: 162372.7500 RMSElog: 9.8226 grad_loss: 16226.4922 normal_loss: 0.9603
[epoch  8][iter  480] loss: 188645.4531 RMSElog: 10.1590 grad_loss: 18853.4082 normal_loss: 0.9794
[epoch  8][iter  490] loss: 160466.8750 RMSElog: 9.9086 grad_loss: 16035.8252 normal_loss: 0.9540
[epoch  8][iter  500] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch  8][iter  510] loss: 176260.7500 RMSElog: 10.0638 grad_loss: 17615.0703 normal_loss: 0.9395
[epoch  8][iter  520] loss: 178784.1250 RMSElog: 9.9460 grad_loss: 17867.5078 normal_loss: 0.9592
[epoch  8][iter  530] loss: 218625.8750 RMSElog: 10.2839 grad_loss: 21851.3457 normal_loss: 0.9592
[epoch  8][iter  540] loss: 175486.0156 RMSElog: 10.0393 grad_loss: 17537.6055 normal_loss: 0.9563
[epoch  8][iter  550] loss: 160782.5156 RMSElog: 9.7710 grad_loss: 16067.5547 normal_loss: 0.9244
[epoch  8][iter  560] loss: 177934.3750 RMSElog: 9.8386 grad_loss: 17782.6445 normal_loss: 0.9542
[epoch  8][iter  570] loss: 235211.2344 RMSElog: 10.3371 grad_loss: 23509.8398 normal_loss: 0.9452
[epoch  8][iter  580] loss: 146942.0781 RMSElog: 9.4227 grad_loss: 14683.8535 normal_loss: 0.9314
[epoch  8][iter  590] loss: 120590.1719 RMSElog: 9.9054 grad_loss: 12048.1719 normal_loss: 0.9408
[epoch  9][iter    0] loss: 150321.2812 RMSElog: 9.9248 grad_loss: 15021.2656 normal_loss: 0.9385
[epoch  9][iter   10] loss: 105896.9375 RMSElog: 9.7662 grad_loss: 10578.9961 normal_loss: 0.9310
[epoch  9][iter   20] loss: 195413.0312 RMSElog: 10.0493 grad_loss: 19530.3008 normal_loss: 0.9539
[epoch  9][iter   30] loss: 173339.3594 RMSElog: 9.8230 grad_loss: 17323.1914 normal_loss: 0.9212
[epoch  9][iter   40] loss: 170488.4688 RMSElog: 9.7164 grad_loss: 17038.1816 normal_loss: 0.9494
[epoch  9][iter   50] loss: 132012.6719 RMSElog: 9.6802 grad_loss: 13190.6582 normal_loss: 0.9291
[epoch  9][iter   60] loss: 125829.2891 RMSElog: 9.7844 grad_loss: 12572.2148 normal_loss: 0.9297
[epoch  9][iter   70] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch  9][iter   80] loss: 175004.6875 RMSElog: 10.1774 grad_loss: 17489.3340 normal_loss: 0.9561
[epoch  9][iter   90] loss: 96006.2578 RMSElog: 9.5560 grad_loss: 9590.1406 normal_loss: 0.9294
[epoch  9][iter  100] loss: 149540.3750 RMSElog: 9.7408 grad_loss: 14943.3740 normal_loss: 0.9229
[epoch  9][iter  110] loss: 183095.1562 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.9696
[epoch  9][iter  120] loss: 115651.6406 RMSElog: 9.1877 grad_loss: 11555.0664 normal_loss: 0.9106
[epoch  9][iter  130] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch  9][iter  140] loss: 163389.5625 RMSElog: 9.7702 grad_loss: 16328.2656 normal_loss: 0.9208
[epoch  9][iter  150] loss: 105794.8828 RMSElog: 9.7676 grad_loss: 10568.7939 normal_loss: 0.9267
[epoch  9][iter  160] loss: 135114.8750 RMSElog: 9.9265 grad_loss: 13500.6055 normal_loss: 0.9548
[epoch  9][iter  170] loss: 100749.6875 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.9377
[epoch  9][iter  180] loss: 133013.4531 RMSElog: 9.5635 grad_loss: 13290.8457 normal_loss: 0.9356
[epoch  9][iter  190] loss: 151723.8750 RMSElog: 9.9680 grad_loss: 15161.4746 normal_loss: 0.9449
[epoch  9][iter  200] loss: 120440.5938 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.9240
[epoch  9][iter  210] loss: 196920.5938 RMSElog: 10.2474 grad_loss: 19680.8340 normal_loss: 0.9760
[epoch  9][iter  220] loss: 179298.9062 RMSElog: 9.7220 grad_loss: 17919.2227 normal_loss: 0.9453
[epoch  9][iter  230] loss: 136869.7500 RMSElog: 9.5771 grad_loss: 13676.4668 normal_loss: 0.9315
[epoch  9][iter  240] loss: 133464.0312 RMSElog: 9.6242 grad_loss: 13335.8584 normal_loss: 0.9201
[epoch  9][iter  250] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch  9][iter  260] loss: 234945.1719 RMSElog: 10.0015 grad_loss: 23483.5664 normal_loss: 0.9500
[epoch  9][iter  270] loss: 128883.6328 RMSElog: 9.8798 grad_loss: 12877.5244 normal_loss: 0.9593
[epoch  9][iter  280] loss: 119470.5156 RMSElog: 9.6196 grad_loss: 11936.5020 normal_loss: 0.9297
[epoch  9][iter  290] loss: 214067.1875 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.9394
[epoch  9][iter  300] loss: 194408.7812 RMSElog: 10.2924 grad_loss: 19429.6328 normal_loss: 0.9537
[epoch  9][iter  310] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch  9][iter  320] loss: 150323.7656 RMSElog: 10.0510 grad_loss: 15021.3848 normal_loss: 0.9410
[epoch  9][iter  330] loss: 175547.8906 RMSElog: 10.1409 grad_loss: 17543.7148 normal_loss: 0.9342
[epoch  9][iter  340] loss: 149387.5469 RMSElog: 9.9550 grad_loss: 14927.8516 normal_loss: 0.9483
[epoch  9][iter  350] loss: 111712.9219 RMSElog: 9.7826 grad_loss: 11160.5811 normal_loss: 0.9290
[epoch  9][iter  360] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch  9][iter  370] loss: 214808.7344 RMSElog: 10.1872 grad_loss: 21469.7441 normal_loss: 0.9423
[epoch  9][iter  380] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch  9][iter  390] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch  9][iter  400] loss: 208184.3438 RMSElog: 10.4061 grad_loss: 20807.0801 normal_loss: 0.9472
[epoch  9][iter  410] loss: 198293.9219 RMSElog: 10.2275 grad_loss: 19818.2148 normal_loss: 0.9521
[epoch  9][iter  420] loss: 144191.5938 RMSElog: 9.6650 grad_loss: 14408.5654 normal_loss: 0.9284
[epoch  9][iter  430] loss: 121838.3672 RMSElog: 9.7453 grad_loss: 12173.1494 normal_loss: 0.9425
[epoch  9][iter  440] loss: 141865.3906 RMSElog: 9.7199 grad_loss: 14175.8896 normal_loss: 0.9298
[epoch  9][iter  450] loss: 136507.7344 RMSElog: 10.0223 grad_loss: 13639.7900 normal_loss: 0.9608
[epoch  9][iter  460] loss: 185071.7031 RMSElog: 10.0456 grad_loss: 18496.1699 normal_loss: 0.9557
[epoch  9][iter  470] loss: 169013.5625 RMSElog: 9.5880 grad_loss: 16890.8262 normal_loss: 0.9419
[epoch  9][iter  480] loss: 121959.7344 RMSElog: 9.7378 grad_loss: 12185.3047 normal_loss: 0.9314
[epoch  9][iter  490] loss: 103948.1719 RMSElog: 9.7608 grad_loss: 10384.1299 normal_loss: 0.9264
[epoch  9][iter  500] loss: 142544.7031 RMSElog: 10.2185 grad_loss: 14243.3027 normal_loss: 0.9486
[epoch  9][iter  510] loss: 142016.3906 RMSElog: 9.9191 grad_loss: 14190.7676 normal_loss: 0.9526
[epoch  9][iter  520] loss: 156173.3594 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.9482
[epoch  9][iter  530] loss: 130145.6328 RMSElog: 9.7206 grad_loss: 13003.9082 normal_loss: 0.9344
[epoch  9][iter  540] loss: 175359.1875 RMSElog: 10.1476 grad_loss: 17524.8125 normal_loss: 0.9571
[epoch  9][iter  550] loss: 129205.9375 RMSElog: 9.8851 grad_loss: 12909.7734 normal_loss: 0.9356
[epoch  9][iter  560] loss: 155482.2031 RMSElog: 10.0818 grad_loss: 15537.1826 normal_loss: 0.9552
[epoch  9][iter  570] loss: 186960.2969 RMSElog: 10.2468 grad_loss: 18684.8457 normal_loss: 0.9380
[epoch  9][iter  580] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch  9][iter  590] loss: 113921.7969 RMSElog: 9.7251 grad_loss: 11381.5195 normal_loss: 0.9357
[epoch 10][iter    0] loss: 72289.2656 RMSElog: 9.4677 grad_loss: 7218.5376 normal_loss: 0.9211
[epoch 10][iter   10] loss: 154776.6094 RMSElog: 9.8981 grad_loss: 15466.8418 normal_loss: 0.9209
[epoch 10][iter   20] loss: 145389.9375 RMSElog: 9.8784 grad_loss: 14528.1660 normal_loss: 0.9489
[epoch 10][iter   30] loss: 102998.8984 RMSElog: 9.8140 grad_loss: 10289.1318 normal_loss: 0.9431
[epoch 10][iter   40] loss: 196437.8125 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.9584
[epoch 10][iter   50] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 10][iter   60] loss: 213417.0312 RMSElog: 10.3416 grad_loss: 21330.4082 normal_loss: 0.9536
[epoch 10][iter   70] loss: 157274.4688 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.9461
[epoch 10][iter   80] loss: 188116.2812 RMSElog: 10.0888 grad_loss: 18800.5703 normal_loss: 0.9711
[epoch 10][iter   90] loss: 120590.1719 RMSElog: 9.9054 grad_loss: 12048.1719 normal_loss: 0.9408
[epoch 10][iter  100] loss: 206764.1875 RMSElog: 10.2849 grad_loss: 20665.1777 normal_loss: 0.9549
[epoch 10][iter  110] loss: 111914.6250 RMSElog: 9.3004 grad_loss: 11181.2402 normal_loss: 0.9218
[epoch 10][iter  120] loss: 134471.5938 RMSElog: 9.9200 grad_loss: 13436.3281 normal_loss: 0.9111
[epoch 10][iter  130] loss: 172755.6875 RMSElog: 10.0251 grad_loss: 17264.6016 normal_loss: 0.9419
[epoch 10][iter  140] loss: 176798.0312 RMSElog: 9.8176 grad_loss: 17669.0293 normal_loss: 0.9559
[epoch 10][iter  150] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 10][iter  160] loss: 144657.9844 RMSElog: 9.9197 grad_loss: 14454.9258 normal_loss: 0.9518
[epoch 10][iter  170] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 10][iter  180] loss: 191971.7188 RMSElog: 10.0873 grad_loss: 19186.1172 normal_loss: 0.9662
[epoch 10][iter  190] loss: 173574.0781 RMSElog: 10.1780 grad_loss: 17346.2734 normal_loss: 0.9575
[epoch 10][iter  200] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 10][iter  210] loss: 126874.0625 RMSElog: 9.7526 grad_loss: 12676.7002 normal_loss: 0.9530
[epoch 10][iter  220] loss: 122331.3906 RMSElog: 9.7180 grad_loss: 12222.4795 normal_loss: 0.9418
[epoch 10][iter  230] loss: 164767.1875 RMSElog: 9.8398 grad_loss: 16465.9102 normal_loss: 0.9691
[epoch 10][iter  240] loss: 112715.8125 RMSElog: 9.6867 grad_loss: 11260.9570 normal_loss: 0.9375
[epoch 10][iter  250] loss: 159340.4375 RMSElog: 9.9507 grad_loss: 15923.1426 normal_loss: 0.9500
[epoch 10][iter  260] loss: 163268.1250 RMSElog: 9.9218 grad_loss: 16315.9277 normal_loss: 0.9630
[epoch 10][iter  270] loss: 210654.5312 RMSElog: 10.4982 grad_loss: 21054.0039 normal_loss: 0.9517
[epoch 10][iter  280] loss: 105896.6094 RMSElog: 9.6983 grad_loss: 10579.0293 normal_loss: 0.9335
[epoch 10][iter  290] loss: 180982.8438 RMSElog: 10.2711 grad_loss: 18087.0605 normal_loss: 0.9528
[epoch 10][iter  300] loss: 132935.3906 RMSElog: 9.9640 grad_loss: 13282.6172 normal_loss: 0.9581
[epoch 10][iter  310] loss: 161084.5312 RMSElog: 9.9606 grad_loss: 16097.5410 normal_loss: 0.9512
[epoch 10][iter  320] loss: 104446.5625 RMSElog: 10.1932 grad_loss: 10433.5342 normal_loss: 0.9288
[epoch 10][iter  330] loss: 136796.3438 RMSElog: 9.6524 grad_loss: 13669.0273 normal_loss: 0.9549
[epoch 10][iter  340] loss: 152332.5469 RMSElog: 9.9813 grad_loss: 15222.3486 normal_loss: 0.9245
[epoch 10][iter  350] loss: 114893.3984 RMSElog: 9.2562 grad_loss: 11479.1777 normal_loss: 0.9067
[epoch 10][iter  360] loss: 154626.7656 RMSElog: 9.9098 grad_loss: 15451.8066 normal_loss: 0.9596
[epoch 10][iter  370] loss: 147371.3906 RMSElog: 9.6635 grad_loss: 14726.5488 normal_loss: 0.9280
[epoch 10][iter  380] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch 10][iter  390] loss: 87697.6250 RMSElog: 9.9487 grad_loss: 8758.8750 normal_loss: 0.9395
[epoch 10][iter  400] loss: 175008.6562 RMSElog: 9.9496 grad_loss: 17489.9434 normal_loss: 0.9734
[epoch 10][iter  410] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 10][iter  420] loss: 161646.4688 RMSElog: 10.1105 grad_loss: 16153.5762 normal_loss: 0.9608
[epoch 10][iter  430] loss: 153447.6875 RMSElog: 9.9051 grad_loss: 15333.9209 normal_loss: 0.9425
[epoch 10][iter  440] loss: 105706.7031 RMSElog: 9.7501 grad_loss: 10559.9883 normal_loss: 0.9321
[epoch 10][iter  450] loss: 212239.7031 RMSElog: 10.2690 grad_loss: 21212.7383 normal_loss: 0.9638
[epoch 10][iter  460] loss: 124246.3594 RMSElog: 9.7165 grad_loss: 12413.9834 normal_loss: 0.9360
[epoch 10][iter  470] loss: 172966.9375 RMSElog: 9.9430 grad_loss: 17285.8008 normal_loss: 0.9485
[epoch 10][iter  480] loss: 130641.2188 RMSElog: 9.7184 grad_loss: 13053.4688 normal_loss: 0.9344
[epoch 10][iter  490] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 10][iter  500] loss: 223875.4062 RMSElog: 10.3929 grad_loss: 22376.1953 normal_loss: 0.9536
[epoch 10][iter  510] loss: 170542.9531 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.9688
[epoch 10][iter  520] loss: 176223.4531 RMSElog: 9.9872 grad_loss: 17611.4141 normal_loss: 0.9446
[epoch 10][iter  530] loss: 105742.0391 RMSElog: 9.7582 grad_loss: 10563.5234 normal_loss: 0.9230
[epoch 10][iter  540] loss: 167211.6250 RMSElog: 10.0285 grad_loss: 16710.1777 normal_loss: 0.9542
[epoch 10][iter  550] loss: 117061.6250 RMSElog: 9.2141 grad_loss: 11696.0439 normal_loss: 0.9046
[epoch 10][iter  560] loss: 143460.8594 RMSElog: 9.7520 grad_loss: 14335.3848 normal_loss: 0.9489
[epoch 10][iter  570] loss: 162372.7500 RMSElog: 9.8226 grad_loss: 16226.4922 normal_loss: 0.9603
[epoch 10][iter  580] loss: 182476.7344 RMSElog: 9.9672 grad_loss: 18236.7656 normal_loss: 0.9407
[epoch 10][iter  590] loss: 146960.1250 RMSElog: 10.0979 grad_loss: 14684.9922 normal_loss: 0.9220
[epoch 11][iter    0] loss: 122331.3906 RMSElog: 9.7180 grad_loss: 12222.4795 normal_loss: 0.9418
[epoch 11][iter   10] loss: 105742.0469 RMSElog: 9.7582 grad_loss: 10563.5244 normal_loss: 0.9230
[epoch 11][iter   20] loss: 105098.6875 RMSElog: 9.7426 grad_loss: 10499.2012 normal_loss: 0.9257
[epoch 11][iter   30] loss: 177934.3750 RMSElog: 9.8386 grad_loss: 17782.6445 normal_loss: 0.9542
[epoch 11][iter   40] loss: 168409.1562 RMSElog: 9.7031 grad_loss: 16830.2910 normal_loss: 0.9228
[epoch 11][iter   50] loss: 155482.2031 RMSElog: 10.0818 grad_loss: 15537.1826 normal_loss: 0.9552
[epoch 11][iter   60] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 11][iter   70] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 11][iter   80] loss: 152517.4844 RMSElog: 9.8233 grad_loss: 15241.0010 normal_loss: 0.9249
[epoch 11][iter   90] loss: 177292.4062 RMSElog: 10.1195 grad_loss: 17718.1602 normal_loss: 0.9615
[epoch 11][iter  100] loss: 139061.3750 RMSElog: 9.6201 grad_loss: 13895.5771 normal_loss: 0.9401
[epoch 11][iter  110] loss: 160024.9375 RMSElog: 9.8489 grad_loss: 15991.7236 normal_loss: 0.9215
[epoch 11][iter  120] loss: 196516.2188 RMSElog: 9.9615 grad_loss: 19640.7129 normal_loss: 0.9475
[epoch 11][iter  130] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 11][iter  140] loss: 182318.7812 RMSElog: 10.1008 grad_loss: 18220.8398 normal_loss: 0.9384
[epoch 11][iter  150] loss: 127463.1875 RMSElog: 9.4952 grad_loss: 12735.9082 normal_loss: 0.9153
[epoch 11][iter  160] loss: 170488.4688 RMSElog: 9.7164 grad_loss: 17038.1816 normal_loss: 0.9494
[epoch 11][iter  170] loss: 132425.4375 RMSElog: 10.0155 grad_loss: 13231.5801 normal_loss: 0.9468
[epoch 11][iter  180] loss: 115738.1953 RMSElog: 9.6968 grad_loss: 11563.1836 normal_loss: 0.9382
[epoch 11][iter  190] loss: 191825.0781 RMSElog: 10.3012 grad_loss: 19171.2500 normal_loss: 0.9570
[epoch 11][iter  200] loss: 115658.3125 RMSElog: 9.1856 grad_loss: 11555.7031 normal_loss: 0.9424
[epoch 11][iter  210] loss: 125486.8672 RMSElog: 9.7758 grad_loss: 12537.9834 normal_loss: 0.9281
[epoch 11][iter  220] loss: 177699.9688 RMSElog: 9.4851 grad_loss: 17759.5488 normal_loss: 0.9621
[epoch 11][iter  230] loss: 168545.0938 RMSElog: 9.6168 grad_loss: 16843.9434 normal_loss: 0.9495
[epoch 11][iter  240] loss: 156982.7188 RMSElog: 10.0093 grad_loss: 15687.3193 normal_loss: 0.9438
[epoch 11][iter  250] loss: 110603.0625 RMSElog: 9.8046 grad_loss: 11049.5654 normal_loss: 0.9364
[epoch 11][iter  260] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 11][iter  270] loss: 165750.3750 RMSElog: 9.8971 grad_loss: 16564.1895 normal_loss: 0.9518
[epoch 11][iter  280] loss: 177063.6250 RMSElog: 10.1532 grad_loss: 17695.2383 normal_loss: 0.9719
[epoch 11][iter  290] loss: 129708.8906 RMSElog: 10.0691 grad_loss: 12959.8711 normal_loss: 0.9481
[epoch 11][iter  300] loss: 152593.5000 RMSElog: 9.8773 grad_loss: 15248.5449 normal_loss: 0.9283
[epoch 11][iter  310] loss: 115534.3672 RMSElog: 9.7196 grad_loss: 11542.7842 normal_loss: 0.9325
[epoch 11][iter  320] loss: 159284.2188 RMSElog: 9.6028 grad_loss: 15917.8828 normal_loss: 0.9361
[epoch 11][iter  330] loss: 151723.8750 RMSElog: 9.9680 grad_loss: 15161.4746 normal_loss: 0.9449
[epoch 11][iter  340] loss: 116073.5938 RMSElog: 9.6844 grad_loss: 11596.7324 normal_loss: 0.9429
[epoch 11][iter  350] loss: 95221.2109 RMSElog: 9.1894 grad_loss: 9512.0205 normal_loss: 0.9115
[epoch 11][iter  360] loss: 104446.5625 RMSElog: 10.1932 grad_loss: 10433.5342 normal_loss: 0.9288
[epoch 11][iter  370] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 11][iter  380] loss: 147598.9844 RMSElog: 9.8981 grad_loss: 14749.0645 normal_loss: 0.9355
[epoch 11][iter  390] loss: 103815.4375 RMSElog: 9.7764 grad_loss: 10370.8340 normal_loss: 0.9338
[epoch 11][iter  400] loss: 148239.1406 RMSElog: 9.8055 grad_loss: 14813.1689 normal_loss: 0.9395
[epoch 11][iter  410] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch 11][iter  420] loss: 167345.2500 RMSElog: 9.8843 grad_loss: 16723.6777 normal_loss: 0.9620
[epoch 11][iter  430] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 11][iter  440] loss: 149807.1562 RMSElog: 9.9060 grad_loss: 14969.8613 normal_loss: 0.9481
[epoch 11][iter  450] loss: 106952.9219 RMSElog: 10.0294 grad_loss: 10684.3398 normal_loss: 0.9231
[epoch 11][iter  460] loss: 150608.8906 RMSElog: 10.0680 grad_loss: 15049.8750 normal_loss: 0.9460
[epoch 11][iter  470] loss: 135114.8750 RMSElog: 9.9265 grad_loss: 13500.6055 normal_loss: 0.9548
[epoch 11][iter  480] loss: 135814.7969 RMSElog: 9.5386 grad_loss: 13571.0137 normal_loss: 0.9281
[epoch 11][iter  490] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 11][iter  500] loss: 125315.5547 RMSElog: 9.7124 grad_loss: 12520.9121 normal_loss: 0.9309
[epoch 11][iter  510] loss: 147765.9219 RMSElog: 10.0607 grad_loss: 14765.6104 normal_loss: 0.9219
[epoch 11][iter  520] loss: 174565.0781 RMSElog: 9.7759 grad_loss: 17445.7832 normal_loss: 0.9484
[epoch 11][iter  530] loss: 173855.4375 RMSElog: 10.0769 grad_loss: 17374.5098 normal_loss: 0.9566
[epoch 11][iter  540] loss: 173339.3594 RMSElog: 9.8230 grad_loss: 17323.1914 normal_loss: 0.9212
[epoch 11][iter  550] loss: 156709.9531 RMSElog: 9.8741 grad_loss: 15660.1758 normal_loss: 0.9453
[epoch 11][iter  560] loss: 174375.6875 RMSElog: 10.0512 grad_loss: 17426.5684 normal_loss: 0.9483
[epoch 11][iter  570] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 11][iter  580] loss: 121916.0000 RMSElog: 9.7464 grad_loss: 12180.9131 normal_loss: 0.9404
[epoch 11][iter  590] loss: 217845.4844 RMSElog: 10.3597 grad_loss: 21773.2129 normal_loss: 0.9774
[epoch 12][iter    0] loss: 159422.2656 RMSElog: 9.7010 grad_loss: 15931.5957 normal_loss: 0.9299
[epoch 12][iter   10] loss: 151723.8750 RMSElog: 9.9680 grad_loss: 15161.4746 normal_loss: 0.9449
[epoch 12][iter   20] loss: 150323.7656 RMSElog: 10.0510 grad_loss: 15021.3848 normal_loss: 0.9410
[epoch 12][iter   30] loss: 152562.3906 RMSElog: 9.8216 grad_loss: 15245.4785 normal_loss: 0.9391
[epoch 12][iter   40] loss: 142016.3906 RMSElog: 9.9191 grad_loss: 14190.7676 normal_loss: 0.9526
[epoch 12][iter   50] loss: 163171.1719 RMSElog: 9.7905 grad_loss: 16306.3613 normal_loss: 0.9652
[epoch 12][iter   60] loss: 167211.6250 RMSElog: 10.0285 grad_loss: 16710.1777 normal_loss: 0.9542
[epoch 12][iter   70] loss: 177934.3750 RMSElog: 9.8386 grad_loss: 17782.6445 normal_loss: 0.9542
[epoch 12][iter   80] loss: 208699.7031 RMSElog: 10.3419 grad_loss: 20858.6719 normal_loss: 0.9568
[epoch 12][iter   90] loss: 149135.0000 RMSElog: 10.0932 grad_loss: 14902.4570 normal_loss: 0.9500
[epoch 12][iter  100] loss: 162542.0469 RMSElog: 9.9393 grad_loss: 16243.3115 normal_loss: 0.9527
[epoch 12][iter  110] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1221 normal_loss: 0.9462
[epoch 12][iter  120] loss: 159284.2188 RMSElog: 9.6028 grad_loss: 15917.8828 normal_loss: 0.9361
[epoch 12][iter  130] loss: 189507.2500 RMSElog: 10.2157 grad_loss: 18939.5586 normal_loss: 0.9510
[epoch 12][iter  140] loss: 95221.2109 RMSElog: 9.1894 grad_loss: 9512.0205 normal_loss: 0.9115
[epoch 12][iter  150] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 12][iter  160] loss: 117061.6250 RMSElog: 9.2141 grad_loss: 11696.0439 normal_loss: 0.9046
[epoch 12][iter  170] loss: 110603.0625 RMSElog: 9.8046 grad_loss: 11049.5654 normal_loss: 0.9364
[epoch 12][iter  180] loss: 206526.4062 RMSElog: 10.1531 grad_loss: 20641.5449 normal_loss: 0.9425
[epoch 12][iter  190] loss: 157706.0781 RMSElog: 9.9981 grad_loss: 15759.6602 normal_loss: 0.9499
[epoch 12][iter  200] loss: 170542.9531 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.9688
[epoch 12][iter  210] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 12][iter  220] loss: 206083.5312 RMSElog: 10.2501 grad_loss: 20597.1465 normal_loss: 0.9562
[epoch 12][iter  230] loss: 162579.5312 RMSElog: 10.1223 grad_loss: 16246.8740 normal_loss: 0.9574
[epoch 12][iter  240] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 12][iter  250] loss: 143613.7656 RMSElog: 9.8882 grad_loss: 14350.5566 normal_loss: 0.9315
[epoch 12][iter  260] loss: 164415.3438 RMSElog: 10.0829 grad_loss: 16430.4961 normal_loss: 0.9571
[epoch 12][iter  270] loss: 164767.1875 RMSElog: 9.8398 grad_loss: 16465.9102 normal_loss: 0.9691
[epoch 12][iter  280] loss: 112535.5625 RMSElog: 9.5823 grad_loss: 11243.0459 normal_loss: 0.9289
[epoch 12][iter  290] loss: 90482.6875 RMSElog: 9.3127 grad_loss: 9038.0186 normal_loss: 0.9378
[epoch 12][iter  300] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 12][iter  310] loss: 151368.4219 RMSElog: 9.7883 grad_loss: 15126.1289 normal_loss: 0.9251
[epoch 12][iter  320] loss: 150364.6250 RMSElog: 9.9123 grad_loss: 15025.6094 normal_loss: 0.9418
[epoch 12][iter  330] loss: 165750.3750 RMSElog: 9.8971 grad_loss: 16564.1895 normal_loss: 0.9518
[epoch 12][iter  340] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 12][iter  350] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 12][iter  360] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 12][iter  370] loss: 232771.8594 RMSElog: 10.2938 grad_loss: 23265.9453 normal_loss: 0.9464
[epoch 12][iter  380] loss: 196277.7188 RMSElog: 10.2453 grad_loss: 19616.5664 normal_loss: 0.9595
[epoch 12][iter  390] loss: 167784.2500 RMSElog: 9.9330 grad_loss: 16767.5391 normal_loss: 0.9539
[epoch 12][iter  400] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 12][iter  410] loss: 188645.4531 RMSElog: 10.1590 grad_loss: 18853.4082 normal_loss: 0.9794
[epoch 12][iter  420] loss: 208184.3125 RMSElog: 10.4061 grad_loss: 20807.0781 normal_loss: 0.9472
[epoch 12][iter  430] loss: 173339.3750 RMSElog: 9.8230 grad_loss: 17323.1934 normal_loss: 0.9212
[epoch 12][iter  440] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 12][iter  450] loss: 165648.1875 RMSElog: 9.7420 grad_loss: 16554.1289 normal_loss: 0.9479
[epoch 12][iter  460] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 12][iter  470] loss: 147765.9219 RMSElog: 10.0607 grad_loss: 14765.6104 normal_loss: 0.9219
[epoch 12][iter  480] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 12][iter  490] loss: 118495.6641 RMSElog: 9.2657 grad_loss: 11839.3906 normal_loss: 0.9103
[epoch 12][iter  500] loss: 115651.6406 RMSElog: 9.1877 grad_loss: 11555.0664 normal_loss: 0.9106
[epoch 12][iter  510] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch 12][iter  520] loss: 138606.5781 RMSElog: 9.6389 grad_loss: 13850.0977 normal_loss: 0.9205
[epoch 12][iter  530] loss: 150296.1406 RMSElog: 9.8188 grad_loss: 15018.8555 normal_loss: 0.9407
[epoch 12][iter  540] loss: 109260.8984 RMSElog: 9.7819 grad_loss: 10915.3799 normal_loss: 0.9279
[epoch 12][iter  550] loss: 172755.6875 RMSElog: 10.0251 grad_loss: 17264.6016 normal_loss: 0.9419
[epoch 12][iter  560] loss: 166542.4219 RMSElog: 9.8913 grad_loss: 16643.4043 normal_loss: 0.9482
[epoch 12][iter  570] loss: 145321.5469 RMSElog: 9.7332 grad_loss: 14521.4590 normal_loss: 0.9632
[epoch 12][iter  580] loss: 182476.7344 RMSElog: 9.9672 grad_loss: 18236.7656 normal_loss: 0.9407
[epoch 12][iter  590] loss: 226949.5156 RMSElog: 10.2029 grad_loss: 22683.8047 normal_loss: 0.9430
[epoch 13][iter    0] loss: 106769.7500 RMSElog: 9.8688 grad_loss: 10666.1914 normal_loss: 0.9140
[epoch 13][iter   10] loss: 147765.9219 RMSElog: 10.0607 grad_loss: 14765.6104 normal_loss: 0.9219
[epoch 13][iter   20] loss: 105828.7812 RMSElog: 10.1032 grad_loss: 10571.8545 normal_loss: 0.9195
[epoch 13][iter   30] loss: 150608.8906 RMSElog: 10.0680 grad_loss: 15049.8750 normal_loss: 0.9460
[epoch 13][iter   40] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 13][iter   50] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch 13][iter   60] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 13][iter   70] loss: 216232.0156 RMSElog: 10.2147 grad_loss: 21612.0215 normal_loss: 0.9640
[epoch 13][iter   80] loss: 148793.9688 RMSElog: 10.1047 grad_loss: 14868.3447 normal_loss: 0.9480
[epoch 13][iter   90] loss: 166492.4375 RMSElog: 9.8376 grad_loss: 16638.4512 normal_loss: 0.9558
[epoch 13][iter  100] loss: 218457.8281 RMSElog: 10.1255 grad_loss: 21834.7168 normal_loss: 0.9418
[epoch 13][iter  110] loss: 105628.3672 RMSElog: 10.0899 grad_loss: 10551.8262 normal_loss: 0.9213
[epoch 13][iter  120] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch 13][iter  130] loss: 134677.6719 RMSElog: 9.8776 grad_loss: 13456.9443 normal_loss: 0.9441
[epoch 13][iter  140] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 13][iter  150] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 13][iter  160] loss: 141228.9219 RMSElog: 9.9926 grad_loss: 14111.9531 normal_loss: 0.9477
[epoch 13][iter  170] loss: 142138.5312 RMSElog: 9.7967 grad_loss: 14203.1270 normal_loss: 0.9291
[epoch 13][iter  180] loss: 134406.2031 RMSElog: 9.9402 grad_loss: 13429.7256 normal_loss: 0.9539
[epoch 13][iter  190] loss: 128277.9766 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.9518
[epoch 13][iter  200] loss: 224943.8906 RMSElog: 10.1206 grad_loss: 22483.3125 normal_loss: 0.9551
[epoch 13][iter  210] loss: 104086.5234 RMSElog: 9.7787 grad_loss: 10397.9453 normal_loss: 0.9289
[epoch 13][iter  220] loss: 135215.1250 RMSElog: 9.9407 grad_loss: 13510.6152 normal_loss: 0.9572
[epoch 13][iter  230] loss: 156709.9531 RMSElog: 9.8741 grad_loss: 15660.1758 normal_loss: 0.9453
[epoch 13][iter  240] loss: 162542.0469 RMSElog: 9.9393 grad_loss: 16243.3115 normal_loss: 0.9527
[epoch 13][iter  250] loss: 146576.9219 RMSElog: 9.6520 grad_loss: 14647.1045 normal_loss: 0.9356
[epoch 13][iter  260] loss: 99107.7500 RMSElog: 9.5230 grad_loss: 9900.3428 normal_loss: 0.9094
[epoch 13][iter  270] loss: 180929.5938 RMSElog: 10.0745 grad_loss: 18081.9297 normal_loss: 0.9546
[epoch 13][iter  280] loss: 137252.6406 RMSElog: 9.3538 grad_loss: 13714.9785 normal_loss: 0.9319
[epoch 13][iter  290] loss: 160782.5156 RMSElog: 9.7710 grad_loss: 16067.5547 normal_loss: 0.9244
[epoch 13][iter  300] loss: 218757.0312 RMSElog: 10.1228 grad_loss: 21864.6270 normal_loss: 0.9524
[epoch 13][iter  310] loss: 121959.7344 RMSElog: 9.7378 grad_loss: 12185.3047 normal_loss: 0.9314
[epoch 13][iter  320] loss: 110808.0469 RMSElog: 9.7171 grad_loss: 11070.1562 normal_loss: 0.9312
[epoch 13][iter  330] loss: 195777.0469 RMSElog: 10.1280 grad_loss: 19566.6035 normal_loss: 0.9726
[epoch 13][iter  340] loss: 159340.4219 RMSElog: 9.9507 grad_loss: 15923.1406 normal_loss: 0.9500
[epoch 13][iter  350] loss: 218949.8281 RMSElog: 10.4462 grad_loss: 21883.5918 normal_loss: 0.9447
[epoch 13][iter  360] loss: 163252.6875 RMSElog: 9.8236 grad_loss: 16314.5117 normal_loss: 0.9348
[epoch 13][iter  370] loss: 166207.1094 RMSElog: 9.7947 grad_loss: 16609.9668 normal_loss: 0.9492
[epoch 13][iter  380] loss: 107948.0312 RMSElog: 9.7377 grad_loss: 10784.1309 normal_loss: 0.9342
[epoch 13][iter  390] loss: 177936.2812 RMSElog: 10.0381 grad_loss: 17782.6348 normal_loss: 0.9545
[epoch 13][iter  400] loss: 181293.3438 RMSElog: 10.0009 grad_loss: 18118.3809 normal_loss: 0.9531
[epoch 13][iter  410] loss: 214808.7344 RMSElog: 10.1872 grad_loss: 21469.7441 normal_loss: 0.9423
[epoch 13][iter  420] loss: 111518.2734 RMSElog: 9.6257 grad_loss: 11141.2676 normal_loss: 0.9335
[epoch 13][iter  430] loss: 196516.2188 RMSElog: 9.9615 grad_loss: 19640.7129 normal_loss: 0.9475
[epoch 13][iter  440] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 13][iter  450] loss: 204650.3281 RMSElog: 10.1934 grad_loss: 20453.8633 normal_loss: 0.9763
[epoch 13][iter  460] loss: 145332.8438 RMSElog: 10.0385 grad_loss: 14522.2842 normal_loss: 0.9619
[epoch 13][iter  470] loss: 184016.5469 RMSElog: 9.9468 grad_loss: 18390.7363 normal_loss: 0.9712
[epoch 13][iter  480] loss: 195671.7031 RMSElog: 10.1080 grad_loss: 19556.1133 normal_loss: 0.9494
[epoch 13][iter  490] loss: 185495.4062 RMSElog: 9.9310 grad_loss: 18538.6641 normal_loss: 0.9455
[epoch 13][iter  500] loss: 185071.7031 RMSElog: 10.0456 grad_loss: 18496.1699 normal_loss: 0.9557
[epoch 13][iter  510] loss: 132623.8750 RMSElog: 9.3325 grad_loss: 13252.1152 normal_loss: 0.9391
[epoch 13][iter  520] loss: 154855.9062 RMSElog: 9.8054 grad_loss: 15474.8340 normal_loss: 0.9510
[epoch 13][iter  530] loss: 95221.2109 RMSElog: 9.1894 grad_loss: 9512.0205 normal_loss: 0.9115
[epoch 13][iter  540] loss: 147479.0312 RMSElog: 9.6781 grad_loss: 14737.2812 normal_loss: 0.9446
[epoch 13][iter  550] loss: 199070.3125 RMSElog: 9.9947 grad_loss: 19896.0605 normal_loss: 0.9757
[epoch 13][iter  560] loss: 126023.2344 RMSElog: 9.6219 grad_loss: 12591.7656 normal_loss: 0.9360
[epoch 13][iter  570] loss: 189017.5781 RMSElog: 10.1390 grad_loss: 18890.6602 normal_loss: 0.9589
[epoch 13][iter  580] loss: 102998.8984 RMSElog: 9.8140 grad_loss: 10289.1318 normal_loss: 0.9431
[epoch 13][iter  590] loss: 223875.4062 RMSElog: 10.3929 grad_loss: 22376.1953 normal_loss: 0.9536
[epoch 14][iter    0] loss: 224257.9688 RMSElog: 10.2842 grad_loss: 22414.5605 normal_loss: 0.9521
[epoch 14][iter   10] loss: 132707.3594 RMSElog: 9.7842 grad_loss: 13260.0049 normal_loss: 0.9472
[epoch 14][iter   20] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 14][iter   30] loss: 139154.8594 RMSElog: 9.5986 grad_loss: 13904.9707 normal_loss: 0.9164
[epoch 14][iter   40] loss: 123289.4609 RMSElog: 9.4106 grad_loss: 12318.5752 normal_loss: 0.9606
[epoch 14][iter   50] loss: 170357.3438 RMSElog: 9.9687 grad_loss: 17024.8008 normal_loss: 0.9644
[epoch 14][iter   60] loss: 147598.9844 RMSElog: 9.8981 grad_loss: 14749.0645 normal_loss: 0.9355
[epoch 14][iter   70] loss: 163171.1562 RMSElog: 9.7905 grad_loss: 16306.3594 normal_loss: 0.9652
[epoch 14][iter   80] loss: 151401.7031 RMSElog: 9.4414 grad_loss: 15129.7930 normal_loss: 0.9361
[epoch 14][iter   90] loss: 207885.1875 RMSElog: 10.4422 grad_loss: 20777.1328 normal_loss: 0.9460
[epoch 14][iter  100] loss: 153501.7031 RMSElog: 10.1127 grad_loss: 15339.1152 normal_loss: 0.9429
[epoch 14][iter  110] loss: 215955.5312 RMSElog: 10.2675 grad_loss: 21584.3203 normal_loss: 0.9654
[epoch 14][iter  120] loss: 189017.5781 RMSElog: 10.1390 grad_loss: 18890.6602 normal_loss: 0.9589
[epoch 14][iter  130] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 14][iter  140] loss: 142005.0938 RMSElog: 9.9168 grad_loss: 14189.6543 normal_loss: 0.9371
[epoch 14][iter  150] loss: 191371.4375 RMSElog: 10.1918 grad_loss: 19126.0020 normal_loss: 0.9504
[epoch 14][iter  160] loss: 178468.8906 RMSElog: 9.9039 grad_loss: 17836.0469 normal_loss: 0.9380
[epoch 14][iter  170] loss: 109101.1250 RMSElog: 9.7363 grad_loss: 10899.4590 normal_loss: 0.9167
[epoch 14][iter  180] loss: 159284.2188 RMSElog: 9.6028 grad_loss: 15917.8828 normal_loss: 0.9361
[epoch 14][iter  190] loss: 193978.6562 RMSElog: 10.3530 grad_loss: 19386.5605 normal_loss: 0.9518
[epoch 14][iter  200] loss: 175524.1250 RMSElog: 10.2056 grad_loss: 17541.2441 normal_loss: 0.9625
[epoch 14][iter  210] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 14][iter  220] loss: 176260.7500 RMSElog: 10.0638 grad_loss: 17615.0703 normal_loss: 0.9395
[epoch 14][iter  230] loss: 196677.7812 RMSElog: 10.0486 grad_loss: 19656.7715 normal_loss: 0.9571
[epoch 14][iter  240] loss: 105816.5000 RMSElog: 9.4266 grad_loss: 10571.3066 normal_loss: 0.9171
[epoch 14][iter  250] loss: 160051.0156 RMSElog: 9.8405 grad_loss: 15994.3105 normal_loss: 0.9506
[epoch 14][iter  260] loss: 113195.8281 RMSElog: 9.1761 grad_loss: 11309.5059 normal_loss: 0.9012
[epoch 14][iter  270] loss: 143534.0938 RMSElog: 9.7662 grad_loss: 14342.7061 normal_loss: 0.9374
[epoch 14][iter  280] loss: 100116.4922 RMSElog: 9.9235 grad_loss: 10000.7998 normal_loss: 0.9258
[epoch 14][iter  290] loss: 126821.0234 RMSElog: 10.1398 grad_loss: 12671.0410 normal_loss: 0.9215
[epoch 14][iter  300] loss: 178076.4688 RMSElog: 9.8778 grad_loss: 17796.8457 normal_loss: 0.9233
[epoch 14][iter  310] loss: 142544.5156 RMSElog: 10.1645 grad_loss: 14243.3457 normal_loss: 0.9425
[epoch 14][iter  320] loss: 177936.2812 RMSElog: 10.0381 grad_loss: 17782.6348 normal_loss: 0.9545
[epoch 14][iter  330] loss: 172966.9375 RMSElog: 9.9430 grad_loss: 17285.8008 normal_loss: 0.9485
[epoch 14][iter  340] loss: 193024.5000 RMSElog: 9.9639 grad_loss: 19291.5117 normal_loss: 0.9740
[epoch 14][iter  350] loss: 191825.0781 RMSElog: 10.3012 grad_loss: 19171.2500 normal_loss: 0.9570
[epoch 14][iter  360] loss: 127463.1875 RMSElog: 9.4952 grad_loss: 12735.9082 normal_loss: 0.9153
[epoch 14][iter  370] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 14][iter  380] loss: 132012.6719 RMSElog: 9.6802 grad_loss: 13190.6582 normal_loss: 0.9291
[epoch 14][iter  390] loss: 146576.9219 RMSElog: 9.6520 grad_loss: 14647.1045 normal_loss: 0.9356
[epoch 14][iter  400] loss: 115651.6406 RMSElog: 9.1877 grad_loss: 11555.0664 normal_loss: 0.9106
[epoch 14][iter  410] loss: 102223.4531 RMSElog: 9.4278 grad_loss: 10212.0010 normal_loss: 0.9169
[epoch 14][iter  420] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 14][iter  430] loss: 230519.3906 RMSElog: 10.3105 grad_loss: 23040.6836 normal_loss: 0.9459
[epoch 14][iter  440] loss: 143460.8594 RMSElog: 9.7520 grad_loss: 14335.3848 normal_loss: 0.9489
[epoch 14][iter  450] loss: 150608.8906 RMSElog: 10.0680 grad_loss: 15049.8750 normal_loss: 0.9460
[epoch 14][iter  460] loss: 195999.5625 RMSElog: 10.1749 grad_loss: 19588.8047 normal_loss: 0.9756
[epoch 14][iter  470] loss: 198743.4219 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.9643
[epoch 14][iter  480] loss: 203093.2969 RMSElog: 10.1238 grad_loss: 20298.2598 normal_loss: 0.9478
[epoch 14][iter  490] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 14][iter  500] loss: 121916.0000 RMSElog: 9.7464 grad_loss: 12180.9131 normal_loss: 0.9404
[epoch 14][iter  510] loss: 141228.9219 RMSElog: 9.9926 grad_loss: 14111.9531 normal_loss: 0.9477
[epoch 14][iter  520] loss: 136796.3438 RMSElog: 9.6524 grad_loss: 13669.0273 normal_loss: 0.9549
[epoch 14][iter  530] loss: 158534.6406 RMSElog: 9.6735 grad_loss: 15842.8672 normal_loss: 0.9232
[epoch 14][iter  540] loss: 106952.9219 RMSElog: 10.0294 grad_loss: 10684.3398 normal_loss: 0.9231
[epoch 14][iter  550] loss: 221213.4531 RMSElog: 10.1740 grad_loss: 22110.2305 normal_loss: 0.9415
[epoch 14][iter  560] loss: 205362.7344 RMSElog: 10.1686 grad_loss: 20525.1582 normal_loss: 0.9475
[epoch 14][iter  570] loss: 218547.0156 RMSElog: 10.4419 grad_loss: 21843.3086 normal_loss: 0.9515
[epoch 14][iter  580] loss: 160934.5156 RMSElog: 9.8035 grad_loss: 16082.6846 normal_loss: 0.9629
[epoch 14][iter  590] loss: 199607.0938 RMSElog: 10.0729 grad_loss: 19949.6758 normal_loss: 0.9604
[epoch 15][iter    0] loss: 114173.8984 RMSElog: 9.3600 grad_loss: 11407.1230 normal_loss: 0.9061
[epoch 15][iter   10] loss: 141962.4844 RMSElog: 9.7918 grad_loss: 14185.5273 normal_loss: 0.9289
[epoch 15][iter   20] loss: 136507.7344 RMSElog: 10.0223 grad_loss: 13639.7900 normal_loss: 0.9608
[epoch 15][iter   30] loss: 104749.2812 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.9281
[epoch 15][iter   40] loss: 150296.1562 RMSElog: 9.8188 grad_loss: 15018.8564 normal_loss: 0.9407
[epoch 15][iter   50] loss: 109260.8906 RMSElog: 9.7819 grad_loss: 10915.3789 normal_loss: 0.9279
[epoch 15][iter   60] loss: 158534.6406 RMSElog: 9.6735 grad_loss: 15842.8672 normal_loss: 0.9232
[epoch 15][iter   70] loss: 114149.3672 RMSElog: 9.2655 grad_loss: 11404.7637 normal_loss: 0.9073
[epoch 15][iter   80] loss: 214808.7344 RMSElog: 10.1872 grad_loss: 21469.7441 normal_loss: 0.9423
[epoch 15][iter   90] loss: 177063.6250 RMSElog: 10.1532 grad_loss: 17695.2383 normal_loss: 0.9719
[epoch 15][iter  100] loss: 116073.5938 RMSElog: 9.6844 grad_loss: 11596.7324 normal_loss: 0.9429
[epoch 15][iter  110] loss: 182005.7031 RMSElog: 10.0998 grad_loss: 18189.5195 normal_loss: 0.9507
[epoch 15][iter  120] loss: 125315.5547 RMSElog: 9.7124 grad_loss: 12520.9121 normal_loss: 0.9309
[epoch 15][iter  130] loss: 167740.4688 RMSElog: 9.8540 grad_loss: 16763.2344 normal_loss: 0.9591
[epoch 15][iter  140] loss: 150699.3750 RMSElog: 9.8567 grad_loss: 15059.1328 normal_loss: 0.9486
[epoch 15][iter  150] loss: 167412.9531 RMSElog: 9.7311 grad_loss: 16730.6387 normal_loss: 0.9260
[epoch 15][iter  160] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 15][iter  170] loss: 104456.8438 RMSElog: 10.0170 grad_loss: 10434.7461 normal_loss: 0.9214
[epoch 15][iter  180] loss: 175934.2344 RMSElog: 10.1481 grad_loss: 17582.3086 normal_loss: 0.9674
[epoch 15][iter  190] loss: 118495.6562 RMSElog: 9.2657 grad_loss: 11839.3896 normal_loss: 0.9103
[epoch 15][iter  200] loss: 189017.5781 RMSElog: 10.1390 grad_loss: 18890.6602 normal_loss: 0.9589
[epoch 15][iter  210] loss: 186053.2812 RMSElog: 10.1470 grad_loss: 18594.2305 normal_loss: 0.9504
[epoch 15][iter  220] loss: 136533.4688 RMSElog: 9.6756 grad_loss: 13642.7363 normal_loss: 0.9359
[epoch 15][iter  230] loss: 107956.6094 RMSElog: 10.0900 grad_loss: 10784.6504 normal_loss: 0.9209
[epoch 15][iter  240] loss: 149540.3750 RMSElog: 9.7408 grad_loss: 14943.3740 normal_loss: 0.9229
[epoch 15][iter  250] loss: 224257.9844 RMSElog: 10.2842 grad_loss: 22414.5625 normal_loss: 0.9521
[epoch 15][iter  260] loss: 221089.3594 RMSElog: 10.3457 grad_loss: 22097.6465 normal_loss: 0.9439
[epoch 15][iter  270] loss: 164415.3438 RMSElog: 10.0829 grad_loss: 16430.4961 normal_loss: 0.9571
[epoch 15][iter  280] loss: 131942.8750 RMSElog: 9.8414 grad_loss: 13183.5000 normal_loss: 0.9453
[epoch 15][iter  290] loss: 160595.2188 RMSElog: 9.9514 grad_loss: 16048.6191 normal_loss: 0.9518
[epoch 15][iter  300] loss: 180663.0469 RMSElog: 10.2319 grad_loss: 18055.1094 normal_loss: 0.9630
[epoch 15][iter  310] loss: 173339.3594 RMSElog: 9.8230 grad_loss: 17323.1914 normal_loss: 0.9212
[epoch 15][iter  320] loss: 128883.6328 RMSElog: 9.8798 grad_loss: 12877.5244 normal_loss: 0.9593
[epoch 15][iter  330] loss: 182315.9688 RMSElog: 10.1291 grad_loss: 18220.5039 normal_loss: 0.9652
[epoch 15][iter  340] loss: 112715.8125 RMSElog: 9.6867 grad_loss: 11260.9570 normal_loss: 0.9375
[epoch 15][iter  350] loss: 105828.7812 RMSElog: 10.1032 grad_loss: 10571.8545 normal_loss: 0.9195
[epoch 15][iter  360] loss: 133024.8594 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.9261
[epoch 15][iter  370] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 15][iter  380] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 15][iter  390] loss: 149128.2188 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.9419
[epoch 15][iter  400] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 15][iter  410] loss: 141118.5312 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.9477
[epoch 15][iter  420] loss: 175004.6719 RMSElog: 10.1774 grad_loss: 17489.3320 normal_loss: 0.9561
[epoch 15][iter  430] loss: 156173.3594 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.9482
[epoch 15][iter  440] loss: 160788.1406 RMSElog: 9.7539 grad_loss: 16068.1289 normal_loss: 0.9318
[epoch 15][iter  450] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 15][iter  460] loss: 189582.6719 RMSElog: 9.9918 grad_loss: 18947.3223 normal_loss: 0.9523
[epoch 15][iter  470] loss: 163389.5625 RMSElog: 9.7702 grad_loss: 16328.2656 normal_loss: 0.9208
[epoch 15][iter  480] loss: 128488.4375 RMSElog: 9.7402 grad_loss: 12838.1719 normal_loss: 0.9319
[epoch 15][iter  490] loss: 119655.7969 RMSElog: 9.6110 grad_loss: 11955.0312 normal_loss: 0.9378
[epoch 15][iter  500] loss: 230519.3906 RMSElog: 10.3105 grad_loss: 23040.6836 normal_loss: 0.9459
[epoch 15][iter  510] loss: 170488.4688 RMSElog: 9.7164 grad_loss: 17038.1816 normal_loss: 0.9494
[epoch 15][iter  520] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 15][iter  530] loss: 146161.1562 RMSElog: 10.0682 grad_loss: 14605.1289 normal_loss: 0.9190
[epoch 15][iter  540] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 15][iter  550] loss: 139830.9062 RMSElog: 9.7552 grad_loss: 13972.3770 normal_loss: 0.9585
[epoch 15][iter  560] loss: 229081.3125 RMSElog: 10.2778 grad_loss: 22896.9121 normal_loss: 0.9420
[epoch 15][iter  570] loss: 139433.9219 RMSElog: 9.8139 grad_loss: 13932.6191 normal_loss: 0.9591
[epoch 15][iter  580] loss: 170690.9219 RMSElog: 9.9328 grad_loss: 17058.2109 normal_loss: 0.9470
[epoch 15][iter  590] loss: 106952.9219 RMSElog: 10.0294 grad_loss: 10684.3398 normal_loss: 0.9231
[epoch 16][iter    0] loss: 150296.1562 RMSElog: 9.8188 grad_loss: 15018.8564 normal_loss: 0.9407
[epoch 16][iter   10] loss: 197715.0000 RMSElog: 10.4355 grad_loss: 19760.1113 normal_loss: 0.9532
[epoch 16][iter   20] loss: 128883.6328 RMSElog: 9.8798 grad_loss: 12877.5244 normal_loss: 0.9593
[epoch 16][iter   30] loss: 113195.8281 RMSElog: 9.1761 grad_loss: 11309.5059 normal_loss: 0.9012
[epoch 16][iter   40] loss: 194578.5781 RMSElog: 10.2312 grad_loss: 19446.6680 normal_loss: 0.9596
[epoch 16][iter   50] loss: 120765.1875 RMSElog: 9.5441 grad_loss: 12066.0400 normal_loss: 0.9348
[epoch 16][iter   60] loss: 169013.5312 RMSElog: 9.5880 grad_loss: 16890.8242 normal_loss: 0.9419
[epoch 16][iter   70] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 16][iter   80] loss: 215542.7500 RMSElog: 10.4358 grad_loss: 21542.8887 normal_loss: 0.9514
[epoch 16][iter   90] loss: 136507.7344 RMSElog: 10.0223 grad_loss: 13639.7900 normal_loss: 0.9608
[epoch 16][iter  100] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 16][iter  110] loss: 156985.6406 RMSElog: 9.5765 grad_loss: 15688.0488 normal_loss: 0.9385
[epoch 16][iter  120] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 16][iter  130] loss: 143613.7656 RMSElog: 9.8882 grad_loss: 14350.5566 normal_loss: 0.9315
[epoch 16][iter  140] loss: 235211.2344 RMSElog: 10.3371 grad_loss: 23509.8398 normal_loss: 0.9452
[epoch 16][iter  150] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 16][iter  160] loss: 180663.0469 RMSElog: 10.2319 grad_loss: 18055.1094 normal_loss: 0.9630
[epoch 16][iter  170] loss: 153501.6875 RMSElog: 10.1127 grad_loss: 15339.1133 normal_loss: 0.9429
[epoch 16][iter  180] loss: 117061.6250 RMSElog: 9.2141 grad_loss: 11696.0439 normal_loss: 0.9046
[epoch 16][iter  190] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 16][iter  200] loss: 122386.0234 RMSElog: 9.6688 grad_loss: 12227.9971 normal_loss: 0.9366
[epoch 16][iter  210] loss: 162542.0469 RMSElog: 9.9393 grad_loss: 16243.3115 normal_loss: 0.9527
[epoch 16][iter  220] loss: 162556.3906 RMSElog: 9.9091 grad_loss: 16244.7939 normal_loss: 0.9368
[epoch 16][iter  230] loss: 153099.1094 RMSElog: 9.8355 grad_loss: 15299.1445 normal_loss: 0.9304
[epoch 16][iter  240] loss: 122446.5469 RMSElog: 9.6438 grad_loss: 12234.0742 normal_loss: 0.9366
[epoch 16][iter  250] loss: 133045.7969 RMSElog: 9.8765 grad_loss: 13293.7480 normal_loss: 0.9538
[epoch 16][iter  260] loss: 143440.0000 RMSElog: 9.6404 grad_loss: 14333.4336 normal_loss: 0.9261
[epoch 16][iter  270] loss: 104086.5234 RMSElog: 9.7787 grad_loss: 10397.9453 normal_loss: 0.9289
[epoch 16][iter  280] loss: 165976.7344 RMSElog: 9.9385 grad_loss: 16586.7695 normal_loss: 0.9645
[epoch 16][iter  290] loss: 106769.7500 RMSElog: 9.8688 grad_loss: 10666.1914 normal_loss: 0.9140
[epoch 16][iter  300] loss: 227080.5938 RMSElog: 10.4127 grad_loss: 22696.6992 normal_loss: 0.9482
[epoch 16][iter  310] loss: 150608.8906 RMSElog: 10.0680 grad_loss: 15049.8750 normal_loss: 0.9460
[epoch 16][iter  320] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 16][iter  330] loss: 217914.6094 RMSElog: 10.2786 grad_loss: 21780.2246 normal_loss: 0.9575
[epoch 16][iter  340] loss: 167211.6250 RMSElog: 10.0285 grad_loss: 16710.1777 normal_loss: 0.9542
[epoch 16][iter  350] loss: 213401.8906 RMSElog: 10.0568 grad_loss: 21329.1582 normal_loss: 0.9749
[epoch 16][iter  360] loss: 182315.9688 RMSElog: 10.1291 grad_loss: 18220.5039 normal_loss: 0.9652
[epoch 16][iter  370] loss: 162522.4531 RMSElog: 9.9860 grad_loss: 16241.3066 normal_loss: 0.9518
[epoch 16][iter  380] loss: 175299.8438 RMSElog: 10.1975 grad_loss: 17518.8301 normal_loss: 0.9576
[epoch 16][iter  390] loss: 122670.8984 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.9331
[epoch 16][iter  400] loss: 180982.8438 RMSElog: 10.2711 grad_loss: 18087.0605 normal_loss: 0.9528
[epoch 16][iter  410] loss: 146942.0781 RMSElog: 9.4227 grad_loss: 14683.8535 normal_loss: 0.9314
[epoch 16][iter  420] loss: 130641.2188 RMSElog: 9.7184 grad_loss: 13053.4688 normal_loss: 0.9344
[epoch 16][iter  430] loss: 164766.2812 RMSElog: 9.6928 grad_loss: 16465.9941 normal_loss: 0.9411
[epoch 16][iter  440] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 16][iter  450] loss: 206526.4062 RMSElog: 10.1531 grad_loss: 20641.5449 normal_loss: 0.9425
[epoch 16][iter  460] loss: 110603.0781 RMSElog: 9.8046 grad_loss: 11049.5664 normal_loss: 0.9364
[epoch 16][iter  470] loss: 152772.4219 RMSElog: 9.8249 grad_loss: 15266.4736 normal_loss: 0.9438
[epoch 16][iter  480] loss: 206400.7812 RMSElog: 10.3027 grad_loss: 20628.8281 normal_loss: 0.9467
[epoch 16][iter  490] loss: 165648.1875 RMSElog: 9.7420 grad_loss: 16554.1289 normal_loss: 0.9479
[epoch 16][iter  500] loss: 208699.7031 RMSElog: 10.3419 grad_loss: 20858.6719 normal_loss: 0.9568
[epoch 16][iter  510] loss: 105706.7109 RMSElog: 9.7501 grad_loss: 10559.9893 normal_loss: 0.9321
[epoch 16][iter  520] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 16][iter  530] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch 16][iter  540] loss: 231696.5312 RMSElog: 10.3202 grad_loss: 23158.3867 normal_loss: 0.9457
[epoch 16][iter  550] loss: 171588.0938 RMSElog: 9.8325 grad_loss: 17148.0527 normal_loss: 0.9237
[epoch 16][iter  560] loss: 137249.3438 RMSElog: 9.7342 grad_loss: 13714.2764 normal_loss: 0.9239
[epoch 16][iter  570] loss: 139878.0781 RMSElog: 9.8515 grad_loss: 13977.0234 normal_loss: 0.9327
[epoch 16][iter  580] loss: 174565.0781 RMSElog: 9.7759 grad_loss: 17445.7832 normal_loss: 0.9484
[epoch 16][iter  590] loss: 220587.5781 RMSElog: 10.2995 grad_loss: 22047.5117 normal_loss: 0.9466
[epoch 17][iter    0] loss: 216509.5938 RMSElog: 10.1942 grad_loss: 21639.8242 normal_loss: 0.9420
[epoch 17][iter   10] loss: 146781.9531 RMSElog: 9.8688 grad_loss: 14667.3818 normal_loss: 0.9440
[epoch 17][iter   20] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 17][iter   30] loss: 106195.4219 RMSElog: 9.2531 grad_loss: 10609.3711 normal_loss: 0.9179
[epoch 17][iter   40] loss: 157274.4688 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.9461
[epoch 17][iter   50] loss: 147207.9844 RMSElog: 9.9779 grad_loss: 14709.8789 normal_loss: 0.9413
[epoch 17][iter   60] loss: 175301.7344 RMSElog: 9.8017 grad_loss: 17519.4180 normal_loss: 0.9555
[epoch 17][iter   70] loss: 139878.0625 RMSElog: 9.8515 grad_loss: 13977.0225 normal_loss: 0.9327
[epoch 17][iter   80] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 17][iter   90] loss: 159422.2500 RMSElog: 9.7010 grad_loss: 15931.5938 normal_loss: 0.9299
[epoch 17][iter  100] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch 17][iter  110] loss: 133013.4531 RMSElog: 9.5635 grad_loss: 13290.8457 normal_loss: 0.9356
[epoch 17][iter  120] loss: 130641.2188 RMSElog: 9.7184 grad_loss: 13053.4688 normal_loss: 0.9344
[epoch 17][iter  130] loss: 140938.8594 RMSElog: 9.7483 grad_loss: 14083.1953 normal_loss: 0.9424
[epoch 17][iter  140] loss: 144657.9844 RMSElog: 9.9197 grad_loss: 14454.9258 normal_loss: 0.9518
[epoch 17][iter  150] loss: 186960.2969 RMSElog: 10.2468 grad_loss: 18684.8457 normal_loss: 0.9380
[epoch 17][iter  160] loss: 183480.3438 RMSElog: 10.0091 grad_loss: 18337.0801 normal_loss: 0.9458
[epoch 17][iter  170] loss: 127633.3516 RMSElog: 10.0540 grad_loss: 12752.3496 normal_loss: 0.9317
[epoch 17][iter  180] loss: 155482.1875 RMSElog: 10.0818 grad_loss: 15537.1816 normal_loss: 0.9552
[epoch 17][iter  190] loss: 154705.2188 RMSElog: 9.9142 grad_loss: 15459.6543 normal_loss: 0.9527
[epoch 17][iter  200] loss: 127061.7500 RMSElog: 9.6726 grad_loss: 12695.5654 normal_loss: 0.9369
[epoch 17][iter  210] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 17][iter  220] loss: 173339.3594 RMSElog: 9.8230 grad_loss: 17323.1914 normal_loss: 0.9212
[epoch 17][iter  230] loss: 105098.6875 RMSElog: 9.7426 grad_loss: 10499.2012 normal_loss: 0.9257
[epoch 17][iter  240] loss: 139098.6406 RMSElog: 9.8619 grad_loss: 13899.0508 normal_loss: 0.9510
[epoch 17][iter  250] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 17][iter  260] loss: 167211.6250 RMSElog: 10.0285 grad_loss: 16710.1777 normal_loss: 0.9542
[epoch 17][iter  270] loss: 146444.9062 RMSElog: 10.1139 grad_loss: 14633.4365 normal_loss: 0.9403
[epoch 17][iter  280] loss: 109101.1250 RMSElog: 9.7363 grad_loss: 10899.4590 normal_loss: 0.9167
[epoch 17][iter  290] loss: 163268.1250 RMSElog: 9.9218 grad_loss: 16315.9277 normal_loss: 0.9630
[epoch 17][iter  300] loss: 160466.8750 RMSElog: 9.9086 grad_loss: 16035.8252 normal_loss: 0.9540
[epoch 17][iter  310] loss: 175547.9062 RMSElog: 10.1409 grad_loss: 17543.7168 normal_loss: 0.9342
[epoch 17][iter  320] loss: 226949.5156 RMSElog: 10.2029 grad_loss: 22683.8047 normal_loss: 0.9430
[epoch 17][iter  330] loss: 174629.2812 RMSElog: 9.9405 grad_loss: 17452.0625 normal_loss: 0.9229
[epoch 17][iter  340] loss: 140057.2812 RMSElog: 9.9766 grad_loss: 13994.7988 normal_loss: 0.9526
[epoch 17][iter  350] loss: 141118.5312 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.9477
[epoch 17][iter  360] loss: 149369.9062 RMSElog: 10.0930 grad_loss: 14925.9756 normal_loss: 0.9225
[epoch 17][iter  370] loss: 100650.2734 RMSElog: 9.7441 grad_loss: 10054.3555 normal_loss: 0.9279
[epoch 17][iter  380] loss: 105794.8828 RMSElog: 9.7676 grad_loss: 10568.7939 normal_loss: 0.9267
[epoch 17][iter  390] loss: 144589.9531 RMSElog: 9.7438 grad_loss: 14448.3340 normal_loss: 0.9167
[epoch 17][iter  400] loss: 158875.5625 RMSElog: 9.5853 grad_loss: 15877.0449 normal_loss: 0.9260
[epoch 17][iter  410] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 17][iter  420] loss: 130145.6328 RMSElog: 9.7206 grad_loss: 13003.9082 normal_loss: 0.9344
[epoch 17][iter  430] loss: 138469.0469 RMSElog: 9.4787 grad_loss: 13836.4834 normal_loss: 0.9438
[epoch 17][iter  440] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 17][iter  450] loss: 157061.8906 RMSElog: 9.9892 grad_loss: 15695.2461 normal_loss: 0.9531
[epoch 17][iter  460] loss: 196842.3281 RMSElog: 10.1249 grad_loss: 19673.1543 normal_loss: 0.9534
[epoch 17][iter  470] loss: 165020.2344 RMSElog: 9.7791 grad_loss: 16491.2910 normal_loss: 0.9530
[epoch 17][iter  480] loss: 122386.0234 RMSElog: 9.6688 grad_loss: 12227.9971 normal_loss: 0.9366
[epoch 17][iter  490] loss: 139433.9219 RMSElog: 9.8139 grad_loss: 13932.6191 normal_loss: 0.9591
[epoch 17][iter  500] loss: 107956.6094 RMSElog: 10.0900 grad_loss: 10784.6504 normal_loss: 0.9209
[epoch 17][iter  510] loss: 114924.9844 RMSElog: 9.6925 grad_loss: 11481.8691 normal_loss: 0.9360
[epoch 17][iter  520] loss: 178468.8906 RMSElog: 9.9039 grad_loss: 17836.0469 normal_loss: 0.9380
[epoch 17][iter  530] loss: 163389.5625 RMSElog: 9.7702 grad_loss: 16328.2656 normal_loss: 0.9208
[epoch 17][iter  540] loss: 175004.6719 RMSElog: 10.1774 grad_loss: 17489.3320 normal_loss: 0.9561
[epoch 17][iter  550] loss: 166492.4688 RMSElog: 9.8376 grad_loss: 16638.4531 normal_loss: 0.9558
[epoch 17][iter  560] loss: 105896.6094 RMSElog: 9.6983 grad_loss: 10579.0293 normal_loss: 0.9335
[epoch 17][iter  570] loss: 135215.1250 RMSElog: 9.9407 grad_loss: 13510.6152 normal_loss: 0.9572
[epoch 17][iter  580] loss: 154029.7812 RMSElog: 9.8645 grad_loss: 15392.1729 normal_loss: 0.9405
[epoch 17][iter  590] loss: 165954.0938 RMSElog: 9.8997 grad_loss: 16584.5449 normal_loss: 0.9646
[epoch 18][iter    0] loss: 129163.5156 RMSElog: 9.7674 grad_loss: 12905.6660 normal_loss: 0.9175
[epoch 18][iter   10] loss: 135814.7969 RMSElog: 9.5386 grad_loss: 13571.0137 normal_loss: 0.9281
[epoch 18][iter   20] loss: 120292.3359 RMSElog: 9.8042 grad_loss: 12018.4854 normal_loss: 0.9430
[epoch 18][iter   30] loss: 186053.2969 RMSElog: 10.1470 grad_loss: 18594.2324 normal_loss: 0.9504
[epoch 18][iter   40] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 18][iter   50] loss: 105896.6094 RMSElog: 9.6983 grad_loss: 10579.0293 normal_loss: 0.9335
[epoch 18][iter   60] loss: 166207.1094 RMSElog: 9.7947 grad_loss: 16609.9668 normal_loss: 0.9492
[epoch 18][iter   70] loss: 165976.7344 RMSElog: 9.9385 grad_loss: 16586.7695 normal_loss: 0.9645
[epoch 18][iter   80] loss: 122331.3906 RMSElog: 9.7180 grad_loss: 12222.4795 normal_loss: 0.9418
[epoch 18][iter   90] loss: 183095.1562 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.9696
[epoch 18][iter  100] loss: 157119.7500 RMSElog: 9.8959 grad_loss: 15701.1318 normal_loss: 0.9480
[epoch 18][iter  110] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch 18][iter  120] loss: 152772.4062 RMSElog: 9.8249 grad_loss: 15266.4727 normal_loss: 0.9438
[epoch 18][iter  130] loss: 188116.2812 RMSElog: 10.0888 grad_loss: 18800.5703 normal_loss: 0.9711
[epoch 18][iter  140] loss: 228338.7500 RMSElog: 10.2936 grad_loss: 22822.6348 normal_loss: 0.9477
[epoch 18][iter  150] loss: 206526.4062 RMSElog: 10.1531 grad_loss: 20641.5449 normal_loss: 0.9425
[epoch 18][iter  160] loss: 163389.5625 RMSElog: 9.7702 grad_loss: 16328.2656 normal_loss: 0.9208
[epoch 18][iter  170] loss: 175004.6719 RMSElog: 10.1774 grad_loss: 17489.3320 normal_loss: 0.9561
[epoch 18][iter  180] loss: 180929.5938 RMSElog: 10.0745 grad_loss: 18081.9297 normal_loss: 0.9546
[epoch 18][iter  190] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 18][iter  200] loss: 142261.5781 RMSElog: 9.7627 grad_loss: 14215.4639 normal_loss: 0.9304
[epoch 18][iter  210] loss: 177063.6250 RMSElog: 10.1532 grad_loss: 17695.2383 normal_loss: 0.9719
[epoch 18][iter  220] loss: 190938.1094 RMSElog: 10.3028 grad_loss: 19082.5547 normal_loss: 0.9541
[epoch 18][iter  230] loss: 149128.2188 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.9419
[epoch 18][iter  240] loss: 157061.8906 RMSElog: 9.9892 grad_loss: 15695.2461 normal_loss: 0.9531
[epoch 18][iter  250] loss: 198743.4219 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.9643
[epoch 18][iter  260] loss: 133464.0312 RMSElog: 9.6242 grad_loss: 13335.8584 normal_loss: 0.9201
[epoch 18][iter  270] loss: 145321.5625 RMSElog: 9.7332 grad_loss: 14521.4600 normal_loss: 0.9632
[epoch 18][iter  280] loss: 96006.2578 RMSElog: 9.5560 grad_loss: 9590.1406 normal_loss: 0.9294
[epoch 18][iter  290] loss: 185772.2500 RMSElog: 9.9702 grad_loss: 18566.2969 normal_loss: 0.9567
[epoch 18][iter  300] loss: 139830.9062 RMSElog: 9.7552 grad_loss: 13972.3770 normal_loss: 0.9585
[epoch 18][iter  310] loss: 185071.7188 RMSElog: 10.0456 grad_loss: 18496.1719 normal_loss: 0.9557
[epoch 18][iter  320] loss: 191320.0938 RMSElog: 10.0978 grad_loss: 19120.9492 normal_loss: 0.9627
[epoch 18][iter  330] loss: 80097.4062 RMSElog: 9.2433 grad_loss: 7999.5806 normal_loss: 0.9166
[epoch 18][iter  340] loss: 181942.5625 RMSElog: 10.0291 grad_loss: 18183.2793 normal_loss: 0.9464
[epoch 18][iter  350] loss: 136869.7500 RMSElog: 9.5771 grad_loss: 13676.4668 normal_loss: 0.9315
[epoch 18][iter  360] loss: 110603.0781 RMSElog: 9.8046 grad_loss: 11049.5664 normal_loss: 0.9364
[epoch 18][iter  370] loss: 204037.7500 RMSElog: 10.1754 grad_loss: 20392.6582 normal_loss: 0.9420
[epoch 18][iter  380] loss: 177195.4844 RMSElog: 10.1516 grad_loss: 17708.4512 normal_loss: 0.9458
[epoch 18][iter  390] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 18][iter  400] loss: 130527.6172 RMSElog: 9.8914 grad_loss: 13041.9189 normal_loss: 0.9509
[epoch 18][iter  410] loss: 114149.3750 RMSElog: 9.2655 grad_loss: 11404.7646 normal_loss: 0.9073
[epoch 18][iter  420] loss: 206083.5312 RMSElog: 10.2501 grad_loss: 20597.1465 normal_loss: 0.9562
[epoch 18][iter  430] loss: 213401.8906 RMSElog: 10.0568 grad_loss: 21329.1582 normal_loss: 0.9749
[epoch 18][iter  440] loss: 113895.6328 RMSElog: 9.2606 grad_loss: 11379.3926 normal_loss: 0.9106
[epoch 18][iter  450] loss: 174761.2344 RMSElog: 9.7333 grad_loss: 17465.4512 normal_loss: 0.9393
[epoch 18][iter  460] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 18][iter  470] loss: 147479.0312 RMSElog: 9.6781 grad_loss: 14737.2812 normal_loss: 0.9446
[epoch 18][iter  480] loss: 157425.7188 RMSElog: 9.9235 grad_loss: 15731.7012 normal_loss: 0.9477
[epoch 18][iter  490] loss: 142138.5156 RMSElog: 9.7967 grad_loss: 14203.1260 normal_loss: 0.9291
[epoch 18][iter  500] loss: 122912.0625 RMSElog: 9.7328 grad_loss: 12280.5225 normal_loss: 0.9509
[epoch 18][iter  510] loss: 160879.7969 RMSElog: 9.7521 grad_loss: 16077.2764 normal_loss: 0.9513
[epoch 18][iter  520] loss: 143440.0000 RMSElog: 9.6404 grad_loss: 14333.4336 normal_loss: 0.9261
[epoch 18][iter  530] loss: 193978.6562 RMSElog: 10.3530 grad_loss: 19386.5605 normal_loss: 0.9518
[epoch 18][iter  540] loss: 165750.3750 RMSElog: 9.8971 grad_loss: 16564.1895 normal_loss: 0.9518
[epoch 18][iter  550] loss: 140938.8594 RMSElog: 9.7483 grad_loss: 14083.1953 normal_loss: 0.9424
[epoch 18][iter  560] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 18][iter  570] loss: 121866.5156 RMSElog: 9.8422 grad_loss: 12175.8965 normal_loss: 0.9131
[epoch 18][iter  580] loss: 178784.1250 RMSElog: 9.9460 grad_loss: 17867.5078 normal_loss: 0.9592
[epoch 18][iter  590] loss: 217845.4844 RMSElog: 10.3597 grad_loss: 21773.2129 normal_loss: 0.9774
[epoch 19][iter    0] loss: 193024.5000 RMSElog: 9.9639 grad_loss: 19291.5117 normal_loss: 0.9740
[epoch 19][iter   10] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch 19][iter   20] loss: 156985.6250 RMSElog: 9.5765 grad_loss: 15688.0479 normal_loss: 0.9385
[epoch 19][iter   30] loss: 165954.0938 RMSElog: 9.8997 grad_loss: 16584.5449 normal_loss: 0.9646
[epoch 19][iter   40] loss: 125829.2891 RMSElog: 9.7844 grad_loss: 12572.2148 normal_loss: 0.9297
[epoch 19][iter   50] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 19][iter   60] loss: 218547.0156 RMSElog: 10.4419 grad_loss: 21843.3086 normal_loss: 0.9515
[epoch 19][iter   70] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch 19][iter   80] loss: 103509.2188 RMSElog: 9.9787 grad_loss: 10340.0186 normal_loss: 0.9251
[epoch 19][iter   90] loss: 188116.2812 RMSElog: 10.0888 grad_loss: 18800.5703 normal_loss: 0.9711
[epoch 19][iter  100] loss: 122670.8984 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.9331
[epoch 19][iter  110] loss: 144657.9844 RMSElog: 9.9197 grad_loss: 14454.9258 normal_loss: 0.9518
[epoch 19][iter  120] loss: 206764.1875 RMSElog: 10.2849 grad_loss: 20665.1777 normal_loss: 0.9549
[epoch 19][iter  130] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 19][iter  140] loss: 213417.0312 RMSElog: 10.3416 grad_loss: 21330.4082 normal_loss: 0.9536
[epoch 19][iter  150] loss: 139154.8594 RMSElog: 9.5986 grad_loss: 13904.9707 normal_loss: 0.9164
[epoch 19][iter  160] loss: 174375.7031 RMSElog: 10.0512 grad_loss: 17426.5703 normal_loss: 0.9483
[epoch 19][iter  170] loss: 191559.9688 RMSElog: 9.9749 grad_loss: 19145.0742 normal_loss: 0.9477
[epoch 19][iter  180] loss: 196277.7188 RMSElog: 10.2453 grad_loss: 19616.5664 normal_loss: 0.9595
[epoch 19][iter  190] loss: 150699.3750 RMSElog: 9.8567 grad_loss: 15059.1328 normal_loss: 0.9486
[epoch 19][iter  200] loss: 180208.2188 RMSElog: 10.0490 grad_loss: 18009.8223 normal_loss: 0.9517
[epoch 19][iter  210] loss: 147371.3906 RMSElog: 9.6635 grad_loss: 14726.5488 normal_loss: 0.9280
[epoch 19][iter  220] loss: 164597.1094 RMSElog: 9.8631 grad_loss: 16448.8984 normal_loss: 0.9502
[epoch 19][iter  230] loss: 107073.5156 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.9313
[epoch 19][iter  240] loss: 210654.5312 RMSElog: 10.4982 grad_loss: 21054.0039 normal_loss: 0.9517
[epoch 19][iter  250] loss: 196516.1875 RMSElog: 9.9615 grad_loss: 19640.7109 normal_loss: 0.9475
[epoch 19][iter  260] loss: 115534.3672 RMSElog: 9.7196 grad_loss: 11542.7842 normal_loss: 0.9325
[epoch 19][iter  270] loss: 155482.1875 RMSElog: 10.0818 grad_loss: 15537.1816 normal_loss: 0.9552
[epoch 19][iter  280] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 19][iter  290] loss: 118495.6641 RMSElog: 9.2657 grad_loss: 11839.3906 normal_loss: 0.9103
[epoch 19][iter  300] loss: 120745.8203 RMSElog: 9.7706 grad_loss: 12063.8691 normal_loss: 0.9428
[epoch 19][iter  310] loss: 194987.6250 RMSElog: 9.8416 grad_loss: 19487.9453 normal_loss: 0.9748
[epoch 19][iter  320] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 19][iter  330] loss: 170542.9531 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.9688
[epoch 19][iter  340] loss: 217914.6094 RMSElog: 10.2786 grad_loss: 21780.2246 normal_loss: 0.9575
[epoch 19][iter  350] loss: 201503.0625 RMSElog: 10.3149 grad_loss: 20139.0410 normal_loss: 0.9514
[epoch 19][iter  360] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 19][iter  370] loss: 105828.7812 RMSElog: 10.1032 grad_loss: 10571.8545 normal_loss: 0.9195
[epoch 19][iter  380] loss: 148057.2500 RMSElog: 9.9895 grad_loss: 14794.7803 normal_loss: 0.9555
[epoch 19][iter  390] loss: 135114.8750 RMSElog: 9.9265 grad_loss: 13500.6055 normal_loss: 0.9548
[epoch 19][iter  400] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 19][iter  410] loss: 214808.7344 RMSElog: 10.1872 grad_loss: 21469.7441 normal_loss: 0.9423
[epoch 19][iter  420] loss: 136533.4688 RMSElog: 9.6756 grad_loss: 13642.7363 normal_loss: 0.9359
[epoch 19][iter  430] loss: 175008.6562 RMSElog: 9.9496 grad_loss: 17489.9434 normal_loss: 0.9734
[epoch 19][iter  440] loss: 149540.3750 RMSElog: 9.7408 grad_loss: 14943.3740 normal_loss: 0.9229
[epoch 19][iter  450] loss: 166093.7344 RMSElog: 10.4480 grad_loss: 16597.9766 normal_loss: 0.9489
[epoch 19][iter  460] loss: 195777.0469 RMSElog: 10.1280 grad_loss: 19566.6035 normal_loss: 0.9726
[epoch 19][iter  470] loss: 198743.4219 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.9643
[epoch 19][iter  480] loss: 111518.2734 RMSElog: 9.6257 grad_loss: 11141.2676 normal_loss: 0.9335
[epoch 19][iter  490] loss: 141118.5312 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.9477
[epoch 19][iter  500] loss: 119655.7969 RMSElog: 9.6110 grad_loss: 11955.0312 normal_loss: 0.9378
[epoch 19][iter  510] loss: 108409.6484 RMSElog: 9.2105 grad_loss: 10830.8506 normal_loss: 0.9033
[epoch 19][iter  520] loss: 135814.7969 RMSElog: 9.5386 grad_loss: 13571.0137 normal_loss: 0.9281
[epoch 19][iter  530] loss: 181983.5312 RMSElog: 10.0741 grad_loss: 18187.3320 normal_loss: 0.9464
[epoch 19][iter  540] loss: 205235.7188 RMSElog: 10.2875 grad_loss: 20512.3281 normal_loss: 0.9564
[epoch 19][iter  550] loss: 115495.2188 RMSElog: 9.6084 grad_loss: 11538.9688 normal_loss: 0.9442
[epoch 19][iter  560] loss: 168688.8125 RMSElog: 9.8493 grad_loss: 16858.0781 normal_loss: 0.9524
[epoch 19][iter  570] loss: 128277.9766 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.9518
[epoch 19][iter  580] loss: 167412.9531 RMSElog: 9.7311 grad_loss: 16730.6387 normal_loss: 0.9260
[epoch 19][iter  590] loss: 178076.4688 RMSElog: 9.8778 grad_loss: 17796.8457 normal_loss: 0.9233
[epoch 20][iter    0] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 20][iter   10] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 20][iter   20] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 20][iter   30] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 20][iter   40] loss: 172115.2812 RMSElog: 9.7682 grad_loss: 17200.8242 normal_loss: 0.9358
[epoch 20][iter   50] loss: 124323.5234 RMSElog: 9.7543 grad_loss: 12421.6660 normal_loss: 0.9322
[epoch 20][iter   60] loss: 167730.9531 RMSElog: 9.9663 grad_loss: 16762.1797 normal_loss: 0.9501
[epoch 20][iter   70] loss: 213417.0312 RMSElog: 10.3416 grad_loss: 21330.4082 normal_loss: 0.9536
[epoch 20][iter   80] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 20][iter   90] loss: 87697.6250 RMSElog: 9.9487 grad_loss: 8758.8750 normal_loss: 0.9395
[epoch 20][iter  100] loss: 152332.5469 RMSElog: 9.9813 grad_loss: 15222.3486 normal_loss: 0.9245
[epoch 20][iter  110] loss: 164415.3438 RMSElog: 10.0829 grad_loss: 16430.4961 normal_loss: 0.9571
[epoch 20][iter  120] loss: 101101.5781 RMSElog: 9.9274 grad_loss: 10099.3008 normal_loss: 0.9297
[epoch 20][iter  130] loss: 175486.0625 RMSElog: 10.0393 grad_loss: 17537.6094 normal_loss: 0.9563
[epoch 20][iter  140] loss: 162542.0312 RMSElog: 9.9393 grad_loss: 16243.3105 normal_loss: 0.9527
[epoch 20][iter  150] loss: 143460.8594 RMSElog: 9.7520 grad_loss: 14335.3848 normal_loss: 0.9489
[epoch 20][iter  160] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 20][iter  170] loss: 170357.3281 RMSElog: 9.9687 grad_loss: 17024.7988 normal_loss: 0.9644
[epoch 20][iter  180] loss: 113895.6328 RMSElog: 9.2606 grad_loss: 11379.3926 normal_loss: 0.9106
[epoch 20][iter  190] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 20][iter  200] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 20][iter  210] loss: 100663.8984 RMSElog: 9.9598 grad_loss: 10055.5020 normal_loss: 0.9277
[epoch 20][iter  220] loss: 108409.6484 RMSElog: 9.2105 grad_loss: 10830.8506 normal_loss: 0.9033
[epoch 20][iter  230] loss: 218547.0156 RMSElog: 10.4419 grad_loss: 21843.3086 normal_loss: 0.9515
[epoch 20][iter  240] loss: 145332.8438 RMSElog: 10.0385 grad_loss: 14522.2842 normal_loss: 0.9619
[epoch 20][iter  250] loss: 229081.2812 RMSElog: 10.2778 grad_loss: 22896.9102 normal_loss: 0.9420
[epoch 20][iter  260] loss: 175299.8438 RMSElog: 10.1975 grad_loss: 17518.8301 normal_loss: 0.9576
[epoch 20][iter  270] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 20][iter  280] loss: 126821.0234 RMSElog: 10.1398 grad_loss: 12671.0410 normal_loss: 0.9215
[epoch 20][iter  290] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 20][iter  300] loss: 109441.5234 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.9300
[epoch 20][iter  310] loss: 139061.3906 RMSElog: 9.6201 grad_loss: 13895.5781 normal_loss: 0.9401
[epoch 20][iter  320] loss: 195777.0156 RMSElog: 10.1280 grad_loss: 19566.5996 normal_loss: 0.9726
[epoch 20][iter  330] loss: 190034.7188 RMSElog: 9.9619 grad_loss: 18992.5625 normal_loss: 0.9485
[epoch 20][iter  340] loss: 170542.9531 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.9688
[epoch 20][iter  350] loss: 105828.7812 RMSElog: 10.1032 grad_loss: 10571.8545 normal_loss: 0.9195
[epoch 20][iter  360] loss: 196277.7188 RMSElog: 10.2453 grad_loss: 19616.5664 normal_loss: 0.9595
[epoch 20][iter  370] loss: 143440.0000 RMSElog: 9.6404 grad_loss: 14333.4336 normal_loss: 0.9261
[epoch 20][iter  380] loss: 124563.3906 RMSElog: 9.9514 grad_loss: 12445.4473 normal_loss: 0.9400
[epoch 20][iter  390] loss: 167008.4531 RMSElog: 10.0165 grad_loss: 16689.8750 normal_loss: 0.9557
[epoch 20][iter  400] loss: 156982.7188 RMSElog: 10.0093 grad_loss: 15687.3193 normal_loss: 0.9438
[epoch 20][iter  410] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 20][iter  420] loss: 140938.8594 RMSElog: 9.7483 grad_loss: 14083.1953 normal_loss: 0.9424
[epoch 20][iter  430] loss: 115500.4766 RMSElog: 9.9924 grad_loss: 11539.1230 normal_loss: 0.9328
[epoch 20][iter  440] loss: 189017.5781 RMSElog: 10.1390 grad_loss: 18890.6602 normal_loss: 0.9589
[epoch 20][iter  450] loss: 183095.1562 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.9696
[epoch 20][iter  460] loss: 134406.1875 RMSElog: 9.9402 grad_loss: 13429.7246 normal_loss: 0.9539
[epoch 20][iter  470] loss: 214808.7500 RMSElog: 10.1872 grad_loss: 21469.7461 normal_loss: 0.9423
[epoch 20][iter  480] loss: 162579.5312 RMSElog: 10.1223 grad_loss: 16246.8740 normal_loss: 0.9574
[epoch 20][iter  490] loss: 182476.7344 RMSElog: 9.9672 grad_loss: 18236.7656 normal_loss: 0.9407
[epoch 20][iter  500] loss: 160051.0156 RMSElog: 9.8405 grad_loss: 15994.3105 normal_loss: 0.9506
[epoch 20][iter  510] loss: 201373.6719 RMSElog: 10.3870 grad_loss: 20126.0312 normal_loss: 0.9491
[epoch 20][iter  520] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 20][iter  530] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch 20][iter  540] loss: 217174.7812 RMSElog: 10.2254 grad_loss: 21706.2910 normal_loss: 0.9635
[epoch 20][iter  550] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch 20][iter  560] loss: 103509.2188 RMSElog: 9.9787 grad_loss: 10340.0186 normal_loss: 0.9251
[epoch 20][iter  570] loss: 113195.8125 RMSElog: 9.1761 grad_loss: 11309.5039 normal_loss: 0.9012
[epoch 20][iter  580] loss: 140645.6875 RMSElog: 10.1118 grad_loss: 14053.4873 normal_loss: 0.9695
[epoch 20][iter  590] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 21][iter    0] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 21][iter   10] loss: 152517.4844 RMSElog: 9.8233 grad_loss: 15241.0010 normal_loss: 0.9249
[epoch 21][iter   20] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 21][iter   30] loss: 160642.9375 RMSElog: 9.9306 grad_loss: 16053.4121 normal_loss: 0.9504
[epoch 21][iter   40] loss: 190938.1250 RMSElog: 10.3028 grad_loss: 19082.5566 normal_loss: 0.9541
[epoch 21][iter   50] loss: 179901.4844 RMSElog: 9.8267 grad_loss: 17979.3633 normal_loss: 0.9589
[epoch 21][iter   60] loss: 153594.7031 RMSElog: 9.8426 grad_loss: 15348.6826 normal_loss: 0.9453
[epoch 21][iter   70] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 21][iter   80] loss: 206764.1875 RMSElog: 10.2849 grad_loss: 20665.1777 normal_loss: 0.9549
[epoch 21][iter   90] loss: 102998.8984 RMSElog: 9.8140 grad_loss: 10289.1318 normal_loss: 0.9431
[epoch 21][iter  100] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 21][iter  110] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1221 normal_loss: 0.9462
[epoch 21][iter  120] loss: 115738.1953 RMSElog: 9.6968 grad_loss: 11563.1836 normal_loss: 0.9382
[epoch 21][iter  130] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch 21][iter  140] loss: 122670.8984 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.9331
[epoch 21][iter  150] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 21][iter  160] loss: 134406.2031 RMSElog: 9.9402 grad_loss: 13429.7256 normal_loss: 0.9539
[epoch 21][iter  170] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 21][iter  180] loss: 115348.2734 RMSElog: 9.7235 grad_loss: 11524.1562 normal_loss: 0.9470
[epoch 21][iter  190] loss: 105816.5000 RMSElog: 9.4266 grad_loss: 10571.3066 normal_loss: 0.9171
[epoch 21][iter  200] loss: 178468.8906 RMSElog: 9.9039 grad_loss: 17836.0469 normal_loss: 0.9380
[epoch 21][iter  210] loss: 198293.9219 RMSElog: 10.2275 grad_loss: 19818.2148 normal_loss: 0.9521
[epoch 21][iter  220] loss: 163268.1250 RMSElog: 9.9218 grad_loss: 16315.9277 normal_loss: 0.9630
[epoch 21][iter  230] loss: 142596.2344 RMSElog: 9.8922 grad_loss: 14248.7793 normal_loss: 0.9508
[epoch 21][iter  240] loss: 115658.3125 RMSElog: 9.1856 grad_loss: 11555.7031 normal_loss: 0.9424
[epoch 21][iter  250] loss: 165648.1875 RMSElog: 9.7420 grad_loss: 16554.1289 normal_loss: 0.9479
[epoch 21][iter  260] loss: 158034.0469 RMSElog: 9.9527 grad_loss: 15792.5078 normal_loss: 0.9445
[epoch 21][iter  270] loss: 144191.5938 RMSElog: 9.6650 grad_loss: 14408.5654 normal_loss: 0.9284
[epoch 21][iter  280] loss: 103305.2500 RMSElog: 9.5543 grad_loss: 10320.0684 normal_loss: 0.9024
[epoch 21][iter  290] loss: 180208.2188 RMSElog: 10.0490 grad_loss: 18009.8223 normal_loss: 0.9517
[epoch 21][iter  300] loss: 186053.2812 RMSElog: 10.1470 grad_loss: 18594.2305 normal_loss: 0.9504
[epoch 21][iter  310] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch 21][iter  320] loss: 149369.9219 RMSElog: 10.0930 grad_loss: 14925.9766 normal_loss: 0.9225
[epoch 21][iter  330] loss: 195777.0469 RMSElog: 10.1280 grad_loss: 19566.6035 normal_loss: 0.9726
[epoch 21][iter  340] loss: 80097.4062 RMSElog: 9.2433 grad_loss: 7999.5806 normal_loss: 0.9166
[epoch 21][iter  350] loss: 218949.8281 RMSElog: 10.4462 grad_loss: 21883.5918 normal_loss: 0.9447
[epoch 21][iter  360] loss: 121838.3672 RMSElog: 9.7453 grad_loss: 12173.1494 normal_loss: 0.9425
[epoch 21][iter  370] loss: 176223.4531 RMSElog: 9.9872 grad_loss: 17611.4141 normal_loss: 0.9446
[epoch 21][iter  380] loss: 188502.1875 RMSElog: 10.1669 grad_loss: 18839.0801 normal_loss: 0.9722
[epoch 21][iter  390] loss: 146781.9531 RMSElog: 9.8688 grad_loss: 14667.3818 normal_loss: 0.9440
[epoch 21][iter  400] loss: 120590.1719 RMSElog: 9.9054 grad_loss: 12048.1719 normal_loss: 0.9408
[epoch 21][iter  410] loss: 227080.5938 RMSElog: 10.4127 grad_loss: 22696.6992 normal_loss: 0.9482
[epoch 21][iter  420] loss: 164843.6719 RMSElog: 9.7972 grad_loss: 16473.6348 normal_loss: 0.9360
[epoch 21][iter  430] loss: 158875.5625 RMSElog: 9.5853 grad_loss: 15877.0449 normal_loss: 0.9260
[epoch 21][iter  440] loss: 162711.9688 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.9427
[epoch 21][iter  450] loss: 167740.4688 RMSElog: 9.8540 grad_loss: 16763.2344 normal_loss: 0.9591
[epoch 21][iter  460] loss: 184374.2188 RMSElog: 10.2641 grad_loss: 18426.1992 normal_loss: 0.9596
[epoch 21][iter  470] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 21][iter  480] loss: 157706.0781 RMSElog: 9.9981 grad_loss: 15759.6602 normal_loss: 0.9499
[epoch 21][iter  490] loss: 155762.3438 RMSElog: 9.8487 grad_loss: 15565.4404 normal_loss: 0.9448
[epoch 21][iter  500] loss: 178076.4688 RMSElog: 9.8778 grad_loss: 17796.8457 normal_loss: 0.9233
[epoch 21][iter  510] loss: 139098.6406 RMSElog: 9.8619 grad_loss: 13899.0508 normal_loss: 0.9510
[epoch 21][iter  520] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 21][iter  530] loss: 173855.4375 RMSElog: 10.0769 grad_loss: 17374.5098 normal_loss: 0.9566
[epoch 21][iter  540] loss: 167084.9219 RMSElog: 9.8660 grad_loss: 16697.6582 normal_loss: 0.9689
[epoch 21][iter  550] loss: 214067.1875 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.9394
[epoch 21][iter  560] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 21][iter  570] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 21][iter  580] loss: 211925.8438 RMSElog: 10.1863 grad_loss: 21181.4551 normal_loss: 0.9436
[epoch 21][iter  590] loss: 131434.0312 RMSElog: 9.5911 grad_loss: 13132.8770 normal_loss: 0.9360
[epoch 22][iter    0] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 22][iter   10] loss: 189582.6719 RMSElog: 9.9918 grad_loss: 18947.3223 normal_loss: 0.9523
[epoch 22][iter   20] loss: 181293.3438 RMSElog: 10.0009 grad_loss: 18118.3809 normal_loss: 0.9531
[epoch 22][iter   30] loss: 106182.2031 RMSElog: 9.7575 grad_loss: 10607.5332 normal_loss: 0.9294
[epoch 22][iter   40] loss: 241971.8750 RMSElog: 10.2390 grad_loss: 24186.0000 normal_loss: 0.9488
[epoch 22][iter   50] loss: 190034.7188 RMSElog: 9.9619 grad_loss: 18992.5625 normal_loss: 0.9485
[epoch 22][iter   60] loss: 162542.0469 RMSElog: 9.9393 grad_loss: 16243.3115 normal_loss: 0.9527
[epoch 22][iter   70] loss: 200470.3906 RMSElog: 10.2414 grad_loss: 20035.8379 normal_loss: 0.9585
[epoch 22][iter   80] loss: 136796.3438 RMSElog: 9.6524 grad_loss: 13669.0273 normal_loss: 0.9549
[epoch 22][iter   90] loss: 128979.7188 RMSElog: 9.7049 grad_loss: 12887.3340 normal_loss: 0.9327
[epoch 22][iter  100] loss: 157810.1406 RMSElog: 9.9254 grad_loss: 15770.1621 normal_loss: 0.9253
[epoch 22][iter  110] loss: 104127.8047 RMSElog: 9.6242 grad_loss: 10402.2324 normal_loss: 0.9237
[epoch 22][iter  120] loss: 160595.2188 RMSElog: 9.9514 grad_loss: 16048.6191 normal_loss: 0.9518
[epoch 22][iter  130] loss: 110874.4688 RMSElog: 9.2829 grad_loss: 11077.2607 normal_loss: 0.9034
[epoch 22][iter  140] loss: 119895.5078 RMSElog: 9.3187 grad_loss: 11979.3164 normal_loss: 0.9157
[epoch 22][iter  150] loss: 224077.6719 RMSElog: 10.3869 grad_loss: 22396.4219 normal_loss: 0.9584
[epoch 22][iter  160] loss: 167345.2500 RMSElog: 9.8843 grad_loss: 16723.6777 normal_loss: 0.9620
[epoch 22][iter  170] loss: 146465.6875 RMSElog: 10.2283 grad_loss: 14635.4062 normal_loss: 0.9337
[epoch 22][iter  180] loss: 190972.3281 RMSElog: 10.1152 grad_loss: 19086.1523 normal_loss: 0.9647
[epoch 22][iter  190] loss: 177814.3125 RMSElog: 10.0854 grad_loss: 17770.3887 normal_loss: 0.9571
[epoch 22][iter  200] loss: 125829.2891 RMSElog: 9.7844 grad_loss: 12572.2148 normal_loss: 0.9297
[epoch 22][iter  210] loss: 133024.8594 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.9261
[epoch 22][iter  220] loss: 205362.7188 RMSElog: 10.1686 grad_loss: 20525.1562 normal_loss: 0.9475
[epoch 22][iter  230] loss: 162835.5469 RMSElog: 9.9145 grad_loss: 16272.6914 normal_loss: 0.9492
[epoch 22][iter  240] loss: 142138.5156 RMSElog: 9.7967 grad_loss: 14203.1260 normal_loss: 0.9291
[epoch 22][iter  250] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 22][iter  260] loss: 162892.2969 RMSElog: 9.8252 grad_loss: 16278.4717 normal_loss: 0.9331
[epoch 22][iter  270] loss: 104086.5234 RMSElog: 9.7787 grad_loss: 10397.9453 normal_loss: 0.9289
[epoch 22][iter  280] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 22][iter  290] loss: 165648.1875 RMSElog: 9.7420 grad_loss: 16554.1289 normal_loss: 0.9479
[epoch 22][iter  300] loss: 96006.2500 RMSElog: 9.5560 grad_loss: 9590.1396 normal_loss: 0.9294
[epoch 22][iter  310] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 22][iter  320] loss: 105628.3594 RMSElog: 10.0899 grad_loss: 10551.8252 normal_loss: 0.9213
[epoch 22][iter  330] loss: 155968.4062 RMSElog: 9.9200 grad_loss: 15585.9980 normal_loss: 0.9232
[epoch 22][iter  340] loss: 204037.7500 RMSElog: 10.1754 grad_loss: 20392.6582 normal_loss: 0.9420
[epoch 22][iter  350] loss: 139878.0781 RMSElog: 9.8515 grad_loss: 13977.0234 normal_loss: 0.9327
[epoch 22][iter  360] loss: 211925.8438 RMSElog: 10.1863 grad_loss: 21181.4551 normal_loss: 0.9436
[epoch 22][iter  370] loss: 160879.7812 RMSElog: 9.7521 grad_loss: 16077.2754 normal_loss: 0.9513
[epoch 22][iter  380] loss: 196842.3281 RMSElog: 10.1249 grad_loss: 19673.1543 normal_loss: 0.9534
[epoch 22][iter  390] loss: 191559.9688 RMSElog: 9.9749 grad_loss: 19145.0742 normal_loss: 0.9477
[epoch 22][iter  400] loss: 166093.7344 RMSElog: 10.4480 grad_loss: 16597.9766 normal_loss: 0.9489
[epoch 22][iter  410] loss: 208699.7031 RMSElog: 10.3419 grad_loss: 20858.6719 normal_loss: 0.9568
[epoch 22][iter  420] loss: 126874.0625 RMSElog: 9.7526 grad_loss: 12676.7002 normal_loss: 0.9530
[epoch 22][iter  430] loss: 176217.8125 RMSElog: 10.1087 grad_loss: 17610.7246 normal_loss: 0.9466
[epoch 22][iter  440] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1221 normal_loss: 0.9462
[epoch 22][iter  450] loss: 149540.3750 RMSElog: 9.7408 grad_loss: 14943.3740 normal_loss: 0.9229
[epoch 22][iter  460] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 22][iter  470] loss: 137249.3438 RMSElog: 9.7342 grad_loss: 13714.2764 normal_loss: 0.9239
[epoch 22][iter  480] loss: 163171.1719 RMSElog: 9.7905 grad_loss: 16306.3613 normal_loss: 0.9652
[epoch 22][iter  490] loss: 218949.8281 RMSElog: 10.4462 grad_loss: 21883.5918 normal_loss: 0.9447
[epoch 22][iter  500] loss: 142596.2344 RMSElog: 9.8922 grad_loss: 14248.7793 normal_loss: 0.9508
[epoch 22][iter  510] loss: 162522.4531 RMSElog: 9.9860 grad_loss: 16241.3066 normal_loss: 0.9518
[epoch 22][iter  520] loss: 122446.5469 RMSElog: 9.6438 grad_loss: 12234.0742 normal_loss: 0.9366
[epoch 22][iter  530] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch 22][iter  540] loss: 111518.2734 RMSElog: 9.6257 grad_loss: 11141.2676 normal_loss: 0.9335
[epoch 22][iter  550] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 22][iter  560] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 22][iter  570] loss: 133760.0469 RMSElog: 10.0653 grad_loss: 13364.9717 normal_loss: 0.9680
[epoch 22][iter  580] loss: 103514.7734 RMSElog: 9.3451 grad_loss: 10341.2100 normal_loss: 0.9229
[epoch 22][iter  590] loss: 201162.3750 RMSElog: 9.9531 grad_loss: 20105.3145 normal_loss: 0.9706
[epoch 23][iter    0] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 23][iter   10] loss: 147765.9219 RMSElog: 10.0607 grad_loss: 14765.6104 normal_loss: 0.9219
[epoch 23][iter   20] loss: 154609.8281 RMSElog: 9.8745 grad_loss: 15450.1855 normal_loss: 0.9220
[epoch 23][iter   30] loss: 163252.6875 RMSElog: 9.8236 grad_loss: 16314.5117 normal_loss: 0.9348
[epoch 23][iter   40] loss: 157706.0781 RMSElog: 9.9981 grad_loss: 15759.6602 normal_loss: 0.9499
[epoch 23][iter   50] loss: 148057.2500 RMSElog: 9.9895 grad_loss: 14794.7803 normal_loss: 0.9555
[epoch 23][iter   60] loss: 145321.5469 RMSElog: 9.7332 grad_loss: 14521.4590 normal_loss: 0.9632
[epoch 23][iter   70] loss: 114310.3047 RMSElog: 9.4026 grad_loss: 11420.7217 normal_loss: 0.9063
[epoch 23][iter   80] loss: 160825.5938 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.9491
[epoch 23][iter   90] loss: 114893.3984 RMSElog: 9.2562 grad_loss: 11479.1777 normal_loss: 0.9067
[epoch 23][iter  100] loss: 172115.2812 RMSElog: 9.7682 grad_loss: 17200.8242 normal_loss: 0.9358
[epoch 23][iter  110] loss: 142544.7031 RMSElog: 10.2185 grad_loss: 14243.3027 normal_loss: 0.9486
[epoch 23][iter  120] loss: 112715.8125 RMSElog: 9.6867 grad_loss: 11260.9570 normal_loss: 0.9375
[epoch 23][iter  130] loss: 196920.5938 RMSElog: 10.2474 grad_loss: 19680.8340 normal_loss: 0.9760
[epoch 23][iter  140] loss: 155968.4062 RMSElog: 9.9200 grad_loss: 15585.9980 normal_loss: 0.9232
[epoch 23][iter  150] loss: 126821.0234 RMSElog: 10.1398 grad_loss: 12671.0410 normal_loss: 0.9215
[epoch 23][iter  160] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 23][iter  170] loss: 110808.0469 RMSElog: 9.7171 grad_loss: 11070.1562 normal_loss: 0.9312
[epoch 23][iter  180] loss: 145409.6719 RMSElog: 9.8330 grad_loss: 14530.1904 normal_loss: 0.9445
[epoch 23][iter  190] loss: 168688.7812 RMSElog: 9.8493 grad_loss: 16858.0762 normal_loss: 0.9524
[epoch 23][iter  200] loss: 204037.7500 RMSElog: 10.1754 grad_loss: 20392.6582 normal_loss: 0.9420
[epoch 23][iter  210] loss: 100116.4922 RMSElog: 9.9235 grad_loss: 10000.7998 normal_loss: 0.9258
[epoch 23][iter  220] loss: 194408.7812 RMSElog: 10.2924 grad_loss: 19429.6328 normal_loss: 0.9537
[epoch 23][iter  230] loss: 220695.7969 RMSElog: 10.2208 grad_loss: 22058.4082 normal_loss: 0.9520
[epoch 23][iter  240] loss: 221089.3594 RMSElog: 10.3457 grad_loss: 22097.6465 normal_loss: 0.9439
[epoch 23][iter  250] loss: 228053.0312 RMSElog: 10.2288 grad_loss: 22794.1328 normal_loss: 0.9422
[epoch 23][iter  260] loss: 154776.6250 RMSElog: 9.8981 grad_loss: 15466.8438 normal_loss: 0.9209
[epoch 23][iter  270] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 23][iter  280] loss: 180425.2344 RMSElog: 10.0354 grad_loss: 18031.5332 normal_loss: 0.9552
[epoch 23][iter  290] loss: 117693.8984 RMSElog: 9.6527 grad_loss: 11758.8105 normal_loss: 0.9267
[epoch 23][iter  300] loss: 133024.8594 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.9261
[epoch 23][iter  310] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 23][iter  320] loss: 174761.2500 RMSElog: 9.7333 grad_loss: 17465.4531 normal_loss: 0.9393
[epoch 23][iter  330] loss: 114924.9844 RMSElog: 9.6925 grad_loss: 11481.8691 normal_loss: 0.9360
[epoch 23][iter  340] loss: 104456.8438 RMSElog: 10.0170 grad_loss: 10434.7461 normal_loss: 0.9214
[epoch 23][iter  350] loss: 114149.3750 RMSElog: 9.2655 grad_loss: 11404.7646 normal_loss: 0.9073
[epoch 23][iter  360] loss: 147915.7812 RMSElog: 10.0131 grad_loss: 14780.6104 normal_loss: 0.9547
[epoch 23][iter  370] loss: 146576.9219 RMSElog: 9.6520 grad_loss: 14647.1045 normal_loss: 0.9356
[epoch 23][iter  380] loss: 206764.1875 RMSElog: 10.2849 grad_loss: 20665.1777 normal_loss: 0.9549
[epoch 23][iter  390] loss: 123289.4609 RMSElog: 9.4106 grad_loss: 12318.5752 normal_loss: 0.9606
[epoch 23][iter  400] loss: 149128.2188 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.9419
[epoch 23][iter  410] loss: 201503.0625 RMSElog: 10.3149 grad_loss: 20139.0410 normal_loss: 0.9514
[epoch 23][iter  420] loss: 175002.7344 RMSElog: 9.8652 grad_loss: 17489.4648 normal_loss: 0.9436
[epoch 23][iter  430] loss: 154855.9062 RMSElog: 9.8054 grad_loss: 15474.8340 normal_loss: 0.9510
[epoch 23][iter  440] loss: 147207.9844 RMSElog: 9.9779 grad_loss: 14709.8789 normal_loss: 0.9413
[epoch 23][iter  450] loss: 116582.6172 RMSElog: 9.7871 grad_loss: 11647.5430 normal_loss: 0.9314
[epoch 23][iter  460] loss: 175934.2344 RMSElog: 10.1481 grad_loss: 17582.3086 normal_loss: 0.9674
[epoch 23][iter  470] loss: 130527.6094 RMSElog: 9.8914 grad_loss: 13041.9180 normal_loss: 0.9509
[epoch 23][iter  480] loss: 160879.7812 RMSElog: 9.7521 grad_loss: 16077.2754 normal_loss: 0.9513
[epoch 23][iter  490] loss: 152540.7500 RMSElog: 9.9175 grad_loss: 15243.2090 normal_loss: 0.9474
[epoch 23][iter  500] loss: 149369.9062 RMSElog: 10.0930 grad_loss: 14925.9756 normal_loss: 0.9225
[epoch 23][iter  510] loss: 115500.4766 RMSElog: 9.9924 grad_loss: 11539.1230 normal_loss: 0.9328
[epoch 23][iter  520] loss: 120590.1719 RMSElog: 9.9054 grad_loss: 12048.1719 normal_loss: 0.9408
[epoch 23][iter  530] loss: 224943.8906 RMSElog: 10.1206 grad_loss: 22483.3125 normal_loss: 0.9551
[epoch 23][iter  540] loss: 100749.6875 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.9377
[epoch 23][iter  550] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 23][iter  560] loss: 173339.3750 RMSElog: 9.8230 grad_loss: 17323.1934 normal_loss: 0.9212
[epoch 23][iter  570] loss: 195671.7031 RMSElog: 10.1080 grad_loss: 19556.1133 normal_loss: 0.9494
[epoch 23][iter  580] loss: 196025.7031 RMSElog: 10.2650 grad_loss: 19591.3496 normal_loss: 0.9559
[epoch 23][iter  590] loss: 162976.7812 RMSElog: 9.6016 grad_loss: 16287.1572 normal_loss: 0.9201
[epoch 24][iter    0] loss: 100990.1562 RMSElog: 9.7350 grad_loss: 10088.3584 normal_loss: 0.9222
[epoch 24][iter   10] loss: 146444.9062 RMSElog: 10.1139 grad_loss: 14633.4365 normal_loss: 0.9403
[epoch 24][iter   20] loss: 138469.0469 RMSElog: 9.4787 grad_loss: 13836.4834 normal_loss: 0.9438
[epoch 24][iter   30] loss: 160788.1562 RMSElog: 9.7539 grad_loss: 16068.1299 normal_loss: 0.9318
[epoch 24][iter   40] loss: 131942.8750 RMSElog: 9.8414 grad_loss: 13183.5000 normal_loss: 0.9453
[epoch 24][iter   50] loss: 181942.5625 RMSElog: 10.0291 grad_loss: 18183.2793 normal_loss: 0.9464
[epoch 24][iter   60] loss: 165306.9531 RMSElog: 9.8881 grad_loss: 16519.8438 normal_loss: 0.9638
[epoch 24][iter   70] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch 24][iter   80] loss: 155968.4062 RMSElog: 9.9200 grad_loss: 15585.9980 normal_loss: 0.9232
[epoch 24][iter   90] loss: 169013.5625 RMSElog: 9.5880 grad_loss: 16890.8262 normal_loss: 0.9419
[epoch 24][iter  100] loss: 166207.1094 RMSElog: 9.7947 grad_loss: 16609.9668 normal_loss: 0.9492
[epoch 24][iter  110] loss: 196842.3281 RMSElog: 10.1249 grad_loss: 19673.1543 normal_loss: 0.9534
[epoch 24][iter  120] loss: 165648.1875 RMSElog: 9.7420 grad_loss: 16554.1289 normal_loss: 0.9479
[epoch 24][iter  130] loss: 221089.3594 RMSElog: 10.3457 grad_loss: 22097.6465 normal_loss: 0.9439
[epoch 24][iter  140] loss: 198743.4219 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.9643
[epoch 24][iter  150] loss: 224943.8906 RMSElog: 10.1206 grad_loss: 22483.3125 normal_loss: 0.9551
[epoch 24][iter  160] loss: 173721.0312 RMSElog: 10.0355 grad_loss: 17361.1211 normal_loss: 0.9468
[epoch 24][iter  170] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch 24][iter  180] loss: 153723.9844 RMSElog: 9.9609 grad_loss: 15361.4902 normal_loss: 0.9475
[epoch 24][iter  190] loss: 170542.9531 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.9688
[epoch 24][iter  200] loss: 211925.8438 RMSElog: 10.1863 grad_loss: 21181.4551 normal_loss: 0.9436
[epoch 24][iter  210] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 24][iter  220] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 24][iter  230] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 24][iter  240] loss: 167730.9531 RMSElog: 9.9663 grad_loss: 16762.1797 normal_loss: 0.9501
[epoch 24][iter  250] loss: 175359.1875 RMSElog: 10.1476 grad_loss: 17524.8125 normal_loss: 0.9571
[epoch 24][iter  260] loss: 218625.8750 RMSElog: 10.2839 grad_loss: 21851.3457 normal_loss: 0.9592
[epoch 24][iter  270] loss: 194408.7812 RMSElog: 10.2924 grad_loss: 19429.6328 normal_loss: 0.9537
[epoch 24][iter  280] loss: 203093.2969 RMSElog: 10.1238 grad_loss: 20298.2598 normal_loss: 0.9478
[epoch 24][iter  290] loss: 146465.6875 RMSElog: 10.2283 grad_loss: 14635.4062 normal_loss: 0.9337
[epoch 24][iter  300] loss: 104749.2812 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.9281
[epoch 24][iter  310] loss: 166010.9531 RMSElog: 9.9249 grad_loss: 16590.2227 normal_loss: 0.9481
[epoch 24][iter  320] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 24][iter  330] loss: 214493.2188 RMSElog: 10.3525 grad_loss: 21438.0078 normal_loss: 0.9611
[epoch 24][iter  340] loss: 182315.9688 RMSElog: 10.1291 grad_loss: 18220.5039 normal_loss: 0.9652
[epoch 24][iter  350] loss: 201373.6875 RMSElog: 10.3870 grad_loss: 20126.0332 normal_loss: 0.9491
[epoch 24][iter  360] loss: 127061.7500 RMSElog: 9.6726 grad_loss: 12695.5654 normal_loss: 0.9369
[epoch 24][iter  370] loss: 214067.1875 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.9394
[epoch 24][iter  380] loss: 160595.2188 RMSElog: 9.9514 grad_loss: 16048.6191 normal_loss: 0.9518
[epoch 24][iter  390] loss: 168545.0938 RMSElog: 9.6168 grad_loss: 16843.9434 normal_loss: 0.9495
[epoch 24][iter  400] loss: 163268.1250 RMSElog: 9.9218 grad_loss: 16315.9277 normal_loss: 0.9630
[epoch 24][iter  410] loss: 139830.9062 RMSElog: 9.7552 grad_loss: 13972.3770 normal_loss: 0.9585
[epoch 24][iter  420] loss: 106516.8047 RMSElog: 9.6966 grad_loss: 10641.0557 normal_loss: 0.9285
[epoch 24][iter  430] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 24][iter  440] loss: 137249.3438 RMSElog: 9.7342 grad_loss: 13714.2764 normal_loss: 0.9239
[epoch 24][iter  450] loss: 120745.8203 RMSElog: 9.7706 grad_loss: 12063.8691 normal_loss: 0.9428
[epoch 24][iter  460] loss: 154855.9062 RMSElog: 9.8054 grad_loss: 15474.8340 normal_loss: 0.9510
[epoch 24][iter  470] loss: 145389.9375 RMSElog: 9.8784 grad_loss: 14528.1660 normal_loss: 0.9489
[epoch 24][iter  480] loss: 141118.5312 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.9477
[epoch 24][iter  490] loss: 143440.0000 RMSElog: 9.6404 grad_loss: 14333.4336 normal_loss: 0.9261
[epoch 24][iter  500] loss: 199607.1562 RMSElog: 10.1504 grad_loss: 19949.6133 normal_loss: 0.9517
[epoch 24][iter  510] loss: 150323.7656 RMSElog: 10.0510 grad_loss: 15021.3848 normal_loss: 0.9410
[epoch 24][iter  520] loss: 128277.9766 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.9518
[epoch 24][iter  530] loss: 196677.7812 RMSElog: 10.0486 grad_loss: 19656.7715 normal_loss: 0.9571
[epoch 24][iter  540] loss: 162892.2969 RMSElog: 9.8252 grad_loss: 16278.4717 normal_loss: 0.9331
[epoch 24][iter  550] loss: 172248.5156 RMSElog: 9.5166 grad_loss: 17214.3730 normal_loss: 0.9619
[epoch 24][iter  560] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 24][iter  570] loss: 152517.4844 RMSElog: 9.8233 grad_loss: 15241.0010 normal_loss: 0.9249
[epoch 24][iter  580] loss: 106195.4219 RMSElog: 9.2531 grad_loss: 10609.3711 normal_loss: 0.9179
[epoch 24][iter  590] loss: 136507.7344 RMSElog: 10.0223 grad_loss: 13639.7900 normal_loss: 0.9608
[epoch 25][iter    0] loss: 126821.0234 RMSElog: 10.1398 grad_loss: 12671.0410 normal_loss: 0.9215
[epoch 25][iter   10] loss: 175359.1875 RMSElog: 10.1476 grad_loss: 17524.8125 normal_loss: 0.9571
[epoch 25][iter   20] loss: 105742.0391 RMSElog: 9.7582 grad_loss: 10563.5234 normal_loss: 0.9230
[epoch 25][iter   30] loss: 133464.0312 RMSElog: 9.6242 grad_loss: 13335.8584 normal_loss: 0.9201
[epoch 25][iter   40] loss: 172115.2812 RMSElog: 9.7682 grad_loss: 17200.8242 normal_loss: 0.9358
[epoch 25][iter   50] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch 25][iter   60] loss: 180425.2344 RMSElog: 10.0354 grad_loss: 18031.5332 normal_loss: 0.9552
[epoch 25][iter   70] loss: 133760.0312 RMSElog: 10.0653 grad_loss: 13364.9707 normal_loss: 0.9680
[epoch 25][iter   80] loss: 140333.8125 RMSElog: 9.8261 grad_loss: 14022.6191 normal_loss: 0.9368
[epoch 25][iter   90] loss: 154776.6250 RMSElog: 9.8981 grad_loss: 15466.8438 normal_loss: 0.9209
[epoch 25][iter  100] loss: 157274.4688 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.9461
[epoch 25][iter  110] loss: 121838.3672 RMSElog: 9.7453 grad_loss: 12173.1494 normal_loss: 0.9425
[epoch 25][iter  120] loss: 169013.5312 RMSElog: 9.5880 grad_loss: 16890.8242 normal_loss: 0.9419
[epoch 25][iter  130] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 25][iter  140] loss: 167211.6250 RMSElog: 10.0285 grad_loss: 16710.1777 normal_loss: 0.9542
[epoch 25][iter  150] loss: 144191.5938 RMSElog: 9.6650 grad_loss: 14408.5654 normal_loss: 0.9284
[epoch 25][iter  160] loss: 164597.1094 RMSElog: 9.8631 grad_loss: 16448.8984 normal_loss: 0.9502
[epoch 25][iter  170] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 25][iter  180] loss: 155911.2344 RMSElog: 9.7863 grad_loss: 15580.3965 normal_loss: 0.9403
[epoch 25][iter  190] loss: 105816.5000 RMSElog: 9.4266 grad_loss: 10571.3066 normal_loss: 0.9171
[epoch 25][iter  200] loss: 191559.9688 RMSElog: 9.9749 grad_loss: 19145.0742 normal_loss: 0.9477
[epoch 25][iter  210] loss: 125281.0156 RMSElog: 9.5401 grad_loss: 12517.6484 normal_loss: 0.9128
[epoch 25][iter  220] loss: 214808.7500 RMSElog: 10.1872 grad_loss: 21469.7461 normal_loss: 0.9423
[epoch 25][iter  230] loss: 105828.7812 RMSElog: 10.1032 grad_loss: 10571.8545 normal_loss: 0.9195
[epoch 25][iter  240] loss: 115452.5781 RMSElog: 9.2301 grad_loss: 11535.1230 normal_loss: 0.9042
[epoch 25][iter  250] loss: 232158.2188 RMSElog: 10.1898 grad_loss: 23204.6875 normal_loss: 0.9455
[epoch 25][iter  260] loss: 228053.0312 RMSElog: 10.2288 grad_loss: 22794.1328 normal_loss: 0.9422
[epoch 25][iter  270] loss: 128319.4062 RMSElog: 9.6733 grad_loss: 12821.3389 normal_loss: 0.9287
[epoch 25][iter  280] loss: 164181.7344 RMSElog: 10.0104 grad_loss: 16407.1973 normal_loss: 0.9660
[epoch 25][iter  290] loss: 104086.5234 RMSElog: 9.7787 grad_loss: 10397.9453 normal_loss: 0.9289
[epoch 25][iter  300] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch 25][iter  310] loss: 154855.9062 RMSElog: 9.8054 grad_loss: 15474.8340 normal_loss: 0.9510
[epoch 25][iter  320] loss: 152772.4219 RMSElog: 9.8249 grad_loss: 15266.4736 normal_loss: 0.9438
[epoch 25][iter  330] loss: 151723.8750 RMSElog: 9.9680 grad_loss: 15161.4746 normal_loss: 0.9449
[epoch 25][iter  340] loss: 122386.0234 RMSElog: 9.6688 grad_loss: 12227.9971 normal_loss: 0.9366
[epoch 25][iter  350] loss: 150323.7656 RMSElog: 10.0510 grad_loss: 15021.3848 normal_loss: 0.9410
[epoch 25][iter  360] loss: 104446.5625 RMSElog: 10.1932 grad_loss: 10433.5342 normal_loss: 0.9288
[epoch 25][iter  370] loss: 191825.0781 RMSElog: 10.3012 grad_loss: 19171.2500 normal_loss: 0.9570
[epoch 25][iter  380] loss: 103355.8125 RMSElog: 9.7106 grad_loss: 10324.9453 normal_loss: 0.9244
[epoch 25][iter  390] loss: 155762.3438 RMSElog: 9.8487 grad_loss: 15565.4404 normal_loss: 0.9448
[epoch 25][iter  400] loss: 121916.0000 RMSElog: 9.7464 grad_loss: 12180.9131 normal_loss: 0.9404
[epoch 25][iter  410] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 25][iter  420] loss: 174565.0781 RMSElog: 9.7759 grad_loss: 17445.7832 normal_loss: 0.9484
[epoch 25][iter  430] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 25][iter  440] loss: 156709.9531 RMSElog: 9.8741 grad_loss: 15660.1758 normal_loss: 0.9453
[epoch 25][iter  450] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 25][iter  460] loss: 134677.6719 RMSElog: 9.8776 grad_loss: 13456.9443 normal_loss: 0.9441
[epoch 25][iter  470] loss: 119655.7969 RMSElog: 9.6110 grad_loss: 11955.0312 normal_loss: 0.9378
[epoch 25][iter  480] loss: 162579.5312 RMSElog: 10.1223 grad_loss: 16246.8740 normal_loss: 0.9574
[epoch 25][iter  490] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 25][iter  500] loss: 154626.7656 RMSElog: 9.9098 grad_loss: 15451.8066 normal_loss: 0.9596
[epoch 25][iter  510] loss: 166207.1094 RMSElog: 9.7947 grad_loss: 16609.9668 normal_loss: 0.9492
[epoch 25][iter  520] loss: 176223.4531 RMSElog: 9.9872 grad_loss: 17611.4141 normal_loss: 0.9446
[epoch 25][iter  530] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1230 normal_loss: 0.9462
[epoch 25][iter  540] loss: 226949.5156 RMSElog: 10.2029 grad_loss: 22683.8047 normal_loss: 0.9430
[epoch 25][iter  550] loss: 143460.8594 RMSElog: 9.7520 grad_loss: 14335.3848 normal_loss: 0.9489
[epoch 25][iter  560] loss: 160934.5156 RMSElog: 9.8035 grad_loss: 16082.6846 normal_loss: 0.9629
[epoch 25][iter  570] loss: 167008.4531 RMSElog: 10.0165 grad_loss: 16689.8750 normal_loss: 0.9557
[epoch 25][iter  580] loss: 103798.3281 RMSElog: 9.6193 grad_loss: 10369.2812 normal_loss: 0.9331
[epoch 25][iter  590] loss: 179298.9062 RMSElog: 9.7220 grad_loss: 17919.2227 normal_loss: 0.9453
[epoch 26][iter    0] loss: 227080.5938 RMSElog: 10.4127 grad_loss: 22696.6992 normal_loss: 0.9482
[epoch 26][iter   10] loss: 110874.4688 RMSElog: 9.2829 grad_loss: 11077.2607 normal_loss: 0.9034
[epoch 26][iter   20] loss: 158534.6406 RMSElog: 9.6735 grad_loss: 15842.8672 normal_loss: 0.9232
[epoch 26][iter   30] loss: 164415.3438 RMSElog: 10.0829 grad_loss: 16430.4961 normal_loss: 0.9571
[epoch 26][iter   40] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 26][iter   50] loss: 234945.1719 RMSElog: 10.0015 grad_loss: 23483.5664 normal_loss: 0.9500
[epoch 26][iter   60] loss: 188645.4531 RMSElog: 10.1590 grad_loss: 18853.4082 normal_loss: 0.9794
[epoch 26][iter   70] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 26][iter   80] loss: 167730.9531 RMSElog: 9.9663 grad_loss: 16762.1797 normal_loss: 0.9501
[epoch 26][iter   90] loss: 226949.5156 RMSElog: 10.2029 grad_loss: 22683.8047 normal_loss: 0.9430
[epoch 26][iter  100] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 26][iter  110] loss: 127075.1875 RMSElog: 10.1217 grad_loss: 12696.4443 normal_loss: 0.9524
[epoch 26][iter  120] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 26][iter  130] loss: 150321.2812 RMSElog: 9.9248 grad_loss: 15021.2656 normal_loss: 0.9385
[epoch 26][iter  140] loss: 180318.6719 RMSElog: 9.9530 grad_loss: 18020.9785 normal_loss: 0.9357
[epoch 26][iter  150] loss: 104749.2812 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.9281
[epoch 26][iter  160] loss: 105706.7109 RMSElog: 9.7501 grad_loss: 10559.9893 normal_loss: 0.9321
[epoch 26][iter  170] loss: 163171.1562 RMSElog: 9.7905 grad_loss: 16306.3594 normal_loss: 0.9652
[epoch 26][iter  180] loss: 165326.5625 RMSElog: 9.8832 grad_loss: 16521.8086 normal_loss: 0.9647
[epoch 26][iter  190] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 26][iter  200] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 26][iter  210] loss: 175301.7344 RMSElog: 9.8017 grad_loss: 17519.4180 normal_loss: 0.9555
[epoch 26][iter  220] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 26][iter  230] loss: 137252.6406 RMSElog: 9.3538 grad_loss: 13714.9795 normal_loss: 0.9319
[epoch 26][iter  240] loss: 143460.8594 RMSElog: 9.7520 grad_loss: 14335.3848 normal_loss: 0.9489
[epoch 26][iter  250] loss: 162711.9688 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.9427
[epoch 26][iter  260] loss: 167745.5625 RMSElog: 9.8817 grad_loss: 16763.7129 normal_loss: 0.9621
[epoch 26][iter  270] loss: 184374.1875 RMSElog: 10.2641 grad_loss: 18426.1953 normal_loss: 0.9596
[epoch 26][iter  280] loss: 129163.5156 RMSElog: 9.7674 grad_loss: 12905.6660 normal_loss: 0.9175
[epoch 26][iter  290] loss: 139154.8594 RMSElog: 9.5986 grad_loss: 13904.9707 normal_loss: 0.9164
[epoch 26][iter  300] loss: 109101.1250 RMSElog: 9.7363 grad_loss: 10899.4590 normal_loss: 0.9167
[epoch 26][iter  310] loss: 102998.8984 RMSElog: 9.8140 grad_loss: 10289.1318 normal_loss: 0.9431
[epoch 26][iter  320] loss: 103509.2188 RMSElog: 9.9787 grad_loss: 10340.0186 normal_loss: 0.9251
[epoch 26][iter  330] loss: 212429.2969 RMSElog: 10.2794 grad_loss: 21231.6719 normal_loss: 0.9784
[epoch 26][iter  340] loss: 191371.4375 RMSElog: 10.1918 grad_loss: 19126.0020 normal_loss: 0.9504
[epoch 26][iter  350] loss: 224077.6719 RMSElog: 10.3869 grad_loss: 22396.4219 normal_loss: 0.9584
[epoch 26][iter  360] loss: 156709.9531 RMSElog: 9.8741 grad_loss: 15660.1758 normal_loss: 0.9453
[epoch 26][iter  370] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch 26][iter  380] loss: 214493.2188 RMSElog: 10.3525 grad_loss: 21438.0078 normal_loss: 0.9611
[epoch 26][iter  390] loss: 161285.2188 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.9476
[epoch 26][iter  400] loss: 201162.4062 RMSElog: 9.9531 grad_loss: 20105.3164 normal_loss: 0.9706
[epoch 26][iter  410] loss: 117693.8984 RMSElog: 9.6527 grad_loss: 11758.8105 normal_loss: 0.9267
[epoch 26][iter  420] loss: 188116.2812 RMSElog: 10.0888 grad_loss: 18800.5703 normal_loss: 0.9711
[epoch 26][iter  430] loss: 104086.5234 RMSElog: 9.7787 grad_loss: 10397.9453 normal_loss: 0.9289
[epoch 26][iter  440] loss: 191971.7188 RMSElog: 10.0873 grad_loss: 19186.1172 normal_loss: 0.9662
[epoch 26][iter  450] loss: 111712.9219 RMSElog: 9.7826 grad_loss: 11160.5811 normal_loss: 0.9290
[epoch 26][iter  460] loss: 173339.3750 RMSElog: 9.8230 grad_loss: 17323.1934 normal_loss: 0.9212
[epoch 26][iter  470] loss: 159798.6094 RMSElog: 9.8075 grad_loss: 15969.1260 normal_loss: 0.9263
[epoch 26][iter  480] loss: 121959.7344 RMSElog: 9.7378 grad_loss: 12185.3047 normal_loss: 0.9314
[epoch 26][iter  490] loss: 173086.7031 RMSElog: 10.4992 grad_loss: 17297.2227 normal_loss: 0.9480
[epoch 26][iter  500] loss: 108409.6484 RMSElog: 9.2105 grad_loss: 10830.8506 normal_loss: 0.9033
[epoch 26][iter  510] loss: 160438.2969 RMSElog: 9.9714 grad_loss: 16032.9092 normal_loss: 0.9487
[epoch 26][iter  520] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 26][iter  530] loss: 188502.1875 RMSElog: 10.1669 grad_loss: 18839.0801 normal_loss: 0.9722
[epoch 26][iter  540] loss: 203023.3438 RMSElog: 10.3036 grad_loss: 20291.0723 normal_loss: 0.9583
[epoch 26][iter  550] loss: 177936.2812 RMSElog: 10.0381 grad_loss: 17782.6348 normal_loss: 0.9545
[epoch 26][iter  560] loss: 112697.1016 RMSElog: 9.7295 grad_loss: 11259.0449 normal_loss: 0.9352
[epoch 26][iter  570] loss: 195412.9844 RMSElog: 10.0493 grad_loss: 19530.2969 normal_loss: 0.9539
[epoch 26][iter  580] loss: 142016.3906 RMSElog: 9.9191 grad_loss: 14190.7676 normal_loss: 0.9526
[epoch 26][iter  590] loss: 166093.7344 RMSElog: 10.4480 grad_loss: 16597.9766 normal_loss: 0.9489
[epoch 27][iter    0] loss: 151354.1562 RMSElog: 9.8837 grad_loss: 15124.5889 normal_loss: 0.9428
[epoch 27][iter   10] loss: 129708.8906 RMSElog: 10.0691 grad_loss: 12959.8711 normal_loss: 0.9481
[epoch 27][iter   20] loss: 146960.1250 RMSElog: 10.0979 grad_loss: 14684.9922 normal_loss: 0.9220
[epoch 27][iter   30] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 27][iter   40] loss: 110874.4688 RMSElog: 9.2829 grad_loss: 11077.2607 normal_loss: 0.9034
[epoch 27][iter   50] loss: 117061.6250 RMSElog: 9.2141 grad_loss: 11696.0439 normal_loss: 0.9046
[epoch 27][iter   60] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch 27][iter   70] loss: 122670.8984 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.9331
[epoch 27][iter   80] loss: 129159.4375 RMSElog: 9.6889 grad_loss: 12905.3271 normal_loss: 0.9279
[epoch 27][iter   90] loss: 163268.1250 RMSElog: 9.9218 grad_loss: 16315.9277 normal_loss: 0.9630
[epoch 27][iter  100] loss: 160595.2188 RMSElog: 9.9514 grad_loss: 16048.6191 normal_loss: 0.9518
[epoch 27][iter  110] loss: 203973.6562 RMSElog: 10.4423 grad_loss: 20385.9727 normal_loss: 0.9505
[epoch 27][iter  120] loss: 172966.9375 RMSElog: 9.9430 grad_loss: 17285.8008 normal_loss: 0.9485
[epoch 27][iter  130] loss: 217174.7656 RMSElog: 10.2254 grad_loss: 21706.2891 normal_loss: 0.9635
[epoch 27][iter  140] loss: 87697.6250 RMSElog: 9.9487 grad_loss: 8758.8750 normal_loss: 0.9395
[epoch 27][iter  150] loss: 141118.5312 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.9477
[epoch 27][iter  160] loss: 104749.2812 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.9281
[epoch 27][iter  170] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1230 normal_loss: 0.9462
[epoch 27][iter  180] loss: 135814.7656 RMSElog: 9.5386 grad_loss: 13571.0107 normal_loss: 0.9281
[epoch 27][iter  190] loss: 202630.0781 RMSElog: 10.0417 grad_loss: 20252.0078 normal_loss: 0.9589
[epoch 27][iter  200] loss: 162835.5469 RMSElog: 9.9145 grad_loss: 16272.6914 normal_loss: 0.9492
[epoch 27][iter  210] loss: 156557.3594 RMSElog: 9.6970 grad_loss: 15645.1025 normal_loss: 0.9363
[epoch 27][iter  220] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 27][iter  230] loss: 112715.8125 RMSElog: 9.6867 grad_loss: 11260.9570 normal_loss: 0.9375
[epoch 27][iter  240] loss: 175004.6875 RMSElog: 10.1774 grad_loss: 17489.3340 normal_loss: 0.9561
[epoch 27][iter  250] loss: 127633.3516 RMSElog: 10.0540 grad_loss: 12752.3496 normal_loss: 0.9317
[epoch 27][iter  260] loss: 128277.9766 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.9518
[epoch 27][iter  270] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 27][iter  280] loss: 175547.9062 RMSElog: 10.1409 grad_loss: 17543.7168 normal_loss: 0.9342
[epoch 27][iter  290] loss: 110808.0469 RMSElog: 9.7171 grad_loss: 11070.1562 normal_loss: 0.9312
[epoch 27][iter  300] loss: 165750.3750 RMSElog: 9.8971 grad_loss: 16564.1895 normal_loss: 0.9518
[epoch 27][iter  310] loss: 158534.6406 RMSElog: 9.6735 grad_loss: 15842.8672 normal_loss: 0.9232
[epoch 27][iter  320] loss: 188662.5156 RMSElog: 10.2592 grad_loss: 18855.0352 normal_loss: 0.9574
[epoch 27][iter  330] loss: 148793.9688 RMSElog: 10.1047 grad_loss: 14868.3447 normal_loss: 0.9480
[epoch 27][iter  340] loss: 130145.6250 RMSElog: 9.7206 grad_loss: 13003.9072 normal_loss: 0.9344
[epoch 27][iter  350] loss: 149369.9062 RMSElog: 10.0930 grad_loss: 14925.9756 normal_loss: 0.9225
[epoch 27][iter  360] loss: 122912.0625 RMSElog: 9.7328 grad_loss: 12280.5225 normal_loss: 0.9509
[epoch 27][iter  370] loss: 160024.9375 RMSElog: 9.8489 grad_loss: 15991.7236 normal_loss: 0.9215
[epoch 27][iter  380] loss: 221213.4531 RMSElog: 10.1740 grad_loss: 22110.2305 normal_loss: 0.9415
[epoch 27][iter  390] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 27][iter  400] loss: 178468.8906 RMSElog: 9.9039 grad_loss: 17836.0469 normal_loss: 0.9380
[epoch 27][iter  410] loss: 162433.1875 RMSElog: 9.8183 grad_loss: 16232.5488 normal_loss: 0.9510
[epoch 27][iter  420] loss: 156982.7188 RMSElog: 10.0093 grad_loss: 15687.3193 normal_loss: 0.9438
[epoch 27][iter  430] loss: 105628.3672 RMSElog: 10.0899 grad_loss: 10551.8262 normal_loss: 0.9213
[epoch 27][iter  440] loss: 124932.5703 RMSElog: 9.4215 grad_loss: 12482.8789 normal_loss: 0.9558
[epoch 27][iter  450] loss: 127776.8359 RMSElog: 10.0947 grad_loss: 12766.6396 normal_loss: 0.9490
[epoch 27][iter  460] loss: 185772.2500 RMSElog: 9.9702 grad_loss: 18566.2969 normal_loss: 0.9567
[epoch 27][iter  470] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 27][iter  480] loss: 181983.5312 RMSElog: 10.0741 grad_loss: 18187.3320 normal_loss: 0.9464
[epoch 27][iter  490] loss: 147371.3906 RMSElog: 9.6635 grad_loss: 14726.5488 normal_loss: 0.9280
[epoch 27][iter  500] loss: 214808.7344 RMSElog: 10.1872 grad_loss: 21469.7441 normal_loss: 0.9423
[epoch 27][iter  510] loss: 133045.7969 RMSElog: 9.8765 grad_loss: 13293.7480 normal_loss: 0.9538
[epoch 27][iter  520] loss: 150364.6250 RMSElog: 9.9123 grad_loss: 15025.6094 normal_loss: 0.9418
[epoch 27][iter  530] loss: 128979.7188 RMSElog: 9.7049 grad_loss: 12887.3340 normal_loss: 0.9327
[epoch 27][iter  540] loss: 177292.4062 RMSElog: 10.1195 grad_loss: 17718.1602 normal_loss: 0.9615
[epoch 27][iter  550] loss: 217845.5000 RMSElog: 10.3597 grad_loss: 21773.2148 normal_loss: 0.9774
[epoch 27][iter  560] loss: 180425.2344 RMSElog: 10.0354 grad_loss: 18031.5332 normal_loss: 0.9552
[epoch 27][iter  570] loss: 201503.0625 RMSElog: 10.3149 grad_loss: 20139.0410 normal_loss: 0.9514
[epoch 27][iter  580] loss: 141962.4844 RMSElog: 9.7918 grad_loss: 14185.5273 normal_loss: 0.9289
[epoch 27][iter  590] loss: 114310.3047 RMSElog: 9.4026 grad_loss: 11420.7217 normal_loss: 0.9063
[epoch 28][iter    0] loss: 101101.5781 RMSElog: 9.9274 grad_loss: 10099.3008 normal_loss: 0.9297
[epoch 28][iter   10] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 28][iter   20] loss: 180929.5938 RMSElog: 10.0745 grad_loss: 18081.9297 normal_loss: 0.9546
[epoch 28][iter   30] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 28][iter   40] loss: 139433.9219 RMSElog: 9.8139 grad_loss: 13932.6191 normal_loss: 0.9591
[epoch 28][iter   50] loss: 175008.6562 RMSElog: 9.9496 grad_loss: 17489.9434 normal_loss: 0.9734
[epoch 28][iter   60] loss: 138469.0469 RMSElog: 9.4787 grad_loss: 13836.4834 normal_loss: 0.9438
[epoch 28][iter   70] loss: 142016.3906 RMSElog: 9.9191 grad_loss: 14190.7676 normal_loss: 0.9526
[epoch 28][iter   80] loss: 158034.0625 RMSElog: 9.9527 grad_loss: 15792.5088 normal_loss: 0.9445
[epoch 28][iter   90] loss: 231696.5312 RMSElog: 10.3202 grad_loss: 23158.3867 normal_loss: 0.9457
[epoch 28][iter  100] loss: 163786.3906 RMSElog: 9.7419 grad_loss: 16367.9502 normal_loss: 0.9470
[epoch 28][iter  110] loss: 120440.5938 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.9240
[epoch 28][iter  120] loss: 139830.9062 RMSElog: 9.7552 grad_loss: 13972.3770 normal_loss: 0.9585
[epoch 28][iter  130] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 28][iter  140] loss: 156173.3594 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.9482
[epoch 28][iter  150] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 28][iter  160] loss: 161285.2188 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.9476
[epoch 28][iter  170] loss: 157119.7500 RMSElog: 9.8959 grad_loss: 15701.1318 normal_loss: 0.9480
[epoch 28][iter  180] loss: 170056.2812 RMSElog: 9.7423 grad_loss: 16994.9395 normal_loss: 0.9472
[epoch 28][iter  190] loss: 114149.3672 RMSElog: 9.2655 grad_loss: 11404.7637 normal_loss: 0.9073
[epoch 28][iter  200] loss: 128488.4375 RMSElog: 9.7402 grad_loss: 12838.1719 normal_loss: 0.9319
[epoch 28][iter  210] loss: 162363.8906 RMSElog: 9.7464 grad_loss: 16225.6777 normal_loss: 0.9661
[epoch 28][iter  220] loss: 124563.3672 RMSElog: 9.9514 grad_loss: 12445.4453 normal_loss: 0.9400
[epoch 28][iter  230] loss: 129743.7969 RMSElog: 9.9523 grad_loss: 12963.4785 normal_loss: 0.9492
[epoch 28][iter  240] loss: 148793.9688 RMSElog: 10.1047 grad_loss: 14868.3447 normal_loss: 0.9480
[epoch 28][iter  250] loss: 150459.7656 RMSElog: 9.9429 grad_loss: 15035.0986 normal_loss: 0.9347
[epoch 28][iter  260] loss: 105794.8906 RMSElog: 9.7676 grad_loss: 10568.7949 normal_loss: 0.9267
[epoch 28][iter  270] loss: 155762.3594 RMSElog: 9.8487 grad_loss: 15565.4414 normal_loss: 0.9448
[epoch 28][iter  280] loss: 116582.6250 RMSElog: 9.7871 grad_loss: 11647.5439 normal_loss: 0.9314
[epoch 28][iter  290] loss: 177814.3125 RMSElog: 10.0854 grad_loss: 17770.3887 normal_loss: 0.9571
[epoch 28][iter  300] loss: 133024.8594 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.9261
[epoch 28][iter  310] loss: 211925.8438 RMSElog: 10.1863 grad_loss: 21181.4551 normal_loss: 0.9436
[epoch 28][iter  320] loss: 178784.0938 RMSElog: 9.9460 grad_loss: 17867.5059 normal_loss: 0.9592
[epoch 28][iter  330] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 28][iter  340] loss: 174629.2812 RMSElog: 9.9405 grad_loss: 17452.0625 normal_loss: 0.9229
[epoch 28][iter  350] loss: 145409.6719 RMSElog: 9.8330 grad_loss: 14530.1904 normal_loss: 0.9445
[epoch 28][iter  360] loss: 153501.7031 RMSElog: 10.1127 grad_loss: 15339.1152 normal_loss: 0.9429
[epoch 28][iter  370] loss: 228053.0312 RMSElog: 10.2288 grad_loss: 22794.1328 normal_loss: 0.9422
[epoch 28][iter  380] loss: 195507.4062 RMSElog: 10.1854 grad_loss: 19539.6016 normal_loss: 0.9533
[epoch 28][iter  390] loss: 137764.4219 RMSElog: 9.8227 grad_loss: 13765.6758 normal_loss: 0.9442
[epoch 28][iter  400] loss: 156253.7656 RMSElog: 9.8231 grad_loss: 15614.6211 normal_loss: 0.9316
[epoch 28][iter  410] loss: 197520.7500 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.9662
[epoch 28][iter  420] loss: 104749.2812 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.9281
[epoch 28][iter  430] loss: 160051.0156 RMSElog: 9.8405 grad_loss: 15994.3105 normal_loss: 0.9506
[epoch 28][iter  440] loss: 131942.8750 RMSElog: 9.8414 grad_loss: 13183.5000 normal_loss: 0.9453
[epoch 28][iter  450] loss: 220695.7969 RMSElog: 10.2208 grad_loss: 22058.4082 normal_loss: 0.9520
[epoch 28][iter  460] loss: 132707.3594 RMSElog: 9.7842 grad_loss: 13260.0049 normal_loss: 0.9472
[epoch 28][iter  470] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 28][iter  480] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 28][iter  490] loss: 181465.8125 RMSElog: 10.1136 grad_loss: 18135.5117 normal_loss: 0.9572
[epoch 28][iter  500] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 28][iter  510] loss: 125683.7969 RMSElog: 9.8131 grad_loss: 12557.6123 normal_loss: 0.9537
[epoch 28][iter  520] loss: 212239.7031 RMSElog: 10.2690 grad_loss: 21212.7383 normal_loss: 0.9638
[epoch 28][iter  530] loss: 135814.7656 RMSElog: 9.5386 grad_loss: 13571.0107 normal_loss: 0.9281
[epoch 28][iter  540] loss: 196277.7188 RMSElog: 10.2453 grad_loss: 19616.5664 normal_loss: 0.9595
[epoch 28][iter  550] loss: 182476.7344 RMSElog: 9.9672 grad_loss: 18236.7656 normal_loss: 0.9407
[epoch 28][iter  560] loss: 177292.4062 RMSElog: 10.1195 grad_loss: 17718.1602 normal_loss: 0.9615
[epoch 28][iter  570] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 28][iter  580] loss: 132012.6719 RMSElog: 9.6802 grad_loss: 13190.6582 normal_loss: 0.9291
[epoch 28][iter  590] loss: 136869.7500 RMSElog: 9.5771 grad_loss: 13676.4668 normal_loss: 0.9315
[epoch 29][iter    0] loss: 165976.7500 RMSElog: 9.9385 grad_loss: 16586.7715 normal_loss: 0.9645
[epoch 29][iter   10] loss: 164766.2812 RMSElog: 9.6928 grad_loss: 16465.9941 normal_loss: 0.9411
[epoch 29][iter   20] loss: 100650.2734 RMSElog: 9.7441 grad_loss: 10054.3555 normal_loss: 0.9279
[epoch 29][iter   30] loss: 195777.0156 RMSElog: 10.1280 grad_loss: 19566.5996 normal_loss: 0.9726
[epoch 29][iter   40] loss: 100663.8984 RMSElog: 9.9598 grad_loss: 10055.5020 normal_loss: 0.9277
[epoch 29][iter   50] loss: 214067.1875 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.9394
[epoch 29][iter   60] loss: 116582.6172 RMSElog: 9.7871 grad_loss: 11647.5430 normal_loss: 0.9314
[epoch 29][iter   70] loss: 103514.7812 RMSElog: 9.3451 grad_loss: 10341.2109 normal_loss: 0.9229
[epoch 29][iter   80] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 29][iter   90] loss: 146576.9219 RMSElog: 9.6520 grad_loss: 14647.1045 normal_loss: 0.9356
[epoch 29][iter  100] loss: 167784.2500 RMSElog: 9.9330 grad_loss: 16767.5391 normal_loss: 0.9539
[epoch 29][iter  110] loss: 167745.5625 RMSElog: 9.8817 grad_loss: 16763.7129 normal_loss: 0.9621
[epoch 29][iter  120] loss: 217914.6094 RMSElog: 10.2786 grad_loss: 21780.2246 normal_loss: 0.9575
[epoch 29][iter  130] loss: 131942.8750 RMSElog: 9.8414 grad_loss: 13183.5000 normal_loss: 0.9453
[epoch 29][iter  140] loss: 125315.5625 RMSElog: 9.7124 grad_loss: 12520.9131 normal_loss: 0.9309
[epoch 29][iter  150] loss: 208821.7812 RMSElog: 10.1565 grad_loss: 20871.0781 normal_loss: 0.9431
[epoch 29][iter  160] loss: 150323.7656 RMSElog: 10.0510 grad_loss: 15021.3848 normal_loss: 0.9410
[epoch 29][iter  170] loss: 129163.5156 RMSElog: 9.7674 grad_loss: 12905.6660 normal_loss: 0.9175
[epoch 29][iter  180] loss: 202630.0781 RMSElog: 10.0417 grad_loss: 20252.0078 normal_loss: 0.9589
[epoch 29][iter  190] loss: 100116.4922 RMSElog: 9.9235 grad_loss: 10000.7998 normal_loss: 0.9258
[epoch 29][iter  200] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 29][iter  210] loss: 114827.1016 RMSElog: 9.7767 grad_loss: 11472.0010 normal_loss: 0.9329
[epoch 29][iter  220] loss: 194578.5781 RMSElog: 10.2312 grad_loss: 19446.6680 normal_loss: 0.9596
[epoch 29][iter  230] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 29][iter  240] loss: 147598.9844 RMSElog: 9.8981 grad_loss: 14749.0645 normal_loss: 0.9355
[epoch 29][iter  250] loss: 123525.9062 RMSElog: 9.3524 grad_loss: 12342.2930 normal_loss: 0.9450
[epoch 29][iter  260] loss: 141865.3906 RMSElog: 9.7199 grad_loss: 14175.8896 normal_loss: 0.9298
[epoch 29][iter  270] loss: 171588.0938 RMSElog: 9.8325 grad_loss: 17148.0527 normal_loss: 0.9237
[epoch 29][iter  280] loss: 141962.4844 RMSElog: 9.7918 grad_loss: 14185.5273 normal_loss: 0.9289
[epoch 29][iter  290] loss: 220695.7969 RMSElog: 10.2208 grad_loss: 22058.4082 normal_loss: 0.9520
[epoch 29][iter  300] loss: 196277.7188 RMSElog: 10.2453 grad_loss: 19616.5664 normal_loss: 0.9595
[epoch 29][iter  310] loss: 190972.3281 RMSElog: 10.1152 grad_loss: 19086.1523 normal_loss: 0.9647
[epoch 29][iter  320] loss: 127499.3281 RMSElog: 9.2769 grad_loss: 12739.7178 normal_loss: 0.9374
[epoch 29][iter  330] loss: 191559.9688 RMSElog: 9.9749 grad_loss: 19145.0742 normal_loss: 0.9477
[epoch 29][iter  340] loss: 106182.2188 RMSElog: 9.7575 grad_loss: 10607.5342 normal_loss: 0.9294
[epoch 29][iter  350] loss: 109441.5234 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.9300
[epoch 29][iter  360] loss: 159422.2656 RMSElog: 9.7010 grad_loss: 15931.5957 normal_loss: 0.9299
[epoch 29][iter  370] loss: 151354.1562 RMSElog: 9.8837 grad_loss: 15124.5889 normal_loss: 0.9428
[epoch 29][iter  380] loss: 177664.5312 RMSElog: 9.7808 grad_loss: 17755.7344 normal_loss: 0.9369
[epoch 29][iter  390] loss: 104340.6328 RMSElog: 9.7692 grad_loss: 10423.3701 normal_loss: 0.9234
[epoch 29][iter  400] loss: 213401.8906 RMSElog: 10.0568 grad_loss: 21329.1582 normal_loss: 0.9749
[epoch 29][iter  410] loss: 120745.8203 RMSElog: 9.7706 grad_loss: 12063.8691 normal_loss: 0.9428
[epoch 29][iter  420] loss: 134471.5781 RMSElog: 9.9200 grad_loss: 13436.3271 normal_loss: 0.9111
[epoch 29][iter  430] loss: 133024.8594 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.9261
[epoch 29][iter  440] loss: 109260.8906 RMSElog: 9.7819 grad_loss: 10915.3789 normal_loss: 0.9279
[epoch 29][iter  450] loss: 115766.5312 RMSElog: 9.7467 grad_loss: 11565.9717 normal_loss: 0.9344
[epoch 29][iter  460] loss: 114893.3984 RMSElog: 9.2562 grad_loss: 11479.1777 normal_loss: 0.9067
[epoch 29][iter  470] loss: 132623.8750 RMSElog: 9.3325 grad_loss: 13252.1152 normal_loss: 0.9391
[epoch 29][iter  480] loss: 160788.1406 RMSElog: 9.7539 grad_loss: 16068.1289 normal_loss: 0.9318
[epoch 29][iter  490] loss: 122386.0234 RMSElog: 9.6688 grad_loss: 12227.9971 normal_loss: 0.9366
[epoch 29][iter  500] loss: 169013.5312 RMSElog: 9.5880 grad_loss: 16890.8242 normal_loss: 0.9419
[epoch 29][iter  510] loss: 232771.8594 RMSElog: 10.2938 grad_loss: 23265.9453 normal_loss: 0.9464
[epoch 29][iter  520] loss: 151401.7031 RMSElog: 9.4414 grad_loss: 15129.7930 normal_loss: 0.9361
[epoch 29][iter  530] loss: 164415.3438 RMSElog: 10.0829 grad_loss: 16430.4961 normal_loss: 0.9571
[epoch 29][iter  540] loss: 194987.6250 RMSElog: 9.8416 grad_loss: 19487.9453 normal_loss: 0.9748
[epoch 29][iter  550] loss: 152562.3750 RMSElog: 9.8216 grad_loss: 15245.4775 normal_loss: 0.9391
[epoch 29][iter  560] loss: 175547.8906 RMSElog: 10.1409 grad_loss: 17543.7148 normal_loss: 0.9342
[epoch 29][iter  570] loss: 163253.2500 RMSElog: 9.8740 grad_loss: 16314.5010 normal_loss: 0.9499
[epoch 29][iter  580] loss: 109101.1250 RMSElog: 9.7363 grad_loss: 10899.4590 normal_loss: 0.9167
[epoch 29][iter  590] loss: 116073.6016 RMSElog: 9.6844 grad_loss: 11596.7334 normal_loss: 0.9429
[epoch 30][iter    0] loss: 141118.5312 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.9477
[epoch 30][iter   10] loss: 212429.2969 RMSElog: 10.2794 grad_loss: 21231.6719 normal_loss: 0.9784
[epoch 30][iter   20] loss: 196437.7969 RMSElog: 10.2319 grad_loss: 19632.5879 normal_loss: 0.9584
[epoch 30][iter   30] loss: 164597.1094 RMSElog: 9.8631 grad_loss: 16448.8984 normal_loss: 0.9502
[epoch 30][iter   40] loss: 165648.1875 RMSElog: 9.7420 grad_loss: 16554.1289 normal_loss: 0.9479
[epoch 30][iter   50] loss: 188502.1875 RMSElog: 10.1669 grad_loss: 18839.0801 normal_loss: 0.9722
[epoch 30][iter   60] loss: 213401.8906 RMSElog: 10.0568 grad_loss: 21329.1582 normal_loss: 0.9749
[epoch 30][iter   70] loss: 147765.9219 RMSElog: 10.0607 grad_loss: 14765.6104 normal_loss: 0.9219
[epoch 30][iter   80] loss: 159798.6094 RMSElog: 9.8075 grad_loss: 15969.1260 normal_loss: 0.9263
[epoch 30][iter   90] loss: 198293.9375 RMSElog: 10.2275 grad_loss: 19818.2168 normal_loss: 0.9521
[epoch 30][iter  100] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 30][iter  110] loss: 157061.8906 RMSElog: 9.9892 grad_loss: 15695.2461 normal_loss: 0.9531
[epoch 30][iter  120] loss: 160074.2031 RMSElog: 9.7506 grad_loss: 15996.7441 normal_loss: 0.9257
[epoch 30][iter  130] loss: 171588.0938 RMSElog: 9.8325 grad_loss: 17148.0527 normal_loss: 0.9237
[epoch 30][iter  140] loss: 133760.0312 RMSElog: 10.0653 grad_loss: 13364.9707 normal_loss: 0.9680
[epoch 30][iter  150] loss: 182005.7031 RMSElog: 10.0998 grad_loss: 18189.5195 normal_loss: 0.9507
[epoch 30][iter  160] loss: 204037.7500 RMSElog: 10.1754 grad_loss: 20392.6582 normal_loss: 0.9420
[epoch 30][iter  170] loss: 154029.7812 RMSElog: 9.8645 grad_loss: 15392.1729 normal_loss: 0.9405
[epoch 30][iter  180] loss: 188662.5156 RMSElog: 10.2592 grad_loss: 18855.0352 normal_loss: 0.9574
[epoch 30][iter  190] loss: 179634.8125 RMSElog: 10.0930 grad_loss: 17952.4258 normal_loss: 0.9607
[epoch 30][iter  200] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch 30][iter  210] loss: 107956.6094 RMSElog: 10.0900 grad_loss: 10784.6504 normal_loss: 0.9209
[epoch 30][iter  220] loss: 115452.5781 RMSElog: 9.2301 grad_loss: 11535.1230 normal_loss: 0.9042
[epoch 30][iter  230] loss: 136869.7500 RMSElog: 9.5771 grad_loss: 13676.4668 normal_loss: 0.9315
[epoch 30][iter  240] loss: 135699.4688 RMSElog: 9.6754 grad_loss: 13559.3340 normal_loss: 0.9364
[epoch 30][iter  250] loss: 152562.3906 RMSElog: 9.8216 grad_loss: 15245.4785 normal_loss: 0.9391
[epoch 30][iter  260] loss: 198743.4219 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.9643
[epoch 30][iter  270] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 30][iter  280] loss: 164181.7344 RMSElog: 10.0104 grad_loss: 16407.1973 normal_loss: 0.9660
[epoch 30][iter  290] loss: 151401.7031 RMSElog: 9.4414 grad_loss: 15129.7930 normal_loss: 0.9361
[epoch 30][iter  300] loss: 175004.6875 RMSElog: 10.1774 grad_loss: 17489.3340 normal_loss: 0.9561
[epoch 30][iter  310] loss: 162835.5312 RMSElog: 9.9145 grad_loss: 16272.6904 normal_loss: 0.9492
[epoch 30][iter  320] loss: 218625.8750 RMSElog: 10.2839 grad_loss: 21851.3457 normal_loss: 0.9592
[epoch 30][iter  330] loss: 173721.0156 RMSElog: 10.0355 grad_loss: 17361.1191 normal_loss: 0.9468
[epoch 30][iter  340] loss: 161285.2188 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.9476
[epoch 30][iter  350] loss: 112715.8125 RMSElog: 9.6867 grad_loss: 11260.9570 normal_loss: 0.9375
[epoch 30][iter  360] loss: 142544.5156 RMSElog: 10.1645 grad_loss: 14243.3457 normal_loss: 0.9425
[epoch 30][iter  370] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 30][iter  380] loss: 184374.2188 RMSElog: 10.2641 grad_loss: 18426.1992 normal_loss: 0.9596
[epoch 30][iter  390] loss: 158534.6406 RMSElog: 9.6735 grad_loss: 15842.8672 normal_loss: 0.9232
[epoch 30][iter  400] loss: 195412.9844 RMSElog: 10.0493 grad_loss: 19530.2969 normal_loss: 0.9539
[epoch 30][iter  410] loss: 105098.6875 RMSElog: 9.7426 grad_loss: 10499.2012 normal_loss: 0.9257
[epoch 30][iter  420] loss: 173574.0781 RMSElog: 10.1780 grad_loss: 17346.2734 normal_loss: 0.9575
[epoch 30][iter  430] loss: 165326.5625 RMSElog: 9.8832 grad_loss: 16521.8086 normal_loss: 0.9647
[epoch 30][iter  440] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 30][iter  450] loss: 154609.8281 RMSElog: 9.8745 grad_loss: 15450.1855 normal_loss: 0.9220
[epoch 30][iter  460] loss: 175002.7344 RMSElog: 9.8652 grad_loss: 17489.4648 normal_loss: 0.9436
[epoch 30][iter  470] loss: 239768.0938 RMSElog: 10.2366 grad_loss: 23965.6250 normal_loss: 0.9466
[epoch 30][iter  480] loss: 128319.4141 RMSElog: 9.6733 grad_loss: 12821.3398 normal_loss: 0.9287
[epoch 30][iter  490] loss: 229081.3125 RMSElog: 10.2778 grad_loss: 22896.9121 normal_loss: 0.9420
[epoch 30][iter  500] loss: 160788.1406 RMSElog: 9.7539 grad_loss: 16068.1289 normal_loss: 0.9318
[epoch 30][iter  510] loss: 130641.2188 RMSElog: 9.7184 grad_loss: 13053.4688 normal_loss: 0.9344
[epoch 30][iter  520] loss: 143440.0000 RMSElog: 9.6404 grad_loss: 14333.4336 normal_loss: 0.9261
[epoch 30][iter  530] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 30][iter  540] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 30][iter  550] loss: 164415.3438 RMSElog: 10.0829 grad_loss: 16430.4961 normal_loss: 0.9571
[epoch 30][iter  560] loss: 206764.1875 RMSElog: 10.2849 grad_loss: 20665.1777 normal_loss: 0.9549
[epoch 30][iter  570] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch 30][iter  580] loss: 149135.0000 RMSElog: 10.0932 grad_loss: 14902.4570 normal_loss: 0.9500
[epoch 30][iter  590] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 31][iter    0] loss: 127633.3516 RMSElog: 10.0540 grad_loss: 12752.3496 normal_loss: 0.9317
[epoch 31][iter   10] loss: 163272.7188 RMSElog: 10.0261 grad_loss: 16316.3047 normal_loss: 0.9400
[epoch 31][iter   20] loss: 139016.5781 RMSElog: 9.6276 grad_loss: 13891.1045 normal_loss: 0.9261
[epoch 31][iter   30] loss: 180663.0469 RMSElog: 10.2319 grad_loss: 18055.1094 normal_loss: 0.9630
[epoch 31][iter   40] loss: 152332.5469 RMSElog: 9.9813 grad_loss: 15222.3486 normal_loss: 0.9245
[epoch 31][iter   50] loss: 116582.6172 RMSElog: 9.7871 grad_loss: 11647.5430 normal_loss: 0.9314
[epoch 31][iter   60] loss: 114827.1016 RMSElog: 9.7767 grad_loss: 11472.0010 normal_loss: 0.9329
[epoch 31][iter   70] loss: 146465.6875 RMSElog: 10.2283 grad_loss: 14635.4062 normal_loss: 0.9337
[epoch 31][iter   80] loss: 177814.3125 RMSElog: 10.0854 grad_loss: 17770.3887 normal_loss: 0.9571
[epoch 31][iter   90] loss: 153723.9844 RMSElog: 9.9609 grad_loss: 15361.4902 normal_loss: 0.9475
[epoch 31][iter  100] loss: 160595.2188 RMSElog: 9.9514 grad_loss: 16048.6191 normal_loss: 0.9518
[epoch 31][iter  110] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 31][iter  120] loss: 146161.1562 RMSElog: 10.0682 grad_loss: 14605.1279 normal_loss: 0.9190
[epoch 31][iter  130] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 31][iter  140] loss: 221213.4219 RMSElog: 10.1740 grad_loss: 22110.2266 normal_loss: 0.9415
[epoch 31][iter  150] loss: 158534.6406 RMSElog: 9.6735 grad_loss: 15842.8672 normal_loss: 0.9232
[epoch 31][iter  160] loss: 177292.4062 RMSElog: 10.1195 grad_loss: 17718.1602 normal_loss: 0.9615
[epoch 31][iter  170] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 31][iter  180] loss: 148057.2500 RMSElog: 9.9895 grad_loss: 14794.7812 normal_loss: 0.9555
[epoch 31][iter  190] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 31][iter  200] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 31][iter  210] loss: 142261.5781 RMSElog: 9.7627 grad_loss: 14215.4639 normal_loss: 0.9304
[epoch 31][iter  220] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 31][iter  230] loss: 229081.3125 RMSElog: 10.2778 grad_loss: 22896.9121 normal_loss: 0.9420
[epoch 31][iter  240] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 31][iter  250] loss: 175486.0156 RMSElog: 10.0393 grad_loss: 17537.6055 normal_loss: 0.9563
[epoch 31][iter  260] loss: 172248.5156 RMSElog: 9.5166 grad_loss: 17214.3730 normal_loss: 0.9619
[epoch 31][iter  270] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch 31][iter  280] loss: 170488.4688 RMSElog: 9.7164 grad_loss: 17038.1816 normal_loss: 0.9494
[epoch 31][iter  290] loss: 181293.3438 RMSElog: 10.0009 grad_loss: 18118.3809 normal_loss: 0.9531
[epoch 31][iter  300] loss: 103815.4375 RMSElog: 9.7764 grad_loss: 10370.8340 normal_loss: 0.9338
[epoch 31][iter  310] loss: 160788.1562 RMSElog: 9.7539 grad_loss: 16068.1299 normal_loss: 0.9318
[epoch 31][iter  320] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 31][iter  330] loss: 211925.8438 RMSElog: 10.1863 grad_loss: 21181.4551 normal_loss: 0.9436
[epoch 31][iter  340] loss: 232771.8594 RMSElog: 10.2938 grad_loss: 23265.9453 normal_loss: 0.9464
[epoch 31][iter  350] loss: 212239.7031 RMSElog: 10.2690 grad_loss: 21212.7383 normal_loss: 0.9638
[epoch 31][iter  360] loss: 135215.1250 RMSElog: 9.9407 grad_loss: 13510.6152 normal_loss: 0.9572
[epoch 31][iter  370] loss: 153501.7031 RMSElog: 10.1127 grad_loss: 15339.1152 normal_loss: 0.9429
[epoch 31][iter  380] loss: 129743.7969 RMSElog: 9.9523 grad_loss: 12963.4785 normal_loss: 0.9492
[epoch 31][iter  390] loss: 130641.2188 RMSElog: 9.7184 grad_loss: 13053.4688 normal_loss: 0.9344
[epoch 31][iter  400] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 31][iter  410] loss: 104340.6328 RMSElog: 9.7692 grad_loss: 10423.3701 normal_loss: 0.9234
[epoch 31][iter  420] loss: 215955.5625 RMSElog: 10.2675 grad_loss: 21584.3242 normal_loss: 0.9654
[epoch 31][iter  430] loss: 149540.3750 RMSElog: 9.7408 grad_loss: 14943.3740 normal_loss: 0.9229
[epoch 31][iter  440] loss: 114149.3750 RMSElog: 9.2655 grad_loss: 11404.7646 normal_loss: 0.9073
[epoch 31][iter  450] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 31][iter  460] loss: 160024.9375 RMSElog: 9.8489 grad_loss: 15991.7236 normal_loss: 0.9215
[epoch 31][iter  470] loss: 191371.4375 RMSElog: 10.1918 grad_loss: 19126.0020 normal_loss: 0.9504
[epoch 31][iter  480] loss: 149369.9062 RMSElog: 10.0930 grad_loss: 14925.9756 normal_loss: 0.9225
[epoch 31][iter  490] loss: 164766.2812 RMSElog: 9.6928 grad_loss: 16465.9941 normal_loss: 0.9411
[epoch 31][iter  500] loss: 96006.2500 RMSElog: 9.5560 grad_loss: 9590.1396 normal_loss: 0.9294
[epoch 31][iter  510] loss: 165306.9531 RMSElog: 9.8881 grad_loss: 16519.8438 normal_loss: 0.9638
[epoch 31][iter  520] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 31][iter  530] loss: 132425.4375 RMSElog: 10.0155 grad_loss: 13231.5801 normal_loss: 0.9468
[epoch 31][iter  540] loss: 175301.7344 RMSElog: 9.8017 grad_loss: 17519.4180 normal_loss: 0.9555
[epoch 31][iter  550] loss: 163389.5469 RMSElog: 9.7702 grad_loss: 16328.2637 normal_loss: 0.9208
[epoch 31][iter  560] loss: 131213.2969 RMSElog: 9.6860 grad_loss: 13110.7217 normal_loss: 0.9217
[epoch 31][iter  570] loss: 188645.4531 RMSElog: 10.1590 grad_loss: 18853.4082 normal_loss: 0.9794
[epoch 31][iter  580] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 31][iter  590] loss: 142544.6875 RMSElog: 10.2185 grad_loss: 14243.3018 normal_loss: 0.9486
[epoch 32][iter    0] loss: 131213.2969 RMSElog: 9.6860 grad_loss: 13110.7217 normal_loss: 0.9217
[epoch 32][iter   10] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 32][iter   20] loss: 143460.8594 RMSElog: 9.7520 grad_loss: 14335.3848 normal_loss: 0.9489
[epoch 32][iter   30] loss: 95221.2109 RMSElog: 9.1894 grad_loss: 9512.0205 normal_loss: 0.9115
[epoch 32][iter   40] loss: 180929.5938 RMSElog: 10.0745 grad_loss: 18081.9297 normal_loss: 0.9546
[epoch 32][iter   50] loss: 96006.2500 RMSElog: 9.5560 grad_loss: 9590.1396 normal_loss: 0.9294
[epoch 32][iter   60] loss: 105877.8750 RMSElog: 9.7638 grad_loss: 10577.0986 normal_loss: 0.9249
[epoch 32][iter   70] loss: 122446.5469 RMSElog: 9.6438 grad_loss: 12234.0742 normal_loss: 0.9366
[epoch 32][iter   80] loss: 162363.8906 RMSElog: 9.7464 grad_loss: 16225.6777 normal_loss: 0.9661
[epoch 32][iter   90] loss: 135966.2969 RMSElog: 9.6504 grad_loss: 13586.0273 normal_loss: 0.9522
[epoch 32][iter  100] loss: 104749.2812 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.9281
[epoch 32][iter  110] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 32][iter  120] loss: 103798.3281 RMSElog: 9.6193 grad_loss: 10369.2812 normal_loss: 0.9331
[epoch 32][iter  130] loss: 107073.5156 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.9313
[epoch 32][iter  140] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 32][iter  150] loss: 147371.3906 RMSElog: 9.6635 grad_loss: 14726.5488 normal_loss: 0.9280
[epoch 32][iter  160] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 32][iter  170] loss: 175002.7344 RMSElog: 9.8652 grad_loss: 17489.4648 normal_loss: 0.9436
[epoch 32][iter  180] loss: 115766.5312 RMSElog: 9.7467 grad_loss: 11565.9717 normal_loss: 0.9344
[epoch 32][iter  190] loss: 196842.3125 RMSElog: 10.1249 grad_loss: 19673.1523 normal_loss: 0.9534
[epoch 32][iter  200] loss: 120765.1875 RMSElog: 9.5441 grad_loss: 12066.0400 normal_loss: 0.9348
[epoch 32][iter  210] loss: 135814.7969 RMSElog: 9.5386 grad_loss: 13571.0137 normal_loss: 0.9281
[epoch 32][iter  220] loss: 196025.7031 RMSElog: 10.2650 grad_loss: 19591.3496 normal_loss: 0.9559
[epoch 32][iter  230] loss: 186053.2812 RMSElog: 10.1470 grad_loss: 18594.2305 normal_loss: 0.9504
[epoch 32][iter  240] loss: 162835.5469 RMSElog: 9.9145 grad_loss: 16272.6914 normal_loss: 0.9492
[epoch 32][iter  250] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 32][iter  260] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 32][iter  270] loss: 177195.4844 RMSElog: 10.1516 grad_loss: 17708.4512 normal_loss: 0.9458
[epoch 32][iter  280] loss: 177292.4062 RMSElog: 10.1195 grad_loss: 17718.1602 normal_loss: 0.9615
[epoch 32][iter  290] loss: 156253.7656 RMSElog: 9.8231 grad_loss: 15614.6211 normal_loss: 0.9316
[epoch 32][iter  300] loss: 162433.1875 RMSElog: 9.8183 grad_loss: 16232.5488 normal_loss: 0.9510
[epoch 32][iter  310] loss: 164597.1094 RMSElog: 9.8631 grad_loss: 16448.8984 normal_loss: 0.9502
[epoch 32][iter  320] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 32][iter  330] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 32][iter  340] loss: 174375.6875 RMSElog: 10.0512 grad_loss: 17426.5684 normal_loss: 0.9483
[epoch 32][iter  350] loss: 144589.9531 RMSElog: 9.7438 grad_loss: 14448.3340 normal_loss: 0.9167
[epoch 32][iter  360] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 32][iter  370] loss: 177699.9688 RMSElog: 9.4851 grad_loss: 17759.5488 normal_loss: 0.9621
[epoch 32][iter  380] loss: 111914.6250 RMSElog: 9.3004 grad_loss: 11181.2402 normal_loss: 0.9218
[epoch 32][iter  390] loss: 155762.3438 RMSElog: 9.8487 grad_loss: 15565.4404 normal_loss: 0.9448
[epoch 32][iter  400] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 32][iter  410] loss: 133013.4531 RMSElog: 9.5635 grad_loss: 13290.8457 normal_loss: 0.9356
[epoch 32][iter  420] loss: 159340.4375 RMSElog: 9.9507 grad_loss: 15923.1426 normal_loss: 0.9500
[epoch 32][iter  430] loss: 128979.7266 RMSElog: 9.7049 grad_loss: 12887.3350 normal_loss: 0.9327
[epoch 32][iter  440] loss: 182318.8125 RMSElog: 10.1008 grad_loss: 18220.8418 normal_loss: 0.9384
[epoch 32][iter  450] loss: 142696.6875 RMSElog: 9.9612 grad_loss: 14258.7588 normal_loss: 0.9493
[epoch 32][iter  460] loss: 218757.0312 RMSElog: 10.1228 grad_loss: 21864.6270 normal_loss: 0.9524
[epoch 32][iter  470] loss: 204650.3281 RMSElog: 10.1934 grad_loss: 20453.8633 normal_loss: 0.9762
[epoch 32][iter  480] loss: 139098.6406 RMSElog: 9.8619 grad_loss: 13899.0508 normal_loss: 0.9510
[epoch 32][iter  490] loss: 216232.0312 RMSElog: 10.2147 grad_loss: 21612.0234 normal_loss: 0.9640
[epoch 32][iter  500] loss: 115348.2734 RMSElog: 9.7235 grad_loss: 11524.1562 normal_loss: 0.9470
[epoch 32][iter  510] loss: 120292.3359 RMSElog: 9.8042 grad_loss: 12018.4854 normal_loss: 0.9430
[epoch 32][iter  520] loss: 131434.0312 RMSElog: 9.5911 grad_loss: 13132.8770 normal_loss: 0.9360
[epoch 32][iter  530] loss: 104340.6328 RMSElog: 9.7692 grad_loss: 10423.3701 normal_loss: 0.9234
[epoch 32][iter  540] loss: 161646.4688 RMSElog: 10.1105 grad_loss: 16153.5762 normal_loss: 0.9608
[epoch 32][iter  550] loss: 174761.2344 RMSElog: 9.7333 grad_loss: 17465.4512 normal_loss: 0.9393
[epoch 32][iter  560] loss: 138057.5156 RMSElog: 9.5188 grad_loss: 13795.3184 normal_loss: 0.9138
[epoch 32][iter  570] loss: 120440.5938 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.9240
[epoch 32][iter  580] loss: 128319.4141 RMSElog: 9.6733 grad_loss: 12821.3398 normal_loss: 0.9287
[epoch 32][iter  590] loss: 191825.0781 RMSElog: 10.3012 grad_loss: 19171.2500 normal_loss: 0.9570
[epoch 33][iter    0] loss: 189017.5781 RMSElog: 10.1390 grad_loss: 18890.6602 normal_loss: 0.9589
[epoch 33][iter   10] loss: 149128.2188 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.9419
[epoch 33][iter   20] loss: 113921.7969 RMSElog: 9.7251 grad_loss: 11381.5195 normal_loss: 0.9357
[epoch 33][iter   30] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 33][iter   40] loss: 103509.2188 RMSElog: 9.9787 grad_loss: 10340.0186 normal_loss: 0.9251
[epoch 33][iter   50] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch 33][iter   60] loss: 177664.5312 RMSElog: 9.7808 grad_loss: 17755.7344 normal_loss: 0.9369
[epoch 33][iter   70] loss: 162372.7500 RMSElog: 9.8226 grad_loss: 16226.4922 normal_loss: 0.9603
[epoch 33][iter   80] loss: 194987.6250 RMSElog: 9.8416 grad_loss: 19487.9453 normal_loss: 0.9748
[epoch 33][iter   90] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 33][iter  100] loss: 214775.1719 RMSElog: 10.1719 grad_loss: 21466.3848 normal_loss: 0.9613
[epoch 33][iter  110] loss: 159798.6094 RMSElog: 9.8075 grad_loss: 15969.1260 normal_loss: 0.9263
[epoch 33][iter  120] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 33][iter  130] loss: 218457.8281 RMSElog: 10.1255 grad_loss: 21834.7168 normal_loss: 0.9418
[epoch 33][iter  140] loss: 139098.6406 RMSElog: 9.8619 grad_loss: 13899.0508 normal_loss: 0.9510
[epoch 33][iter  150] loss: 172868.6875 RMSElog: 10.0539 grad_loss: 17275.8652 normal_loss: 0.9500
[epoch 33][iter  160] loss: 177195.4844 RMSElog: 10.1516 grad_loss: 17708.4512 normal_loss: 0.9458
[epoch 33][iter  170] loss: 141118.5312 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.9477
[epoch 33][iter  180] loss: 106516.8047 RMSElog: 9.6966 grad_loss: 10641.0557 normal_loss: 0.9285
[epoch 33][iter  190] loss: 127499.3281 RMSElog: 9.2769 grad_loss: 12739.7178 normal_loss: 0.9374
[epoch 33][iter  200] loss: 103514.7734 RMSElog: 9.3451 grad_loss: 10341.2100 normal_loss: 0.9229
[epoch 33][iter  210] loss: 175301.7344 RMSElog: 9.8017 grad_loss: 17519.4180 normal_loss: 0.9555
[epoch 33][iter  220] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch 33][iter  230] loss: 102223.4531 RMSElog: 9.4278 grad_loss: 10212.0010 normal_loss: 0.9169
[epoch 33][iter  240] loss: 163171.1719 RMSElog: 9.7905 grad_loss: 16306.3613 normal_loss: 0.9652
[epoch 33][iter  250] loss: 186053.2969 RMSElog: 10.1470 grad_loss: 18594.2324 normal_loss: 0.9504
[epoch 33][iter  260] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 33][iter  270] loss: 154705.2188 RMSElog: 9.9142 grad_loss: 15459.6543 normal_loss: 0.9527
[epoch 33][iter  280] loss: 196842.3125 RMSElog: 10.1249 grad_loss: 19673.1523 normal_loss: 0.9534
[epoch 33][iter  290] loss: 107073.5156 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.9313
[epoch 33][iter  300] loss: 132425.4375 RMSElog: 10.0155 grad_loss: 13231.5801 normal_loss: 0.9468
[epoch 33][iter  310] loss: 161633.2812 RMSElog: 10.0107 grad_loss: 16152.3652 normal_loss: 0.9518
[epoch 33][iter  320] loss: 104340.6328 RMSElog: 9.7692 grad_loss: 10423.3701 normal_loss: 0.9234
[epoch 33][iter  330] loss: 190972.3281 RMSElog: 10.1152 grad_loss: 19086.1523 normal_loss: 0.9647
[epoch 33][iter  340] loss: 178784.1250 RMSElog: 9.9460 grad_loss: 17867.5078 normal_loss: 0.9592
[epoch 33][iter  350] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 33][iter  360] loss: 175547.8906 RMSElog: 10.1409 grad_loss: 17543.7148 normal_loss: 0.9342
[epoch 33][iter  370] loss: 157425.7188 RMSElog: 9.9235 grad_loss: 15731.7012 normal_loss: 0.9477
[epoch 33][iter  380] loss: 140645.6875 RMSElog: 10.1118 grad_loss: 14053.4873 normal_loss: 0.9695
[epoch 33][iter  390] loss: 164843.6875 RMSElog: 9.7972 grad_loss: 16473.6367 normal_loss: 0.9360
[epoch 33][iter  400] loss: 179901.4844 RMSElog: 9.8267 grad_loss: 17979.3633 normal_loss: 0.9589
[epoch 33][iter  410] loss: 147371.3906 RMSElog: 9.6635 grad_loss: 14726.5488 normal_loss: 0.9280
[epoch 33][iter  420] loss: 103534.6562 RMSElog: 9.7670 grad_loss: 10342.7715 normal_loss: 0.9280
[epoch 33][iter  430] loss: 160642.9375 RMSElog: 9.9306 grad_loss: 16053.4121 normal_loss: 0.9504
[epoch 33][iter  440] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 33][iter  450] loss: 122912.0625 RMSElog: 9.7328 grad_loss: 12280.5225 normal_loss: 0.9509
[epoch 33][iter  460] loss: 111914.6250 RMSElog: 9.3004 grad_loss: 11181.2402 normal_loss: 0.9218
[epoch 33][iter  470] loss: 168409.1562 RMSElog: 9.7031 grad_loss: 16830.2910 normal_loss: 0.9228
[epoch 33][iter  480] loss: 235211.2344 RMSElog: 10.3371 grad_loss: 23509.8398 normal_loss: 0.9452
[epoch 33][iter  490] loss: 210654.5312 RMSElog: 10.4982 grad_loss: 21054.0039 normal_loss: 0.9517
[epoch 33][iter  500] loss: 180929.5938 RMSElog: 10.0745 grad_loss: 18081.9297 normal_loss: 0.9546
[epoch 33][iter  510] loss: 144589.9531 RMSElog: 9.7438 grad_loss: 14448.3340 normal_loss: 0.9167
[epoch 33][iter  520] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 33][iter  530] loss: 196920.5625 RMSElog: 10.2474 grad_loss: 19680.8320 normal_loss: 0.9760
[epoch 33][iter  540] loss: 133013.4531 RMSElog: 9.5635 grad_loss: 13290.8457 normal_loss: 0.9356
[epoch 33][iter  550] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1221 normal_loss: 0.9462
[epoch 33][iter  560] loss: 108830.7344 RMSElog: 9.7359 grad_loss: 10872.4062 normal_loss: 0.9307
[epoch 33][iter  570] loss: 195507.4062 RMSElog: 10.1854 grad_loss: 19539.6016 normal_loss: 0.9533
[epoch 33][iter  580] loss: 162711.9688 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.9427
[epoch 33][iter  590] loss: 160024.9375 RMSElog: 9.8489 grad_loss: 15991.7236 normal_loss: 0.9215
[epoch 34][iter    0] loss: 224943.8906 RMSElog: 10.1206 grad_loss: 22483.3125 normal_loss: 0.9551
[epoch 34][iter   10] loss: 170690.9219 RMSElog: 9.9328 grad_loss: 17058.2109 normal_loss: 0.9470
[epoch 34][iter   20] loss: 183480.3438 RMSElog: 10.0091 grad_loss: 18337.0801 normal_loss: 0.9458
[epoch 34][iter   30] loss: 161088.9688 RMSElog: 9.9258 grad_loss: 16098.0254 normal_loss: 0.9455
[epoch 34][iter   40] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 34][iter   50] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 34][iter   60] loss: 180208.2188 RMSElog: 10.0490 grad_loss: 18009.8223 normal_loss: 0.9517
[epoch 34][iter   70] loss: 154626.7500 RMSElog: 9.9098 grad_loss: 15451.8057 normal_loss: 0.9596
[epoch 34][iter   80] loss: 202630.0781 RMSElog: 10.0417 grad_loss: 20252.0078 normal_loss: 0.9589
[epoch 34][iter   90] loss: 201503.0625 RMSElog: 10.3149 grad_loss: 20139.0410 normal_loss: 0.9514
[epoch 34][iter  100] loss: 239768.0938 RMSElog: 10.2366 grad_loss: 23965.6250 normal_loss: 0.9466
[epoch 34][iter  110] loss: 148136.9375 RMSElog: 9.9557 grad_loss: 14802.7871 normal_loss: 0.9498
[epoch 34][iter  120] loss: 136507.7344 RMSElog: 10.0223 grad_loss: 13639.7900 normal_loss: 0.9608
[epoch 34][iter  130] loss: 120440.5938 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.9240
[epoch 34][iter  140] loss: 123289.4609 RMSElog: 9.4106 grad_loss: 12318.5752 normal_loss: 0.9606
[epoch 34][iter  150] loss: 116073.5938 RMSElog: 9.6844 grad_loss: 11596.7324 normal_loss: 0.9429
[epoch 34][iter  160] loss: 160595.2188 RMSElog: 9.9514 grad_loss: 16048.6182 normal_loss: 0.9518
[epoch 34][iter  170] loss: 129163.5156 RMSElog: 9.7674 grad_loss: 12905.6660 normal_loss: 0.9175
[epoch 34][iter  180] loss: 122912.0625 RMSElog: 9.7328 grad_loss: 12280.5225 normal_loss: 0.9509
[epoch 34][iter  190] loss: 107472.2578 RMSElog: 9.0654 grad_loss: 10737.2480 normal_loss: 0.9124
[epoch 34][iter  200] loss: 176260.7500 RMSElog: 10.0638 grad_loss: 17615.0703 normal_loss: 0.9395
[epoch 34][iter  210] loss: 163268.1250 RMSElog: 9.9218 grad_loss: 16315.9277 normal_loss: 0.9630
[epoch 34][iter  220] loss: 149128.2188 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.9419
[epoch 34][iter  230] loss: 147479.0312 RMSElog: 9.6781 grad_loss: 14737.2812 normal_loss: 0.9446
[epoch 34][iter  240] loss: 142596.2344 RMSElog: 9.8922 grad_loss: 14248.7793 normal_loss: 0.9508
[epoch 34][iter  250] loss: 127499.3281 RMSElog: 9.2769 grad_loss: 12739.7178 normal_loss: 0.9374
[epoch 34][iter  260] loss: 191371.4375 RMSElog: 10.1918 grad_loss: 19126.0020 normal_loss: 0.9504
[epoch 34][iter  270] loss: 162835.5312 RMSElog: 9.9145 grad_loss: 16272.6904 normal_loss: 0.9492
[epoch 34][iter  280] loss: 114149.3672 RMSElog: 9.2655 grad_loss: 11404.7637 normal_loss: 0.9073
[epoch 34][iter  290] loss: 128277.9766 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.9518
[epoch 34][iter  300] loss: 120765.1875 RMSElog: 9.5441 grad_loss: 12066.0400 normal_loss: 0.9348
[epoch 34][iter  310] loss: 120292.3359 RMSElog: 9.8042 grad_loss: 12018.4854 normal_loss: 0.9430
[epoch 34][iter  320] loss: 146444.9062 RMSElog: 10.1139 grad_loss: 14633.4365 normal_loss: 0.9403
[epoch 34][iter  330] loss: 122386.0234 RMSElog: 9.6688 grad_loss: 12227.9971 normal_loss: 0.9366
[epoch 34][iter  340] loss: 151368.4219 RMSElog: 9.7883 grad_loss: 15126.1289 normal_loss: 0.9251
[epoch 34][iter  350] loss: 168545.0938 RMSElog: 9.6168 grad_loss: 16843.9434 normal_loss: 0.9495
[epoch 34][iter  360] loss: 156173.3594 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.9482
[epoch 34][iter  370] loss: 191559.9688 RMSElog: 9.9749 grad_loss: 19145.0742 normal_loss: 0.9477
[epoch 34][iter  380] loss: 172755.6875 RMSElog: 10.0251 grad_loss: 17264.6016 normal_loss: 0.9419
[epoch 34][iter  390] loss: 167784.2500 RMSElog: 9.9330 grad_loss: 16767.5391 normal_loss: 0.9539
[epoch 34][iter  400] loss: 180318.6719 RMSElog: 9.9530 grad_loss: 18020.9785 normal_loss: 0.9357
[epoch 34][iter  410] loss: 142544.5156 RMSElog: 10.1645 grad_loss: 14243.3457 normal_loss: 0.9425
[epoch 34][iter  420] loss: 111914.6406 RMSElog: 9.3004 grad_loss: 11181.2412 normal_loss: 0.9218
[epoch 34][iter  430] loss: 206083.5156 RMSElog: 10.2501 grad_loss: 20597.1445 normal_loss: 0.9562
[epoch 34][iter  440] loss: 142544.7031 RMSElog: 10.2185 grad_loss: 14243.3027 normal_loss: 0.9486
[epoch 34][iter  450] loss: 218547.0156 RMSElog: 10.4419 grad_loss: 21843.3086 normal_loss: 0.9515
[epoch 34][iter  460] loss: 131942.8750 RMSElog: 9.8414 grad_loss: 13183.5000 normal_loss: 0.9453
[epoch 34][iter  470] loss: 182476.7344 RMSElog: 9.9672 grad_loss: 18236.7656 normal_loss: 0.9407
[epoch 34][iter  480] loss: 174565.0781 RMSElog: 9.7759 grad_loss: 17445.7832 normal_loss: 0.9484
[epoch 34][iter  490] loss: 142005.0781 RMSElog: 9.9168 grad_loss: 14189.6533 normal_loss: 0.9371
[epoch 34][iter  500] loss: 127061.7500 RMSElog: 9.6726 grad_loss: 12695.5654 normal_loss: 0.9369
[epoch 34][iter  510] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 34][iter  520] loss: 226865.1406 RMSElog: 10.2887 grad_loss: 22675.2832 normal_loss: 0.9418
[epoch 34][iter  530] loss: 144987.0938 RMSElog: 9.8653 grad_loss: 14487.9062 normal_loss: 0.9378
[epoch 34][iter  540] loss: 115766.5312 RMSElog: 9.7467 grad_loss: 11565.9717 normal_loss: 0.9344
[epoch 34][iter  550] loss: 158034.0625 RMSElog: 9.9527 grad_loss: 15792.5088 normal_loss: 0.9445
[epoch 34][iter  560] loss: 103798.3281 RMSElog: 9.6193 grad_loss: 10369.2812 normal_loss: 0.9331
[epoch 34][iter  570] loss: 140645.6875 RMSElog: 10.1118 grad_loss: 14053.4873 normal_loss: 0.9695
[epoch 34][iter  580] loss: 173855.4375 RMSElog: 10.0769 grad_loss: 17374.5098 normal_loss: 0.9566
[epoch 34][iter  590] loss: 164766.2812 RMSElog: 9.6928 grad_loss: 16465.9941 normal_loss: 0.9411
[epoch 35][iter    0] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 35][iter   10] loss: 105628.3672 RMSElog: 10.0899 grad_loss: 10551.8262 normal_loss: 0.9213
[epoch 35][iter   20] loss: 139830.9062 RMSElog: 9.7552 grad_loss: 13972.3770 normal_loss: 0.9585
[epoch 35][iter   30] loss: 106769.7500 RMSElog: 9.8688 grad_loss: 10666.1914 normal_loss: 0.9140
[epoch 35][iter   40] loss: 111712.9219 RMSElog: 9.7826 grad_loss: 11160.5811 normal_loss: 0.9290
[epoch 35][iter   50] loss: 180318.6719 RMSElog: 9.9530 grad_loss: 18020.9785 normal_loss: 0.9357
[epoch 35][iter   60] loss: 178468.8906 RMSElog: 9.9039 grad_loss: 17836.0469 normal_loss: 0.9380
[epoch 35][iter   70] loss: 112697.1016 RMSElog: 9.7295 grad_loss: 11259.0449 normal_loss: 0.9352
[epoch 35][iter   80] loss: 198293.9219 RMSElog: 10.2275 grad_loss: 19818.2148 normal_loss: 0.9521
[epoch 35][iter   90] loss: 217845.4844 RMSElog: 10.3597 grad_loss: 21773.2129 normal_loss: 0.9774
[epoch 35][iter  100] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 35][iter  110] loss: 156253.7656 RMSElog: 9.8231 grad_loss: 15614.6211 normal_loss: 0.9316
[epoch 35][iter  120] loss: 188717.5625 RMSElog: 10.0336 grad_loss: 18860.7715 normal_loss: 0.9509
[epoch 35][iter  130] loss: 197520.7500 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.9662
[epoch 35][iter  140] loss: 143613.7656 RMSElog: 9.8882 grad_loss: 14350.5566 normal_loss: 0.9315
[epoch 35][iter  150] loss: 138469.0469 RMSElog: 9.4787 grad_loss: 13836.4834 normal_loss: 0.9438
[epoch 35][iter  160] loss: 163389.5625 RMSElog: 9.7702 grad_loss: 16328.2656 normal_loss: 0.9208
[epoch 35][iter  170] loss: 154626.7500 RMSElog: 9.9098 grad_loss: 15451.8057 normal_loss: 0.9596
[epoch 35][iter  180] loss: 201373.6719 RMSElog: 10.3870 grad_loss: 20126.0312 normal_loss: 0.9491
[epoch 35][iter  190] loss: 101101.5547 RMSElog: 9.9274 grad_loss: 10099.2979 normal_loss: 0.9297
[epoch 35][iter  200] loss: 234945.1719 RMSElog: 10.0015 grad_loss: 23483.5664 normal_loss: 0.9500
[epoch 35][iter  210] loss: 166010.9531 RMSElog: 9.9249 grad_loss: 16590.2227 normal_loss: 0.9481
[epoch 35][iter  220] loss: 139433.9219 RMSElog: 9.8139 grad_loss: 13932.6191 normal_loss: 0.9591
[epoch 35][iter  230] loss: 168688.8125 RMSElog: 9.8493 grad_loss: 16858.0781 normal_loss: 0.9524
[epoch 35][iter  240] loss: 133760.0469 RMSElog: 10.0653 grad_loss: 13364.9717 normal_loss: 0.9680
[epoch 35][iter  250] loss: 201503.0625 RMSElog: 10.3149 grad_loss: 20139.0410 normal_loss: 0.9514
[epoch 35][iter  260] loss: 141865.3906 RMSElog: 9.7199 grad_loss: 14175.8896 normal_loss: 0.9298
[epoch 35][iter  270] loss: 113426.9531 RMSElog: 9.7682 grad_loss: 11331.9902 normal_loss: 0.9362
[epoch 35][iter  280] loss: 106182.2031 RMSElog: 9.7575 grad_loss: 10607.5332 normal_loss: 0.9294
[epoch 35][iter  290] loss: 121916.0000 RMSElog: 9.7464 grad_loss: 12180.9131 normal_loss: 0.9404
[epoch 35][iter  300] loss: 183095.1562 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.9696
[epoch 35][iter  310] loss: 185071.7188 RMSElog: 10.0456 grad_loss: 18496.1719 normal_loss: 0.9557
[epoch 35][iter  320] loss: 194987.6250 RMSElog: 9.8416 grad_loss: 19487.9453 normal_loss: 0.9748
[epoch 35][iter  330] loss: 135966.2969 RMSElog: 9.6504 grad_loss: 13586.0273 normal_loss: 0.9522
[epoch 35][iter  340] loss: 170357.3438 RMSElog: 9.9687 grad_loss: 17024.8008 normal_loss: 0.9644
[epoch 35][iter  350] loss: 137252.6406 RMSElog: 9.3538 grad_loss: 13714.9795 normal_loss: 0.9319
[epoch 35][iter  360] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 35][iter  370] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 35][iter  380] loss: 156173.3594 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.9482
[epoch 35][iter  390] loss: 103355.8125 RMSElog: 9.7106 grad_loss: 10324.9453 normal_loss: 0.9244
[epoch 35][iter  400] loss: 137764.4219 RMSElog: 9.8227 grad_loss: 13765.6758 normal_loss: 0.9442
[epoch 35][iter  410] loss: 193978.6250 RMSElog: 10.3530 grad_loss: 19386.5586 normal_loss: 0.9518
[epoch 35][iter  420] loss: 134406.2031 RMSElog: 9.9402 grad_loss: 13429.7256 normal_loss: 0.9539
[epoch 35][iter  430] loss: 160782.5156 RMSElog: 9.7710 grad_loss: 16067.5547 normal_loss: 0.9244
[epoch 35][iter  440] loss: 99107.7500 RMSElog: 9.5230 grad_loss: 9900.3428 normal_loss: 0.9094
[epoch 35][iter  450] loss: 154029.7812 RMSElog: 9.8645 grad_loss: 15392.1729 normal_loss: 0.9405
[epoch 35][iter  460] loss: 138950.6406 RMSElog: 9.9777 grad_loss: 13884.1387 normal_loss: 0.9482
[epoch 35][iter  470] loss: 152593.5000 RMSElog: 9.8773 grad_loss: 15248.5439 normal_loss: 0.9283
[epoch 35][iter  480] loss: 184016.5469 RMSElog: 9.9468 grad_loss: 18390.7363 normal_loss: 0.9712
[epoch 35][iter  490] loss: 184374.2188 RMSElog: 10.2641 grad_loss: 18426.1992 normal_loss: 0.9596
[epoch 35][iter  500] loss: 154705.2344 RMSElog: 9.9142 grad_loss: 15459.6562 normal_loss: 0.9527
[epoch 35][iter  510] loss: 164415.3438 RMSElog: 10.0829 grad_loss: 16430.4961 normal_loss: 0.9571
[epoch 35][iter  520] loss: 128319.4141 RMSElog: 9.6733 grad_loss: 12821.3398 normal_loss: 0.9287
[epoch 35][iter  530] loss: 103948.1875 RMSElog: 9.7608 grad_loss: 10384.1309 normal_loss: 0.9264
[epoch 35][iter  540] loss: 113895.6328 RMSElog: 9.2606 grad_loss: 11379.3926 normal_loss: 0.9106
[epoch 35][iter  550] loss: 100663.8984 RMSElog: 9.9598 grad_loss: 10055.5020 normal_loss: 0.9277
[epoch 35][iter  560] loss: 159422.2656 RMSElog: 9.7010 grad_loss: 15931.5957 normal_loss: 0.9299
[epoch 35][iter  570] loss: 103305.2422 RMSElog: 9.5543 grad_loss: 10320.0674 normal_loss: 0.9024
[epoch 35][iter  580] loss: 208699.7031 RMSElog: 10.3419 grad_loss: 20858.6719 normal_loss: 0.9568
[epoch 35][iter  590] loss: 109441.5234 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.9300
[epoch 36][iter    0] loss: 146444.9062 RMSElog: 10.1139 grad_loss: 14633.4365 normal_loss: 0.9403
[epoch 36][iter   10] loss: 122446.5469 RMSElog: 9.6438 grad_loss: 12234.0742 normal_loss: 0.9366
[epoch 36][iter   20] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 36][iter   30] loss: 154290.2500 RMSElog: 9.8471 grad_loss: 15418.2334 normal_loss: 0.9458
[epoch 36][iter   40] loss: 149387.5469 RMSElog: 9.9550 grad_loss: 14927.8516 normal_loss: 0.9483
[epoch 36][iter   50] loss: 149540.3750 RMSElog: 9.7408 grad_loss: 14943.3740 normal_loss: 0.9229
[epoch 36][iter   60] loss: 160074.2031 RMSElog: 9.7506 grad_loss: 15996.7441 normal_loss: 0.9257
[epoch 36][iter   70] loss: 202630.0781 RMSElog: 10.0417 grad_loss: 20252.0078 normal_loss: 0.9589
[epoch 36][iter   80] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 36][iter   90] loss: 208770.3906 RMSElog: 10.1964 grad_loss: 20865.8984 normal_loss: 0.9442
[epoch 36][iter  100] loss: 208184.3438 RMSElog: 10.4061 grad_loss: 20807.0801 normal_loss: 0.9472
[epoch 36][iter  110] loss: 195412.9844 RMSElog: 10.0493 grad_loss: 19530.2969 normal_loss: 0.9539
[epoch 36][iter  120] loss: 216509.5938 RMSElog: 10.1942 grad_loss: 21639.8242 normal_loss: 0.9420
[epoch 36][iter  130] loss: 120440.5938 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.9240
[epoch 36][iter  140] loss: 143613.7656 RMSElog: 9.8882 grad_loss: 14350.5566 normal_loss: 0.9315
[epoch 36][iter  150] loss: 214775.1719 RMSElog: 10.1719 grad_loss: 21466.3848 normal_loss: 0.9613
[epoch 36][iter  160] loss: 147598.9844 RMSElog: 9.8981 grad_loss: 14749.0645 normal_loss: 0.9355
[epoch 36][iter  170] loss: 224943.8906 RMSElog: 10.1206 grad_loss: 22483.3125 normal_loss: 0.9551
[epoch 36][iter  180] loss: 166492.4375 RMSElog: 9.8376 grad_loss: 16638.4512 normal_loss: 0.9558
[epoch 36][iter  190] loss: 221213.4219 RMSElog: 10.1740 grad_loss: 22110.2266 normal_loss: 0.9415
[epoch 36][iter  200] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch 36][iter  210] loss: 150321.2812 RMSElog: 9.9248 grad_loss: 15021.2656 normal_loss: 0.9385
[epoch 36][iter  220] loss: 218547.0156 RMSElog: 10.4419 grad_loss: 21843.3086 normal_loss: 0.9515
[epoch 36][iter  230] loss: 111655.4766 RMSElog: 9.2050 grad_loss: 11155.4395 normal_loss: 0.9029
[epoch 36][iter  240] loss: 100116.4922 RMSElog: 9.9235 grad_loss: 10000.7998 normal_loss: 0.9258
[epoch 36][iter  250] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 36][iter  260] loss: 153447.6875 RMSElog: 9.9051 grad_loss: 15333.9209 normal_loss: 0.9425
[epoch 36][iter  270] loss: 230519.3906 RMSElog: 10.3105 grad_loss: 23040.6836 normal_loss: 0.9459
[epoch 36][iter  280] loss: 133024.8594 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.9261
[epoch 36][iter  290] loss: 122331.3906 RMSElog: 9.7180 grad_loss: 12222.4795 normal_loss: 0.9418
[epoch 36][iter  300] loss: 115348.2734 RMSElog: 9.7235 grad_loss: 11524.1562 normal_loss: 0.9470
[epoch 36][iter  310] loss: 151354.1562 RMSElog: 9.8837 grad_loss: 15124.5889 normal_loss: 0.9428
[epoch 36][iter  320] loss: 121838.3672 RMSElog: 9.7453 grad_loss: 12173.1494 normal_loss: 0.9425
[epoch 36][iter  330] loss: 174375.6875 RMSElog: 10.0512 grad_loss: 17426.5684 normal_loss: 0.9483
[epoch 36][iter  340] loss: 162892.2969 RMSElog: 9.8252 grad_loss: 16278.4717 normal_loss: 0.9331
[epoch 36][iter  350] loss: 153724.0000 RMSElog: 9.9609 grad_loss: 15361.4922 normal_loss: 0.9475
[epoch 36][iter  360] loss: 217845.5000 RMSElog: 10.3597 grad_loss: 21773.2148 normal_loss: 0.9774
[epoch 36][iter  370] loss: 150699.3750 RMSElog: 9.8567 grad_loss: 15059.1328 normal_loss: 0.9486
[epoch 36][iter  380] loss: 158875.5625 RMSElog: 9.5853 grad_loss: 15877.0449 normal_loss: 0.9260
[epoch 36][iter  390] loss: 144987.0938 RMSElog: 9.8653 grad_loss: 14487.9062 normal_loss: 0.9378
[epoch 36][iter  400] loss: 115658.3125 RMSElog: 9.1856 grad_loss: 11555.7031 normal_loss: 0.9424
[epoch 36][iter  410] loss: 127075.1875 RMSElog: 10.1217 grad_loss: 12696.4443 normal_loss: 0.9524
[epoch 36][iter  420] loss: 127499.3281 RMSElog: 9.2769 grad_loss: 12739.7178 normal_loss: 0.9374
[epoch 36][iter  430] loss: 167412.9531 RMSElog: 9.7311 grad_loss: 16730.6387 normal_loss: 0.9260
[epoch 36][iter  440] loss: 137252.6406 RMSElog: 9.3538 grad_loss: 13714.9795 normal_loss: 0.9319
[epoch 36][iter  450] loss: 162542.0469 RMSElog: 9.9393 grad_loss: 16243.3115 normal_loss: 0.9527
[epoch 36][iter  460] loss: 196437.8125 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.9584
[epoch 36][iter  470] loss: 177195.4844 RMSElog: 10.1516 grad_loss: 17708.4512 normal_loss: 0.9458
[epoch 36][iter  480] loss: 226949.5156 RMSElog: 10.2029 grad_loss: 22683.8047 normal_loss: 0.9430
[epoch 36][iter  490] loss: 130145.6250 RMSElog: 9.7206 grad_loss: 13003.9072 normal_loss: 0.9344
[epoch 36][iter  500] loss: 151368.4219 RMSElog: 9.7883 grad_loss: 15126.1289 normal_loss: 0.9251
[epoch 36][iter  510] loss: 127061.7500 RMSElog: 9.6726 grad_loss: 12695.5654 normal_loss: 0.9369
[epoch 36][iter  520] loss: 165306.9531 RMSElog: 9.8881 grad_loss: 16519.8438 normal_loss: 0.9638
[epoch 36][iter  530] loss: 122670.8984 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.9331
[epoch 36][iter  540] loss: 140938.8594 RMSElog: 9.7483 grad_loss: 14083.1953 normal_loss: 0.9424
[epoch 36][iter  550] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 36][iter  560] loss: 211925.8438 RMSElog: 10.1863 grad_loss: 21181.4551 normal_loss: 0.9436
[epoch 36][iter  570] loss: 184374.2188 RMSElog: 10.2641 grad_loss: 18426.1992 normal_loss: 0.9596
[epoch 36][iter  580] loss: 165020.2344 RMSElog: 9.7791 grad_loss: 16491.2910 normal_loss: 0.9530
[epoch 36][iter  590] loss: 117693.8984 RMSElog: 9.6527 grad_loss: 11758.8105 normal_loss: 0.9267
[epoch 37][iter    0] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 37][iter   10] loss: 179740.0625 RMSElog: 10.1206 grad_loss: 17962.9453 normal_loss: 0.9397
[epoch 37][iter   20] loss: 150608.8906 RMSElog: 10.0680 grad_loss: 15049.8750 normal_loss: 0.9460
[epoch 37][iter   30] loss: 111518.2734 RMSElog: 9.6257 grad_loss: 11141.2676 normal_loss: 0.9335
[epoch 37][iter   40] loss: 114310.3047 RMSElog: 9.4026 grad_loss: 11420.7217 normal_loss: 0.9063
[epoch 37][iter   50] loss: 133760.0469 RMSElog: 10.0653 grad_loss: 13364.9717 normal_loss: 0.9680
[epoch 37][iter   60] loss: 182187.7188 RMSElog: 10.0835 grad_loss: 18207.7461 normal_loss: 0.9413
[epoch 37][iter   70] loss: 181983.5312 RMSElog: 10.0741 grad_loss: 18187.3320 normal_loss: 0.9464
[epoch 37][iter   80] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 37][iter   90] loss: 100749.6875 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.9377
[epoch 37][iter  100] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 37][iter  110] loss: 162976.7812 RMSElog: 9.6016 grad_loss: 16287.1572 normal_loss: 0.9201
[epoch 37][iter  120] loss: 228338.7500 RMSElog: 10.2936 grad_loss: 22822.6348 normal_loss: 0.9477
[epoch 37][iter  130] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 37][iter  140] loss: 150459.7656 RMSElog: 9.9429 grad_loss: 15035.0986 normal_loss: 0.9347
[epoch 37][iter  150] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch 37][iter  160] loss: 180208.2188 RMSElog: 10.0490 grad_loss: 18009.8223 normal_loss: 0.9517
[epoch 37][iter  170] loss: 160466.8750 RMSElog: 9.9085 grad_loss: 16035.8252 normal_loss: 0.9540
[epoch 37][iter  180] loss: 115534.3672 RMSElog: 9.7196 grad_loss: 11542.7842 normal_loss: 0.9325
[epoch 37][iter  190] loss: 160438.2969 RMSElog: 9.9714 grad_loss: 16032.9092 normal_loss: 0.9487
[epoch 37][iter  200] loss: 202119.8125 RMSElog: 10.2544 grad_loss: 20200.7715 normal_loss: 0.9549
[epoch 37][iter  210] loss: 196677.7812 RMSElog: 10.0486 grad_loss: 19656.7715 normal_loss: 0.9571
[epoch 37][iter  220] loss: 155762.3594 RMSElog: 9.8487 grad_loss: 15565.4414 normal_loss: 0.9448
[epoch 37][iter  230] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 37][iter  240] loss: 128883.6406 RMSElog: 9.8798 grad_loss: 12877.5254 normal_loss: 0.9593
[epoch 37][iter  250] loss: 160788.1562 RMSElog: 9.7539 grad_loss: 16068.1299 normal_loss: 0.9318
[epoch 37][iter  260] loss: 158875.5312 RMSElog: 9.5853 grad_loss: 15877.0430 normal_loss: 0.9260
[epoch 37][iter  270] loss: 199607.0938 RMSElog: 10.0729 grad_loss: 19949.6758 normal_loss: 0.9604
[epoch 37][iter  280] loss: 151354.1562 RMSElog: 9.8837 grad_loss: 15124.5889 normal_loss: 0.9428
[epoch 37][iter  290] loss: 158034.0625 RMSElog: 9.9527 grad_loss: 15792.5088 normal_loss: 0.9445
[epoch 37][iter  300] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 37][iter  310] loss: 173855.4375 RMSElog: 10.0769 grad_loss: 17374.5098 normal_loss: 0.9566
[epoch 37][iter  320] loss: 162556.3906 RMSElog: 9.9091 grad_loss: 16244.7939 normal_loss: 0.9368
[epoch 37][iter  330] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 37][iter  340] loss: 106195.4219 RMSElog: 9.2531 grad_loss: 10609.3711 normal_loss: 0.9179
[epoch 37][iter  350] loss: 160051.0156 RMSElog: 9.8405 grad_loss: 15994.3105 normal_loss: 0.9506
[epoch 37][iter  360] loss: 229081.3125 RMSElog: 10.2778 grad_loss: 22896.9121 normal_loss: 0.9420
[epoch 37][iter  370] loss: 173086.7031 RMSElog: 10.4992 grad_loss: 17297.2227 normal_loss: 0.9480
[epoch 37][iter  380] loss: 154855.9062 RMSElog: 9.8054 grad_loss: 15474.8340 normal_loss: 0.9510
[epoch 37][iter  390] loss: 189017.5781 RMSElog: 10.1390 grad_loss: 18890.6602 normal_loss: 0.9589
[epoch 37][iter  400] loss: 186053.2812 RMSElog: 10.1470 grad_loss: 18594.2305 normal_loss: 0.9504
[epoch 37][iter  410] loss: 188502.1875 RMSElog: 10.1669 grad_loss: 18839.0801 normal_loss: 0.9722
[epoch 37][iter  420] loss: 217914.6094 RMSElog: 10.2786 grad_loss: 21780.2246 normal_loss: 0.9575
[epoch 37][iter  430] loss: 177292.4062 RMSElog: 10.1195 grad_loss: 17718.1602 normal_loss: 0.9615
[epoch 37][iter  440] loss: 160743.4062 RMSElog: 9.7965 grad_loss: 16063.6025 normal_loss: 0.9413
[epoch 37][iter  450] loss: 155911.2344 RMSElog: 9.7863 grad_loss: 15580.3965 normal_loss: 0.9403
[epoch 37][iter  460] loss: 130641.2188 RMSElog: 9.7184 grad_loss: 13053.4688 normal_loss: 0.9344
[epoch 37][iter  470] loss: 165648.1875 RMSElog: 9.7420 grad_loss: 16554.1289 normal_loss: 0.9479
[epoch 37][iter  480] loss: 122359.4531 RMSElog: 9.7683 grad_loss: 12225.2402 normal_loss: 0.9361
[epoch 37][iter  490] loss: 154609.8281 RMSElog: 9.8745 grad_loss: 15450.1855 normal_loss: 0.9220
[epoch 37][iter  500] loss: 168545.0938 RMSElog: 9.6168 grad_loss: 16843.9434 normal_loss: 0.9495
[epoch 37][iter  510] loss: 107948.0156 RMSElog: 9.7377 grad_loss: 10784.1299 normal_loss: 0.9342
[epoch 37][iter  520] loss: 218457.8281 RMSElog: 10.1255 grad_loss: 21834.7168 normal_loss: 0.9418
[epoch 37][iter  530] loss: 156557.3594 RMSElog: 9.6970 grad_loss: 15645.1025 normal_loss: 0.9363
[epoch 37][iter  540] loss: 163268.1250 RMSElog: 9.9218 grad_loss: 16315.9277 normal_loss: 0.9630
[epoch 37][iter  550] loss: 155968.4062 RMSElog: 9.9200 grad_loss: 15585.9980 normal_loss: 0.9232
[epoch 37][iter  560] loss: 108830.7344 RMSElog: 9.7359 grad_loss: 10872.4062 normal_loss: 0.9307
[epoch 37][iter  570] loss: 115658.3125 RMSElog: 9.1856 grad_loss: 11555.7031 normal_loss: 0.9424
[epoch 37][iter  580] loss: 111914.6250 RMSElog: 9.3004 grad_loss: 11181.2402 normal_loss: 0.9218
[epoch 37][iter  590] loss: 168409.1562 RMSElog: 9.7031 grad_loss: 16830.2910 normal_loss: 0.9228
[epoch 38][iter    0] loss: 80097.4062 RMSElog: 9.2433 grad_loss: 7999.5806 normal_loss: 0.9166
[epoch 38][iter   10] loss: 202630.0781 RMSElog: 10.0417 grad_loss: 20252.0078 normal_loss: 0.9589
[epoch 38][iter   20] loss: 201162.3750 RMSElog: 9.9531 grad_loss: 20105.3145 normal_loss: 0.9706
[epoch 38][iter   30] loss: 114149.3672 RMSElog: 9.2655 grad_loss: 11404.7637 normal_loss: 0.9073
[epoch 38][iter   40] loss: 145409.6719 RMSElog: 9.8330 grad_loss: 14530.1904 normal_loss: 0.9445
[epoch 38][iter   50] loss: 90482.6875 RMSElog: 9.3127 grad_loss: 9038.0186 normal_loss: 0.9378
[epoch 38][iter   60] loss: 217174.7656 RMSElog: 10.2254 grad_loss: 21706.2891 normal_loss: 0.9635
[epoch 38][iter   70] loss: 199607.1562 RMSElog: 10.1504 grad_loss: 19949.6133 normal_loss: 0.9517
[epoch 38][iter   80] loss: 146960.1406 RMSElog: 10.0979 grad_loss: 14684.9941 normal_loss: 0.9220
[epoch 38][iter   90] loss: 176260.7500 RMSElog: 10.0638 grad_loss: 17615.0703 normal_loss: 0.9395
[epoch 38][iter  100] loss: 234945.1719 RMSElog: 10.0015 grad_loss: 23483.5664 normal_loss: 0.9500
[epoch 38][iter  110] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 38][iter  120] loss: 189507.2500 RMSElog: 10.2157 grad_loss: 18939.5586 normal_loss: 0.9510
[epoch 38][iter  130] loss: 162372.7500 RMSElog: 9.8226 grad_loss: 16226.4922 normal_loss: 0.9603
[epoch 38][iter  140] loss: 120292.3359 RMSElog: 9.8042 grad_loss: 12018.4854 normal_loss: 0.9430
[epoch 38][iter  150] loss: 132707.3594 RMSElog: 9.7842 grad_loss: 13260.0049 normal_loss: 0.9472
[epoch 38][iter  160] loss: 179634.8125 RMSElog: 10.0930 grad_loss: 17952.4258 normal_loss: 0.9607
[epoch 38][iter  170] loss: 127463.1953 RMSElog: 9.4952 grad_loss: 12735.9092 normal_loss: 0.9153
[epoch 38][iter  180] loss: 160788.1562 RMSElog: 9.7539 grad_loss: 16068.1299 normal_loss: 0.9318
[epoch 38][iter  190] loss: 154776.6250 RMSElog: 9.8981 grad_loss: 15466.8438 normal_loss: 0.9209
[epoch 38][iter  200] loss: 132623.8750 RMSElog: 9.3325 grad_loss: 13252.1152 normal_loss: 0.9391
[epoch 38][iter  210] loss: 172966.9375 RMSElog: 9.9430 grad_loss: 17285.8008 normal_loss: 0.9485
[epoch 38][iter  220] loss: 194408.7812 RMSElog: 10.2924 grad_loss: 19429.6328 normal_loss: 0.9537
[epoch 38][iter  230] loss: 182859.0469 RMSElog: 9.8110 grad_loss: 18275.1250 normal_loss: 0.9678
[epoch 38][iter  240] loss: 147598.9844 RMSElog: 9.8981 grad_loss: 14749.0645 normal_loss: 0.9355
[epoch 38][iter  250] loss: 224077.7188 RMSElog: 10.3869 grad_loss: 22396.4258 normal_loss: 0.9584
[epoch 38][iter  260] loss: 103305.2500 RMSElog: 9.5543 grad_loss: 10320.0684 normal_loss: 0.9024
[epoch 38][iter  270] loss: 103514.7812 RMSElog: 9.3451 grad_loss: 10341.2109 normal_loss: 0.9229
[epoch 38][iter  280] loss: 160642.9375 RMSElog: 9.9306 grad_loss: 16053.4121 normal_loss: 0.9504
[epoch 38][iter  290] loss: 207885.1875 RMSElog: 10.4422 grad_loss: 20777.1328 normal_loss: 0.9460
[epoch 38][iter  300] loss: 148239.1406 RMSElog: 9.8055 grad_loss: 14813.1689 normal_loss: 0.9395
[epoch 38][iter  310] loss: 182318.7812 RMSElog: 10.1008 grad_loss: 18220.8398 normal_loss: 0.9384
[epoch 38][iter  320] loss: 223875.4062 RMSElog: 10.3929 grad_loss: 22376.1953 normal_loss: 0.9536
[epoch 38][iter  330] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch 38][iter  340] loss: 126023.2344 RMSElog: 9.6219 grad_loss: 12591.7656 normal_loss: 0.9360
[epoch 38][iter  350] loss: 157274.4688 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.9461
[epoch 38][iter  360] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 38][iter  370] loss: 104749.2812 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.9281
[epoch 38][iter  380] loss: 214808.7344 RMSElog: 10.1872 grad_loss: 21469.7441 normal_loss: 0.9423
[epoch 38][iter  390] loss: 138057.5156 RMSElog: 9.5188 grad_loss: 13795.3184 normal_loss: 0.9138
[epoch 38][iter  400] loss: 163272.7188 RMSElog: 10.0261 grad_loss: 16316.3047 normal_loss: 0.9400
[epoch 38][iter  410] loss: 186960.2969 RMSElog: 10.2468 grad_loss: 18684.8457 normal_loss: 0.9380
[epoch 38][iter  420] loss: 158230.6094 RMSElog: 9.9234 grad_loss: 15812.1895 normal_loss: 0.9483
[epoch 38][iter  430] loss: 149387.5469 RMSElog: 9.9550 grad_loss: 14927.8516 normal_loss: 0.9483
[epoch 38][iter  440] loss: 195507.4062 RMSElog: 10.1854 grad_loss: 19539.6016 normal_loss: 0.9533
[epoch 38][iter  450] loss: 127776.8359 RMSElog: 10.0947 grad_loss: 12766.6396 normal_loss: 0.9490
[epoch 38][iter  460] loss: 156709.9531 RMSElog: 9.8741 grad_loss: 15660.1758 normal_loss: 0.9453
[epoch 38][iter  470] loss: 201503.0625 RMSElog: 10.3149 grad_loss: 20139.0410 normal_loss: 0.9514
[epoch 38][iter  480] loss: 127499.3281 RMSElog: 9.2769 grad_loss: 12739.7178 normal_loss: 0.9374
[epoch 38][iter  490] loss: 168409.1562 RMSElog: 9.7031 grad_loss: 16830.2910 normal_loss: 0.9228
[epoch 38][iter  500] loss: 212239.7031 RMSElog: 10.2690 grad_loss: 21212.7383 normal_loss: 0.9638
[epoch 38][iter  510] loss: 142596.2344 RMSElog: 9.8922 grad_loss: 14248.7803 normal_loss: 0.9508
[epoch 38][iter  520] loss: 105816.5000 RMSElog: 9.4266 grad_loss: 10571.3066 normal_loss: 0.9171
[epoch 38][iter  530] loss: 107073.5156 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.9313
[epoch 38][iter  540] loss: 235211.2344 RMSElog: 10.3371 grad_loss: 23509.8398 normal_loss: 0.9452
[epoch 38][iter  550] loss: 146576.9219 RMSElog: 9.6520 grad_loss: 14647.1045 normal_loss: 0.9356
[epoch 38][iter  560] loss: 163268.1250 RMSElog: 9.9218 grad_loss: 16315.9277 normal_loss: 0.9630
[epoch 38][iter  570] loss: 157706.0781 RMSElog: 9.9981 grad_loss: 15759.6602 normal_loss: 0.9499
[epoch 38][iter  580] loss: 159340.4219 RMSElog: 9.9507 grad_loss: 15923.1406 normal_loss: 0.9500
[epoch 38][iter  590] loss: 120440.5938 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.9240
[epoch 39][iter    0] loss: 160825.5938 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.9491
[epoch 39][iter   10] loss: 87697.6250 RMSElog: 9.9487 grad_loss: 8758.8750 normal_loss: 0.9395
[epoch 39][iter   20] loss: 203023.3438 RMSElog: 10.3036 grad_loss: 20291.0723 normal_loss: 0.9583
[epoch 39][iter   30] loss: 135966.2969 RMSElog: 9.6504 grad_loss: 13586.0273 normal_loss: 0.9522
[epoch 39][iter   40] loss: 168688.8125 RMSElog: 9.8493 grad_loss: 16858.0781 normal_loss: 0.9524
[epoch 39][iter   50] loss: 109441.5234 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.9300
[epoch 39][iter   60] loss: 154626.7656 RMSElog: 9.9098 grad_loss: 15451.8066 normal_loss: 0.9596
[epoch 39][iter   70] loss: 167084.9219 RMSElog: 9.8660 grad_loss: 16697.6582 normal_loss: 0.9689
[epoch 39][iter   80] loss: 213417.0312 RMSElog: 10.3416 grad_loss: 21330.4082 normal_loss: 0.9536
[epoch 39][iter   90] loss: 148136.9375 RMSElog: 9.9557 grad_loss: 14802.7871 normal_loss: 0.9498
[epoch 39][iter  100] loss: 160438.2812 RMSElog: 9.9714 grad_loss: 16032.9082 normal_loss: 0.9487
[epoch 39][iter  110] loss: 191559.9688 RMSElog: 9.9749 grad_loss: 19145.0742 normal_loss: 0.9477
[epoch 39][iter  120] loss: 103534.6562 RMSElog: 9.7670 grad_loss: 10342.7715 normal_loss: 0.9280
[epoch 39][iter  130] loss: 164597.1094 RMSElog: 9.8631 grad_loss: 16448.8984 normal_loss: 0.9502
[epoch 39][iter  140] loss: 140645.6875 RMSElog: 10.1118 grad_loss: 14053.4873 normal_loss: 0.9695
[epoch 39][iter  150] loss: 139433.9219 RMSElog: 9.8139 grad_loss: 13932.6191 normal_loss: 0.9591
[epoch 39][iter  160] loss: 102998.8984 RMSElog: 9.8140 grad_loss: 10289.1318 normal_loss: 0.9431
[epoch 39][iter  170] loss: 147598.9844 RMSElog: 9.8981 grad_loss: 14749.0645 normal_loss: 0.9355
[epoch 39][iter  180] loss: 172683.9219 RMSElog: 9.9061 grad_loss: 17257.5312 normal_loss: 0.9550
[epoch 39][iter  190] loss: 125486.8672 RMSElog: 9.7758 grad_loss: 12537.9834 normal_loss: 0.9281
[epoch 39][iter  200] loss: 133045.7969 RMSElog: 9.8765 grad_loss: 13293.7490 normal_loss: 0.9538
[epoch 39][iter  210] loss: 129708.8906 RMSElog: 10.0691 grad_loss: 12959.8711 normal_loss: 0.9481
[epoch 39][iter  220] loss: 176260.7500 RMSElog: 10.0638 grad_loss: 17615.0703 normal_loss: 0.9395
[epoch 39][iter  230] loss: 120765.1875 RMSElog: 9.5441 grad_loss: 12066.0400 normal_loss: 0.9348
[epoch 39][iter  240] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 39][iter  250] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 39][iter  260] loss: 194578.5781 RMSElog: 10.2312 grad_loss: 19446.6680 normal_loss: 0.9596
[epoch 39][iter  270] loss: 103355.8203 RMSElog: 9.7106 grad_loss: 10324.9463 normal_loss: 0.9244
[epoch 39][iter  280] loss: 196677.7812 RMSElog: 10.0486 grad_loss: 19656.7715 normal_loss: 0.9571
[epoch 39][iter  290] loss: 162372.7500 RMSElog: 9.8226 grad_loss: 16226.4922 normal_loss: 0.9603
[epoch 39][iter  300] loss: 118495.6641 RMSElog: 9.2657 grad_loss: 11839.3906 normal_loss: 0.9103
[epoch 39][iter  310] loss: 191371.4375 RMSElog: 10.1918 grad_loss: 19126.0020 normal_loss: 0.9504
[epoch 39][iter  320] loss: 156985.6250 RMSElog: 9.5765 grad_loss: 15688.0479 normal_loss: 0.9385
[epoch 39][iter  330] loss: 175301.7344 RMSElog: 9.8017 grad_loss: 17519.4180 normal_loss: 0.9555
[epoch 39][iter  340] loss: 206083.5156 RMSElog: 10.2501 grad_loss: 20597.1445 normal_loss: 0.9562
[epoch 39][iter  350] loss: 177814.3125 RMSElog: 10.0854 grad_loss: 17770.3887 normal_loss: 0.9571
[epoch 39][iter  360] loss: 195507.4062 RMSElog: 10.1854 grad_loss: 19539.6016 normal_loss: 0.9533
[epoch 39][iter  370] loss: 162433.1875 RMSElog: 9.8183 grad_loss: 16232.5488 normal_loss: 0.9510
[epoch 39][iter  380] loss: 151401.7031 RMSElog: 9.4414 grad_loss: 15129.7930 normal_loss: 0.9361
[epoch 39][iter  390] loss: 139016.5781 RMSElog: 9.6276 grad_loss: 13891.1045 normal_loss: 0.9261
[epoch 39][iter  400] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 39][iter  410] loss: 167008.4531 RMSElog: 10.0165 grad_loss: 16689.8750 normal_loss: 0.9557
[epoch 39][iter  420] loss: 129166.5312 RMSElog: 9.7364 grad_loss: 12905.9775 normal_loss: 0.9391
[epoch 39][iter  430] loss: 169013.5312 RMSElog: 9.5880 grad_loss: 16890.8242 normal_loss: 0.9419
[epoch 39][iter  440] loss: 140333.8125 RMSElog: 9.8261 grad_loss: 14022.6191 normal_loss: 0.9368
[epoch 39][iter  450] loss: 147371.3906 RMSElog: 9.6635 grad_loss: 14726.5488 normal_loss: 0.9280
[epoch 39][iter  460] loss: 224943.8906 RMSElog: 10.1206 grad_loss: 22483.3125 normal_loss: 0.9551
[epoch 39][iter  470] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 39][iter  480] loss: 105816.5000 RMSElog: 9.4266 grad_loss: 10571.3066 normal_loss: 0.9171
[epoch 39][iter  490] loss: 227323.8281 RMSElog: 10.4159 grad_loss: 22721.0195 normal_loss: 0.9477
[epoch 39][iter  500] loss: 162892.2969 RMSElog: 9.8252 grad_loss: 16278.4717 normal_loss: 0.9331
[epoch 39][iter  510] loss: 152540.7500 RMSElog: 9.9175 grad_loss: 15243.2090 normal_loss: 0.9474
[epoch 39][iter  520] loss: 206400.7812 RMSElog: 10.3027 grad_loss: 20628.8281 normal_loss: 0.9467
[epoch 39][iter  530] loss: 200953.4062 RMSElog: 10.1163 grad_loss: 20084.2598 normal_loss: 0.9623
[epoch 39][iter  540] loss: 229081.2812 RMSElog: 10.2778 grad_loss: 22896.9102 normal_loss: 0.9420
[epoch 39][iter  550] loss: 157274.4688 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.9461
[epoch 39][iter  560] loss: 160466.8750 RMSElog: 9.9086 grad_loss: 16035.8252 normal_loss: 0.9540
[epoch 39][iter  570] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 39][iter  580] loss: 175486.0625 RMSElog: 10.0393 grad_loss: 17537.6094 normal_loss: 0.9563
[epoch 39][iter  590] loss: 103509.2188 RMSElog: 9.9787 grad_loss: 10340.0186 normal_loss: 0.9251
[epoch 40][iter    0] loss: 150364.6250 RMSElog: 9.9123 grad_loss: 15025.6094 normal_loss: 0.9418
[epoch 40][iter   10] loss: 105628.3672 RMSElog: 10.0899 grad_loss: 10551.8262 normal_loss: 0.9213
[epoch 40][iter   20] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 40][iter   30] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 40][iter   40] loss: 106195.4219 RMSElog: 9.2531 grad_loss: 10609.3711 normal_loss: 0.9179
[epoch 40][iter   50] loss: 167730.9531 RMSElog: 9.9663 grad_loss: 16762.1797 normal_loss: 0.9501
[epoch 40][iter   60] loss: 162542.0469 RMSElog: 9.9393 grad_loss: 16243.3115 normal_loss: 0.9527
[epoch 40][iter   70] loss: 196842.3125 RMSElog: 10.1249 grad_loss: 19673.1523 normal_loss: 0.9534
[epoch 40][iter   80] loss: 183480.3438 RMSElog: 10.0091 grad_loss: 18337.0801 normal_loss: 0.9458
[epoch 40][iter   90] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch 40][iter  100] loss: 195777.0469 RMSElog: 10.1280 grad_loss: 19566.6035 normal_loss: 0.9726
[epoch 40][iter  110] loss: 239768.0938 RMSElog: 10.2366 grad_loss: 23965.6250 normal_loss: 0.9466
[epoch 40][iter  120] loss: 170357.3438 RMSElog: 9.9687 grad_loss: 17024.8008 normal_loss: 0.9644
[epoch 40][iter  130] loss: 152772.4062 RMSElog: 9.8249 grad_loss: 15266.4727 normal_loss: 0.9438
[epoch 40][iter  140] loss: 214775.1719 RMSElog: 10.1719 grad_loss: 21466.3848 normal_loss: 0.9613
[epoch 40][iter  150] loss: 142138.5156 RMSElog: 9.7967 grad_loss: 14203.1260 normal_loss: 0.9291
[epoch 40][iter  160] loss: 198293.9375 RMSElog: 10.2275 grad_loss: 19818.2168 normal_loss: 0.9521
[epoch 40][iter  170] loss: 166207.1094 RMSElog: 9.7947 grad_loss: 16609.9668 normal_loss: 0.9492
[epoch 40][iter  180] loss: 114374.2344 RMSElog: 9.1913 grad_loss: 11427.3242 normal_loss: 0.9087
[epoch 40][iter  190] loss: 160825.5938 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.9491
[epoch 40][iter  200] loss: 151401.7031 RMSElog: 9.4414 grad_loss: 15129.7930 normal_loss: 0.9361
[epoch 40][iter  210] loss: 175547.8906 RMSElog: 10.1409 grad_loss: 17543.7148 normal_loss: 0.9342
[epoch 40][iter  220] loss: 177063.6250 RMSElog: 10.1532 grad_loss: 17695.2383 normal_loss: 0.9719
[epoch 40][iter  230] loss: 148136.9375 RMSElog: 9.9557 grad_loss: 14802.7871 normal_loss: 0.9498
[epoch 40][iter  240] loss: 195412.9844 RMSElog: 10.0493 grad_loss: 19530.2969 normal_loss: 0.9539
[epoch 40][iter  250] loss: 138469.0469 RMSElog: 9.4787 grad_loss: 13836.4834 normal_loss: 0.9438
[epoch 40][iter  260] loss: 175934.2344 RMSElog: 10.1481 grad_loss: 17582.3086 normal_loss: 0.9674
[epoch 40][iter  270] loss: 173721.0312 RMSElog: 10.0355 grad_loss: 17361.1211 normal_loss: 0.9468
[epoch 40][iter  280] loss: 212429.2969 RMSElog: 10.2794 grad_loss: 21231.6719 normal_loss: 0.9784
[epoch 40][iter  290] loss: 201503.0625 RMSElog: 10.3149 grad_loss: 20139.0410 normal_loss: 0.9514
[epoch 40][iter  300] loss: 104446.5625 RMSElog: 10.1932 grad_loss: 10433.5342 normal_loss: 0.9288
[epoch 40][iter  310] loss: 189582.6719 RMSElog: 9.9918 grad_loss: 18947.3223 normal_loss: 0.9523
[epoch 40][iter  320] loss: 134471.5781 RMSElog: 9.9200 grad_loss: 13436.3271 normal_loss: 0.9111
[epoch 40][iter  330] loss: 159824.3594 RMSElog: 9.8973 grad_loss: 15971.5811 normal_loss: 0.9569
[epoch 40][iter  340] loss: 150608.8906 RMSElog: 10.0680 grad_loss: 15049.8750 normal_loss: 0.9460
[epoch 40][iter  350] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 40][iter  360] loss: 111655.4766 RMSElog: 9.2050 grad_loss: 11155.4395 normal_loss: 0.9029
[epoch 40][iter  370] loss: 221213.4531 RMSElog: 10.1740 grad_loss: 22110.2305 normal_loss: 0.9415
[epoch 40][iter  380] loss: 199607.1562 RMSElog: 10.1504 grad_loss: 19949.6133 normal_loss: 0.9517
[epoch 40][iter  390] loss: 213417.0312 RMSElog: 10.3416 grad_loss: 21330.4082 normal_loss: 0.9536
[epoch 40][iter  400] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 40][iter  410] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1221 normal_loss: 0.9462
[epoch 40][iter  420] loss: 179634.8125 RMSElog: 10.0930 grad_loss: 17952.4258 normal_loss: 0.9607
[epoch 40][iter  430] loss: 200470.3906 RMSElog: 10.2414 grad_loss: 20035.8379 normal_loss: 0.9585
[epoch 40][iter  440] loss: 133013.4531 RMSElog: 9.5635 grad_loss: 13290.8457 normal_loss: 0.9356
[epoch 40][iter  450] loss: 145321.5469 RMSElog: 9.7332 grad_loss: 14521.4590 normal_loss: 0.9632
[epoch 40][iter  460] loss: 224257.9688 RMSElog: 10.2842 grad_loss: 22414.5605 normal_loss: 0.9521
[epoch 40][iter  470] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 40][iter  480] loss: 175002.7344 RMSElog: 9.8652 grad_loss: 17489.4648 normal_loss: 0.9436
[epoch 40][iter  490] loss: 165020.2344 RMSElog: 9.7791 grad_loss: 16491.2910 normal_loss: 0.9530
[epoch 40][iter  500] loss: 195671.7031 RMSElog: 10.1080 grad_loss: 19556.1133 normal_loss: 0.9494
[epoch 40][iter  510] loss: 167455.8750 RMSElog: 9.7229 grad_loss: 16734.9395 normal_loss: 0.9256
[epoch 40][iter  520] loss: 163695.2656 RMSElog: 9.7037 grad_loss: 16358.8877 normal_loss: 0.9345
[epoch 40][iter  530] loss: 157810.1562 RMSElog: 9.9254 grad_loss: 15770.1641 normal_loss: 0.9253
[epoch 40][iter  540] loss: 144987.0938 RMSElog: 9.8653 grad_loss: 14487.9062 normal_loss: 0.9378
[epoch 40][iter  550] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 40][iter  560] loss: 165648.1875 RMSElog: 9.7420 grad_loss: 16554.1289 normal_loss: 0.9479
[epoch 40][iter  570] loss: 148239.1406 RMSElog: 9.8055 grad_loss: 14813.1689 normal_loss: 0.9395
[epoch 40][iter  580] loss: 107073.5156 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.9313
[epoch 40][iter  590] loss: 152540.7500 RMSElog: 9.9175 grad_loss: 15243.2090 normal_loss: 0.9474
[epoch 41][iter    0] loss: 127110.9375 RMSElog: 9.5273 grad_loss: 12700.6064 normal_loss: 0.9604
[epoch 41][iter   10] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 41][iter   20] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 41][iter   30] loss: 154776.6250 RMSElog: 9.8981 grad_loss: 15466.8438 normal_loss: 0.9209
[epoch 41][iter   40] loss: 103305.2422 RMSElog: 9.5543 grad_loss: 10320.0674 normal_loss: 0.9024
[epoch 41][iter   50] loss: 156253.7656 RMSElog: 9.8231 grad_loss: 15614.6211 normal_loss: 0.9316
[epoch 41][iter   60] loss: 160934.5156 RMSElog: 9.8035 grad_loss: 16082.6846 normal_loss: 0.9629
[epoch 41][iter   70] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1230 normal_loss: 0.9462
[epoch 41][iter   80] loss: 142138.5156 RMSElog: 9.7967 grad_loss: 14203.1260 normal_loss: 0.9291
[epoch 41][iter   90] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 41][iter  100] loss: 190972.3281 RMSElog: 10.1152 grad_loss: 19086.1523 normal_loss: 0.9647
[epoch 41][iter  110] loss: 180982.8438 RMSElog: 10.2711 grad_loss: 18087.0605 normal_loss: 0.9528
[epoch 41][iter  120] loss: 111518.2734 RMSElog: 9.6257 grad_loss: 11141.2676 normal_loss: 0.9335
[epoch 41][iter  130] loss: 173855.4375 RMSElog: 10.0769 grad_loss: 17374.5098 normal_loss: 0.9566
[epoch 41][iter  140] loss: 157425.7500 RMSElog: 9.9235 grad_loss: 15731.7031 normal_loss: 0.9477
[epoch 41][iter  150] loss: 175524.1250 RMSElog: 10.2056 grad_loss: 17541.2441 normal_loss: 0.9625
[epoch 41][iter  160] loss: 220587.5781 RMSElog: 10.2995 grad_loss: 22047.5117 normal_loss: 0.9466
[epoch 41][iter  170] loss: 114173.9062 RMSElog: 9.3600 grad_loss: 11407.1240 normal_loss: 0.9061
[epoch 41][iter  180] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 41][iter  190] loss: 180663.0469 RMSElog: 10.2319 grad_loss: 18055.1094 normal_loss: 0.9630
[epoch 41][iter  200] loss: 120745.8203 RMSElog: 9.7706 grad_loss: 12063.8691 normal_loss: 0.9428
[epoch 41][iter  210] loss: 105628.3672 RMSElog: 10.0899 grad_loss: 10551.8262 normal_loss: 0.9213
[epoch 41][iter  220] loss: 110808.0469 RMSElog: 9.7171 grad_loss: 11070.1562 normal_loss: 0.9312
[epoch 41][iter  230] loss: 127463.1875 RMSElog: 9.4952 grad_loss: 12735.9082 normal_loss: 0.9153
[epoch 41][iter  240] loss: 114149.3750 RMSElog: 9.2655 grad_loss: 11404.7646 normal_loss: 0.9073
[epoch 41][iter  250] loss: 177195.4844 RMSElog: 10.1516 grad_loss: 17708.4512 normal_loss: 0.9458
[epoch 41][iter  260] loss: 162522.4531 RMSElog: 9.9860 grad_loss: 16241.3066 normal_loss: 0.9518
[epoch 41][iter  270] loss: 175008.6562 RMSElog: 9.9496 grad_loss: 17489.9434 normal_loss: 0.9734
[epoch 41][iter  280] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 41][iter  290] loss: 172966.9375 RMSElog: 9.9430 grad_loss: 17285.8008 normal_loss: 0.9485
[epoch 41][iter  300] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 41][iter  310] loss: 139878.0625 RMSElog: 9.8515 grad_loss: 13977.0225 normal_loss: 0.9327
[epoch 41][iter  320] loss: 136533.4688 RMSElog: 9.6756 grad_loss: 13642.7363 normal_loss: 0.9359
[epoch 41][iter  330] loss: 114827.1016 RMSElog: 9.7767 grad_loss: 11472.0010 normal_loss: 0.9329
[epoch 41][iter  340] loss: 147598.9844 RMSElog: 9.8981 grad_loss: 14749.0645 normal_loss: 0.9355
[epoch 41][iter  350] loss: 172115.2812 RMSElog: 9.7682 grad_loss: 17200.8242 normal_loss: 0.9358
[epoch 41][iter  360] loss: 148793.9688 RMSElog: 10.1047 grad_loss: 14868.3447 normal_loss: 0.9480
[epoch 41][iter  370] loss: 87697.6250 RMSElog: 9.9487 grad_loss: 8758.8750 normal_loss: 0.9395
[epoch 41][iter  380] loss: 110603.0781 RMSElog: 9.8046 grad_loss: 11049.5664 normal_loss: 0.9364
[epoch 41][iter  390] loss: 174375.6875 RMSElog: 10.0512 grad_loss: 17426.5684 normal_loss: 0.9483
[epoch 41][iter  400] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 41][iter  410] loss: 133045.7969 RMSElog: 9.8765 grad_loss: 13293.7490 normal_loss: 0.9538
[epoch 41][iter  420] loss: 184374.1875 RMSElog: 10.2641 grad_loss: 18426.1953 normal_loss: 0.9596
[epoch 41][iter  430] loss: 191559.9688 RMSElog: 9.9749 grad_loss: 19145.0742 normal_loss: 0.9477
[epoch 41][iter  440] loss: 105706.7031 RMSElog: 9.7501 grad_loss: 10559.9883 normal_loss: 0.9321
[epoch 41][iter  450] loss: 126023.2344 RMSElog: 9.6219 grad_loss: 12591.7656 normal_loss: 0.9360
[epoch 41][iter  460] loss: 172755.6875 RMSElog: 10.0251 grad_loss: 17264.6016 normal_loss: 0.9419
[epoch 41][iter  470] loss: 146942.0781 RMSElog: 9.4227 grad_loss: 14683.8535 normal_loss: 0.9314
[epoch 41][iter  480] loss: 129708.8906 RMSElog: 10.0691 grad_loss: 12959.8711 normal_loss: 0.9481
[epoch 41][iter  490] loss: 107472.2500 RMSElog: 9.0654 grad_loss: 10737.2471 normal_loss: 0.9124
[epoch 41][iter  500] loss: 127499.3281 RMSElog: 9.2769 grad_loss: 12739.7178 normal_loss: 0.9374
[epoch 41][iter  510] loss: 133013.4531 RMSElog: 9.5635 grad_loss: 13290.8457 normal_loss: 0.9356
[epoch 41][iter  520] loss: 177936.2812 RMSElog: 10.0381 grad_loss: 17782.6348 normal_loss: 0.9545
[epoch 41][iter  530] loss: 132935.3906 RMSElog: 9.9640 grad_loss: 13282.6172 normal_loss: 0.9581
[epoch 41][iter  540] loss: 158034.0469 RMSElog: 9.9527 grad_loss: 15792.5078 normal_loss: 0.9445
[epoch 41][iter  550] loss: 201373.6875 RMSElog: 10.3870 grad_loss: 20126.0332 normal_loss: 0.9491
[epoch 41][iter  560] loss: 134677.6719 RMSElog: 9.8776 grad_loss: 13456.9443 normal_loss: 0.9441
[epoch 41][iter  570] loss: 125683.7969 RMSElog: 9.8131 grad_loss: 12557.6123 normal_loss: 0.9537
[epoch 41][iter  580] loss: 166492.4688 RMSElog: 9.8376 grad_loss: 16638.4531 normal_loss: 0.9558
[epoch 41][iter  590] loss: 138950.6406 RMSElog: 9.9777 grad_loss: 13884.1387 normal_loss: 0.9482
[epoch 42][iter    0] loss: 180425.2344 RMSElog: 10.0354 grad_loss: 18031.5332 normal_loss: 0.9552
[epoch 42][iter   10] loss: 161633.2656 RMSElog: 10.0107 grad_loss: 16152.3643 normal_loss: 0.9518
[epoch 42][iter   20] loss: 167740.4688 RMSElog: 9.8540 grad_loss: 16763.2344 normal_loss: 0.9591
[epoch 42][iter   30] loss: 146942.0781 RMSElog: 9.4227 grad_loss: 14683.8535 normal_loss: 0.9314
[epoch 42][iter   40] loss: 110808.0469 RMSElog: 9.7171 grad_loss: 11070.1562 normal_loss: 0.9312
[epoch 42][iter   50] loss: 175002.7344 RMSElog: 9.8652 grad_loss: 17489.4648 normal_loss: 0.9436
[epoch 42][iter   60] loss: 156985.6406 RMSElog: 9.5765 grad_loss: 15688.0488 normal_loss: 0.9385
[epoch 42][iter   70] loss: 181293.3438 RMSElog: 10.0009 grad_loss: 18118.3809 normal_loss: 0.9531
[epoch 42][iter   80] loss: 205362.7344 RMSElog: 10.1686 grad_loss: 20525.1582 normal_loss: 0.9475
[epoch 42][iter   90] loss: 147915.7812 RMSElog: 10.0131 grad_loss: 14780.6104 normal_loss: 0.9547
[epoch 42][iter  100] loss: 132037.4375 RMSElog: 9.6100 grad_loss: 13193.2246 normal_loss: 0.9082
[epoch 42][iter  110] loss: 125281.0156 RMSElog: 9.5401 grad_loss: 12517.6484 normal_loss: 0.9128
[epoch 42][iter  120] loss: 221089.3594 RMSElog: 10.3457 grad_loss: 22097.6465 normal_loss: 0.9439
[epoch 42][iter  130] loss: 203093.2969 RMSElog: 10.1238 grad_loss: 20298.2598 normal_loss: 0.9478
[epoch 42][iter  140] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 42][iter  150] loss: 130145.6250 RMSElog: 9.7206 grad_loss: 13003.9072 normal_loss: 0.9344
[epoch 42][iter  160] loss: 113195.8281 RMSElog: 9.1761 grad_loss: 11309.5059 normal_loss: 0.9012
[epoch 42][iter  170] loss: 110235.3906 RMSElog: 9.7805 grad_loss: 11012.8271 normal_loss: 0.9312
[epoch 42][iter  180] loss: 186960.2969 RMSElog: 10.2468 grad_loss: 18684.8457 normal_loss: 0.9380
[epoch 42][iter  190] loss: 140938.8594 RMSElog: 9.7483 grad_loss: 14083.1953 normal_loss: 0.9424
[epoch 42][iter  200] loss: 230519.3906 RMSElog: 10.3105 grad_loss: 23040.6836 normal_loss: 0.9459
[epoch 42][iter  210] loss: 163389.5469 RMSElog: 9.7702 grad_loss: 16328.2637 normal_loss: 0.9208
[epoch 42][iter  220] loss: 226865.1406 RMSElog: 10.2887 grad_loss: 22675.2832 normal_loss: 0.9418
[epoch 42][iter  230] loss: 195671.7031 RMSElog: 10.1080 grad_loss: 19556.1133 normal_loss: 0.9494
[epoch 42][iter  240] loss: 143613.7656 RMSElog: 9.8882 grad_loss: 14350.5566 normal_loss: 0.9315
[epoch 42][iter  250] loss: 160642.9375 RMSElog: 9.9306 grad_loss: 16053.4121 normal_loss: 0.9504
[epoch 42][iter  260] loss: 167794.0469 RMSElog: 9.8335 grad_loss: 16768.6211 normal_loss: 0.9500
[epoch 42][iter  270] loss: 214808.7500 RMSElog: 10.1872 grad_loss: 21469.7461 normal_loss: 0.9423
[epoch 42][iter  280] loss: 145389.9375 RMSElog: 9.8784 grad_loss: 14528.1660 normal_loss: 0.9489
[epoch 42][iter  290] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 42][iter  300] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 42][iter  310] loss: 103798.3281 RMSElog: 9.6193 grad_loss: 10369.2812 normal_loss: 0.9331
[epoch 42][iter  320] loss: 132012.6719 RMSElog: 9.6802 grad_loss: 13190.6582 normal_loss: 0.9291
[epoch 42][iter  330] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 42][iter  340] loss: 99107.7500 RMSElog: 9.5230 grad_loss: 9900.3428 normal_loss: 0.9094
[epoch 42][iter  350] loss: 162892.2969 RMSElog: 9.8252 grad_loss: 16278.4717 normal_loss: 0.9331
[epoch 42][iter  360] loss: 161285.2188 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.9476
[epoch 42][iter  370] loss: 166207.1094 RMSElog: 9.7947 grad_loss: 16609.9668 normal_loss: 0.9492
[epoch 42][iter  380] loss: 179298.9062 RMSElog: 9.7220 grad_loss: 17919.2227 normal_loss: 0.9453
[epoch 42][iter  390] loss: 214067.1875 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.9394
[epoch 42][iter  400] loss: 142596.2344 RMSElog: 9.8922 grad_loss: 14248.7793 normal_loss: 0.9508
[epoch 42][iter  410] loss: 180208.2188 RMSElog: 10.0490 grad_loss: 18009.8223 normal_loss: 0.9517
[epoch 42][iter  420] loss: 186053.2969 RMSElog: 10.1470 grad_loss: 18594.2324 normal_loss: 0.9504
[epoch 42][iter  430] loss: 158034.0625 RMSElog: 9.9527 grad_loss: 15792.5088 normal_loss: 0.9445
[epoch 42][iter  440] loss: 190938.1250 RMSElog: 10.3028 grad_loss: 19082.5566 normal_loss: 0.9541
[epoch 42][iter  450] loss: 167455.8750 RMSElog: 9.7229 grad_loss: 16734.9395 normal_loss: 0.9256
[epoch 42][iter  460] loss: 213401.8906 RMSElog: 10.0568 grad_loss: 21329.1582 normal_loss: 0.9749
[epoch 42][iter  470] loss: 131213.2969 RMSElog: 9.6860 grad_loss: 13110.7217 normal_loss: 0.9217
[epoch 42][iter  480] loss: 124563.3906 RMSElog: 9.9514 grad_loss: 12445.4473 normal_loss: 0.9400
[epoch 42][iter  490] loss: 139433.9219 RMSElog: 9.8139 grad_loss: 13932.6191 normal_loss: 0.9591
[epoch 42][iter  500] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 42][iter  510] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 42][iter  520] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch 42][iter  530] loss: 140057.2812 RMSElog: 9.9766 grad_loss: 13994.7988 normal_loss: 0.9526
[epoch 42][iter  540] loss: 100990.1562 RMSElog: 9.7350 grad_loss: 10088.3584 normal_loss: 0.9222
[epoch 42][iter  550] loss: 165326.5625 RMSElog: 9.8832 grad_loss: 16521.8086 normal_loss: 0.9647
[epoch 42][iter  560] loss: 154705.2344 RMSElog: 9.9142 grad_loss: 15459.6562 normal_loss: 0.9527
[epoch 42][iter  570] loss: 116582.6172 RMSElog: 9.7871 grad_loss: 11647.5430 normal_loss: 0.9314
[epoch 42][iter  580] loss: 198743.4219 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.9643
[epoch 42][iter  590] loss: 162711.9688 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.9427
[epoch 43][iter    0] loss: 174375.6875 RMSElog: 10.0512 grad_loss: 17426.5684 normal_loss: 0.9483
[epoch 43][iter   10] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 43][iter   20] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 43][iter   30] loss: 150699.3750 RMSElog: 9.8567 grad_loss: 15059.1328 normal_loss: 0.9486
[epoch 43][iter   40] loss: 152540.7500 RMSElog: 9.9175 grad_loss: 15243.2090 normal_loss: 0.9474
[epoch 43][iter   50] loss: 103305.2422 RMSElog: 9.5543 grad_loss: 10320.0674 normal_loss: 0.9024
[epoch 43][iter   60] loss: 189582.6719 RMSElog: 9.9918 grad_loss: 18947.3223 normal_loss: 0.9523
[epoch 43][iter   70] loss: 163171.1562 RMSElog: 9.7905 grad_loss: 16306.3594 normal_loss: 0.9652
[epoch 43][iter   80] loss: 114149.3750 RMSElog: 9.2655 grad_loss: 11404.7646 normal_loss: 0.9073
[epoch 43][iter   90] loss: 115534.3672 RMSElog: 9.7196 grad_loss: 11542.7842 normal_loss: 0.9325
[epoch 43][iter  100] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 43][iter  110] loss: 133464.0312 RMSElog: 9.6242 grad_loss: 13335.8584 normal_loss: 0.9201
[epoch 43][iter  120] loss: 155762.3438 RMSElog: 9.8487 grad_loss: 15565.4404 normal_loss: 0.9448
[epoch 43][iter  130] loss: 181983.5312 RMSElog: 10.0741 grad_loss: 18187.3320 normal_loss: 0.9464
[epoch 43][iter  140] loss: 195999.5625 RMSElog: 10.1749 grad_loss: 19588.8047 normal_loss: 0.9756
[epoch 43][iter  150] loss: 152562.3750 RMSElog: 9.8216 grad_loss: 15245.4775 normal_loss: 0.9391
[epoch 43][iter  160] loss: 146465.6875 RMSElog: 10.2283 grad_loss: 14635.4062 normal_loss: 0.9337
[epoch 43][iter  170] loss: 133024.8594 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.9261
[epoch 43][iter  180] loss: 124323.5156 RMSElog: 9.7543 grad_loss: 12421.6650 normal_loss: 0.9322
[epoch 43][iter  190] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 43][iter  200] loss: 199070.3125 RMSElog: 9.9947 grad_loss: 19896.0605 normal_loss: 0.9757
[epoch 43][iter  210] loss: 208821.7812 RMSElog: 10.1565 grad_loss: 20871.0781 normal_loss: 0.9431
[epoch 43][iter  220] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 43][iter  230] loss: 129743.7969 RMSElog: 9.9523 grad_loss: 12963.4785 normal_loss: 0.9492
[epoch 43][iter  240] loss: 154855.9062 RMSElog: 9.8054 grad_loss: 15474.8340 normal_loss: 0.9510
[epoch 43][iter  250] loss: 140938.8594 RMSElog: 9.7483 grad_loss: 14083.1953 normal_loss: 0.9424
[epoch 43][iter  260] loss: 156985.6250 RMSElog: 9.5765 grad_loss: 15688.0479 normal_loss: 0.9385
[epoch 43][iter  270] loss: 190034.7188 RMSElog: 9.9619 grad_loss: 18992.5625 normal_loss: 0.9485
[epoch 43][iter  280] loss: 185495.4062 RMSElog: 9.9310 grad_loss: 18538.6641 normal_loss: 0.9455
[epoch 43][iter  290] loss: 113921.7891 RMSElog: 9.7251 grad_loss: 11381.5186 normal_loss: 0.9357
[epoch 43][iter  300] loss: 152517.4844 RMSElog: 9.8233 grad_loss: 15241.0010 normal_loss: 0.9249
[epoch 43][iter  310] loss: 161088.9688 RMSElog: 9.9258 grad_loss: 16098.0254 normal_loss: 0.9455
[epoch 43][iter  320] loss: 160934.5156 RMSElog: 9.8035 grad_loss: 16082.6846 normal_loss: 0.9629
[epoch 43][iter  330] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 43][iter  340] loss: 175359.1875 RMSElog: 10.1476 grad_loss: 17524.8125 normal_loss: 0.9571
[epoch 43][iter  350] loss: 112535.5625 RMSElog: 9.5823 grad_loss: 11243.0459 normal_loss: 0.9289
[epoch 43][iter  360] loss: 200470.3906 RMSElog: 10.2414 grad_loss: 20035.8379 normal_loss: 0.9585
[epoch 43][iter  370] loss: 130527.6172 RMSElog: 9.8914 grad_loss: 13041.9189 normal_loss: 0.9509
[epoch 43][iter  380] loss: 215955.5312 RMSElog: 10.2675 grad_loss: 21584.3203 normal_loss: 0.9654
[epoch 43][iter  390] loss: 211925.8438 RMSElog: 10.1863 grad_loss: 21181.4551 normal_loss: 0.9436
[epoch 43][iter  400] loss: 185071.7031 RMSElog: 10.0456 grad_loss: 18496.1699 normal_loss: 0.9557
[epoch 43][iter  410] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 43][iter  420] loss: 163253.2500 RMSElog: 9.8740 grad_loss: 16314.5010 normal_loss: 0.9499
[epoch 43][iter  430] loss: 186049.0312 RMSElog: 10.0165 grad_loss: 18593.9277 normal_loss: 0.9585
[epoch 43][iter  440] loss: 123289.4609 RMSElog: 9.4106 grad_loss: 12318.5752 normal_loss: 0.9606
[epoch 43][iter  450] loss: 138469.0469 RMSElog: 9.4787 grad_loss: 13836.4834 normal_loss: 0.9438
[epoch 43][iter  460] loss: 180929.5938 RMSElog: 10.0745 grad_loss: 18081.9297 normal_loss: 0.9546
[epoch 43][iter  470] loss: 136533.4688 RMSElog: 9.6756 grad_loss: 13642.7363 normal_loss: 0.9359
[epoch 43][iter  480] loss: 105628.3672 RMSElog: 10.0899 grad_loss: 10551.8262 normal_loss: 0.9213
[epoch 43][iter  490] loss: 115348.2734 RMSElog: 9.7235 grad_loss: 11524.1562 normal_loss: 0.9470
[epoch 43][iter  500] loss: 142138.5156 RMSElog: 9.7967 grad_loss: 14203.1260 normal_loss: 0.9291
[epoch 43][iter  510] loss: 138714.8906 RMSElog: 10.1491 grad_loss: 13860.4043 normal_loss: 0.9360
[epoch 43][iter  520] loss: 115495.2188 RMSElog: 9.6084 grad_loss: 11538.9688 normal_loss: 0.9442
[epoch 43][iter  530] loss: 136796.3594 RMSElog: 9.6524 grad_loss: 13669.0283 normal_loss: 0.9549
[epoch 43][iter  540] loss: 162711.9688 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.9427
[epoch 43][iter  550] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 43][iter  560] loss: 103355.8125 RMSElog: 9.7106 grad_loss: 10324.9453 normal_loss: 0.9244
[epoch 43][iter  570] loss: 115738.1953 RMSElog: 9.6968 grad_loss: 11563.1836 normal_loss: 0.9382
[epoch 43][iter  580] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 43][iter  590] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 44][iter    0] loss: 162892.2969 RMSElog: 9.8252 grad_loss: 16278.4717 normal_loss: 0.9331
[epoch 44][iter   10] loss: 163272.7188 RMSElog: 10.0261 grad_loss: 16316.3047 normal_loss: 0.9400
[epoch 44][iter   20] loss: 215955.5625 RMSElog: 10.2675 grad_loss: 21584.3242 normal_loss: 0.9654
[epoch 44][iter   30] loss: 164415.3438 RMSElog: 10.0829 grad_loss: 16430.4961 normal_loss: 0.9571
[epoch 44][iter   40] loss: 196437.8125 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.9584
[epoch 44][iter   50] loss: 202119.8125 RMSElog: 10.2544 grad_loss: 20200.7715 normal_loss: 0.9549
[epoch 44][iter   60] loss: 120440.5938 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.9240
[epoch 44][iter   70] loss: 115452.5781 RMSElog: 9.2301 grad_loss: 11535.1230 normal_loss: 0.9042
[epoch 44][iter   80] loss: 129743.7969 RMSElog: 9.9523 grad_loss: 12963.4785 normal_loss: 0.9492
[epoch 44][iter   90] loss: 121838.3672 RMSElog: 9.7453 grad_loss: 12173.1494 normal_loss: 0.9425
[epoch 44][iter  100] loss: 125486.8672 RMSElog: 9.7758 grad_loss: 12537.9834 normal_loss: 0.9281
[epoch 44][iter  110] loss: 113895.6328 RMSElog: 9.2606 grad_loss: 11379.3926 normal_loss: 0.9106
[epoch 44][iter  120] loss: 124246.3594 RMSElog: 9.7165 grad_loss: 12413.9834 normal_loss: 0.9360
[epoch 44][iter  130] loss: 115495.2188 RMSElog: 9.6084 grad_loss: 11538.9688 normal_loss: 0.9442
[epoch 44][iter  140] loss: 177936.2812 RMSElog: 10.0381 grad_loss: 17782.6348 normal_loss: 0.9545
[epoch 44][iter  150] loss: 166492.4688 RMSElog: 9.8376 grad_loss: 16638.4531 normal_loss: 0.9558
[epoch 44][iter  160] loss: 194408.7812 RMSElog: 10.2924 grad_loss: 19429.6328 normal_loss: 0.9537
[epoch 44][iter  170] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 44][iter  180] loss: 153447.6875 RMSElog: 9.9051 grad_loss: 15333.9209 normal_loss: 0.9425
[epoch 44][iter  190] loss: 159340.4375 RMSElog: 9.9507 grad_loss: 15923.1426 normal_loss: 0.9500
[epoch 44][iter  200] loss: 101101.5781 RMSElog: 9.9274 grad_loss: 10099.3008 normal_loss: 0.9297
[epoch 44][iter  210] loss: 161646.4688 RMSElog: 10.1105 grad_loss: 16153.5762 normal_loss: 0.9608
[epoch 44][iter  220] loss: 110874.4688 RMSElog: 9.2829 grad_loss: 11077.2607 normal_loss: 0.9034
[epoch 44][iter  230] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 44][iter  240] loss: 105628.3672 RMSElog: 10.0899 grad_loss: 10551.8262 normal_loss: 0.9213
[epoch 44][iter  250] loss: 160642.9375 RMSElog: 9.9306 grad_loss: 16053.4121 normal_loss: 0.9504
[epoch 44][iter  260] loss: 162372.7500 RMSElog: 9.8226 grad_loss: 16226.4922 normal_loss: 0.9603
[epoch 44][iter  270] loss: 150364.6250 RMSElog: 9.9123 grad_loss: 15025.6094 normal_loss: 0.9418
[epoch 44][iter  280] loss: 106195.4219 RMSElog: 9.2531 grad_loss: 10609.3711 normal_loss: 0.9179
[epoch 44][iter  290] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 44][iter  300] loss: 136796.3438 RMSElog: 9.6524 grad_loss: 13669.0273 normal_loss: 0.9549
[epoch 44][iter  310] loss: 161633.2812 RMSElog: 10.0107 grad_loss: 16152.3652 normal_loss: 0.9518
[epoch 44][iter  320] loss: 231696.5312 RMSElog: 10.3202 grad_loss: 23158.3867 normal_loss: 0.9457
[epoch 44][iter  330] loss: 130145.6250 RMSElog: 9.7206 grad_loss: 13003.9072 normal_loss: 0.9344
[epoch 44][iter  340] loss: 189507.2500 RMSElog: 10.2157 grad_loss: 18939.5586 normal_loss: 0.9510
[epoch 44][iter  350] loss: 161084.5469 RMSElog: 9.9606 grad_loss: 16097.5430 normal_loss: 0.9512
[epoch 44][iter  360] loss: 126821.0234 RMSElog: 10.1398 grad_loss: 12671.0410 normal_loss: 0.9215
[epoch 44][iter  370] loss: 173574.0781 RMSElog: 10.1780 grad_loss: 17346.2734 normal_loss: 0.9575
[epoch 44][iter  380] loss: 114310.3047 RMSElog: 9.4026 grad_loss: 11420.7217 normal_loss: 0.9063
[epoch 44][iter  390] loss: 134471.5938 RMSElog: 9.9200 grad_loss: 13436.3281 normal_loss: 0.9111
[epoch 44][iter  400] loss: 170488.4688 RMSElog: 9.7164 grad_loss: 17038.1816 normal_loss: 0.9494
[epoch 44][iter  410] loss: 114827.1016 RMSElog: 9.7767 grad_loss: 11472.0010 normal_loss: 0.9329
[epoch 44][iter  420] loss: 148136.9375 RMSElog: 9.9557 grad_loss: 14802.7871 normal_loss: 0.9498
[epoch 44][iter  430] loss: 195671.7031 RMSElog: 10.1080 grad_loss: 19556.1133 normal_loss: 0.9494
[epoch 44][iter  440] loss: 104340.6328 RMSElog: 9.7692 grad_loss: 10423.3701 normal_loss: 0.9234
[epoch 44][iter  450] loss: 127776.8359 RMSElog: 10.0947 grad_loss: 12766.6396 normal_loss: 0.9490
[epoch 44][iter  460] loss: 165976.7500 RMSElog: 9.9385 grad_loss: 16586.7715 normal_loss: 0.9645
[epoch 44][iter  470] loss: 137296.6562 RMSElog: 9.9750 grad_loss: 13718.7412 normal_loss: 0.9495
[epoch 44][iter  480] loss: 184016.5469 RMSElog: 9.9468 grad_loss: 18390.7363 normal_loss: 0.9712
[epoch 44][iter  490] loss: 154609.8281 RMSElog: 9.8745 grad_loss: 15450.1855 normal_loss: 0.9220
[epoch 44][iter  500] loss: 160743.4062 RMSElog: 9.7965 grad_loss: 16063.6025 normal_loss: 0.9413
[epoch 44][iter  510] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 44][iter  520] loss: 142696.6875 RMSElog: 9.9612 grad_loss: 14258.7588 normal_loss: 0.9493
[epoch 44][iter  530] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 44][iter  540] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 44][iter  550] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 44][iter  560] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 44][iter  570] loss: 105877.8750 RMSElog: 9.7638 grad_loss: 10577.0986 normal_loss: 0.9249
[epoch 44][iter  580] loss: 179740.0625 RMSElog: 10.1206 grad_loss: 17962.9453 normal_loss: 0.9397
[epoch 44][iter  590] loss: 137252.6406 RMSElog: 9.3538 grad_loss: 13714.9785 normal_loss: 0.9319
[epoch 45][iter    0] loss: 161633.2656 RMSElog: 10.0107 grad_loss: 16152.3643 normal_loss: 0.9518
[epoch 45][iter   10] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 45][iter   20] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch 45][iter   30] loss: 111914.6406 RMSElog: 9.3004 grad_loss: 11181.2412 normal_loss: 0.9218
[epoch 45][iter   40] loss: 197520.7500 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.9662
[epoch 45][iter   50] loss: 195412.9844 RMSElog: 10.0493 grad_loss: 19530.2969 normal_loss: 0.9539
[epoch 45][iter   60] loss: 167412.9531 RMSElog: 9.7311 grad_loss: 16730.6387 normal_loss: 0.9260
[epoch 45][iter   70] loss: 154029.7812 RMSElog: 9.8645 grad_loss: 15392.1729 normal_loss: 0.9405
[epoch 45][iter   80] loss: 177063.6250 RMSElog: 10.1532 grad_loss: 17695.2383 normal_loss: 0.9719
[epoch 45][iter   90] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch 45][iter  100] loss: 167008.4531 RMSElog: 10.0165 grad_loss: 16689.8750 normal_loss: 0.9557
[epoch 45][iter  110] loss: 154609.8281 RMSElog: 9.8745 grad_loss: 15450.1855 normal_loss: 0.9220
[epoch 45][iter  120] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 45][iter  130] loss: 168688.8125 RMSElog: 9.8493 grad_loss: 16858.0781 normal_loss: 0.9524
[epoch 45][iter  140] loss: 153447.6875 RMSElog: 9.9051 grad_loss: 15333.9209 normal_loss: 0.9425
[epoch 45][iter  150] loss: 176260.7500 RMSElog: 10.0638 grad_loss: 17615.0703 normal_loss: 0.9395
[epoch 45][iter  160] loss: 147371.3906 RMSElog: 9.6635 grad_loss: 14726.5488 normal_loss: 0.9280
[epoch 45][iter  170] loss: 146465.6875 RMSElog: 10.2283 grad_loss: 14635.4062 normal_loss: 0.9337
[epoch 45][iter  180] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 45][iter  190] loss: 154165.2969 RMSElog: 10.0187 grad_loss: 15405.5605 normal_loss: 0.9498
[epoch 45][iter  200] loss: 141865.3906 RMSElog: 9.7199 grad_loss: 14175.8896 normal_loss: 0.9298
[epoch 45][iter  210] loss: 208770.3906 RMSElog: 10.1964 grad_loss: 20865.8984 normal_loss: 0.9442
[epoch 45][iter  220] loss: 156985.6250 RMSElog: 9.5765 grad_loss: 15688.0479 normal_loss: 0.9385
[epoch 45][iter  230] loss: 193024.5000 RMSElog: 9.9639 grad_loss: 19291.5117 normal_loss: 0.9740
[epoch 45][iter  240] loss: 109441.5234 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.9300
[epoch 45][iter  250] loss: 177814.3125 RMSElog: 10.0854 grad_loss: 17770.3887 normal_loss: 0.9571
[epoch 45][iter  260] loss: 134677.6719 RMSElog: 9.8776 grad_loss: 13456.9443 normal_loss: 0.9441
[epoch 45][iter  270] loss: 149369.9219 RMSElog: 10.0930 grad_loss: 14925.9766 normal_loss: 0.9225
[epoch 45][iter  280] loss: 106769.7500 RMSElog: 9.8688 grad_loss: 10666.1914 normal_loss: 0.9140
[epoch 45][iter  290] loss: 196437.8125 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.9584
[epoch 45][iter  300] loss: 179740.0625 RMSElog: 10.1206 grad_loss: 17962.9453 normal_loss: 0.9397
[epoch 45][iter  310] loss: 199070.3125 RMSElog: 9.9947 grad_loss: 19896.0605 normal_loss: 0.9757
[epoch 45][iter  320] loss: 104446.5625 RMSElog: 10.1932 grad_loss: 10433.5342 normal_loss: 0.9288
[epoch 45][iter  330] loss: 211925.8438 RMSElog: 10.1863 grad_loss: 21181.4551 normal_loss: 0.9436
[epoch 45][iter  340] loss: 167345.2500 RMSElog: 9.8843 grad_loss: 16723.6777 normal_loss: 0.9620
[epoch 45][iter  350] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 45][iter  360] loss: 185772.2500 RMSElog: 9.9702 grad_loss: 18566.2969 normal_loss: 0.9567
[epoch 45][iter  370] loss: 105816.5000 RMSElog: 9.4266 grad_loss: 10571.3066 normal_loss: 0.9171
[epoch 45][iter  380] loss: 162522.4531 RMSElog: 9.9860 grad_loss: 16241.3066 normal_loss: 0.9518
[epoch 45][iter  390] loss: 193978.6250 RMSElog: 10.3530 grad_loss: 19386.5586 normal_loss: 0.9518
[epoch 45][iter  400] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 45][iter  410] loss: 224077.6719 RMSElog: 10.3869 grad_loss: 22396.4219 normal_loss: 0.9584
[epoch 45][iter  420] loss: 164843.6719 RMSElog: 9.7972 grad_loss: 16473.6348 normal_loss: 0.9360
[epoch 45][iter  430] loss: 166542.4219 RMSElog: 9.8913 grad_loss: 16643.4043 normal_loss: 0.9482
[epoch 45][iter  440] loss: 151723.8750 RMSElog: 9.9680 grad_loss: 15161.4746 normal_loss: 0.9449
[epoch 45][iter  450] loss: 113426.9688 RMSElog: 9.7682 grad_loss: 11331.9922 normal_loss: 0.9362
[epoch 45][iter  460] loss: 185495.4062 RMSElog: 9.9310 grad_loss: 18538.6641 normal_loss: 0.9455
[epoch 45][iter  470] loss: 160074.2031 RMSElog: 9.7506 grad_loss: 15996.7432 normal_loss: 0.9257
[epoch 45][iter  480] loss: 135114.8750 RMSElog: 9.9265 grad_loss: 13500.6055 normal_loss: 0.9548
[epoch 45][iter  490] loss: 157706.0781 RMSElog: 9.9981 grad_loss: 15759.6602 normal_loss: 0.9499
[epoch 45][iter  500] loss: 206083.5156 RMSElog: 10.2501 grad_loss: 20597.1445 normal_loss: 0.9562
[epoch 45][iter  510] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 45][iter  520] loss: 169013.5312 RMSElog: 9.5880 grad_loss: 16890.8242 normal_loss: 0.9419
[epoch 45][iter  530] loss: 110603.0625 RMSElog: 9.8046 grad_loss: 11049.5654 normal_loss: 0.9364
[epoch 45][iter  540] loss: 148057.2500 RMSElog: 9.9895 grad_loss: 14794.7812 normal_loss: 0.9555
[epoch 45][iter  550] loss: 119655.7969 RMSElog: 9.6110 grad_loss: 11955.0312 normal_loss: 0.9378
[epoch 45][iter  560] loss: 137296.6406 RMSElog: 9.9750 grad_loss: 13718.7402 normal_loss: 0.9495
[epoch 45][iter  570] loss: 104749.2812 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.9281
[epoch 45][iter  580] loss: 201162.4062 RMSElog: 9.9531 grad_loss: 20105.3164 normal_loss: 0.9706
[epoch 45][iter  590] loss: 138950.6406 RMSElog: 9.9777 grad_loss: 13884.1387 normal_loss: 0.9482
[epoch 46][iter    0] loss: 167730.9531 RMSElog: 9.9663 grad_loss: 16762.1797 normal_loss: 0.9501
[epoch 46][iter   10] loss: 121959.7344 RMSElog: 9.7378 grad_loss: 12185.3047 normal_loss: 0.9314
[epoch 46][iter   20] loss: 115452.5781 RMSElog: 9.2301 grad_loss: 11535.1230 normal_loss: 0.9042
[epoch 46][iter   30] loss: 117693.8984 RMSElog: 9.6527 grad_loss: 11758.8105 normal_loss: 0.9267
[epoch 46][iter   40] loss: 157810.1406 RMSElog: 9.9254 grad_loss: 15770.1621 normal_loss: 0.9253
[epoch 46][iter   50] loss: 190938.1250 RMSElog: 10.3028 grad_loss: 19082.5566 normal_loss: 0.9541
[epoch 46][iter   60] loss: 178784.1250 RMSElog: 9.9460 grad_loss: 17867.5078 normal_loss: 0.9592
[epoch 46][iter   70] loss: 203973.6562 RMSElog: 10.4423 grad_loss: 20385.9727 normal_loss: 0.9505
[epoch 46][iter   80] loss: 196437.8125 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.9584
[epoch 46][iter   90] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 46][iter  100] loss: 198293.9219 RMSElog: 10.2275 grad_loss: 19818.2148 normal_loss: 0.9521
[epoch 46][iter  110] loss: 129743.7969 RMSElog: 9.9523 grad_loss: 12963.4785 normal_loss: 0.9492
[epoch 46][iter  120] loss: 182005.7031 RMSElog: 10.0998 grad_loss: 18189.5195 normal_loss: 0.9507
[epoch 46][iter  130] loss: 149387.5469 RMSElog: 9.9550 grad_loss: 14927.8516 normal_loss: 0.9483
[epoch 46][iter  140] loss: 110874.4688 RMSElog: 9.2829 grad_loss: 11077.2607 normal_loss: 0.9034
[epoch 46][iter  150] loss: 122331.3906 RMSElog: 9.7180 grad_loss: 12222.4795 normal_loss: 0.9418
[epoch 46][iter  160] loss: 184016.5469 RMSElog: 9.9468 grad_loss: 18390.7363 normal_loss: 0.9712
[epoch 46][iter  170] loss: 160825.5938 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.9491
[epoch 46][iter  180] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 46][iter  190] loss: 216509.5625 RMSElog: 10.1942 grad_loss: 21639.8223 normal_loss: 0.9420
[epoch 46][iter  200] loss: 164181.7344 RMSElog: 10.0104 grad_loss: 16407.1973 normal_loss: 0.9660
[epoch 46][iter  210] loss: 110808.0469 RMSElog: 9.7171 grad_loss: 11070.1562 normal_loss: 0.9312
[epoch 46][iter  220] loss: 214775.1719 RMSElog: 10.1719 grad_loss: 21466.3848 normal_loss: 0.9613
[epoch 46][iter  230] loss: 137296.6406 RMSElog: 9.9750 grad_loss: 13718.7402 normal_loss: 0.9495
[epoch 46][iter  240] loss: 224077.6719 RMSElog: 10.3869 grad_loss: 22396.4219 normal_loss: 0.9584
[epoch 46][iter  250] loss: 175008.6562 RMSElog: 9.9496 grad_loss: 17489.9434 normal_loss: 0.9734
[epoch 46][iter  260] loss: 158875.5312 RMSElog: 9.5853 grad_loss: 15877.0430 normal_loss: 0.9260
[epoch 46][iter  270] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch 46][iter  280] loss: 119895.5078 RMSElog: 9.3187 grad_loss: 11979.3164 normal_loss: 0.9157
[epoch 46][iter  290] loss: 181465.8125 RMSElog: 10.1136 grad_loss: 18135.5117 normal_loss: 0.9572
[epoch 46][iter  300] loss: 161633.2656 RMSElog: 10.0107 grad_loss: 16152.3643 normal_loss: 0.9518
[epoch 46][iter  310] loss: 154609.8281 RMSElog: 9.8745 grad_loss: 15450.1855 normal_loss: 0.9220
[epoch 46][iter  320] loss: 111518.2734 RMSElog: 9.6257 grad_loss: 11141.2676 normal_loss: 0.9335
[epoch 46][iter  330] loss: 206764.1875 RMSElog: 10.2849 grad_loss: 20665.1777 normal_loss: 0.9549
[epoch 46][iter  340] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 46][iter  350] loss: 167211.6250 RMSElog: 10.0285 grad_loss: 16710.1777 normal_loss: 0.9542
[epoch 46][iter  360] loss: 135215.1250 RMSElog: 9.9407 grad_loss: 13510.6152 normal_loss: 0.9572
[epoch 46][iter  370] loss: 114924.9844 RMSElog: 9.6925 grad_loss: 11481.8691 normal_loss: 0.9360
[epoch 46][iter  380] loss: 136869.7500 RMSElog: 9.5771 grad_loss: 13676.4668 normal_loss: 0.9315
[epoch 46][iter  390] loss: 216232.0312 RMSElog: 10.2147 grad_loss: 21612.0234 normal_loss: 0.9640
[epoch 46][iter  400] loss: 207885.1875 RMSElog: 10.4422 grad_loss: 20777.1328 normal_loss: 0.9460
[epoch 46][iter  410] loss: 175359.1875 RMSElog: 10.1476 grad_loss: 17524.8125 normal_loss: 0.9571
[epoch 46][iter  420] loss: 162835.5312 RMSElog: 9.9145 grad_loss: 16272.6904 normal_loss: 0.9492
[epoch 46][iter  430] loss: 203023.3438 RMSElog: 10.3036 grad_loss: 20291.0723 normal_loss: 0.9583
[epoch 46][iter  440] loss: 135699.4688 RMSElog: 9.6754 grad_loss: 13559.3340 normal_loss: 0.9364
[epoch 46][iter  450] loss: 188717.5625 RMSElog: 10.0336 grad_loss: 18860.7715 normal_loss: 0.9509
[epoch 46][iter  460] loss: 198743.4219 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.9643
[epoch 46][iter  470] loss: 189507.2500 RMSElog: 10.2157 grad_loss: 18939.5586 normal_loss: 0.9510
[epoch 46][iter  480] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 46][iter  490] loss: 108409.6484 RMSElog: 9.2105 grad_loss: 10830.8506 normal_loss: 0.9033
[epoch 46][iter  500] loss: 220587.5781 RMSElog: 10.2995 grad_loss: 22047.5117 normal_loss: 0.9466
[epoch 46][iter  510] loss: 162522.4531 RMSElog: 9.9860 grad_loss: 16241.3066 normal_loss: 0.9518
[epoch 46][iter  520] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch 46][iter  530] loss: 145332.8438 RMSElog: 10.0385 grad_loss: 14522.2842 normal_loss: 0.9619
[epoch 46][iter  540] loss: 188502.1875 RMSElog: 10.1669 grad_loss: 18839.0801 normal_loss: 0.9722
[epoch 46][iter  550] loss: 124246.3594 RMSElog: 9.7165 grad_loss: 12413.9834 normal_loss: 0.9360
[epoch 46][iter  560] loss: 170542.9531 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.9688
[epoch 46][iter  570] loss: 197520.7500 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.9662
[epoch 46][iter  580] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch 46][iter  590] loss: 99107.7500 RMSElog: 9.5230 grad_loss: 9900.3428 normal_loss: 0.9094
[epoch 47][iter    0] loss: 140645.6875 RMSElog: 10.1118 grad_loss: 14053.4873 normal_loss: 0.9695
[epoch 47][iter   10] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 47][iter   20] loss: 151723.8750 RMSElog: 9.9680 grad_loss: 15161.4746 normal_loss: 0.9449
[epoch 47][iter   30] loss: 148057.2500 RMSElog: 9.9895 grad_loss: 14794.7812 normal_loss: 0.9555
[epoch 47][iter   40] loss: 182315.9688 RMSElog: 10.1291 grad_loss: 18220.5039 normal_loss: 0.9652
[epoch 47][iter   50] loss: 172755.6875 RMSElog: 10.0251 grad_loss: 17264.6016 normal_loss: 0.9419
[epoch 47][iter   60] loss: 164767.1875 RMSElog: 9.8398 grad_loss: 16465.9102 normal_loss: 0.9691
[epoch 47][iter   70] loss: 145409.6719 RMSElog: 9.8330 grad_loss: 14530.1904 normal_loss: 0.9445
[epoch 47][iter   80] loss: 141228.9219 RMSElog: 9.9926 grad_loss: 14111.9531 normal_loss: 0.9477
[epoch 47][iter   90] loss: 160074.2031 RMSElog: 9.7506 grad_loss: 15996.7432 normal_loss: 0.9257
[epoch 47][iter  100] loss: 120765.1875 RMSElog: 9.5441 grad_loss: 12066.0400 normal_loss: 0.9348
[epoch 47][iter  110] loss: 206400.7812 RMSElog: 10.3027 grad_loss: 20628.8281 normal_loss: 0.9467
[epoch 47][iter  120] loss: 147765.9219 RMSElog: 10.0607 grad_loss: 14765.6104 normal_loss: 0.9219
[epoch 47][iter  130] loss: 161285.2188 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.9476
[epoch 47][iter  140] loss: 110808.0469 RMSElog: 9.7171 grad_loss: 11070.1562 normal_loss: 0.9312
[epoch 47][iter  150] loss: 138606.5781 RMSElog: 9.6389 grad_loss: 13850.0977 normal_loss: 0.9205
[epoch 47][iter  160] loss: 161088.9688 RMSElog: 9.9258 grad_loss: 16098.0254 normal_loss: 0.9455
[epoch 47][iter  170] loss: 148184.5469 RMSElog: 10.0681 grad_loss: 14807.4355 normal_loss: 0.9504
[epoch 47][iter  180] loss: 146161.1562 RMSElog: 10.0682 grad_loss: 14605.1289 normal_loss: 0.9190
[epoch 47][iter  190] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 47][iter  200] loss: 150364.6250 RMSElog: 9.9123 grad_loss: 15025.6094 normal_loss: 0.9418
[epoch 47][iter  210] loss: 132707.3594 RMSElog: 9.7842 grad_loss: 13260.0049 normal_loss: 0.9472
[epoch 47][iter  220] loss: 110603.0625 RMSElog: 9.8046 grad_loss: 11049.5654 normal_loss: 0.9364
[epoch 47][iter  230] loss: 150323.7656 RMSElog: 10.0510 grad_loss: 15021.3848 normal_loss: 0.9410
[epoch 47][iter  240] loss: 129743.7969 RMSElog: 9.9523 grad_loss: 12963.4785 normal_loss: 0.9492
[epoch 47][iter  250] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 47][iter  260] loss: 182859.0469 RMSElog: 9.8110 grad_loss: 18275.1250 normal_loss: 0.9678
[epoch 47][iter  270] loss: 218625.8750 RMSElog: 10.2839 grad_loss: 21851.3457 normal_loss: 0.9592
[epoch 47][iter  280] loss: 138057.5156 RMSElog: 9.5188 grad_loss: 13795.3184 normal_loss: 0.9138
[epoch 47][iter  290] loss: 181942.5625 RMSElog: 10.0291 grad_loss: 18183.2793 normal_loss: 0.9464
[epoch 47][iter  300] loss: 127463.1875 RMSElog: 9.4952 grad_loss: 12735.9082 normal_loss: 0.9153
[epoch 47][iter  310] loss: 114827.1094 RMSElog: 9.7767 grad_loss: 11472.0020 normal_loss: 0.9329
[epoch 47][iter  320] loss: 137249.3438 RMSElog: 9.7342 grad_loss: 13714.2764 normal_loss: 0.9239
[epoch 47][iter  330] loss: 104340.6328 RMSElog: 9.7692 grad_loss: 10423.3701 normal_loss: 0.9234
[epoch 47][iter  340] loss: 120590.1719 RMSElog: 9.9054 grad_loss: 12048.1719 normal_loss: 0.9408
[epoch 47][iter  350] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 47][iter  360] loss: 146960.1406 RMSElog: 10.0979 grad_loss: 14684.9941 normal_loss: 0.9220
[epoch 47][iter  370] loss: 144657.9844 RMSElog: 9.9197 grad_loss: 14454.9258 normal_loss: 0.9518
[epoch 47][iter  380] loss: 193024.5000 RMSElog: 9.9639 grad_loss: 19291.5117 normal_loss: 0.9740
[epoch 47][iter  390] loss: 196277.7188 RMSElog: 10.2453 grad_loss: 19616.5664 normal_loss: 0.9595
[epoch 47][iter  400] loss: 162556.3906 RMSElog: 9.9091 grad_loss: 16244.7939 normal_loss: 0.9368
[epoch 47][iter  410] loss: 168688.8125 RMSElog: 9.8493 grad_loss: 16858.0781 normal_loss: 0.9524
[epoch 47][iter  420] loss: 137252.6406 RMSElog: 9.3538 grad_loss: 13714.9785 normal_loss: 0.9319
[epoch 47][iter  430] loss: 105828.7812 RMSElog: 10.1032 grad_loss: 10571.8545 normal_loss: 0.9195
[epoch 47][iter  440] loss: 161646.4688 RMSElog: 10.1105 grad_loss: 16153.5762 normal_loss: 0.9608
[epoch 47][iter  450] loss: 218949.8281 RMSElog: 10.4462 grad_loss: 21883.5918 normal_loss: 0.9447
[epoch 47][iter  460] loss: 165020.2344 RMSElog: 9.7791 grad_loss: 16491.2910 normal_loss: 0.9530
[epoch 47][iter  470] loss: 195999.5625 RMSElog: 10.1749 grad_loss: 19588.8047 normal_loss: 0.9756
[epoch 47][iter  480] loss: 106516.8047 RMSElog: 9.6966 grad_loss: 10641.0557 normal_loss: 0.9285
[epoch 47][iter  490] loss: 218457.8281 RMSElog: 10.1255 grad_loss: 21834.7168 normal_loss: 0.9418
[epoch 47][iter  500] loss: 142016.3906 RMSElog: 9.9191 grad_loss: 14190.7676 normal_loss: 0.9526
[epoch 47][iter  510] loss: 127499.3281 RMSElog: 9.2769 grad_loss: 12739.7178 normal_loss: 0.9374
[epoch 47][iter  520] loss: 114149.3750 RMSElog: 9.2655 grad_loss: 11404.7646 normal_loss: 0.9073
[epoch 47][iter  530] loss: 224077.7188 RMSElog: 10.3869 grad_loss: 22396.4258 normal_loss: 0.9584
[epoch 47][iter  540] loss: 215542.7500 RMSElog: 10.4358 grad_loss: 21542.8887 normal_loss: 0.9514
[epoch 47][iter  550] loss: 112535.5625 RMSElog: 9.5823 grad_loss: 11243.0459 normal_loss: 0.9289
[epoch 47][iter  560] loss: 142005.0781 RMSElog: 9.9168 grad_loss: 14189.6533 normal_loss: 0.9371
[epoch 47][iter  570] loss: 169013.5312 RMSElog: 9.5880 grad_loss: 16890.8242 normal_loss: 0.9419
[epoch 47][iter  580] loss: 188717.5625 RMSElog: 10.0336 grad_loss: 18860.7715 normal_loss: 0.9509
[epoch 47][iter  590] loss: 144191.5938 RMSElog: 9.6650 grad_loss: 14408.5654 normal_loss: 0.9284
[epoch 48][iter    0] loss: 162363.8906 RMSElog: 9.7464 grad_loss: 16225.6777 normal_loss: 0.9661
[epoch 48][iter   10] loss: 142016.3906 RMSElog: 9.9191 grad_loss: 14190.7676 normal_loss: 0.9526
[epoch 48][iter   20] loss: 141118.5312 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.9477
[epoch 48][iter   30] loss: 154609.8281 RMSElog: 9.8745 grad_loss: 15450.1855 normal_loss: 0.9220
[epoch 48][iter   40] loss: 159798.6094 RMSElog: 9.8075 grad_loss: 15969.1260 normal_loss: 0.9263
[epoch 48][iter   50] loss: 172248.5156 RMSElog: 9.5166 grad_loss: 17214.3730 normal_loss: 0.9619
[epoch 48][iter   60] loss: 133024.8594 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.9261
[epoch 48][iter   70] loss: 153723.9844 RMSElog: 9.9609 grad_loss: 15361.4902 normal_loss: 0.9475
[epoch 48][iter   80] loss: 180425.2344 RMSElog: 10.0354 grad_loss: 18031.5332 normal_loss: 0.9552
[epoch 48][iter   90] loss: 148793.9688 RMSElog: 10.1047 grad_loss: 14868.3438 normal_loss: 0.9480
[epoch 48][iter  100] loss: 112535.5625 RMSElog: 9.5823 grad_loss: 11243.0459 normal_loss: 0.9289
[epoch 48][iter  110] loss: 178468.8906 RMSElog: 9.9039 grad_loss: 17836.0469 normal_loss: 0.9380
[epoch 48][iter  120] loss: 129205.9375 RMSElog: 9.8851 grad_loss: 12909.7734 normal_loss: 0.9356
[epoch 48][iter  130] loss: 158034.0625 RMSElog: 9.9527 grad_loss: 15792.5088 normal_loss: 0.9445
[epoch 48][iter  140] loss: 239768.0938 RMSElog: 10.2366 grad_loss: 23965.6250 normal_loss: 0.9466
[epoch 48][iter  150] loss: 146942.0781 RMSElog: 9.4227 grad_loss: 14683.8535 normal_loss: 0.9314
[epoch 48][iter  160] loss: 120440.5938 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.9240
[epoch 48][iter  170] loss: 177936.2812 RMSElog: 10.0381 grad_loss: 17782.6348 normal_loss: 0.9545
[epoch 48][iter  180] loss: 136869.7500 RMSElog: 9.5771 grad_loss: 13676.4668 normal_loss: 0.9315
[epoch 48][iter  190] loss: 154165.2969 RMSElog: 10.0187 grad_loss: 15405.5605 normal_loss: 0.9498
[epoch 48][iter  200] loss: 218949.8281 RMSElog: 10.4462 grad_loss: 21883.5918 normal_loss: 0.9447
[epoch 48][iter  210] loss: 160782.5156 RMSElog: 9.7710 grad_loss: 16067.5547 normal_loss: 0.9244
[epoch 48][iter  220] loss: 111712.9062 RMSElog: 9.7826 grad_loss: 11160.5801 normal_loss: 0.9290
[epoch 48][iter  230] loss: 195671.7031 RMSElog: 10.1080 grad_loss: 19556.1133 normal_loss: 0.9494
[epoch 48][iter  240] loss: 160667.2500 RMSElog: 9.9014 grad_loss: 16055.8711 normal_loss: 0.9534
[epoch 48][iter  250] loss: 188502.1875 RMSElog: 10.1669 grad_loss: 18839.0801 normal_loss: 0.9722
[epoch 48][iter  260] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 48][iter  270] loss: 221213.4219 RMSElog: 10.1740 grad_loss: 22110.2266 normal_loss: 0.9415
[epoch 48][iter  280] loss: 162711.9688 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.9427
[epoch 48][iter  290] loss: 155482.2031 RMSElog: 10.0818 grad_loss: 15537.1826 normal_loss: 0.9552
[epoch 48][iter  300] loss: 175486.0625 RMSElog: 10.0393 grad_loss: 17537.6094 normal_loss: 0.9563
[epoch 48][iter  310] loss: 128883.6328 RMSElog: 9.8798 grad_loss: 12877.5244 normal_loss: 0.9593
[epoch 48][iter  320] loss: 110808.0469 RMSElog: 9.7171 grad_loss: 11070.1562 normal_loss: 0.9312
[epoch 48][iter  330] loss: 165954.0938 RMSElog: 9.8997 grad_loss: 16584.5449 normal_loss: 0.9646
[epoch 48][iter  340] loss: 100749.6875 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.9377
[epoch 48][iter  350] loss: 139061.3750 RMSElog: 9.6201 grad_loss: 13895.5771 normal_loss: 0.9401
[epoch 48][iter  360] loss: 153594.7031 RMSElog: 9.8426 grad_loss: 15348.6826 normal_loss: 0.9453
[epoch 48][iter  370] loss: 113895.6328 RMSElog: 9.2606 grad_loss: 11379.3926 normal_loss: 0.9106
[epoch 48][iter  380] loss: 151401.7031 RMSElog: 9.4414 grad_loss: 15129.7930 normal_loss: 0.9361
[epoch 48][iter  390] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 48][iter  400] loss: 181983.5312 RMSElog: 10.0741 grad_loss: 18187.3320 normal_loss: 0.9464
[epoch 48][iter  410] loss: 122386.0234 RMSElog: 9.6688 grad_loss: 12227.9971 normal_loss: 0.9366
[epoch 48][iter  420] loss: 177063.6250 RMSElog: 10.1532 grad_loss: 17695.2383 normal_loss: 0.9719
[epoch 48][iter  430] loss: 189507.2500 RMSElog: 10.2157 grad_loss: 18939.5586 normal_loss: 0.9510
[epoch 48][iter  440] loss: 80097.4062 RMSElog: 9.2433 grad_loss: 7999.5806 normal_loss: 0.9166
[epoch 48][iter  450] loss: 204650.3281 RMSElog: 10.1934 grad_loss: 20453.8633 normal_loss: 0.9763
[epoch 48][iter  460] loss: 163253.2500 RMSElog: 9.8740 grad_loss: 16314.5010 normal_loss: 0.9499
[epoch 48][iter  470] loss: 194578.5781 RMSElog: 10.2312 grad_loss: 19446.6680 normal_loss: 0.9596
[epoch 48][iter  480] loss: 134406.1875 RMSElog: 9.9402 grad_loss: 13429.7246 normal_loss: 0.9539
[epoch 48][iter  490] loss: 172966.9375 RMSElog: 9.9430 grad_loss: 17285.8008 normal_loss: 0.9485
[epoch 48][iter  500] loss: 163272.7188 RMSElog: 10.0261 grad_loss: 16316.3047 normal_loss: 0.9400
[epoch 48][iter  510] loss: 148057.2500 RMSElog: 9.9895 grad_loss: 14794.7812 normal_loss: 0.9555
[epoch 48][iter  520] loss: 214493.2188 RMSElog: 10.3525 grad_loss: 21438.0078 normal_loss: 0.9611
[epoch 48][iter  530] loss: 178076.4688 RMSElog: 9.8778 grad_loss: 17796.8457 normal_loss: 0.9233
[epoch 48][iter  540] loss: 197714.9844 RMSElog: 10.4355 grad_loss: 19760.1094 normal_loss: 0.9532
[epoch 48][iter  550] loss: 105896.9375 RMSElog: 9.7662 grad_loss: 10578.9961 normal_loss: 0.9310
[epoch 48][iter  560] loss: 128488.4375 RMSElog: 9.7402 grad_loss: 12838.1719 normal_loss: 0.9319
[epoch 48][iter  570] loss: 160743.4062 RMSElog: 9.7965 grad_loss: 16063.6025 normal_loss: 0.9413
[epoch 48][iter  580] loss: 167730.9531 RMSElog: 9.9663 grad_loss: 16762.1797 normal_loss: 0.9501
[epoch 48][iter  590] loss: 162433.1875 RMSElog: 9.8183 grad_loss: 16232.5488 normal_loss: 0.9510
[epoch 49][iter    0] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 49][iter   10] loss: 226949.5156 RMSElog: 10.2029 grad_loss: 22683.8047 normal_loss: 0.9430
[epoch 49][iter   20] loss: 125315.5625 RMSElog: 9.7124 grad_loss: 12520.9131 normal_loss: 0.9309
[epoch 49][iter   30] loss: 196842.3125 RMSElog: 10.1249 grad_loss: 19673.1523 normal_loss: 0.9534
[epoch 49][iter   40] loss: 128883.6406 RMSElog: 9.8798 grad_loss: 12877.5254 normal_loss: 0.9593
[epoch 49][iter   50] loss: 149135.0000 RMSElog: 10.0932 grad_loss: 14902.4570 normal_loss: 0.9500
[epoch 49][iter   60] loss: 197520.7500 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.9662
[epoch 49][iter   70] loss: 195413.0312 RMSElog: 10.0493 grad_loss: 19530.3008 normal_loss: 0.9539
[epoch 49][iter   80] loss: 158230.6094 RMSElog: 9.9234 grad_loss: 15812.1895 normal_loss: 0.9483
[epoch 49][iter   90] loss: 177195.4844 RMSElog: 10.1516 grad_loss: 17708.4512 normal_loss: 0.9458
[epoch 49][iter  100] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 49][iter  110] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 49][iter  120] loss: 131942.8750 RMSElog: 9.8414 grad_loss: 13183.5000 normal_loss: 0.9453
[epoch 49][iter  130] loss: 177814.3125 RMSElog: 10.0854 grad_loss: 17770.3887 normal_loss: 0.9571
[epoch 49][iter  140] loss: 147371.3906 RMSElog: 9.6635 grad_loss: 14726.5488 normal_loss: 0.9280
[epoch 49][iter  150] loss: 199070.3125 RMSElog: 9.9947 grad_loss: 19896.0605 normal_loss: 0.9757
[epoch 49][iter  160] loss: 130527.6094 RMSElog: 9.8914 grad_loss: 13041.9180 normal_loss: 0.9509
[epoch 49][iter  170] loss: 80097.4062 RMSElog: 9.2433 grad_loss: 7999.5806 normal_loss: 0.9166
[epoch 49][iter  180] loss: 124246.3594 RMSElog: 9.7165 grad_loss: 12413.9834 normal_loss: 0.9360
[epoch 49][iter  190] loss: 140938.8594 RMSElog: 9.7483 grad_loss: 14083.1953 normal_loss: 0.9424
[epoch 49][iter  200] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 49][iter  210] loss: 205362.7344 RMSElog: 10.1686 grad_loss: 20525.1582 normal_loss: 0.9475
[epoch 49][iter  220] loss: 169013.5625 RMSElog: 9.5880 grad_loss: 16890.8262 normal_loss: 0.9419
[epoch 49][iter  230] loss: 167794.0469 RMSElog: 9.8335 grad_loss: 16768.6211 normal_loss: 0.9500
[epoch 49][iter  240] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch 49][iter  250] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 49][iter  260] loss: 154165.2969 RMSElog: 10.0187 grad_loss: 15405.5605 normal_loss: 0.9498
[epoch 49][iter  270] loss: 123525.9062 RMSElog: 9.3524 grad_loss: 12342.2930 normal_loss: 0.9450
[epoch 49][iter  280] loss: 217174.7812 RMSElog: 10.2254 grad_loss: 21706.2910 normal_loss: 0.9635
[epoch 49][iter  290] loss: 103305.2422 RMSElog: 9.5543 grad_loss: 10320.0674 normal_loss: 0.9024
[epoch 49][iter  300] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 49][iter  310] loss: 178784.0938 RMSElog: 9.9460 grad_loss: 17867.5059 normal_loss: 0.9592
[epoch 49][iter  320] loss: 121866.5156 RMSElog: 9.8422 grad_loss: 12175.8965 normal_loss: 0.9131
[epoch 49][iter  330] loss: 170542.9531 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.9688
[epoch 49][iter  340] loss: 183095.1562 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.9696
[epoch 49][iter  350] loss: 107956.6094 RMSElog: 10.0900 grad_loss: 10784.6504 normal_loss: 0.9209
[epoch 49][iter  360] loss: 87697.6250 RMSElog: 9.9487 grad_loss: 8758.8750 normal_loss: 0.9395
[epoch 49][iter  370] loss: 142544.5156 RMSElog: 10.1645 grad_loss: 14243.3457 normal_loss: 0.9425
[epoch 49][iter  380] loss: 138606.5781 RMSElog: 9.6389 grad_loss: 13850.0977 normal_loss: 0.9205
[epoch 49][iter  390] loss: 182318.8125 RMSElog: 10.1008 grad_loss: 18220.8418 normal_loss: 0.9384
[epoch 49][iter  400] loss: 104127.8047 RMSElog: 9.6242 grad_loss: 10402.2324 normal_loss: 0.9237
[epoch 49][iter  410] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 49][iter  420] loss: 119655.7969 RMSElog: 9.6110 grad_loss: 11955.0312 normal_loss: 0.9378
[epoch 49][iter  430] loss: 132012.6719 RMSElog: 9.6802 grad_loss: 13190.6582 normal_loss: 0.9291
[epoch 49][iter  440] loss: 191559.9688 RMSElog: 9.9749 grad_loss: 19145.0742 normal_loss: 0.9477
[epoch 49][iter  450] loss: 150323.7656 RMSElog: 10.0510 grad_loss: 15021.3848 normal_loss: 0.9410
[epoch 49][iter  460] loss: 154290.2500 RMSElog: 9.8471 grad_loss: 15418.2334 normal_loss: 0.9458
[epoch 49][iter  470] loss: 191825.0781 RMSElog: 10.3012 grad_loss: 19171.2500 normal_loss: 0.9570
[epoch 49][iter  480] loss: 150321.2812 RMSElog: 9.9248 grad_loss: 15021.2656 normal_loss: 0.9385
[epoch 49][iter  490] loss: 139433.9219 RMSElog: 9.8139 grad_loss: 13932.6191 normal_loss: 0.9591
[epoch 49][iter  500] loss: 208770.3906 RMSElog: 10.1964 grad_loss: 20865.8984 normal_loss: 0.9442
[epoch 49][iter  510] loss: 146960.1250 RMSElog: 10.0979 grad_loss: 14684.9922 normal_loss: 0.9220
[epoch 49][iter  520] loss: 180425.2344 RMSElog: 10.0354 grad_loss: 18031.5332 normal_loss: 0.9552
[epoch 49][iter  530] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 49][iter  540] loss: 165954.0938 RMSElog: 9.8997 grad_loss: 16584.5449 normal_loss: 0.9646
[epoch 49][iter  550] loss: 223875.4062 RMSElog: 10.3929 grad_loss: 22376.1953 normal_loss: 0.9536
[epoch 49][iter  560] loss: 103509.2188 RMSElog: 9.9787 grad_loss: 10340.0186 normal_loss: 0.9251
[epoch 49][iter  570] loss: 152593.5000 RMSElog: 9.8773 grad_loss: 15248.5449 normal_loss: 0.9283
[epoch 49][iter  580] loss: 228053.0312 RMSElog: 10.2288 grad_loss: 22794.1328 normal_loss: 0.9422
[epoch 49][iter  590] loss: 139878.0625 RMSElog: 9.8515 grad_loss: 13977.0225 normal_loss: 0.9327
[epoch 50][iter    0] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 50][iter   10] loss: 154626.7656 RMSElog: 9.9098 grad_loss: 15451.8066 normal_loss: 0.9596
[epoch 50][iter   20] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 50][iter   30] loss: 143534.0938 RMSElog: 9.7662 grad_loss: 14342.7061 normal_loss: 0.9374
[epoch 50][iter   40] loss: 202119.8125 RMSElog: 10.2544 grad_loss: 20200.7715 normal_loss: 0.9549
[epoch 50][iter   50] loss: 159824.3594 RMSElog: 9.8973 grad_loss: 15971.5811 normal_loss: 0.9569
[epoch 50][iter   60] loss: 135814.7969 RMSElog: 9.5386 grad_loss: 13571.0137 normal_loss: 0.9281
[epoch 50][iter   70] loss: 139433.9219 RMSElog: 9.8139 grad_loss: 13932.6191 normal_loss: 0.9591
[epoch 50][iter   80] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 50][iter   90] loss: 122912.0625 RMSElog: 9.7328 grad_loss: 12280.5225 normal_loss: 0.9509
[epoch 50][iter  100] loss: 146942.0781 RMSElog: 9.4227 grad_loss: 14683.8535 normal_loss: 0.9314
[epoch 50][iter  110] loss: 119655.7969 RMSElog: 9.6110 grad_loss: 11955.0312 normal_loss: 0.9378
[epoch 50][iter  120] loss: 181293.3438 RMSElog: 10.0009 grad_loss: 18118.3809 normal_loss: 0.9531
[epoch 50][iter  130] loss: 140333.8125 RMSElog: 9.8261 grad_loss: 14022.6191 normal_loss: 0.9368
[epoch 50][iter  140] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 50][iter  150] loss: 114173.8984 RMSElog: 9.3600 grad_loss: 11407.1230 normal_loss: 0.9061
[epoch 50][iter  160] loss: 153594.7031 RMSElog: 9.8426 grad_loss: 15348.6826 normal_loss: 0.9453
[epoch 50][iter  170] loss: 103815.4375 RMSElog: 9.7764 grad_loss: 10370.8340 normal_loss: 0.9338
[epoch 50][iter  180] loss: 100749.6875 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.9377
[epoch 50][iter  190] loss: 107073.5156 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.9313
[epoch 50][iter  200] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 50][iter  210] loss: 166492.4688 RMSElog: 9.8376 grad_loss: 16638.4531 normal_loss: 0.9558
[epoch 50][iter  220] loss: 203023.3438 RMSElog: 10.3036 grad_loss: 20291.0723 normal_loss: 0.9583
[epoch 50][iter  230] loss: 231696.5312 RMSElog: 10.3202 grad_loss: 23158.3867 normal_loss: 0.9457
[epoch 50][iter  240] loss: 160934.5156 RMSElog: 9.8035 grad_loss: 16082.6846 normal_loss: 0.9629
[epoch 50][iter  250] loss: 132012.6719 RMSElog: 9.6802 grad_loss: 13190.6582 normal_loss: 0.9291
[epoch 50][iter  260] loss: 132425.4375 RMSElog: 10.0155 grad_loss: 13231.5801 normal_loss: 0.9468
[epoch 50][iter  270] loss: 136533.4688 RMSElog: 9.6756 grad_loss: 13642.7363 normal_loss: 0.9359
[epoch 50][iter  280] loss: 119895.5078 RMSElog: 9.3187 grad_loss: 11979.3164 normal_loss: 0.9157
[epoch 50][iter  290] loss: 163786.3906 RMSElog: 9.7419 grad_loss: 16367.9502 normal_loss: 0.9470
[epoch 50][iter  300] loss: 195412.9844 RMSElog: 10.0493 grad_loss: 19530.2969 normal_loss: 0.9539
[epoch 50][iter  310] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 50][iter  320] loss: 109260.8984 RMSElog: 9.7819 grad_loss: 10915.3799 normal_loss: 0.9279
[epoch 50][iter  330] loss: 147915.7812 RMSElog: 10.0131 grad_loss: 14780.6104 normal_loss: 0.9547
[epoch 50][iter  340] loss: 215955.5312 RMSElog: 10.2675 grad_loss: 21584.3203 normal_loss: 0.9654
[epoch 50][iter  350] loss: 130145.6250 RMSElog: 9.7206 grad_loss: 13003.9072 normal_loss: 0.9344
[epoch 50][iter  360] loss: 160667.2500 RMSElog: 9.9014 grad_loss: 16055.8711 normal_loss: 0.9534
[epoch 50][iter  370] loss: 135966.2969 RMSElog: 9.6504 grad_loss: 13586.0273 normal_loss: 0.9522
[epoch 50][iter  380] loss: 167740.4688 RMSElog: 9.8540 grad_loss: 16763.2344 normal_loss: 0.9591
[epoch 50][iter  390] loss: 124932.5703 RMSElog: 9.4215 grad_loss: 12482.8789 normal_loss: 0.9558
[epoch 50][iter  400] loss: 226865.1406 RMSElog: 10.2887 grad_loss: 22675.2832 normal_loss: 0.9418
[epoch 50][iter  410] loss: 218547.0156 RMSElog: 10.4419 grad_loss: 21843.3086 normal_loss: 0.9515
[epoch 50][iter  420] loss: 179740.0625 RMSElog: 10.1206 grad_loss: 17962.9453 normal_loss: 0.9397
[epoch 50][iter  430] loss: 109101.1250 RMSElog: 9.7363 grad_loss: 10899.4590 normal_loss: 0.9167
[epoch 50][iter  440] loss: 197715.0000 RMSElog: 10.4355 grad_loss: 19760.1113 normal_loss: 0.9532
[epoch 50][iter  450] loss: 172683.9219 RMSElog: 9.9061 grad_loss: 17257.5312 normal_loss: 0.9550
[epoch 50][iter  460] loss: 124246.3594 RMSElog: 9.7165 grad_loss: 12413.9834 normal_loss: 0.9360
[epoch 50][iter  470] loss: 100663.8984 RMSElog: 9.9598 grad_loss: 10055.5020 normal_loss: 0.9277
[epoch 50][iter  480] loss: 182476.7344 RMSElog: 9.9672 grad_loss: 18236.7656 normal_loss: 0.9407
[epoch 50][iter  490] loss: 224257.9688 RMSElog: 10.2842 grad_loss: 22414.5605 normal_loss: 0.9521
[epoch 50][iter  500] loss: 179901.4844 RMSElog: 9.8267 grad_loss: 17979.3633 normal_loss: 0.9589
[epoch 50][iter  510] loss: 148239.1406 RMSElog: 9.8055 grad_loss: 14813.1689 normal_loss: 0.9395
[epoch 50][iter  520] loss: 137249.3438 RMSElog: 9.7342 grad_loss: 13714.2764 normal_loss: 0.9239
[epoch 50][iter  530] loss: 104749.2812 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.9281
[epoch 50][iter  540] loss: 158230.6094 RMSElog: 9.9234 grad_loss: 15812.1895 normal_loss: 0.9483
[epoch 50][iter  550] loss: 115500.4766 RMSElog: 9.9924 grad_loss: 11539.1230 normal_loss: 0.9328
[epoch 50][iter  560] loss: 162976.7812 RMSElog: 9.6016 grad_loss: 16287.1572 normal_loss: 0.9201
[epoch 50][iter  570] loss: 114893.3984 RMSElog: 9.2562 grad_loss: 11479.1777 normal_loss: 0.9067
[epoch 50][iter  580] loss: 162556.3906 RMSElog: 9.9091 grad_loss: 16244.7939 normal_loss: 0.9368
[epoch 50][iter  590] loss: 134677.6719 RMSElog: 9.8776 grad_loss: 13456.9443 normal_loss: 0.9441
[epoch 51][iter    0] loss: 142138.5156 RMSElog: 9.7967 grad_loss: 14203.1260 normal_loss: 0.9291
[epoch 51][iter   10] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 51][iter   20] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 51][iter   30] loss: 201373.6719 RMSElog: 10.3870 grad_loss: 20126.0312 normal_loss: 0.9491
[epoch 51][iter   40] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch 51][iter   50] loss: 165020.2344 RMSElog: 9.7791 grad_loss: 16491.2910 normal_loss: 0.9530
[epoch 51][iter   60] loss: 167084.9219 RMSElog: 9.8660 grad_loss: 16697.6582 normal_loss: 0.9689
[epoch 51][iter   70] loss: 135966.2969 RMSElog: 9.6504 grad_loss: 13586.0273 normal_loss: 0.9522
[epoch 51][iter   80] loss: 156253.7656 RMSElog: 9.8231 grad_loss: 15614.6211 normal_loss: 0.9316
[epoch 51][iter   90] loss: 177664.5469 RMSElog: 9.7808 grad_loss: 17755.7363 normal_loss: 0.9369
[epoch 51][iter  100] loss: 188645.4531 RMSElog: 10.1590 grad_loss: 18853.4082 normal_loss: 0.9794
[epoch 51][iter  110] loss: 153099.1094 RMSElog: 9.8355 grad_loss: 15299.1445 normal_loss: 0.9304
[epoch 51][iter  120] loss: 163272.7188 RMSElog: 10.0261 grad_loss: 16316.3047 normal_loss: 0.9400
[epoch 51][iter  130] loss: 185772.2500 RMSElog: 9.9702 grad_loss: 18566.2969 normal_loss: 0.9567
[epoch 51][iter  140] loss: 156173.3594 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.9482
[epoch 51][iter  150] loss: 162522.4531 RMSElog: 9.9860 grad_loss: 16241.3066 normal_loss: 0.9518
[epoch 51][iter  160] loss: 139154.8594 RMSElog: 9.5986 grad_loss: 13904.9707 normal_loss: 0.9164
[epoch 51][iter  170] loss: 214808.7500 RMSElog: 10.1872 grad_loss: 21469.7461 normal_loss: 0.9423
[epoch 51][iter  180] loss: 106769.7500 RMSElog: 9.8688 grad_loss: 10666.1914 normal_loss: 0.9140
[epoch 51][iter  190] loss: 161285.2188 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.9476
[epoch 51][iter  200] loss: 189507.2500 RMSElog: 10.2157 grad_loss: 18939.5586 normal_loss: 0.9510
[epoch 51][iter  210] loss: 117693.8984 RMSElog: 9.6527 grad_loss: 11758.8105 normal_loss: 0.9267
[epoch 51][iter  220] loss: 161633.2812 RMSElog: 10.0107 grad_loss: 16152.3652 normal_loss: 0.9518
[epoch 51][iter  230] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 51][iter  240] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch 51][iter  250] loss: 132623.8750 RMSElog: 9.3325 grad_loss: 13252.1152 normal_loss: 0.9391
[epoch 51][iter  260] loss: 181983.5312 RMSElog: 10.0741 grad_loss: 18187.3320 normal_loss: 0.9464
[epoch 51][iter  270] loss: 132707.3594 RMSElog: 9.7842 grad_loss: 13260.0049 normal_loss: 0.9472
[epoch 51][iter  280] loss: 218757.0312 RMSElog: 10.1228 grad_loss: 21864.6270 normal_loss: 0.9524
[epoch 51][iter  290] loss: 103948.1719 RMSElog: 9.7608 grad_loss: 10384.1299 normal_loss: 0.9264
[epoch 51][iter  300] loss: 170056.2812 RMSElog: 9.7423 grad_loss: 16994.9395 normal_loss: 0.9472
[epoch 51][iter  310] loss: 147371.3906 RMSElog: 9.6635 grad_loss: 14726.5488 normal_loss: 0.9280
[epoch 51][iter  320] loss: 136796.3594 RMSElog: 9.6524 grad_loss: 13669.0283 normal_loss: 0.9549
[epoch 51][iter  330] loss: 226949.5156 RMSElog: 10.2029 grad_loss: 22683.8047 normal_loss: 0.9430
[epoch 51][iter  340] loss: 143440.0000 RMSElog: 9.6404 grad_loss: 14333.4336 normal_loss: 0.9261
[epoch 51][iter  350] loss: 104749.2812 RMSElog: 9.7512 grad_loss: 10464.2490 normal_loss: 0.9281
[epoch 51][iter  360] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 51][iter  370] loss: 152593.5000 RMSElog: 9.8773 grad_loss: 15248.5449 normal_loss: 0.9283
[epoch 51][iter  380] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 51][iter  390] loss: 221213.4531 RMSElog: 10.1740 grad_loss: 22110.2305 normal_loss: 0.9415
[epoch 51][iter  400] loss: 156709.9531 RMSElog: 9.8741 grad_loss: 15660.1758 normal_loss: 0.9453
[epoch 51][iter  410] loss: 145332.8438 RMSElog: 10.0385 grad_loss: 14522.2842 normal_loss: 0.9619
[epoch 51][iter  420] loss: 104456.8438 RMSElog: 10.0170 grad_loss: 10434.7461 normal_loss: 0.9214
[epoch 51][iter  430] loss: 197715.0000 RMSElog: 10.4355 grad_loss: 19760.1113 normal_loss: 0.9532
[epoch 51][iter  440] loss: 152540.7500 RMSElog: 9.9175 grad_loss: 15243.2090 normal_loss: 0.9474
[epoch 51][iter  450] loss: 182315.9688 RMSElog: 10.1291 grad_loss: 18220.5039 normal_loss: 0.9652
[epoch 51][iter  460] loss: 127499.3281 RMSElog: 9.2769 grad_loss: 12739.7178 normal_loss: 0.9374
[epoch 51][iter  470] loss: 180208.2188 RMSElog: 10.0490 grad_loss: 18009.8223 normal_loss: 0.9517
[epoch 51][iter  480] loss: 174565.0781 RMSElog: 9.7759 grad_loss: 17445.7832 normal_loss: 0.9484
[epoch 51][iter  490] loss: 208699.7031 RMSElog: 10.3419 grad_loss: 20858.6719 normal_loss: 0.9568
[epoch 51][iter  500] loss: 167740.4688 RMSElog: 9.8540 grad_loss: 16763.2344 normal_loss: 0.9591
[epoch 51][iter  510] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch 51][iter  520] loss: 134406.1875 RMSElog: 9.9402 grad_loss: 13429.7246 normal_loss: 0.9539
[epoch 51][iter  530] loss: 163171.1562 RMSElog: 9.7905 grad_loss: 16306.3594 normal_loss: 0.9652
[epoch 51][iter  540] loss: 167784.2500 RMSElog: 9.9330 grad_loss: 16767.5391 normal_loss: 0.9539
[epoch 51][iter  550] loss: 154609.8281 RMSElog: 9.8745 grad_loss: 15450.1855 normal_loss: 0.9220
[epoch 51][iter  560] loss: 125281.0156 RMSElog: 9.5401 grad_loss: 12517.6484 normal_loss: 0.9128
[epoch 51][iter  570] loss: 137249.3438 RMSElog: 9.7342 grad_loss: 13714.2764 normal_loss: 0.9239
[epoch 51][iter  580] loss: 102998.8984 RMSElog: 9.8140 grad_loss: 10289.1318 normal_loss: 0.9431
[epoch 51][iter  590] loss: 202119.8125 RMSElog: 10.2544 grad_loss: 20200.7715 normal_loss: 0.9549
[epoch 52][iter    0] loss: 137764.4219 RMSElog: 9.8227 grad_loss: 13765.6758 normal_loss: 0.9442
[epoch 52][iter   10] loss: 188662.5156 RMSElog: 10.2592 grad_loss: 18855.0352 normal_loss: 0.9574
[epoch 52][iter   20] loss: 208699.7031 RMSElog: 10.3419 grad_loss: 20858.6719 normal_loss: 0.9568
[epoch 52][iter   30] loss: 140333.8438 RMSElog: 9.8261 grad_loss: 14022.6211 normal_loss: 0.9368
[epoch 52][iter   40] loss: 180318.6719 RMSElog: 9.9530 grad_loss: 18020.9785 normal_loss: 0.9357
[epoch 52][iter   50] loss: 218757.0312 RMSElog: 10.1228 grad_loss: 21864.6270 normal_loss: 0.9524
[epoch 52][iter   60] loss: 159422.2656 RMSElog: 9.7010 grad_loss: 15931.5957 normal_loss: 0.9299
[epoch 52][iter   70] loss: 119470.5156 RMSElog: 9.6196 grad_loss: 11936.5020 normal_loss: 0.9297
[epoch 52][iter   80] loss: 165954.0938 RMSElog: 9.8997 grad_loss: 16584.5449 normal_loss: 0.9646
[epoch 52][iter   90] loss: 105877.8750 RMSElog: 9.7638 grad_loss: 10577.0986 normal_loss: 0.9249
[epoch 52][iter  100] loss: 232158.2188 RMSElog: 10.1898 grad_loss: 23204.6875 normal_loss: 0.9455
[epoch 52][iter  110] loss: 204650.3281 RMSElog: 10.1934 grad_loss: 20453.8633 normal_loss: 0.9763
[epoch 52][iter  120] loss: 114924.9844 RMSElog: 9.6925 grad_loss: 11481.8691 normal_loss: 0.9360
[epoch 52][iter  130] loss: 100749.6875 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.9377
[epoch 52][iter  140] loss: 128277.9766 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.9518
[epoch 52][iter  150] loss: 215955.5312 RMSElog: 10.2675 grad_loss: 21584.3203 normal_loss: 0.9654
[epoch 52][iter  160] loss: 113426.9531 RMSElog: 9.7682 grad_loss: 11331.9902 normal_loss: 0.9362
[epoch 52][iter  170] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 52][iter  180] loss: 104127.7969 RMSElog: 9.6242 grad_loss: 10402.2314 normal_loss: 0.9237
[epoch 52][iter  190] loss: 184016.5469 RMSElog: 9.9468 grad_loss: 18390.7363 normal_loss: 0.9712
[epoch 52][iter  200] loss: 196277.7188 RMSElog: 10.2453 grad_loss: 19616.5664 normal_loss: 0.9595
[epoch 52][iter  210] loss: 162433.1875 RMSElog: 9.8183 grad_loss: 16232.5488 normal_loss: 0.9510
[epoch 52][iter  220] loss: 191825.0781 RMSElog: 10.3012 grad_loss: 19171.2500 normal_loss: 0.9570
[epoch 52][iter  230] loss: 189017.5781 RMSElog: 10.1390 grad_loss: 18890.6602 normal_loss: 0.9589
[epoch 52][iter  240] loss: 176798.0469 RMSElog: 9.8176 grad_loss: 17669.0312 normal_loss: 0.9559
[epoch 52][iter  250] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 52][iter  260] loss: 135114.8750 RMSElog: 9.9265 grad_loss: 13500.6055 normal_loss: 0.9548
[epoch 52][iter  270] loss: 126821.0234 RMSElog: 10.1398 grad_loss: 12671.0410 normal_loss: 0.9215
[epoch 52][iter  280] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 52][iter  290] loss: 158230.6094 RMSElog: 9.9234 grad_loss: 15812.1895 normal_loss: 0.9483
[epoch 52][iter  300] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch 52][iter  310] loss: 179298.9062 RMSElog: 9.7220 grad_loss: 17919.2227 normal_loss: 0.9453
[epoch 52][iter  320] loss: 136507.7344 RMSElog: 10.0223 grad_loss: 13639.7900 normal_loss: 0.9608
[epoch 52][iter  330] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1221 normal_loss: 0.9462
[epoch 52][iter  340] loss: 109260.8906 RMSElog: 9.7819 grad_loss: 10915.3789 normal_loss: 0.9279
[epoch 52][iter  350] loss: 182318.8125 RMSElog: 10.1008 grad_loss: 18220.8418 normal_loss: 0.9384
[epoch 52][iter  360] loss: 151368.4219 RMSElog: 9.7883 grad_loss: 15126.1289 normal_loss: 0.9251
[epoch 52][iter  370] loss: 145332.8438 RMSElog: 10.0385 grad_loss: 14522.2842 normal_loss: 0.9619
[epoch 52][iter  380] loss: 185772.2500 RMSElog: 9.9702 grad_loss: 18566.2969 normal_loss: 0.9567
[epoch 52][iter  390] loss: 196437.8125 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.9584
[epoch 52][iter  400] loss: 152517.4844 RMSElog: 9.8233 grad_loss: 15241.0010 normal_loss: 0.9249
[epoch 52][iter  410] loss: 130641.2188 RMSElog: 9.7184 grad_loss: 13053.4688 normal_loss: 0.9344
[epoch 52][iter  420] loss: 197714.9844 RMSElog: 10.4355 grad_loss: 19760.1094 normal_loss: 0.9532
[epoch 52][iter  430] loss: 203973.6562 RMSElog: 10.4423 grad_loss: 20385.9727 normal_loss: 0.9505
[epoch 52][iter  440] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch 52][iter  450] loss: 228338.7500 RMSElog: 10.2936 grad_loss: 22822.6348 normal_loss: 0.9477
[epoch 52][iter  460] loss: 198743.4219 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.9643
[epoch 52][iter  470] loss: 214067.1875 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.9394
[epoch 52][iter  480] loss: 186049.0312 RMSElog: 10.0165 grad_loss: 18593.9277 normal_loss: 0.9585
[epoch 52][iter  490] loss: 111655.4766 RMSElog: 9.2050 grad_loss: 11155.4395 normal_loss: 0.9029
[epoch 52][iter  500] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 52][iter  510] loss: 206526.4062 RMSElog: 10.1531 grad_loss: 20641.5449 normal_loss: 0.9425
[epoch 52][iter  520] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 52][iter  530] loss: 150364.6250 RMSElog: 9.9123 grad_loss: 15025.6094 normal_loss: 0.9418
[epoch 52][iter  540] loss: 126023.2344 RMSElog: 9.6219 grad_loss: 12591.7656 normal_loss: 0.9360
[epoch 52][iter  550] loss: 221089.3594 RMSElog: 10.3457 grad_loss: 22097.6465 normal_loss: 0.9439
[epoch 52][iter  560] loss: 190938.1250 RMSElog: 10.3028 grad_loss: 19082.5566 normal_loss: 0.9541
[epoch 52][iter  570] loss: 197520.7500 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.9662
[epoch 52][iter  580] loss: 158534.6406 RMSElog: 9.6735 grad_loss: 15842.8672 normal_loss: 0.9232
[epoch 52][iter  590] loss: 141228.9219 RMSElog: 9.9926 grad_loss: 14111.9531 normal_loss: 0.9477
[epoch 53][iter    0] loss: 121866.5156 RMSElog: 9.8422 grad_loss: 12175.8965 normal_loss: 0.9131
[epoch 53][iter   10] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 53][iter   20] loss: 201264.6250 RMSElog: 10.1098 grad_loss: 20115.4023 normal_loss: 0.9505
[epoch 53][iter   30] loss: 166207.1094 RMSElog: 9.7947 grad_loss: 16609.9668 normal_loss: 0.9492
[epoch 53][iter   40] loss: 154776.6094 RMSElog: 9.8981 grad_loss: 15466.8418 normal_loss: 0.9209
[epoch 53][iter   50] loss: 173574.0781 RMSElog: 10.1780 grad_loss: 17346.2734 normal_loss: 0.9575
[epoch 53][iter   60] loss: 114893.3984 RMSElog: 9.2562 grad_loss: 11479.1777 normal_loss: 0.9067
[epoch 53][iter   70] loss: 189507.2500 RMSElog: 10.2157 grad_loss: 18939.5586 normal_loss: 0.9510
[epoch 53][iter   80] loss: 203973.6562 RMSElog: 10.4423 grad_loss: 20385.9727 normal_loss: 0.9505
[epoch 53][iter   90] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 53][iter  100] loss: 100663.8984 RMSElog: 9.9598 grad_loss: 10055.5020 normal_loss: 0.9277
[epoch 53][iter  110] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 53][iter  120] loss: 105706.7031 RMSElog: 9.7501 grad_loss: 10559.9883 normal_loss: 0.9321
[epoch 53][iter  130] loss: 136869.7500 RMSElog: 9.5771 grad_loss: 13676.4668 normal_loss: 0.9315
[epoch 53][iter  140] loss: 123289.4609 RMSElog: 9.4106 grad_loss: 12318.5752 normal_loss: 0.9606
[epoch 53][iter  150] loss: 139154.8594 RMSElog: 9.5986 grad_loss: 13904.9707 normal_loss: 0.9164
[epoch 53][iter  160] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch 53][iter  170] loss: 153099.1094 RMSElog: 9.8355 grad_loss: 15299.1445 normal_loss: 0.9304
[epoch 53][iter  180] loss: 125486.8672 RMSElog: 9.7758 grad_loss: 12537.9834 normal_loss: 0.9281
[epoch 53][iter  190] loss: 115534.3672 RMSElog: 9.7196 grad_loss: 11542.7842 normal_loss: 0.9325
[epoch 53][iter  200] loss: 204037.7500 RMSElog: 10.1754 grad_loss: 20392.6582 normal_loss: 0.9420
[epoch 53][iter  210] loss: 135966.2969 RMSElog: 9.6504 grad_loss: 13586.0273 normal_loss: 0.9522
[epoch 53][iter  220] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 53][iter  230] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 53][iter  240] loss: 185772.2500 RMSElog: 9.9702 grad_loss: 18566.2969 normal_loss: 0.9567
[epoch 53][iter  250] loss: 175524.1250 RMSElog: 10.2056 grad_loss: 17541.2441 normal_loss: 0.9625
[epoch 53][iter  260] loss: 160642.9375 RMSElog: 9.9306 grad_loss: 16053.4121 normal_loss: 0.9504
[epoch 53][iter  270] loss: 108830.7344 RMSElog: 9.7359 grad_loss: 10872.4062 normal_loss: 0.9307
[epoch 53][iter  280] loss: 101101.5547 RMSElog: 9.9274 grad_loss: 10099.2979 normal_loss: 0.9297
[epoch 53][iter  290] loss: 163252.6875 RMSElog: 9.8236 grad_loss: 16314.5117 normal_loss: 0.9348
[epoch 53][iter  300] loss: 139098.6406 RMSElog: 9.8619 grad_loss: 13899.0508 normal_loss: 0.9510
[epoch 53][iter  310] loss: 195999.5625 RMSElog: 10.1749 grad_loss: 19588.8047 normal_loss: 0.9756
[epoch 53][iter  320] loss: 194987.6250 RMSElog: 9.8416 grad_loss: 19487.9453 normal_loss: 0.9748
[epoch 53][iter  330] loss: 114924.9844 RMSElog: 9.6925 grad_loss: 11481.8691 normal_loss: 0.9360
[epoch 53][iter  340] loss: 131942.8750 RMSElog: 9.8414 grad_loss: 13183.5000 normal_loss: 0.9453
[epoch 53][iter  350] loss: 167740.4688 RMSElog: 9.8540 grad_loss: 16763.2344 normal_loss: 0.9591
[epoch 53][iter  360] loss: 159824.3594 RMSElog: 9.8973 grad_loss: 15971.5811 normal_loss: 0.9569
[epoch 53][iter  370] loss: 148184.5469 RMSElog: 10.0681 grad_loss: 14807.4355 normal_loss: 0.9504
[epoch 53][iter  380] loss: 188645.4531 RMSElog: 10.1590 grad_loss: 18853.4082 normal_loss: 0.9794
[epoch 53][iter  390] loss: 157119.7500 RMSElog: 9.8959 grad_loss: 15701.1318 normal_loss: 0.9480
[epoch 53][iter  400] loss: 212239.7031 RMSElog: 10.2690 grad_loss: 21212.7383 normal_loss: 0.9638
[epoch 53][iter  410] loss: 142016.3906 RMSElog: 9.9191 grad_loss: 14190.7676 normal_loss: 0.9526
[epoch 53][iter  420] loss: 178468.8906 RMSElog: 9.9039 grad_loss: 17836.0469 normal_loss: 0.9380
[epoch 53][iter  430] loss: 117693.8984 RMSElog: 9.6527 grad_loss: 11758.8105 normal_loss: 0.9267
[epoch 53][iter  440] loss: 130641.2188 RMSElog: 9.7184 grad_loss: 13053.4688 normal_loss: 0.9344
[epoch 53][iter  450] loss: 142544.5156 RMSElog: 10.1645 grad_loss: 14243.3457 normal_loss: 0.9425
[epoch 53][iter  460] loss: 103815.4375 RMSElog: 9.7764 grad_loss: 10370.8340 normal_loss: 0.9338
[epoch 53][iter  470] loss: 105098.6875 RMSElog: 9.7426 grad_loss: 10499.2012 normal_loss: 0.9257
[epoch 53][iter  480] loss: 181293.3438 RMSElog: 10.0009 grad_loss: 18118.3809 normal_loss: 0.9531
[epoch 53][iter  490] loss: 191371.4375 RMSElog: 10.1918 grad_loss: 19126.0020 normal_loss: 0.9504
[epoch 53][iter  500] loss: 216509.5938 RMSElog: 10.1942 grad_loss: 21639.8242 normal_loss: 0.9420
[epoch 53][iter  510] loss: 159284.2188 RMSElog: 9.6028 grad_loss: 15917.8828 normal_loss: 0.9361
[epoch 53][iter  520] loss: 155968.4062 RMSElog: 9.9200 grad_loss: 15585.9980 normal_loss: 0.9232
[epoch 53][iter  530] loss: 137249.3438 RMSElog: 9.7342 grad_loss: 13714.2764 normal_loss: 0.9239
[epoch 53][iter  540] loss: 164843.6719 RMSElog: 9.7972 grad_loss: 16473.6348 normal_loss: 0.9360
[epoch 53][iter  550] loss: 96006.2500 RMSElog: 9.5560 grad_loss: 9590.1396 normal_loss: 0.9294
[epoch 53][iter  560] loss: 154165.2969 RMSElog: 10.0187 grad_loss: 15405.5605 normal_loss: 0.9498
[epoch 53][iter  570] loss: 182187.7188 RMSElog: 10.0835 grad_loss: 18207.7461 normal_loss: 0.9413
[epoch 53][iter  580] loss: 223875.4062 RMSElog: 10.3929 grad_loss: 22376.1953 normal_loss: 0.9536
[epoch 53][iter  590] loss: 177664.5469 RMSElog: 9.7808 grad_loss: 17755.7363 normal_loss: 0.9369
[epoch 54][iter    0] loss: 157425.7188 RMSElog: 9.9235 grad_loss: 15731.7012 normal_loss: 0.9477
[epoch 54][iter   10] loss: 111518.2734 RMSElog: 9.6257 grad_loss: 11141.2676 normal_loss: 0.9335
[epoch 54][iter   20] loss: 196677.7812 RMSElog: 10.0486 grad_loss: 19656.7715 normal_loss: 0.9571
[epoch 54][iter   30] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 54][iter   40] loss: 110874.4688 RMSElog: 9.2829 grad_loss: 11077.2607 normal_loss: 0.9034
[epoch 54][iter   50] loss: 122359.4531 RMSElog: 9.7683 grad_loss: 12225.2402 normal_loss: 0.9361
[epoch 54][iter   60] loss: 127463.1875 RMSElog: 9.4952 grad_loss: 12735.9082 normal_loss: 0.9153
[epoch 54][iter   70] loss: 140645.6875 RMSElog: 10.1118 grad_loss: 14053.4873 normal_loss: 0.9695
[epoch 54][iter   80] loss: 123289.4609 RMSElog: 9.4106 grad_loss: 12318.5752 normal_loss: 0.9606
[epoch 54][iter   90] loss: 204650.3281 RMSElog: 10.1934 grad_loss: 20453.8633 normal_loss: 0.9762
[epoch 54][iter  100] loss: 153099.1094 RMSElog: 9.8355 grad_loss: 15299.1445 normal_loss: 0.9304
[epoch 54][iter  110] loss: 148184.5469 RMSElog: 10.0681 grad_loss: 14807.4355 normal_loss: 0.9504
[epoch 54][iter  120] loss: 189582.6719 RMSElog: 9.9918 grad_loss: 18947.3223 normal_loss: 0.9523
[epoch 54][iter  130] loss: 119895.5000 RMSElog: 9.3187 grad_loss: 11979.3154 normal_loss: 0.9157
[epoch 54][iter  140] loss: 170357.3281 RMSElog: 9.9687 grad_loss: 17024.7988 normal_loss: 0.9644
[epoch 54][iter  150] loss: 203973.6562 RMSElog: 10.4423 grad_loss: 20385.9727 normal_loss: 0.9505
[epoch 54][iter  160] loss: 104086.5234 RMSElog: 9.7787 grad_loss: 10397.9453 normal_loss: 0.9289
[epoch 54][iter  170] loss: 111712.9062 RMSElog: 9.7826 grad_loss: 11160.5801 normal_loss: 0.9290
[epoch 54][iter  180] loss: 214067.1875 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.9394
[epoch 54][iter  190] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 54][iter  200] loss: 195777.0469 RMSElog: 10.1280 grad_loss: 19566.6035 normal_loss: 0.9726
[epoch 54][iter  210] loss: 175299.8438 RMSElog: 10.1975 grad_loss: 17518.8301 normal_loss: 0.9576
[epoch 54][iter  220] loss: 105794.8906 RMSElog: 9.7676 grad_loss: 10568.7949 normal_loss: 0.9267
[epoch 54][iter  230] loss: 195507.4062 RMSElog: 10.1854 grad_loss: 19539.6016 normal_loss: 0.9533
[epoch 54][iter  240] loss: 142544.5156 RMSElog: 10.1645 grad_loss: 14243.3457 normal_loss: 0.9425
[epoch 54][iter  250] loss: 184374.1875 RMSElog: 10.2641 grad_loss: 18426.1953 normal_loss: 0.9596
[epoch 54][iter  260] loss: 216509.5625 RMSElog: 10.1942 grad_loss: 21639.8223 normal_loss: 0.9420
[epoch 54][iter  270] loss: 100650.2734 RMSElog: 9.7441 grad_loss: 10054.3555 normal_loss: 0.9279
[epoch 54][iter  280] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 54][iter  290] loss: 168545.0938 RMSElog: 9.6168 grad_loss: 16843.9434 normal_loss: 0.9495
[epoch 54][iter  300] loss: 160788.1406 RMSElog: 9.7539 grad_loss: 16068.1289 normal_loss: 0.9318
[epoch 54][iter  310] loss: 220587.5781 RMSElog: 10.2995 grad_loss: 22047.5117 normal_loss: 0.9466
[epoch 54][iter  320] loss: 146465.6875 RMSElog: 10.2283 grad_loss: 14635.4062 normal_loss: 0.9337
[epoch 54][iter  330] loss: 113921.7891 RMSElog: 9.7251 grad_loss: 11381.5186 normal_loss: 0.9357
[epoch 54][iter  340] loss: 221213.4531 RMSElog: 10.1740 grad_loss: 22110.2305 normal_loss: 0.9415
[epoch 54][iter  350] loss: 235211.2344 RMSElog: 10.3371 grad_loss: 23509.8398 normal_loss: 0.9452
[epoch 54][iter  360] loss: 183095.1562 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.9696
[epoch 54][iter  370] loss: 205235.7188 RMSElog: 10.2875 grad_loss: 20512.3281 normal_loss: 0.9564
[epoch 54][iter  380] loss: 167784.2500 RMSElog: 9.9330 grad_loss: 16767.5391 normal_loss: 0.9539
[epoch 54][iter  390] loss: 142005.0781 RMSElog: 9.9168 grad_loss: 14189.6533 normal_loss: 0.9371
[epoch 54][iter  400] loss: 212239.7031 RMSElog: 10.2690 grad_loss: 21212.7383 normal_loss: 0.9638
[epoch 54][iter  410] loss: 146161.1562 RMSElog: 10.0682 grad_loss: 14605.1279 normal_loss: 0.9190
[epoch 54][iter  420] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 54][iter  430] loss: 149369.9062 RMSElog: 10.0930 grad_loss: 14925.9756 normal_loss: 0.9225
[epoch 54][iter  440] loss: 124563.3906 RMSElog: 9.9514 grad_loss: 12445.4473 normal_loss: 0.9400
[epoch 54][iter  450] loss: 167455.8750 RMSElog: 9.7229 grad_loss: 16734.9395 normal_loss: 0.9256
[epoch 54][iter  460] loss: 185495.4062 RMSElog: 9.9310 grad_loss: 18538.6641 normal_loss: 0.9455
[epoch 54][iter  470] loss: 181465.8125 RMSElog: 10.1136 grad_loss: 18135.5117 normal_loss: 0.9572
[epoch 54][iter  480] loss: 213401.8906 RMSElog: 10.0568 grad_loss: 21329.1582 normal_loss: 0.9749
[epoch 54][iter  490] loss: 104446.5625 RMSElog: 10.1932 grad_loss: 10433.5342 normal_loss: 0.9288
[epoch 54][iter  500] loss: 128277.9766 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.9518
[epoch 54][iter  510] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 54][iter  520] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1221 normal_loss: 0.9462
[epoch 54][iter  530] loss: 160466.8750 RMSElog: 9.9085 grad_loss: 16035.8252 normal_loss: 0.9540
[epoch 54][iter  540] loss: 214493.2031 RMSElog: 10.3525 grad_loss: 21438.0059 normal_loss: 0.9611
[epoch 54][iter  550] loss: 185071.7031 RMSElog: 10.0456 grad_loss: 18496.1699 normal_loss: 0.9557
[epoch 54][iter  560] loss: 122446.5469 RMSElog: 9.6438 grad_loss: 12234.0742 normal_loss: 0.9366
[epoch 54][iter  570] loss: 165453.0938 RMSElog: 9.9262 grad_loss: 16534.4160 normal_loss: 0.9660
[epoch 54][iter  580] loss: 157706.0781 RMSElog: 9.9981 grad_loss: 15759.6602 normal_loss: 0.9499
[epoch 54][iter  590] loss: 152562.3906 RMSElog: 9.8216 grad_loss: 15245.4785 normal_loss: 0.9391
[epoch 55][iter    0] loss: 152562.3750 RMSElog: 9.8216 grad_loss: 15245.4775 normal_loss: 0.9391
[epoch 55][iter   10] loss: 183095.1562 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.9696
[epoch 55][iter   20] loss: 157061.8906 RMSElog: 9.9892 grad_loss: 15695.2461 normal_loss: 0.9531
[epoch 55][iter   30] loss: 113426.9531 RMSElog: 9.7682 grad_loss: 11331.9902 normal_loss: 0.9362
[epoch 55][iter   40] loss: 140938.8594 RMSElog: 9.7483 grad_loss: 14083.1953 normal_loss: 0.9424
[epoch 55][iter   50] loss: 90482.6875 RMSElog: 9.3127 grad_loss: 9038.0186 normal_loss: 0.9378
[epoch 55][iter   60] loss: 163389.5469 RMSElog: 9.7702 grad_loss: 16328.2637 normal_loss: 0.9208
[epoch 55][iter   70] loss: 199607.1562 RMSElog: 10.1504 grad_loss: 19949.6133 normal_loss: 0.9517
[epoch 55][iter   80] loss: 100749.6875 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.9377
[epoch 55][iter   90] loss: 165954.0938 RMSElog: 9.8997 grad_loss: 16584.5449 normal_loss: 0.9646
[epoch 55][iter  100] loss: 155482.2031 RMSElog: 10.0818 grad_loss: 15537.1826 normal_loss: 0.9552
[epoch 55][iter  110] loss: 160051.0156 RMSElog: 9.8405 grad_loss: 15994.3105 normal_loss: 0.9506
[epoch 55][iter  120] loss: 149807.1562 RMSElog: 9.9060 grad_loss: 14969.8613 normal_loss: 0.9481
[epoch 55][iter  130] loss: 164181.7344 RMSElog: 10.0104 grad_loss: 16407.1973 normal_loss: 0.9660
[epoch 55][iter  140] loss: 115658.3125 RMSElog: 9.1856 grad_loss: 11555.7031 normal_loss: 0.9424
[epoch 55][iter  150] loss: 196677.7812 RMSElog: 10.0486 grad_loss: 19656.7715 normal_loss: 0.9571
[epoch 55][iter  160] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 55][iter  170] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 55][iter  180] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 55][iter  190] loss: 107073.5156 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.9313
[epoch 55][iter  200] loss: 155762.3438 RMSElog: 9.8487 grad_loss: 15565.4404 normal_loss: 0.9448
[epoch 55][iter  210] loss: 111518.2734 RMSElog: 9.6257 grad_loss: 11141.2676 normal_loss: 0.9335
[epoch 55][iter  220] loss: 151354.1562 RMSElog: 9.8837 grad_loss: 15124.5889 normal_loss: 0.9428
[epoch 55][iter  230] loss: 106952.9219 RMSElog: 10.0294 grad_loss: 10684.3398 normal_loss: 0.9231
[epoch 55][iter  240] loss: 156173.3594 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.9482
[epoch 55][iter  250] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 55][iter  260] loss: 150459.7656 RMSElog: 9.9429 grad_loss: 15035.0986 normal_loss: 0.9347
[epoch 55][iter  270] loss: 134406.2031 RMSElog: 9.9402 grad_loss: 13429.7256 normal_loss: 0.9539
[epoch 55][iter  280] loss: 121838.3672 RMSElog: 9.7453 grad_loss: 12173.1494 normal_loss: 0.9425
[epoch 55][iter  290] loss: 147915.7812 RMSElog: 10.0131 grad_loss: 14780.6104 normal_loss: 0.9547
[epoch 55][iter  300] loss: 177934.3750 RMSElog: 9.8386 grad_loss: 17782.6445 normal_loss: 0.9542
[epoch 55][iter  310] loss: 112851.7266 RMSElog: 9.4205 grad_loss: 11274.8320 normal_loss: 0.9199
[epoch 55][iter  320] loss: 202119.8125 RMSElog: 10.2544 grad_loss: 20200.7715 normal_loss: 0.9549
[epoch 55][iter  330] loss: 96006.2500 RMSElog: 9.5560 grad_loss: 9590.1396 normal_loss: 0.9294
[epoch 55][iter  340] loss: 239768.0938 RMSElog: 10.2366 grad_loss: 23965.6250 normal_loss: 0.9466
[epoch 55][iter  350] loss: 131213.2969 RMSElog: 9.6860 grad_loss: 13110.7217 normal_loss: 0.9217
[epoch 55][iter  360] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 55][iter  370] loss: 119470.5156 RMSElog: 9.6196 grad_loss: 11936.5020 normal_loss: 0.9297
[epoch 55][iter  380] loss: 167745.5625 RMSElog: 9.8817 grad_loss: 16763.7129 normal_loss: 0.9621
[epoch 55][iter  390] loss: 148136.9375 RMSElog: 9.9557 grad_loss: 14802.7871 normal_loss: 0.9498
[epoch 55][iter  400] loss: 175299.8438 RMSElog: 10.1975 grad_loss: 17518.8301 normal_loss: 0.9576
[epoch 55][iter  410] loss: 157274.4688 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.9461
[epoch 55][iter  420] loss: 132425.4375 RMSElog: 10.0155 grad_loss: 13231.5801 normal_loss: 0.9468
[epoch 55][iter  430] loss: 167455.8750 RMSElog: 9.7229 grad_loss: 16734.9395 normal_loss: 0.9256
[epoch 55][iter  440] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1221 normal_loss: 0.9462
[epoch 55][iter  450] loss: 175547.8906 RMSElog: 10.1409 grad_loss: 17543.7148 normal_loss: 0.9342
[epoch 55][iter  460] loss: 148184.5469 RMSElog: 10.0681 grad_loss: 14807.4355 normal_loss: 0.9504
[epoch 55][iter  470] loss: 166492.4375 RMSElog: 9.8376 grad_loss: 16638.4512 normal_loss: 0.9558
[epoch 55][iter  480] loss: 160024.9375 RMSElog: 9.8489 grad_loss: 15991.7236 normal_loss: 0.9215
[epoch 55][iter  490] loss: 147765.9219 RMSElog: 10.0607 grad_loss: 14765.6104 normal_loss: 0.9219
[epoch 55][iter  500] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 55][iter  510] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 55][iter  520] loss: 129708.8906 RMSElog: 10.0691 grad_loss: 12959.8711 normal_loss: 0.9481
[epoch 55][iter  530] loss: 164766.2812 RMSElog: 9.6928 grad_loss: 16465.9941 normal_loss: 0.9411
[epoch 55][iter  540] loss: 191825.0781 RMSElog: 10.3012 grad_loss: 19171.2500 normal_loss: 0.9570
[epoch 55][iter  550] loss: 106769.7500 RMSElog: 9.8688 grad_loss: 10666.1914 normal_loss: 0.9140
[epoch 55][iter  560] loss: 129743.7969 RMSElog: 9.9523 grad_loss: 12963.4785 normal_loss: 0.9492
[epoch 55][iter  570] loss: 136869.7500 RMSElog: 9.5771 grad_loss: 13676.4668 normal_loss: 0.9315
[epoch 55][iter  580] loss: 139830.9062 RMSElog: 9.7552 grad_loss: 13972.3770 normal_loss: 0.9585
[epoch 55][iter  590] loss: 136507.7344 RMSElog: 10.0223 grad_loss: 13639.7900 normal_loss: 0.9608
[epoch 56][iter    0] loss: 114173.8984 RMSElog: 9.3600 grad_loss: 11407.1230 normal_loss: 0.9061
[epoch 56][iter   10] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 56][iter   20] loss: 132012.6719 RMSElog: 9.6802 grad_loss: 13190.6582 normal_loss: 0.9291
[epoch 56][iter   30] loss: 227080.5938 RMSElog: 10.4127 grad_loss: 22696.6992 normal_loss: 0.9482
[epoch 56][iter   40] loss: 158230.6094 RMSElog: 9.9234 grad_loss: 15812.1895 normal_loss: 0.9483
[epoch 56][iter   50] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 56][iter   60] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 56][iter   70] loss: 126821.0234 RMSElog: 10.1398 grad_loss: 12671.0410 normal_loss: 0.9215
[epoch 56][iter   80] loss: 162892.2969 RMSElog: 9.8252 grad_loss: 16278.4717 normal_loss: 0.9331
[epoch 56][iter   90] loss: 136533.4688 RMSElog: 9.6756 grad_loss: 13642.7363 normal_loss: 0.9359
[epoch 56][iter  100] loss: 128883.6406 RMSElog: 9.8798 grad_loss: 12877.5254 normal_loss: 0.9593
[epoch 56][iter  110] loss: 173721.0156 RMSElog: 10.0355 grad_loss: 17361.1191 normal_loss: 0.9468
[epoch 56][iter  120] loss: 164843.6875 RMSElog: 9.7972 grad_loss: 16473.6367 normal_loss: 0.9360
[epoch 56][iter  130] loss: 153724.0000 RMSElog: 9.9609 grad_loss: 15361.4922 normal_loss: 0.9475
[epoch 56][iter  140] loss: 103514.7812 RMSElog: 9.3451 grad_loss: 10341.2109 normal_loss: 0.9229
[epoch 56][iter  150] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 56][iter  160] loss: 157706.0781 RMSElog: 9.9981 grad_loss: 15759.6602 normal_loss: 0.9499
[epoch 56][iter  170] loss: 126023.2344 RMSElog: 9.6219 grad_loss: 12591.7656 normal_loss: 0.9360
[epoch 56][iter  180] loss: 87697.6250 RMSElog: 9.9487 grad_loss: 8758.8750 normal_loss: 0.9395
[epoch 56][iter  190] loss: 139098.6406 RMSElog: 9.8619 grad_loss: 13899.0508 normal_loss: 0.9510
[epoch 56][iter  200] loss: 188502.1875 RMSElog: 10.1669 grad_loss: 18839.0801 normal_loss: 0.9722
[epoch 56][iter  210] loss: 147598.9844 RMSElog: 9.8981 grad_loss: 14749.0645 normal_loss: 0.9355
[epoch 56][iter  220] loss: 170690.9375 RMSElog: 9.9328 grad_loss: 17058.2129 normal_loss: 0.9470
[epoch 56][iter  230] loss: 72289.2656 RMSElog: 9.4677 grad_loss: 7218.5376 normal_loss: 0.9211
[epoch 56][iter  240] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 56][iter  250] loss: 170056.2812 RMSElog: 9.7423 grad_loss: 16994.9395 normal_loss: 0.9472
[epoch 56][iter  260] loss: 165954.0938 RMSElog: 9.8997 grad_loss: 16584.5449 normal_loss: 0.9646
[epoch 56][iter  270] loss: 177292.4062 RMSElog: 10.1195 grad_loss: 17718.1602 normal_loss: 0.9615
[epoch 56][iter  280] loss: 167740.4688 RMSElog: 9.8540 grad_loss: 16763.2344 normal_loss: 0.9591
[epoch 56][iter  290] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 56][iter  300] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 56][iter  310] loss: 177195.4844 RMSElog: 10.1516 grad_loss: 17708.4512 normal_loss: 0.9458
[epoch 56][iter  320] loss: 106516.8047 RMSElog: 9.6966 grad_loss: 10641.0557 normal_loss: 0.9285
[epoch 56][iter  330] loss: 148136.9375 RMSElog: 9.9557 grad_loss: 14802.7871 normal_loss: 0.9498
[epoch 56][iter  340] loss: 146781.9531 RMSElog: 9.8688 grad_loss: 14667.3818 normal_loss: 0.9440
[epoch 56][iter  350] loss: 148184.5469 RMSElog: 10.0681 grad_loss: 14807.4355 normal_loss: 0.9504
[epoch 56][iter  360] loss: 152593.5000 RMSElog: 9.8773 grad_loss: 15248.5449 normal_loss: 0.9283
[epoch 56][iter  370] loss: 178076.4688 RMSElog: 9.8778 grad_loss: 17796.8457 normal_loss: 0.9233
[epoch 56][iter  380] loss: 130527.6172 RMSElog: 9.8914 grad_loss: 13041.9189 normal_loss: 0.9509
[epoch 56][iter  390] loss: 158924.9062 RMSElog: 9.8027 grad_loss: 15881.7363 normal_loss: 0.9524
[epoch 56][iter  400] loss: 108830.7344 RMSElog: 9.7359 grad_loss: 10872.4062 normal_loss: 0.9307
[epoch 56][iter  410] loss: 127075.1875 RMSElog: 10.1217 grad_loss: 12696.4443 normal_loss: 0.9524
[epoch 56][iter  420] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 56][iter  430] loss: 175301.7344 RMSElog: 9.8017 grad_loss: 17519.4180 normal_loss: 0.9555
[epoch 56][iter  440] loss: 176217.8125 RMSElog: 10.1087 grad_loss: 17610.7246 normal_loss: 0.9466
[epoch 56][iter  450] loss: 100650.2734 RMSElog: 9.7441 grad_loss: 10054.3555 normal_loss: 0.9279
[epoch 56][iter  460] loss: 203973.6562 RMSElog: 10.4423 grad_loss: 20385.9727 normal_loss: 0.9505
[epoch 56][iter  470] loss: 156982.7188 RMSElog: 10.0093 grad_loss: 15687.3193 normal_loss: 0.9438
[epoch 56][iter  480] loss: 156557.3594 RMSElog: 9.6970 grad_loss: 15645.1025 normal_loss: 0.9363
[epoch 56][iter  490] loss: 144191.5938 RMSElog: 9.6650 grad_loss: 14408.5654 normal_loss: 0.9284
[epoch 56][iter  500] loss: 110874.4688 RMSElog: 9.2829 grad_loss: 11077.2607 normal_loss: 0.9034
[epoch 56][iter  510] loss: 155482.1875 RMSElog: 10.0818 grad_loss: 15537.1816 normal_loss: 0.9552
[epoch 56][iter  520] loss: 176223.4531 RMSElog: 9.9872 grad_loss: 17611.4141 normal_loss: 0.9446
[epoch 56][iter  530] loss: 182187.7188 RMSElog: 10.0835 grad_loss: 18207.7461 normal_loss: 0.9413
[epoch 56][iter  540] loss: 198743.4219 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.9643
[epoch 56][iter  550] loss: 122912.0625 RMSElog: 9.7328 grad_loss: 12280.5225 normal_loss: 0.9509
[epoch 56][iter  560] loss: 112697.1016 RMSElog: 9.7295 grad_loss: 11259.0449 normal_loss: 0.9352
[epoch 56][iter  570] loss: 175524.1250 RMSElog: 10.2056 grad_loss: 17541.2441 normal_loss: 0.9625
[epoch 56][iter  580] loss: 162542.0469 RMSElog: 9.9393 grad_loss: 16243.3115 normal_loss: 0.9527
[epoch 56][iter  590] loss: 150364.6250 RMSElog: 9.9123 grad_loss: 15025.6094 normal_loss: 0.9418
[epoch 57][iter    0] loss: 162892.2969 RMSElog: 9.8252 grad_loss: 16278.4717 normal_loss: 0.9331
[epoch 57][iter   10] loss: 156253.7656 RMSElog: 9.8231 grad_loss: 15614.6211 normal_loss: 0.9316
[epoch 57][iter   20] loss: 165306.9531 RMSElog: 9.8881 grad_loss: 16519.8438 normal_loss: 0.9638
[epoch 57][iter   30] loss: 212429.2969 RMSElog: 10.2794 grad_loss: 21231.6719 normal_loss: 0.9784
[epoch 57][iter   40] loss: 159824.3594 RMSElog: 9.8973 grad_loss: 15971.5811 normal_loss: 0.9569
[epoch 57][iter   50] loss: 111655.4766 RMSElog: 9.2050 grad_loss: 11155.4395 normal_loss: 0.9029
[epoch 57][iter   60] loss: 188662.5156 RMSElog: 10.2592 grad_loss: 18855.0352 normal_loss: 0.9574
[epoch 57][iter   70] loss: 87697.6250 RMSElog: 9.9487 grad_loss: 8758.8750 normal_loss: 0.9395
[epoch 57][iter   80] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 57][iter   90] loss: 152540.7500 RMSElog: 9.9175 grad_loss: 15243.2090 normal_loss: 0.9474
[epoch 57][iter  100] loss: 214067.1875 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.9394
[epoch 57][iter  110] loss: 103509.2188 RMSElog: 9.9787 grad_loss: 10340.0186 normal_loss: 0.9251
[epoch 57][iter  120] loss: 179634.8125 RMSElog: 10.0930 grad_loss: 17952.4258 normal_loss: 0.9607
[epoch 57][iter  130] loss: 121866.5156 RMSElog: 9.8422 grad_loss: 12175.8965 normal_loss: 0.9131
[epoch 57][iter  140] loss: 143534.0938 RMSElog: 9.7662 grad_loss: 14342.7061 normal_loss: 0.9374
[epoch 57][iter  150] loss: 194987.6250 RMSElog: 9.8416 grad_loss: 19487.9453 normal_loss: 0.9748
[epoch 57][iter  160] loss: 206764.2031 RMSElog: 10.2849 grad_loss: 20665.1797 normal_loss: 0.9549
[epoch 57][iter  170] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 57][iter  180] loss: 127075.1953 RMSElog: 10.1217 grad_loss: 12696.4453 normal_loss: 0.9524
[epoch 57][iter  190] loss: 100990.1562 RMSElog: 9.7350 grad_loss: 10088.3584 normal_loss: 0.9222
[epoch 57][iter  200] loss: 106516.8047 RMSElog: 9.6966 grad_loss: 10641.0557 normal_loss: 0.9285
[epoch 57][iter  210] loss: 166492.4688 RMSElog: 9.8376 grad_loss: 16638.4531 normal_loss: 0.9558
[epoch 57][iter  220] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1230 normal_loss: 0.9462
[epoch 57][iter  230] loss: 127110.9375 RMSElog: 9.5273 grad_loss: 12700.6064 normal_loss: 0.9604
[epoch 57][iter  240] loss: 181293.3438 RMSElog: 10.0009 grad_loss: 18118.3809 normal_loss: 0.9531
[epoch 57][iter  250] loss: 149807.1562 RMSElog: 9.9060 grad_loss: 14969.8613 normal_loss: 0.9481
[epoch 57][iter  260] loss: 122670.8984 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.9331
[epoch 57][iter  270] loss: 106182.2031 RMSElog: 9.7575 grad_loss: 10607.5332 normal_loss: 0.9294
[epoch 57][iter  280] loss: 107948.0156 RMSElog: 9.7377 grad_loss: 10784.1299 normal_loss: 0.9342
[epoch 57][iter  290] loss: 130145.6250 RMSElog: 9.7206 grad_loss: 13003.9072 normal_loss: 0.9344
[epoch 57][iter  300] loss: 182476.7344 RMSElog: 9.9672 grad_loss: 18236.7656 normal_loss: 0.9407
[epoch 57][iter  310] loss: 151368.4219 RMSElog: 9.7883 grad_loss: 15126.1289 normal_loss: 0.9251
[epoch 57][iter  320] loss: 196842.3125 RMSElog: 10.1249 grad_loss: 19673.1523 normal_loss: 0.9534
[epoch 57][iter  330] loss: 158924.9062 RMSElog: 9.8027 grad_loss: 15881.7363 normal_loss: 0.9524
[epoch 57][iter  340] loss: 113195.8125 RMSElog: 9.1761 grad_loss: 11309.5039 normal_loss: 0.9012
[epoch 57][iter  350] loss: 105628.3672 RMSElog: 10.0899 grad_loss: 10551.8262 normal_loss: 0.9213
[epoch 57][iter  360] loss: 224943.8906 RMSElog: 10.1206 grad_loss: 22483.3125 normal_loss: 0.9551
[epoch 57][iter  370] loss: 196437.8125 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.9584
[epoch 57][iter  380] loss: 103948.1719 RMSElog: 9.7608 grad_loss: 10384.1299 normal_loss: 0.9264
[epoch 57][iter  390] loss: 127061.7500 RMSElog: 9.6726 grad_loss: 12695.5654 normal_loss: 0.9369
[epoch 57][iter  400] loss: 203973.6562 RMSElog: 10.4423 grad_loss: 20385.9727 normal_loss: 0.9505
[epoch 57][iter  410] loss: 178468.8906 RMSElog: 9.9039 grad_loss: 17836.0469 normal_loss: 0.9380
[epoch 57][iter  420] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 57][iter  430] loss: 160825.5938 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.9491
[epoch 57][iter  440] loss: 128883.6406 RMSElog: 9.8798 grad_loss: 12877.5254 normal_loss: 0.9593
[epoch 57][iter  450] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 57][iter  460] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 57][iter  470] loss: 175004.6719 RMSElog: 10.1774 grad_loss: 17489.3320 normal_loss: 0.9561
[epoch 57][iter  480] loss: 212239.7031 RMSElog: 10.2690 grad_loss: 21212.7383 normal_loss: 0.9638
[epoch 57][iter  490] loss: 129205.9375 RMSElog: 9.8851 grad_loss: 12909.7734 normal_loss: 0.9356
[epoch 57][iter  500] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 57][iter  510] loss: 140057.2812 RMSElog: 9.9766 grad_loss: 13994.7988 normal_loss: 0.9526
[epoch 57][iter  520] loss: 120292.3438 RMSElog: 9.8042 grad_loss: 12018.4863 normal_loss: 0.9430
[epoch 57][iter  530] loss: 115500.4766 RMSElog: 9.9924 grad_loss: 11539.1230 normal_loss: 0.9328
[epoch 57][iter  540] loss: 137764.4062 RMSElog: 9.8227 grad_loss: 13765.6748 normal_loss: 0.9442
[epoch 57][iter  550] loss: 200470.3906 RMSElog: 10.2414 grad_loss: 20035.8379 normal_loss: 0.9585
[epoch 57][iter  560] loss: 135203.5938 RMSElog: 9.4545 grad_loss: 13509.9697 normal_loss: 0.9356
[epoch 57][iter  570] loss: 134406.1875 RMSElog: 9.9402 grad_loss: 13429.7246 normal_loss: 0.9539
[epoch 57][iter  580] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 57][iter  590] loss: 120745.8203 RMSElog: 9.7706 grad_loss: 12063.8691 normal_loss: 0.9428
[epoch 58][iter    0] loss: 153447.6875 RMSElog: 9.9051 grad_loss: 15333.9209 normal_loss: 0.9425
[epoch 58][iter   10] loss: 154855.9062 RMSElog: 9.8054 grad_loss: 15474.8340 normal_loss: 0.9510
[epoch 58][iter   20] loss: 216509.5625 RMSElog: 10.1942 grad_loss: 21639.8223 normal_loss: 0.9420
[epoch 58][iter   30] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 58][iter   40] loss: 156253.7656 RMSElog: 9.8231 grad_loss: 15614.6211 normal_loss: 0.9316
[epoch 58][iter   50] loss: 164766.2812 RMSElog: 9.6928 grad_loss: 16465.9941 normal_loss: 0.9411
[epoch 58][iter   60] loss: 104446.5625 RMSElog: 10.1932 grad_loss: 10433.5342 normal_loss: 0.9288
[epoch 58][iter   70] loss: 146444.9062 RMSElog: 10.1139 grad_loss: 14633.4365 normal_loss: 0.9403
[epoch 58][iter   80] loss: 121866.5156 RMSElog: 9.8422 grad_loss: 12175.8965 normal_loss: 0.9131
[epoch 58][iter   90] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 58][iter  100] loss: 108830.7344 RMSElog: 9.7359 grad_loss: 10872.4062 normal_loss: 0.9307
[epoch 58][iter  110] loss: 212239.7031 RMSElog: 10.2690 grad_loss: 21212.7383 normal_loss: 0.9638
[epoch 58][iter  120] loss: 161633.2656 RMSElog: 10.0107 grad_loss: 16152.3643 normal_loss: 0.9518
[epoch 58][iter  130] loss: 157119.7500 RMSElog: 9.8959 grad_loss: 15701.1318 normal_loss: 0.9480
[epoch 58][iter  140] loss: 111712.9062 RMSElog: 9.7826 grad_loss: 11160.5801 normal_loss: 0.9290
[epoch 58][iter  150] loss: 138714.8906 RMSElog: 10.1491 grad_loss: 13860.4043 normal_loss: 0.9360
[epoch 58][iter  160] loss: 176223.4531 RMSElog: 9.9872 grad_loss: 17611.4141 normal_loss: 0.9446
[epoch 58][iter  170] loss: 196437.7969 RMSElog: 10.2319 grad_loss: 19632.5879 normal_loss: 0.9584
[epoch 58][iter  180] loss: 190972.3281 RMSElog: 10.1152 grad_loss: 19086.1523 normal_loss: 0.9647
[epoch 58][iter  190] loss: 142596.2344 RMSElog: 9.8922 grad_loss: 14248.7803 normal_loss: 0.9508
[epoch 58][iter  200] loss: 135699.4688 RMSElog: 9.6754 grad_loss: 13559.3340 normal_loss: 0.9364
[epoch 58][iter  210] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 58][iter  220] loss: 165750.3750 RMSElog: 9.8971 grad_loss: 16564.1895 normal_loss: 0.9518
[epoch 58][iter  230] loss: 160051.0156 RMSElog: 9.8405 grad_loss: 15994.3105 normal_loss: 0.9506
[epoch 58][iter  240] loss: 172248.5156 RMSElog: 9.5166 grad_loss: 17214.3730 normal_loss: 0.9619
[epoch 58][iter  250] loss: 218457.8281 RMSElog: 10.1255 grad_loss: 21834.7168 normal_loss: 0.9418
[epoch 58][iter  260] loss: 125315.5625 RMSElog: 9.7124 grad_loss: 12520.9131 normal_loss: 0.9309
[epoch 58][iter  270] loss: 146161.1562 RMSElog: 10.0682 grad_loss: 14605.1289 normal_loss: 0.9190
[epoch 58][iter  280] loss: 173574.0781 RMSElog: 10.1780 grad_loss: 17346.2734 normal_loss: 0.9575
[epoch 58][iter  290] loss: 224257.9688 RMSElog: 10.2842 grad_loss: 22414.5605 normal_loss: 0.9521
[epoch 58][iter  300] loss: 112715.8125 RMSElog: 9.6867 grad_loss: 11260.9570 normal_loss: 0.9375
[epoch 58][iter  310] loss: 186960.2969 RMSElog: 10.2468 grad_loss: 18684.8457 normal_loss: 0.9380
[epoch 58][iter  320] loss: 201503.0625 RMSElog: 10.3149 grad_loss: 20139.0410 normal_loss: 0.9514
[epoch 58][iter  330] loss: 217174.7656 RMSElog: 10.2254 grad_loss: 21706.2891 normal_loss: 0.9635
[epoch 58][iter  340] loss: 179740.0625 RMSElog: 10.1206 grad_loss: 17962.9453 normal_loss: 0.9397
[epoch 58][iter  350] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch 58][iter  360] loss: 150608.8906 RMSElog: 10.0680 grad_loss: 15049.8750 normal_loss: 0.9460
[epoch 58][iter  370] loss: 111518.2734 RMSElog: 9.6257 grad_loss: 11141.2676 normal_loss: 0.9335
[epoch 58][iter  380] loss: 175934.2344 RMSElog: 10.1481 grad_loss: 17582.3086 normal_loss: 0.9674
[epoch 58][iter  390] loss: 147915.7812 RMSElog: 10.0131 grad_loss: 14780.6104 normal_loss: 0.9547
[epoch 58][iter  400] loss: 196677.7812 RMSElog: 10.0486 grad_loss: 19656.7715 normal_loss: 0.9571
[epoch 58][iter  410] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 58][iter  420] loss: 103514.7812 RMSElog: 9.3451 grad_loss: 10341.2109 normal_loss: 0.9229
[epoch 58][iter  430] loss: 114893.3984 RMSElog: 9.2562 grad_loss: 11479.1777 normal_loss: 0.9067
[epoch 58][iter  440] loss: 141865.3906 RMSElog: 9.7199 grad_loss: 14175.8896 normal_loss: 0.9298
[epoch 58][iter  450] loss: 148184.5469 RMSElog: 10.0681 grad_loss: 14807.4355 normal_loss: 0.9504
[epoch 58][iter  460] loss: 117693.8984 RMSElog: 9.6527 grad_loss: 11758.8105 normal_loss: 0.9267
[epoch 58][iter  470] loss: 200953.4062 RMSElog: 10.1163 grad_loss: 20084.2598 normal_loss: 0.9623
[epoch 58][iter  480] loss: 100116.4922 RMSElog: 9.9235 grad_loss: 10000.7998 normal_loss: 0.9258
[epoch 58][iter  490] loss: 103815.4375 RMSElog: 9.7764 grad_loss: 10370.8340 normal_loss: 0.9338
[epoch 58][iter  500] loss: 159798.6094 RMSElog: 9.8075 grad_loss: 15969.1260 normal_loss: 0.9263
[epoch 58][iter  510] loss: 176798.0312 RMSElog: 9.8176 grad_loss: 17669.0293 normal_loss: 0.9559
[epoch 58][iter  520] loss: 95221.2109 RMSElog: 9.1894 grad_loss: 9512.0205 normal_loss: 0.9115
[epoch 58][iter  530] loss: 124246.3594 RMSElog: 9.7165 grad_loss: 12413.9834 normal_loss: 0.9360
[epoch 58][iter  540] loss: 132935.3906 RMSElog: 9.9640 grad_loss: 13282.6172 normal_loss: 0.9581
[epoch 58][iter  550] loss: 104086.5234 RMSElog: 9.7787 grad_loss: 10397.9453 normal_loss: 0.9289
[epoch 58][iter  560] loss: 144589.9531 RMSElog: 9.7438 grad_loss: 14448.3340 normal_loss: 0.9167
[epoch 58][iter  570] loss: 199607.1562 RMSElog: 10.1504 grad_loss: 19949.6133 normal_loss: 0.9517
[epoch 58][iter  580] loss: 181942.5625 RMSElog: 10.0291 grad_loss: 18183.2793 normal_loss: 0.9464
[epoch 58][iter  590] loss: 129708.8906 RMSElog: 10.0691 grad_loss: 12959.8711 normal_loss: 0.9481
[epoch 59][iter    0] loss: 177664.5312 RMSElog: 9.7808 grad_loss: 17755.7344 normal_loss: 0.9369
[epoch 59][iter   10] loss: 116073.5938 RMSElog: 9.6844 grad_loss: 11596.7324 normal_loss: 0.9429
[epoch 59][iter   20] loss: 168409.1562 RMSElog: 9.7031 grad_loss: 16830.2910 normal_loss: 0.9228
[epoch 59][iter   30] loss: 142138.5312 RMSElog: 9.7967 grad_loss: 14203.1270 normal_loss: 0.9291
[epoch 59][iter   40] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 59][iter   50] loss: 108830.7344 RMSElog: 9.7359 grad_loss: 10872.4062 normal_loss: 0.9307
[epoch 59][iter   60] loss: 170542.9531 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.9688
[epoch 59][iter   70] loss: 232771.8594 RMSElog: 10.2938 grad_loss: 23265.9453 normal_loss: 0.9464
[epoch 59][iter   80] loss: 182476.7344 RMSElog: 9.9672 grad_loss: 18236.7656 normal_loss: 0.9407
[epoch 59][iter   90] loss: 122446.5469 RMSElog: 9.6438 grad_loss: 12234.0742 normal_loss: 0.9366
[epoch 59][iter  100] loss: 105098.6875 RMSElog: 9.7426 grad_loss: 10499.2012 normal_loss: 0.9257
[epoch 59][iter  110] loss: 166093.7344 RMSElog: 10.4480 grad_loss: 16597.9766 normal_loss: 0.9489
[epoch 59][iter  120] loss: 127463.1875 RMSElog: 9.4952 grad_loss: 12735.9082 normal_loss: 0.9153
[epoch 59][iter  130] loss: 179901.4844 RMSElog: 9.8267 grad_loss: 17979.3633 normal_loss: 0.9589
[epoch 59][iter  140] loss: 172868.6875 RMSElog: 10.0539 grad_loss: 17275.8652 normal_loss: 0.9500
[epoch 59][iter  150] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch 59][iter  160] loss: 203023.3438 RMSElog: 10.3036 grad_loss: 20291.0723 normal_loss: 0.9583
[epoch 59][iter  170] loss: 114374.2344 RMSElog: 9.1913 grad_loss: 11427.3242 normal_loss: 0.9087
[epoch 59][iter  180] loss: 184374.1875 RMSElog: 10.2641 grad_loss: 18426.1953 normal_loss: 0.9596
[epoch 59][iter  190] loss: 103798.3281 RMSElog: 9.6193 grad_loss: 10369.2812 normal_loss: 0.9331
[epoch 59][iter  200] loss: 100650.2734 RMSElog: 9.7441 grad_loss: 10054.3555 normal_loss: 0.9279
[epoch 59][iter  210] loss: 172115.2812 RMSElog: 9.7682 grad_loss: 17200.8242 normal_loss: 0.9358
[epoch 59][iter  220] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 59][iter  230] loss: 105877.8750 RMSElog: 9.7638 grad_loss: 10577.0986 normal_loss: 0.9249
[epoch 59][iter  240] loss: 175002.7344 RMSElog: 9.8652 grad_loss: 17489.4648 normal_loss: 0.9436
[epoch 59][iter  250] loss: 232158.2188 RMSElog: 10.1898 grad_loss: 23204.6875 normal_loss: 0.9455
[epoch 59][iter  260] loss: 208184.3125 RMSElog: 10.4061 grad_loss: 20807.0781 normal_loss: 0.9472
[epoch 59][iter  270] loss: 159798.6094 RMSElog: 9.8075 grad_loss: 15969.1260 normal_loss: 0.9263
[epoch 59][iter  280] loss: 146960.1250 RMSElog: 10.0979 grad_loss: 14684.9922 normal_loss: 0.9220
[epoch 59][iter  290] loss: 199607.1562 RMSElog: 10.1504 grad_loss: 19949.6133 normal_loss: 0.9517
[epoch 59][iter  300] loss: 156982.7188 RMSElog: 10.0093 grad_loss: 15687.3193 normal_loss: 0.9438
[epoch 59][iter  310] loss: 207885.1875 RMSElog: 10.4422 grad_loss: 20777.1328 normal_loss: 0.9460
[epoch 59][iter  320] loss: 185071.7188 RMSElog: 10.0456 grad_loss: 18496.1719 normal_loss: 0.9557
[epoch 59][iter  330] loss: 177699.9688 RMSElog: 9.4851 grad_loss: 17759.5488 normal_loss: 0.9621
[epoch 59][iter  340] loss: 136507.7344 RMSElog: 10.0223 grad_loss: 13639.7900 normal_loss: 0.9608
[epoch 59][iter  350] loss: 188645.4531 RMSElog: 10.1590 grad_loss: 18853.4082 normal_loss: 0.9794
[epoch 59][iter  360] loss: 181293.3438 RMSElog: 10.0009 grad_loss: 18118.3809 normal_loss: 0.9531
[epoch 59][iter  370] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 59][iter  380] loss: 214067.1875 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.9394
[epoch 59][iter  390] loss: 156253.7656 RMSElog: 9.8231 grad_loss: 15614.6211 normal_loss: 0.9316
[epoch 59][iter  400] loss: 120590.1719 RMSElog: 9.9054 grad_loss: 12048.1719 normal_loss: 0.9408
[epoch 59][iter  410] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1221 normal_loss: 0.9462
[epoch 59][iter  420] loss: 160825.5938 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.9491
[epoch 59][iter  430] loss: 174565.0781 RMSElog: 9.7759 grad_loss: 17445.7832 normal_loss: 0.9484
[epoch 59][iter  440] loss: 104086.5234 RMSElog: 9.7787 grad_loss: 10397.9453 normal_loss: 0.9289
[epoch 59][iter  450] loss: 112715.8125 RMSElog: 9.6867 grad_loss: 11260.9570 normal_loss: 0.9375
[epoch 59][iter  460] loss: 124246.3594 RMSElog: 9.7165 grad_loss: 12413.9834 normal_loss: 0.9360
[epoch 59][iter  470] loss: 230519.3906 RMSElog: 10.3105 grad_loss: 23040.6836 normal_loss: 0.9459
[epoch 59][iter  480] loss: 125486.8672 RMSElog: 9.7758 grad_loss: 12537.9834 normal_loss: 0.9281
[epoch 59][iter  490] loss: 182005.7031 RMSElog: 10.0998 grad_loss: 18189.5195 normal_loss: 0.9507
[epoch 59][iter  500] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 59][iter  510] loss: 106516.8047 RMSElog: 9.6966 grad_loss: 10641.0557 normal_loss: 0.9285
[epoch 59][iter  520] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 59][iter  530] loss: 205362.7188 RMSElog: 10.1686 grad_loss: 20525.1562 normal_loss: 0.9475
[epoch 59][iter  540] loss: 160743.4062 RMSElog: 9.7965 grad_loss: 16063.6025 normal_loss: 0.9413
[epoch 59][iter  550] loss: 160788.1406 RMSElog: 9.7539 grad_loss: 16068.1289 normal_loss: 0.9318
[epoch 59][iter  560] loss: 132623.8750 RMSElog: 9.3325 grad_loss: 13252.1152 normal_loss: 0.9391
[epoch 59][iter  570] loss: 104456.8438 RMSElog: 10.0170 grad_loss: 10434.7461 normal_loss: 0.9214
[epoch 59][iter  580] loss: 148184.5469 RMSElog: 10.0681 grad_loss: 14807.4355 normal_loss: 0.9504
[epoch 59][iter  590] loss: 221213.4219 RMSElog: 10.1740 grad_loss: 22110.2266 normal_loss: 0.9415
[epoch 60][iter    0] loss: 109441.5234 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.9300
[epoch 60][iter   10] loss: 194408.7812 RMSElog: 10.2924 grad_loss: 19429.6328 normal_loss: 0.9537
[epoch 60][iter   20] loss: 221089.3594 RMSElog: 10.3457 grad_loss: 22097.6465 normal_loss: 0.9439
[epoch 60][iter   30] loss: 159824.3594 RMSElog: 9.8973 grad_loss: 15971.5811 normal_loss: 0.9569
[epoch 60][iter   40] loss: 143460.8594 RMSElog: 9.7520 grad_loss: 14335.3848 normal_loss: 0.9489
[epoch 60][iter   50] loss: 153594.7031 RMSElog: 9.8426 grad_loss: 15348.6826 normal_loss: 0.9453
[epoch 60][iter   60] loss: 182005.7031 RMSElog: 10.0998 grad_loss: 18189.5195 normal_loss: 0.9507
[epoch 60][iter   70] loss: 175299.8438 RMSElog: 10.1975 grad_loss: 17518.8301 normal_loss: 0.9576
[epoch 60][iter   80] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 60][iter   90] loss: 218757.0312 RMSElog: 10.1228 grad_loss: 21864.6270 normal_loss: 0.9524
[epoch 60][iter  100] loss: 191971.7188 RMSElog: 10.0873 grad_loss: 19186.1172 normal_loss: 0.9662
[epoch 60][iter  110] loss: 164767.1875 RMSElog: 9.8398 grad_loss: 16465.9102 normal_loss: 0.9691
[epoch 60][iter  120] loss: 115495.2188 RMSElog: 9.6084 grad_loss: 11538.9688 normal_loss: 0.9442
[epoch 60][iter  130] loss: 167784.2500 RMSElog: 9.9330 grad_loss: 16767.5391 normal_loss: 0.9539
[epoch 60][iter  140] loss: 107472.2578 RMSElog: 9.0654 grad_loss: 10737.2480 normal_loss: 0.9124
[epoch 60][iter  150] loss: 199607.1562 RMSElog: 10.1504 grad_loss: 19949.6133 normal_loss: 0.9517
[epoch 60][iter  160] loss: 177664.5469 RMSElog: 9.7808 grad_loss: 17755.7363 normal_loss: 0.9369
[epoch 60][iter  170] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 60][iter  180] loss: 124323.5156 RMSElog: 9.7543 grad_loss: 12421.6650 normal_loss: 0.9322
[epoch 60][iter  190] loss: 149128.2188 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.9419
[epoch 60][iter  200] loss: 170542.9531 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.9688
[epoch 60][iter  210] loss: 113895.6328 RMSElog: 9.2606 grad_loss: 11379.3926 normal_loss: 0.9106
[epoch 60][iter  220] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 60][iter  230] loss: 156557.3594 RMSElog: 9.6970 grad_loss: 15645.1025 normal_loss: 0.9363
[epoch 60][iter  240] loss: 218457.8281 RMSElog: 10.1255 grad_loss: 21834.7168 normal_loss: 0.9418
[epoch 60][iter  250] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch 60][iter  260] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 60][iter  270] loss: 206083.5312 RMSElog: 10.2501 grad_loss: 20597.1465 normal_loss: 0.9562
[epoch 60][iter  280] loss: 166207.1094 RMSElog: 9.7947 grad_loss: 16609.9668 normal_loss: 0.9492
[epoch 60][iter  290] loss: 206400.7812 RMSElog: 10.3027 grad_loss: 20628.8281 normal_loss: 0.9467
[epoch 60][iter  300] loss: 172755.6875 RMSElog: 10.0251 grad_loss: 17264.6016 normal_loss: 0.9419
[epoch 60][iter  310] loss: 141962.4844 RMSElog: 9.7918 grad_loss: 14185.5273 normal_loss: 0.9289
[epoch 60][iter  320] loss: 167794.0469 RMSElog: 9.8335 grad_loss: 16768.6211 normal_loss: 0.9500
[epoch 60][iter  330] loss: 160788.1406 RMSElog: 9.7539 grad_loss: 16068.1289 normal_loss: 0.9318
[epoch 60][iter  340] loss: 103514.7734 RMSElog: 9.3451 grad_loss: 10341.2100 normal_loss: 0.9229
[epoch 60][iter  350] loss: 107948.0312 RMSElog: 9.7377 grad_loss: 10784.1309 normal_loss: 0.9342
[epoch 60][iter  360] loss: 146465.6875 RMSElog: 10.2283 grad_loss: 14635.4062 normal_loss: 0.9337
[epoch 60][iter  370] loss: 129743.7969 RMSElog: 9.9523 grad_loss: 12963.4785 normal_loss: 0.9492
[epoch 60][iter  380] loss: 177936.2812 RMSElog: 10.0381 grad_loss: 17782.6348 normal_loss: 0.9545
[epoch 60][iter  390] loss: 106516.8047 RMSElog: 9.6966 grad_loss: 10641.0557 normal_loss: 0.9285
[epoch 60][iter  400] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 60][iter  410] loss: 205235.7188 RMSElog: 10.2875 grad_loss: 20512.3281 normal_loss: 0.9564
[epoch 60][iter  420] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 60][iter  430] loss: 103305.2422 RMSElog: 9.5543 grad_loss: 10320.0674 normal_loss: 0.9024
[epoch 60][iter  440] loss: 197520.7500 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.9662
[epoch 60][iter  450] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 60][iter  460] loss: 210654.5312 RMSElog: 10.4982 grad_loss: 21054.0039 normal_loss: 0.9517
[epoch 60][iter  470] loss: 143613.7656 RMSElog: 9.8882 grad_loss: 14350.5566 normal_loss: 0.9315
[epoch 60][iter  480] loss: 150323.7656 RMSElog: 10.0510 grad_loss: 15021.3848 normal_loss: 0.9410
[epoch 60][iter  490] loss: 148057.2500 RMSElog: 9.9895 grad_loss: 14794.7803 normal_loss: 0.9555
[epoch 60][iter  500] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 60][iter  510] loss: 160879.7969 RMSElog: 9.7521 grad_loss: 16077.2764 normal_loss: 0.9513
[epoch 60][iter  520] loss: 105816.5000 RMSElog: 9.4266 grad_loss: 10571.3066 normal_loss: 0.9171
[epoch 60][iter  530] loss: 148239.1406 RMSElog: 9.8055 grad_loss: 14813.1689 normal_loss: 0.9395
[epoch 60][iter  540] loss: 145389.9375 RMSElog: 9.8784 grad_loss: 14528.1660 normal_loss: 0.9489
[epoch 60][iter  550] loss: 204037.7500 RMSElog: 10.1754 grad_loss: 20392.6582 normal_loss: 0.9420
[epoch 60][iter  560] loss: 144589.9531 RMSElog: 9.7438 grad_loss: 14448.3340 normal_loss: 0.9167
[epoch 60][iter  570] loss: 139433.9219 RMSElog: 9.8139 grad_loss: 13932.6191 normal_loss: 0.9591
[epoch 60][iter  580] loss: 227323.8281 RMSElog: 10.4159 grad_loss: 22721.0195 normal_loss: 0.9477
[epoch 60][iter  590] loss: 175524.1250 RMSElog: 10.2056 grad_loss: 17541.2441 normal_loss: 0.9625
[epoch 61][iter    0] loss: 110808.0469 RMSElog: 9.7171 grad_loss: 11070.1562 normal_loss: 0.9312
[epoch 61][iter   10] loss: 189507.2500 RMSElog: 10.2157 grad_loss: 18939.5586 normal_loss: 0.9510
[epoch 61][iter   20] loss: 228338.7500 RMSElog: 10.2936 grad_loss: 22822.6348 normal_loss: 0.9477
[epoch 61][iter   30] loss: 175524.1250 RMSElog: 10.2056 grad_loss: 17541.2441 normal_loss: 0.9625
[epoch 61][iter   40] loss: 113895.6328 RMSElog: 9.2606 grad_loss: 11379.3926 normal_loss: 0.9106
[epoch 61][iter   50] loss: 194987.6250 RMSElog: 9.8416 grad_loss: 19487.9453 normal_loss: 0.9748
[epoch 61][iter   60] loss: 105628.3672 RMSElog: 10.0899 grad_loss: 10551.8262 normal_loss: 0.9213
[epoch 61][iter   70] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 61][iter   80] loss: 154290.2500 RMSElog: 9.8471 grad_loss: 15418.2334 normal_loss: 0.9458
[epoch 61][iter   90] loss: 224257.9844 RMSElog: 10.2842 grad_loss: 22414.5625 normal_loss: 0.9521
[epoch 61][iter  100] loss: 114374.2344 RMSElog: 9.1913 grad_loss: 11427.3242 normal_loss: 0.9087
[epoch 61][iter  110] loss: 147598.9844 RMSElog: 9.8981 grad_loss: 14749.0645 normal_loss: 0.9355
[epoch 61][iter  120] loss: 194578.5781 RMSElog: 10.2312 grad_loss: 19446.6680 normal_loss: 0.9596
[epoch 61][iter  130] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch 61][iter  140] loss: 221213.4219 RMSElog: 10.1740 grad_loss: 22110.2266 normal_loss: 0.9415
[epoch 61][iter  150] loss: 176223.4531 RMSElog: 9.9872 grad_loss: 17611.4141 normal_loss: 0.9446
[epoch 61][iter  160] loss: 105098.6875 RMSElog: 9.7426 grad_loss: 10499.2012 normal_loss: 0.9257
[epoch 61][iter  170] loss: 177936.2812 RMSElog: 10.0381 grad_loss: 17782.6348 normal_loss: 0.9545
[epoch 61][iter  180] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 61][iter  190] loss: 100990.1562 RMSElog: 9.7350 grad_loss: 10088.3584 normal_loss: 0.9222
[epoch 61][iter  200] loss: 218949.8281 RMSElog: 10.4462 grad_loss: 21883.5918 normal_loss: 0.9447
[epoch 61][iter  210] loss: 147207.9844 RMSElog: 9.9779 grad_loss: 14709.8789 normal_loss: 0.9413
[epoch 61][iter  220] loss: 103534.6562 RMSElog: 9.7670 grad_loss: 10342.7715 normal_loss: 0.9280
[epoch 61][iter  230] loss: 213401.8906 RMSElog: 10.0568 grad_loss: 21329.1582 normal_loss: 0.9749
[epoch 61][iter  240] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 61][iter  250] loss: 160825.5938 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.9491
[epoch 61][iter  260] loss: 163268.1250 RMSElog: 9.9218 grad_loss: 16315.9277 normal_loss: 0.9630
[epoch 61][iter  270] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 61][iter  280] loss: 177664.5469 RMSElog: 9.7808 grad_loss: 17755.7363 normal_loss: 0.9369
[epoch 61][iter  290] loss: 105706.7031 RMSElog: 9.7501 grad_loss: 10559.9883 normal_loss: 0.9321
[epoch 61][iter  300] loss: 218547.0156 RMSElog: 10.4419 grad_loss: 21843.3086 normal_loss: 0.9515
[epoch 61][iter  310] loss: 214775.1719 RMSElog: 10.1719 grad_loss: 21466.3848 normal_loss: 0.9613
[epoch 61][iter  320] loss: 115500.4766 RMSElog: 9.9924 grad_loss: 11539.1230 normal_loss: 0.9328
[epoch 61][iter  330] loss: 153594.7031 RMSElog: 9.8426 grad_loss: 15348.6826 normal_loss: 0.9453
[epoch 61][iter  340] loss: 200470.3906 RMSElog: 10.2414 grad_loss: 20035.8379 normal_loss: 0.9585
[epoch 61][iter  350] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 61][iter  360] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 61][iter  370] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch 61][iter  380] loss: 115452.5781 RMSElog: 9.2301 grad_loss: 11535.1230 normal_loss: 0.9042
[epoch 61][iter  390] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 61][iter  400] loss: 153501.7031 RMSElog: 10.1127 grad_loss: 15339.1152 normal_loss: 0.9429
[epoch 61][iter  410] loss: 119655.7969 RMSElog: 9.6110 grad_loss: 11955.0312 normal_loss: 0.9378
[epoch 61][iter  420] loss: 175002.7344 RMSElog: 9.8652 grad_loss: 17489.4648 normal_loss: 0.9436
[epoch 61][iter  430] loss: 175301.7344 RMSElog: 9.8017 grad_loss: 17519.4180 normal_loss: 0.9555
[epoch 61][iter  440] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 61][iter  450] loss: 234945.1719 RMSElog: 10.0015 grad_loss: 23483.5664 normal_loss: 0.9500
[epoch 61][iter  460] loss: 129163.5156 RMSElog: 9.7674 grad_loss: 12905.6660 normal_loss: 0.9175
[epoch 61][iter  470] loss: 109441.5234 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.9300
[epoch 61][iter  480] loss: 125281.0156 RMSElog: 9.5401 grad_loss: 12517.6484 normal_loss: 0.9128
[epoch 61][iter  490] loss: 196025.7031 RMSElog: 10.2650 grad_loss: 19591.3496 normal_loss: 0.9559
[epoch 61][iter  500] loss: 145409.6719 RMSElog: 9.8330 grad_loss: 14530.1904 normal_loss: 0.9445
[epoch 61][iter  510] loss: 195999.5625 RMSElog: 10.1749 grad_loss: 19588.8047 normal_loss: 0.9756
[epoch 61][iter  520] loss: 164766.2812 RMSElog: 9.6928 grad_loss: 16465.9941 normal_loss: 0.9411
[epoch 61][iter  530] loss: 182476.7344 RMSElog: 9.9672 grad_loss: 18236.7656 normal_loss: 0.9407
[epoch 61][iter  540] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 61][iter  550] loss: 173574.0781 RMSElog: 10.1780 grad_loss: 17346.2734 normal_loss: 0.9575
[epoch 61][iter  560] loss: 177063.6250 RMSElog: 10.1532 grad_loss: 17695.2383 normal_loss: 0.9719
[epoch 61][iter  570] loss: 128883.6406 RMSElog: 9.8798 grad_loss: 12877.5254 normal_loss: 0.9593
[epoch 61][iter  580] loss: 120292.3438 RMSElog: 9.8042 grad_loss: 12018.4863 normal_loss: 0.9430
[epoch 61][iter  590] loss: 214808.7500 RMSElog: 10.1872 grad_loss: 21469.7461 normal_loss: 0.9423
[epoch 62][iter    0] loss: 218625.8750 RMSElog: 10.2839 grad_loss: 21851.3457 normal_loss: 0.9592
[epoch 62][iter   10] loss: 198293.9219 RMSElog: 10.2275 grad_loss: 19818.2148 normal_loss: 0.9521
[epoch 62][iter   20] loss: 174375.7031 RMSElog: 10.0512 grad_loss: 17426.5703 normal_loss: 0.9483
[epoch 62][iter   30] loss: 133464.0312 RMSElog: 9.6242 grad_loss: 13335.8584 normal_loss: 0.9201
[epoch 62][iter   40] loss: 107073.5156 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.9313
[epoch 62][iter   50] loss: 103509.2188 RMSElog: 9.9787 grad_loss: 10340.0186 normal_loss: 0.9251
[epoch 62][iter   60] loss: 206083.5156 RMSElog: 10.2501 grad_loss: 20597.1445 normal_loss: 0.9562
[epoch 62][iter   70] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch 62][iter   80] loss: 123525.9062 RMSElog: 9.3524 grad_loss: 12342.2930 normal_loss: 0.9450
[epoch 62][iter   90] loss: 227080.5938 RMSElog: 10.4127 grad_loss: 22696.6992 normal_loss: 0.9482
[epoch 62][iter  100] loss: 143534.0938 RMSElog: 9.7662 grad_loss: 14342.7061 normal_loss: 0.9374
[epoch 62][iter  110] loss: 152593.5000 RMSElog: 9.8773 grad_loss: 15248.5449 normal_loss: 0.9283
[epoch 62][iter  120] loss: 130641.2188 RMSElog: 9.7184 grad_loss: 13053.4688 normal_loss: 0.9344
[epoch 62][iter  130] loss: 136796.3438 RMSElog: 9.6524 grad_loss: 13669.0273 normal_loss: 0.9549
[epoch 62][iter  140] loss: 159824.3594 RMSElog: 9.8973 grad_loss: 15971.5811 normal_loss: 0.9569
[epoch 62][iter  150] loss: 175002.7344 RMSElog: 9.8652 grad_loss: 17489.4648 normal_loss: 0.9436
[epoch 62][iter  160] loss: 201503.0625 RMSElog: 10.3149 grad_loss: 20139.0410 normal_loss: 0.9514
[epoch 62][iter  170] loss: 149369.9219 RMSElog: 10.0930 grad_loss: 14925.9766 normal_loss: 0.9225
[epoch 62][iter  180] loss: 175301.7344 RMSElog: 9.8017 grad_loss: 17519.4180 normal_loss: 0.9555
[epoch 62][iter  190] loss: 173855.4375 RMSElog: 10.0769 grad_loss: 17374.5098 normal_loss: 0.9566
[epoch 62][iter  200] loss: 188717.5625 RMSElog: 10.0336 grad_loss: 18860.7715 normal_loss: 0.9509
[epoch 62][iter  210] loss: 148057.2500 RMSElog: 9.9895 grad_loss: 14794.7803 normal_loss: 0.9555
[epoch 62][iter  220] loss: 163171.1562 RMSElog: 9.7905 grad_loss: 16306.3594 normal_loss: 0.9652
[epoch 62][iter  230] loss: 105742.0469 RMSElog: 9.7582 grad_loss: 10563.5244 normal_loss: 0.9230
[epoch 62][iter  240] loss: 95221.2109 RMSElog: 9.1894 grad_loss: 9512.0205 normal_loss: 0.9115
[epoch 62][iter  250] loss: 190972.3281 RMSElog: 10.1152 grad_loss: 19086.1523 normal_loss: 0.9647
[epoch 62][iter  260] loss: 122331.3906 RMSElog: 9.7180 grad_loss: 12222.4795 normal_loss: 0.9418
[epoch 62][iter  270] loss: 128277.9766 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.9518
[epoch 62][iter  280] loss: 138057.5156 RMSElog: 9.5188 grad_loss: 13795.3184 normal_loss: 0.9138
[epoch 62][iter  290] loss: 162711.9688 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.9427
[epoch 62][iter  300] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch 62][iter  310] loss: 103534.6562 RMSElog: 9.7670 grad_loss: 10342.7715 normal_loss: 0.9280
[epoch 62][iter  320] loss: 203023.3438 RMSElog: 10.3036 grad_loss: 20291.0723 normal_loss: 0.9583
[epoch 62][iter  330] loss: 113895.6328 RMSElog: 9.2606 grad_loss: 11379.3926 normal_loss: 0.9106
[epoch 62][iter  340] loss: 101101.5781 RMSElog: 9.9274 grad_loss: 10099.3008 normal_loss: 0.9297
[epoch 62][iter  350] loss: 176798.0469 RMSElog: 9.8176 grad_loss: 17669.0312 normal_loss: 0.9559
[epoch 62][iter  360] loss: 152772.4062 RMSElog: 9.8249 grad_loss: 15266.4727 normal_loss: 0.9438
[epoch 62][iter  370] loss: 106952.9219 RMSElog: 10.0294 grad_loss: 10684.3398 normal_loss: 0.9231
[epoch 62][iter  380] loss: 143613.7656 RMSElog: 9.8882 grad_loss: 14350.5566 normal_loss: 0.9315
[epoch 62][iter  390] loss: 153724.0000 RMSElog: 9.9609 grad_loss: 15361.4922 normal_loss: 0.9475
[epoch 62][iter  400] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch 62][iter  410] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 62][iter  420] loss: 157061.8906 RMSElog: 9.9892 grad_loss: 15695.2461 normal_loss: 0.9531
[epoch 62][iter  430] loss: 195412.9844 RMSElog: 10.0493 grad_loss: 19530.2969 normal_loss: 0.9539
[epoch 62][iter  440] loss: 153099.1094 RMSElog: 9.8355 grad_loss: 15299.1445 normal_loss: 0.9304
[epoch 62][iter  450] loss: 162433.1875 RMSElog: 9.8183 grad_loss: 16232.5488 normal_loss: 0.9510
[epoch 62][iter  460] loss: 150321.2812 RMSElog: 9.9248 grad_loss: 15021.2656 normal_loss: 0.9385
[epoch 62][iter  470] loss: 135215.1250 RMSElog: 9.9407 grad_loss: 13510.6152 normal_loss: 0.9572
[epoch 62][iter  480] loss: 195777.0469 RMSElog: 10.1280 grad_loss: 19566.6035 normal_loss: 0.9726
[epoch 62][iter  490] loss: 127110.9375 RMSElog: 9.5273 grad_loss: 12700.6064 normal_loss: 0.9604
[epoch 62][iter  500] loss: 109260.8906 RMSElog: 9.7819 grad_loss: 10915.3789 normal_loss: 0.9279
[epoch 62][iter  510] loss: 160642.9375 RMSElog: 9.9306 grad_loss: 16053.4121 normal_loss: 0.9504
[epoch 62][iter  520] loss: 161084.5469 RMSElog: 9.9606 grad_loss: 16097.5430 normal_loss: 0.9512
[epoch 62][iter  530] loss: 170690.9375 RMSElog: 9.9328 grad_loss: 17058.2129 normal_loss: 0.9470
[epoch 62][iter  540] loss: 115658.3125 RMSElog: 9.1856 grad_loss: 11555.7031 normal_loss: 0.9424
[epoch 62][iter  550] loss: 174565.0781 RMSElog: 9.7759 grad_loss: 17445.7832 normal_loss: 0.9484
[epoch 62][iter  560] loss: 156982.7188 RMSElog: 10.0093 grad_loss: 15687.3193 normal_loss: 0.9438
[epoch 62][iter  570] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 62][iter  580] loss: 180982.8438 RMSElog: 10.2711 grad_loss: 18087.0605 normal_loss: 0.9528
[epoch 62][iter  590] loss: 112851.7266 RMSElog: 9.4205 grad_loss: 11274.8320 normal_loss: 0.9199
[epoch 63][iter    0] loss: 189507.2500 RMSElog: 10.2157 grad_loss: 18939.5586 normal_loss: 0.9510
[epoch 63][iter   10] loss: 184374.2188 RMSElog: 10.2641 grad_loss: 18426.1992 normal_loss: 0.9596
[epoch 63][iter   20] loss: 234945.1719 RMSElog: 10.0015 grad_loss: 23483.5664 normal_loss: 0.9500
[epoch 63][iter   30] loss: 106195.4219 RMSElog: 9.2531 grad_loss: 10609.3711 normal_loss: 0.9179
[epoch 63][iter   40] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 63][iter   50] loss: 139154.8594 RMSElog: 9.5986 grad_loss: 13904.9707 normal_loss: 0.9164
[epoch 63][iter   60] loss: 206083.5156 RMSElog: 10.2501 grad_loss: 20597.1445 normal_loss: 0.9562
[epoch 63][iter   70] loss: 106952.9219 RMSElog: 10.0294 grad_loss: 10684.3398 normal_loss: 0.9231
[epoch 63][iter   80] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 63][iter   90] loss: 122359.4531 RMSElog: 9.7683 grad_loss: 12225.2402 normal_loss: 0.9361
[epoch 63][iter  100] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 63][iter  110] loss: 154165.2969 RMSElog: 10.0187 grad_loss: 15405.5605 normal_loss: 0.9498
[epoch 63][iter  120] loss: 166010.9531 RMSElog: 9.9249 grad_loss: 16590.2227 normal_loss: 0.9481
[epoch 63][iter  130] loss: 162372.7500 RMSElog: 9.8226 grad_loss: 16226.4922 normal_loss: 0.9603
[epoch 63][iter  140] loss: 215542.7500 RMSElog: 10.4358 grad_loss: 21542.8887 normal_loss: 0.9514
[epoch 63][iter  150] loss: 133045.7969 RMSElog: 9.8765 grad_loss: 13293.7490 normal_loss: 0.9538
[epoch 63][iter  160] loss: 191320.0938 RMSElog: 10.0978 grad_loss: 19120.9492 normal_loss: 0.9627
[epoch 63][iter  170] loss: 197714.9844 RMSElog: 10.4355 grad_loss: 19760.1094 normal_loss: 0.9532
[epoch 63][iter  180] loss: 165750.3750 RMSElog: 9.8971 grad_loss: 16564.1895 normal_loss: 0.9518
[epoch 63][iter  190] loss: 163389.5625 RMSElog: 9.7702 grad_loss: 16328.2656 normal_loss: 0.9208
[epoch 63][iter  200] loss: 172115.2812 RMSElog: 9.7682 grad_loss: 17200.8242 normal_loss: 0.9358
[epoch 63][iter  210] loss: 126023.2344 RMSElog: 9.6219 grad_loss: 12591.7656 normal_loss: 0.9360
[epoch 63][iter  220] loss: 139830.9062 RMSElog: 9.7552 grad_loss: 13972.3770 normal_loss: 0.9585
[epoch 63][iter  230] loss: 138950.6406 RMSElog: 9.9777 grad_loss: 13884.1387 normal_loss: 0.9482
[epoch 63][iter  240] loss: 212239.7031 RMSElog: 10.2690 grad_loss: 21212.7383 normal_loss: 0.9638
[epoch 63][iter  250] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 63][iter  260] loss: 186049.0312 RMSElog: 10.0165 grad_loss: 18593.9277 normal_loss: 0.9585
[epoch 63][iter  270] loss: 151401.7188 RMSElog: 9.4414 grad_loss: 15129.7939 normal_loss: 0.9361
[epoch 63][iter  280] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch 63][iter  290] loss: 189582.6719 RMSElog: 9.9918 grad_loss: 18947.3223 normal_loss: 0.9523
[epoch 63][iter  300] loss: 130641.2188 RMSElog: 9.7184 grad_loss: 13053.4688 normal_loss: 0.9344
[epoch 63][iter  310] loss: 100663.8984 RMSElog: 9.9598 grad_loss: 10055.5020 normal_loss: 0.9277
[epoch 63][iter  320] loss: 103305.2500 RMSElog: 9.5543 grad_loss: 10320.0684 normal_loss: 0.9024
[epoch 63][iter  330] loss: 127075.1875 RMSElog: 10.1217 grad_loss: 12696.4443 normal_loss: 0.9524
[epoch 63][iter  340] loss: 175002.7344 RMSElog: 9.8652 grad_loss: 17489.4648 normal_loss: 0.9436
[epoch 63][iter  350] loss: 214493.2188 RMSElog: 10.3525 grad_loss: 21438.0078 normal_loss: 0.9611
[epoch 63][iter  360] loss: 157425.7188 RMSElog: 9.9235 grad_loss: 15731.7012 normal_loss: 0.9477
[epoch 63][iter  370] loss: 159340.4219 RMSElog: 9.9507 grad_loss: 15923.1406 normal_loss: 0.9500
[epoch 63][iter  380] loss: 103798.3281 RMSElog: 9.6193 grad_loss: 10369.2812 normal_loss: 0.9331
[epoch 63][iter  390] loss: 196437.8125 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.9584
[epoch 63][iter  400] loss: 159824.3594 RMSElog: 9.8973 grad_loss: 15971.5811 normal_loss: 0.9569
[epoch 63][iter  410] loss: 146781.9531 RMSElog: 9.8688 grad_loss: 14667.3818 normal_loss: 0.9440
[epoch 63][iter  420] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch 63][iter  430] loss: 131213.2969 RMSElog: 9.6860 grad_loss: 13110.7217 normal_loss: 0.9217
[epoch 63][iter  440] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 63][iter  450] loss: 141228.9219 RMSElog: 9.9926 grad_loss: 14111.9531 normal_loss: 0.9477
[epoch 63][iter  460] loss: 144589.9531 RMSElog: 9.7438 grad_loss: 14448.3340 normal_loss: 0.9167
[epoch 63][iter  470] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 63][iter  480] loss: 145409.6719 RMSElog: 9.8330 grad_loss: 14530.1904 normal_loss: 0.9445
[epoch 63][iter  490] loss: 125683.7969 RMSElog: 9.8131 grad_loss: 12557.6123 normal_loss: 0.9537
[epoch 63][iter  500] loss: 142016.3906 RMSElog: 9.9191 grad_loss: 14190.7676 normal_loss: 0.9526
[epoch 63][iter  510] loss: 183480.3438 RMSElog: 10.0091 grad_loss: 18337.0801 normal_loss: 0.9458
[epoch 63][iter  520] loss: 218949.8281 RMSElog: 10.4462 grad_loss: 21883.5918 normal_loss: 0.9447
[epoch 63][iter  530] loss: 232771.8594 RMSElog: 10.2938 grad_loss: 23265.9453 normal_loss: 0.9464
[epoch 63][iter  540] loss: 125281.0078 RMSElog: 9.5401 grad_loss: 12517.6475 normal_loss: 0.9128
[epoch 63][iter  550] loss: 188116.2812 RMSElog: 10.0888 grad_loss: 18800.5703 normal_loss: 0.9711
[epoch 63][iter  560] loss: 158534.6406 RMSElog: 9.6735 grad_loss: 15842.8672 normal_loss: 0.9232
[epoch 63][iter  570] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 63][iter  580] loss: 197520.7500 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.9662
[epoch 63][iter  590] loss: 188662.5156 RMSElog: 10.2592 grad_loss: 18855.0352 normal_loss: 0.9574
[epoch 64][iter    0] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 64][iter   10] loss: 114374.2344 RMSElog: 9.1913 grad_loss: 11427.3242 normal_loss: 0.9087
[epoch 64][iter   20] loss: 176223.4531 RMSElog: 9.9872 grad_loss: 17611.4141 normal_loss: 0.9446
[epoch 64][iter   30] loss: 164415.3438 RMSElog: 10.0829 grad_loss: 16430.4961 normal_loss: 0.9571
[epoch 64][iter   40] loss: 218949.8281 RMSElog: 10.4462 grad_loss: 21883.5918 normal_loss: 0.9447
[epoch 64][iter   50] loss: 128319.4141 RMSElog: 9.6733 grad_loss: 12821.3398 normal_loss: 0.9287
[epoch 64][iter   60] loss: 174375.6875 RMSElog: 10.0512 grad_loss: 17426.5684 normal_loss: 0.9483
[epoch 64][iter   70] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 64][iter   80] loss: 142696.6875 RMSElog: 9.9612 grad_loss: 14258.7588 normal_loss: 0.9493
[epoch 64][iter   90] loss: 133045.7969 RMSElog: 9.8765 grad_loss: 13293.7480 normal_loss: 0.9538
[epoch 64][iter  100] loss: 153724.0000 RMSElog: 9.9609 grad_loss: 15361.4922 normal_loss: 0.9475
[epoch 64][iter  110] loss: 153594.7031 RMSElog: 9.8426 grad_loss: 15348.6826 normal_loss: 0.9453
[epoch 64][iter  120] loss: 142138.5156 RMSElog: 9.7967 grad_loss: 14203.1260 normal_loss: 0.9291
[epoch 64][iter  130] loss: 175486.0625 RMSElog: 10.0393 grad_loss: 17537.6094 normal_loss: 0.9563
[epoch 64][iter  140] loss: 160051.0156 RMSElog: 9.8405 grad_loss: 15994.3105 normal_loss: 0.9506
[epoch 64][iter  150] loss: 110603.0781 RMSElog: 9.8046 grad_loss: 11049.5664 normal_loss: 0.9364
[epoch 64][iter  160] loss: 163171.1562 RMSElog: 9.7905 grad_loss: 16306.3594 normal_loss: 0.9652
[epoch 64][iter  170] loss: 129743.7969 RMSElog: 9.9523 grad_loss: 12963.4785 normal_loss: 0.9492
[epoch 64][iter  180] loss: 195413.0312 RMSElog: 10.0493 grad_loss: 19530.3008 normal_loss: 0.9539
[epoch 64][iter  190] loss: 125281.0078 RMSElog: 9.5401 grad_loss: 12517.6475 normal_loss: 0.9128
[epoch 64][iter  200] loss: 166093.7344 RMSElog: 10.4480 grad_loss: 16597.9766 normal_loss: 0.9489
[epoch 64][iter  210] loss: 105896.6094 RMSElog: 9.6983 grad_loss: 10579.0293 normal_loss: 0.9335
[epoch 64][iter  220] loss: 140938.8594 RMSElog: 9.7483 grad_loss: 14083.1953 normal_loss: 0.9424
[epoch 64][iter  230] loss: 178076.4688 RMSElog: 9.8778 grad_loss: 17796.8457 normal_loss: 0.9233
[epoch 64][iter  240] loss: 180929.5938 RMSElog: 10.0745 grad_loss: 18081.9297 normal_loss: 0.9546
[epoch 64][iter  250] loss: 199607.0938 RMSElog: 10.0729 grad_loss: 19949.6758 normal_loss: 0.9604
[epoch 64][iter  260] loss: 160074.2031 RMSElog: 9.7506 grad_loss: 15996.7432 normal_loss: 0.9257
[epoch 64][iter  270] loss: 170357.3281 RMSElog: 9.9687 grad_loss: 17024.7988 normal_loss: 0.9644
[epoch 64][iter  280] loss: 154776.6250 RMSElog: 9.8981 grad_loss: 15466.8438 normal_loss: 0.9209
[epoch 64][iter  290] loss: 104340.6328 RMSElog: 9.7692 grad_loss: 10423.3701 normal_loss: 0.9234
[epoch 64][iter  300] loss: 107956.6094 RMSElog: 10.0900 grad_loss: 10784.6504 normal_loss: 0.9209
[epoch 64][iter  310] loss: 128488.4375 RMSElog: 9.7402 grad_loss: 12838.1719 normal_loss: 0.9319
[epoch 64][iter  320] loss: 135203.5938 RMSElog: 9.4545 grad_loss: 13509.9697 normal_loss: 0.9356
[epoch 64][iter  330] loss: 134406.1875 RMSElog: 9.9402 grad_loss: 13429.7246 normal_loss: 0.9539
[epoch 64][iter  340] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 64][iter  350] loss: 157425.7188 RMSElog: 9.9235 grad_loss: 15731.7012 normal_loss: 0.9477
[epoch 64][iter  360] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch 64][iter  370] loss: 122670.8984 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.9331
[epoch 64][iter  380] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1221 normal_loss: 0.9462
[epoch 64][iter  390] loss: 103514.7734 RMSElog: 9.3451 grad_loss: 10341.2100 normal_loss: 0.9229
[epoch 64][iter  400] loss: 136507.7344 RMSElog: 10.0223 grad_loss: 13639.7900 normal_loss: 0.9608
[epoch 64][iter  410] loss: 135699.4688 RMSElog: 9.6754 grad_loss: 13559.3340 normal_loss: 0.9364
[epoch 64][iter  420] loss: 129166.5312 RMSElog: 9.7364 grad_loss: 12905.9775 normal_loss: 0.9391
[epoch 64][iter  430] loss: 151401.7031 RMSElog: 9.4414 grad_loss: 15129.7930 normal_loss: 0.9361
[epoch 64][iter  440] loss: 160466.8750 RMSElog: 9.9086 grad_loss: 16035.8252 normal_loss: 0.9540
[epoch 64][iter  450] loss: 143534.0938 RMSElog: 9.7662 grad_loss: 14342.7061 normal_loss: 0.9374
[epoch 64][iter  460] loss: 161084.5469 RMSElog: 9.9606 grad_loss: 16097.5430 normal_loss: 0.9512
[epoch 64][iter  470] loss: 188645.4531 RMSElog: 10.1590 grad_loss: 18853.4082 normal_loss: 0.9794
[epoch 64][iter  480] loss: 220587.5781 RMSElog: 10.2995 grad_loss: 22047.5117 normal_loss: 0.9466
[epoch 64][iter  490] loss: 161646.4688 RMSElog: 10.1105 grad_loss: 16153.5762 normal_loss: 0.9608
[epoch 64][iter  500] loss: 180318.6719 RMSElog: 9.9530 grad_loss: 18020.9785 normal_loss: 0.9357
[epoch 64][iter  510] loss: 90482.6875 RMSElog: 9.3127 grad_loss: 9038.0186 normal_loss: 0.9378
[epoch 64][iter  520] loss: 116582.6172 RMSElog: 9.7871 grad_loss: 11647.5430 normal_loss: 0.9314
[epoch 64][iter  530] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 64][iter  540] loss: 191825.0781 RMSElog: 10.3012 grad_loss: 19171.2500 normal_loss: 0.9570
[epoch 64][iter  550] loss: 139154.8594 RMSElog: 9.5986 grad_loss: 13904.9707 normal_loss: 0.9164
[epoch 64][iter  560] loss: 130527.6172 RMSElog: 9.8914 grad_loss: 13041.9189 normal_loss: 0.9509
[epoch 64][iter  570] loss: 201373.6875 RMSElog: 10.3870 grad_loss: 20126.0332 normal_loss: 0.9491
[epoch 64][iter  580] loss: 127463.1875 RMSElog: 9.4952 grad_loss: 12735.9082 normal_loss: 0.9153
[epoch 64][iter  590] loss: 195777.0156 RMSElog: 10.1280 grad_loss: 19566.5996 normal_loss: 0.9726
[epoch 65][iter    0] loss: 109260.8906 RMSElog: 9.7819 grad_loss: 10915.3789 normal_loss: 0.9279
[epoch 65][iter   10] loss: 114893.3984 RMSElog: 9.2562 grad_loss: 11479.1777 normal_loss: 0.9067
[epoch 65][iter   20] loss: 119470.5156 RMSElog: 9.6196 grad_loss: 11936.5020 normal_loss: 0.9297
[epoch 65][iter   30] loss: 205362.7188 RMSElog: 10.1686 grad_loss: 20525.1562 normal_loss: 0.9475
[epoch 65][iter   40] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 65][iter   50] loss: 201162.4062 RMSElog: 9.9531 grad_loss: 20105.3164 normal_loss: 0.9706
[epoch 65][iter   60] loss: 113895.6328 RMSElog: 9.2606 grad_loss: 11379.3926 normal_loss: 0.9106
[epoch 65][iter   70] loss: 102223.4531 RMSElog: 9.4278 grad_loss: 10212.0010 normal_loss: 0.9169
[epoch 65][iter   80] loss: 154705.2344 RMSElog: 9.9142 grad_loss: 15459.6562 normal_loss: 0.9527
[epoch 65][iter   90] loss: 122450.9844 RMSElog: 9.6977 grad_loss: 12234.4727 normal_loss: 0.9292
[epoch 65][iter  100] loss: 221089.3594 RMSElog: 10.3457 grad_loss: 22097.6465 normal_loss: 0.9439
[epoch 65][iter  110] loss: 157274.4688 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.9461
[epoch 65][iter  120] loss: 138057.5156 RMSElog: 9.5188 grad_loss: 13795.3184 normal_loss: 0.9138
[epoch 65][iter  130] loss: 151368.4219 RMSElog: 9.7883 grad_loss: 15126.1289 normal_loss: 0.9251
[epoch 65][iter  140] loss: 171588.0938 RMSElog: 9.8325 grad_loss: 17148.0527 normal_loss: 0.9237
[epoch 65][iter  150] loss: 104340.6328 RMSElog: 9.7692 grad_loss: 10423.3701 normal_loss: 0.9234
[epoch 65][iter  160] loss: 108830.7344 RMSElog: 9.7359 grad_loss: 10872.4062 normal_loss: 0.9307
[epoch 65][iter  170] loss: 167784.2500 RMSElog: 9.9330 grad_loss: 16767.5391 normal_loss: 0.9539
[epoch 65][iter  180] loss: 186960.2969 RMSElog: 10.2468 grad_loss: 18684.8457 normal_loss: 0.9380
[epoch 65][iter  190] loss: 170056.2812 RMSElog: 9.7423 grad_loss: 16994.9395 normal_loss: 0.9472
[epoch 65][iter  200] loss: 148184.5469 RMSElog: 10.0681 grad_loss: 14807.4355 normal_loss: 0.9504
[epoch 65][iter  210] loss: 115495.2188 RMSElog: 9.6084 grad_loss: 11538.9688 normal_loss: 0.9442
[epoch 65][iter  220] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 65][iter  230] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 65][iter  240] loss: 193024.5000 RMSElog: 9.9639 grad_loss: 19291.5117 normal_loss: 0.9740
[epoch 65][iter  250] loss: 206083.5312 RMSElog: 10.2501 grad_loss: 20597.1465 normal_loss: 0.9562
[epoch 65][iter  260] loss: 162372.7500 RMSElog: 9.8226 grad_loss: 16226.4922 normal_loss: 0.9603
[epoch 65][iter  270] loss: 125829.2891 RMSElog: 9.7844 grad_loss: 12572.2148 normal_loss: 0.9297
[epoch 65][iter  280] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 65][iter  290] loss: 166093.7344 RMSElog: 10.4480 grad_loss: 16597.9766 normal_loss: 0.9489
[epoch 65][iter  300] loss: 114827.1016 RMSElog: 9.7767 grad_loss: 11472.0010 normal_loss: 0.9329
[epoch 65][iter  310] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 65][iter  320] loss: 147598.9844 RMSElog: 9.8981 grad_loss: 14749.0645 normal_loss: 0.9355
[epoch 65][iter  330] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch 65][iter  340] loss: 127776.8359 RMSElog: 10.0947 grad_loss: 12766.6396 normal_loss: 0.9490
[epoch 65][iter  350] loss: 133013.4531 RMSElog: 9.5635 grad_loss: 13290.8457 normal_loss: 0.9356
[epoch 65][iter  360] loss: 164843.6875 RMSElog: 9.7972 grad_loss: 16473.6367 normal_loss: 0.9360
[epoch 65][iter  370] loss: 123289.4609 RMSElog: 9.4106 grad_loss: 12318.5752 normal_loss: 0.9606
[epoch 65][iter  380] loss: 134677.6719 RMSElog: 9.8776 grad_loss: 13456.9443 normal_loss: 0.9441
[epoch 65][iter  390] loss: 160743.4062 RMSElog: 9.7965 grad_loss: 16063.6025 normal_loss: 0.9413
[epoch 65][iter  400] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 65][iter  410] loss: 217174.7656 RMSElog: 10.2254 grad_loss: 21706.2891 normal_loss: 0.9635
[epoch 65][iter  420] loss: 137252.6406 RMSElog: 9.3538 grad_loss: 13714.9785 normal_loss: 0.9319
[epoch 65][iter  430] loss: 167745.5625 RMSElog: 9.8817 grad_loss: 16763.7129 normal_loss: 0.9621
[epoch 65][iter  440] loss: 146960.1406 RMSElog: 10.0979 grad_loss: 14684.9941 normal_loss: 0.9220
[epoch 65][iter  450] loss: 157810.1406 RMSElog: 9.9254 grad_loss: 15770.1621 normal_loss: 0.9253
[epoch 65][iter  460] loss: 190938.1250 RMSElog: 10.3028 grad_loss: 19082.5566 normal_loss: 0.9541
[epoch 65][iter  470] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 65][iter  480] loss: 160438.2812 RMSElog: 9.9714 grad_loss: 16032.9082 normal_loss: 0.9487
[epoch 65][iter  490] loss: 72289.2656 RMSElog: 9.4677 grad_loss: 7218.5376 normal_loss: 0.9211
[epoch 65][iter  500] loss: 108409.6484 RMSElog: 9.2105 grad_loss: 10830.8506 normal_loss: 0.9033
[epoch 65][iter  510] loss: 175547.9062 RMSElog: 10.1409 grad_loss: 17543.7168 normal_loss: 0.9342
[epoch 65][iter  520] loss: 130145.6250 RMSElog: 9.7206 grad_loss: 13003.9072 normal_loss: 0.9344
[epoch 65][iter  530] loss: 160024.9375 RMSElog: 9.8489 grad_loss: 15991.7236 normal_loss: 0.9215
[epoch 65][iter  540] loss: 175008.6562 RMSElog: 9.9496 grad_loss: 17489.9434 normal_loss: 0.9734
[epoch 65][iter  550] loss: 122331.3906 RMSElog: 9.7180 grad_loss: 12222.4795 normal_loss: 0.9418
[epoch 65][iter  560] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch 65][iter  570] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 65][iter  580] loss: 106182.2188 RMSElog: 9.7575 grad_loss: 10607.5342 normal_loss: 0.9294
[epoch 65][iter  590] loss: 87697.6250 RMSElog: 9.9487 grad_loss: 8758.8750 normal_loss: 0.9395
[epoch 66][iter    0] loss: 147765.9219 RMSElog: 10.0607 grad_loss: 14765.6104 normal_loss: 0.9219
[epoch 66][iter   10] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 66][iter   20] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 66][iter   30] loss: 105706.7109 RMSElog: 9.7501 grad_loss: 10559.9893 normal_loss: 0.9321
[epoch 66][iter   40] loss: 224077.6719 RMSElog: 10.3869 grad_loss: 22396.4219 normal_loss: 0.9584
[epoch 66][iter   50] loss: 180663.0469 RMSElog: 10.2319 grad_loss: 18055.1094 normal_loss: 0.9630
[epoch 66][iter   60] loss: 102223.4531 RMSElog: 9.4278 grad_loss: 10212.0010 normal_loss: 0.9169
[epoch 66][iter   70] loss: 159422.2500 RMSElog: 9.7010 grad_loss: 15931.5938 normal_loss: 0.9299
[epoch 66][iter   80] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 66][iter   90] loss: 229081.2812 RMSElog: 10.2778 grad_loss: 22896.9102 normal_loss: 0.9420
[epoch 66][iter  100] loss: 112697.1016 RMSElog: 9.7295 grad_loss: 11259.0449 normal_loss: 0.9352
[epoch 66][iter  110] loss: 149135.0000 RMSElog: 10.0932 grad_loss: 14902.4570 normal_loss: 0.9500
[epoch 66][iter  120] loss: 115500.4766 RMSElog: 9.9924 grad_loss: 11539.1230 normal_loss: 0.9328
[epoch 66][iter  130] loss: 160743.4062 RMSElog: 9.7965 grad_loss: 16063.6025 normal_loss: 0.9413
[epoch 66][iter  140] loss: 195999.5625 RMSElog: 10.1749 grad_loss: 19588.8047 normal_loss: 0.9756
[epoch 66][iter  150] loss: 103305.2422 RMSElog: 9.5543 grad_loss: 10320.0674 normal_loss: 0.9024
[epoch 66][iter  160] loss: 132012.6719 RMSElog: 9.6802 grad_loss: 13190.6582 normal_loss: 0.9291
[epoch 66][iter  170] loss: 166207.1094 RMSElog: 9.7947 grad_loss: 16609.9668 normal_loss: 0.9492
[epoch 66][iter  180] loss: 115534.3672 RMSElog: 9.7196 grad_loss: 11542.7842 normal_loss: 0.9325
[epoch 66][iter  190] loss: 153447.6875 RMSElog: 9.9051 grad_loss: 15333.9209 normal_loss: 0.9425
[epoch 66][iter  200] loss: 124563.3906 RMSElog: 9.9514 grad_loss: 12445.4473 normal_loss: 0.9400
[epoch 66][iter  210] loss: 177292.4062 RMSElog: 10.1195 grad_loss: 17718.1602 normal_loss: 0.9615
[epoch 66][iter  220] loss: 190938.1094 RMSElog: 10.3028 grad_loss: 19082.5547 normal_loss: 0.9541
[epoch 66][iter  230] loss: 163253.2500 RMSElog: 9.8740 grad_loss: 16314.5010 normal_loss: 0.9499
[epoch 66][iter  240] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 66][iter  250] loss: 227080.5938 RMSElog: 10.4127 grad_loss: 22696.6992 normal_loss: 0.9482
[epoch 66][iter  260] loss: 180425.2344 RMSElog: 10.0354 grad_loss: 18031.5332 normal_loss: 0.9552
[epoch 66][iter  270] loss: 228338.7500 RMSElog: 10.2936 grad_loss: 22822.6348 normal_loss: 0.9477
[epoch 66][iter  280] loss: 141865.3906 RMSElog: 9.7199 grad_loss: 14175.8896 normal_loss: 0.9298
[epoch 66][iter  290] loss: 95221.2109 RMSElog: 9.1894 grad_loss: 9512.0205 normal_loss: 0.9115
[epoch 66][iter  300] loss: 197715.0000 RMSElog: 10.4355 grad_loss: 19760.1113 normal_loss: 0.9532
[epoch 66][iter  310] loss: 204037.7500 RMSElog: 10.1754 grad_loss: 20392.6582 normal_loss: 0.9420
[epoch 66][iter  320] loss: 115651.6406 RMSElog: 9.1877 grad_loss: 11555.0664 normal_loss: 0.9106
[epoch 66][iter  330] loss: 159798.6094 RMSElog: 9.8075 grad_loss: 15969.1260 normal_loss: 0.9263
[epoch 66][iter  340] loss: 185495.4062 RMSElog: 9.9310 grad_loss: 18538.6641 normal_loss: 0.9455
[epoch 66][iter  350] loss: 179649.7188 RMSElog: 10.2020 grad_loss: 17953.8125 normal_loss: 0.9593
[epoch 66][iter  360] loss: 182187.7188 RMSElog: 10.0835 grad_loss: 18207.7461 normal_loss: 0.9413
[epoch 66][iter  370] loss: 166069.7812 RMSElog: 9.6813 grad_loss: 16596.3574 normal_loss: 0.9393
[epoch 66][iter  380] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 66][iter  390] loss: 195671.7031 RMSElog: 10.1080 grad_loss: 19556.1133 normal_loss: 0.9494
[epoch 66][iter  400] loss: 163695.2656 RMSElog: 9.7037 grad_loss: 16358.8877 normal_loss: 0.9345
[epoch 66][iter  410] loss: 178593.9688 RMSElog: 10.0081 grad_loss: 17848.4395 normal_loss: 0.9490
[epoch 66][iter  420] loss: 104456.8438 RMSElog: 10.0170 grad_loss: 10434.7461 normal_loss: 0.9214
[epoch 66][iter  430] loss: 147915.7812 RMSElog: 10.0131 grad_loss: 14780.6104 normal_loss: 0.9547
[epoch 66][iter  440] loss: 175299.8438 RMSElog: 10.1975 grad_loss: 17518.8301 normal_loss: 0.9576
[epoch 66][iter  450] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 66][iter  460] loss: 160788.1406 RMSElog: 9.7539 grad_loss: 16068.1289 normal_loss: 0.9318
[epoch 66][iter  470] loss: 116073.6016 RMSElog: 9.6844 grad_loss: 11596.7334 normal_loss: 0.9429
[epoch 66][iter  480] loss: 135699.4688 RMSElog: 9.6754 grad_loss: 13559.3340 normal_loss: 0.9364
[epoch 66][iter  490] loss: 161285.2188 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.9476
[epoch 66][iter  500] loss: 133464.0312 RMSElog: 9.6242 grad_loss: 13335.8584 normal_loss: 0.9201
[epoch 66][iter  510] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 66][iter  520] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 66][iter  530] loss: 114149.3672 RMSElog: 9.2655 grad_loss: 11404.7637 normal_loss: 0.9073
[epoch 66][iter  540] loss: 105896.9375 RMSElog: 9.7662 grad_loss: 10578.9961 normal_loss: 0.9310
[epoch 66][iter  550] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch 66][iter  560] loss: 217174.7656 RMSElog: 10.2254 grad_loss: 21706.2891 normal_loss: 0.9635
[epoch 66][iter  570] loss: 136796.3438 RMSElog: 9.6524 grad_loss: 13669.0273 normal_loss: 0.9549
[epoch 66][iter  580] loss: 100749.6875 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.9377
[epoch 66][iter  590] loss: 167784.2500 RMSElog: 9.9330 grad_loss: 16767.5391 normal_loss: 0.9539
[epoch 67][iter    0] loss: 121959.7344 RMSElog: 9.7378 grad_loss: 12185.3047 normal_loss: 0.9314
[epoch 67][iter   10] loss: 135114.8750 RMSElog: 9.9265 grad_loss: 13500.6055 normal_loss: 0.9548
[epoch 67][iter   20] loss: 105706.7109 RMSElog: 9.7501 grad_loss: 10559.9893 normal_loss: 0.9321
[epoch 67][iter   30] loss: 151354.1562 RMSElog: 9.8837 grad_loss: 15124.5889 normal_loss: 0.9428
[epoch 67][iter   40] loss: 128979.7266 RMSElog: 9.7049 grad_loss: 12887.3350 normal_loss: 0.9327
[epoch 67][iter   50] loss: 160825.5938 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.9491
[epoch 67][iter   60] loss: 148239.1406 RMSElog: 9.8055 grad_loss: 14813.1689 normal_loss: 0.9395
[epoch 67][iter   70] loss: 202630.0781 RMSElog: 10.0417 grad_loss: 20252.0078 normal_loss: 0.9589
[epoch 67][iter   80] loss: 134406.1875 RMSElog: 9.9402 grad_loss: 13429.7246 normal_loss: 0.9539
[epoch 67][iter   90] loss: 146465.6875 RMSElog: 10.2283 grad_loss: 14635.4062 normal_loss: 0.9337
[epoch 67][iter  100] loss: 186960.2969 RMSElog: 10.2468 grad_loss: 18684.8457 normal_loss: 0.9380
[epoch 67][iter  110] loss: 173339.3750 RMSElog: 9.8230 grad_loss: 17323.1934 normal_loss: 0.9212
[epoch 67][iter  120] loss: 110235.3906 RMSElog: 9.7805 grad_loss: 11012.8271 normal_loss: 0.9312
[epoch 67][iter  130] loss: 162433.1875 RMSElog: 9.8183 grad_loss: 16232.5488 normal_loss: 0.9510
[epoch 67][iter  140] loss: 139878.0625 RMSElog: 9.8515 grad_loss: 13977.0225 normal_loss: 0.9327
[epoch 67][iter  150] loss: 103509.2188 RMSElog: 9.9787 grad_loss: 10340.0186 normal_loss: 0.9251
[epoch 67][iter  160] loss: 121866.5156 RMSElog: 9.8422 grad_loss: 12175.8965 normal_loss: 0.9131
[epoch 67][iter  170] loss: 161088.9688 RMSElog: 9.9258 grad_loss: 16098.0254 normal_loss: 0.9455
[epoch 67][iter  180] loss: 221089.3594 RMSElog: 10.3457 grad_loss: 22097.6465 normal_loss: 0.9439
[epoch 67][iter  190] loss: 195999.5625 RMSElog: 10.1749 grad_loss: 19588.8047 normal_loss: 0.9756
[epoch 67][iter  200] loss: 120765.1875 RMSElog: 9.5441 grad_loss: 12066.0400 normal_loss: 0.9348
[epoch 67][iter  210] loss: 105896.9375 RMSElog: 9.7662 grad_loss: 10578.9961 normal_loss: 0.9310
[epoch 67][iter  220] loss: 165750.3750 RMSElog: 9.8971 grad_loss: 16564.1895 normal_loss: 0.9518
[epoch 67][iter  230] loss: 111655.4766 RMSElog: 9.2050 grad_loss: 11155.4395 normal_loss: 0.9029
[epoch 67][iter  240] loss: 185772.2500 RMSElog: 9.9702 grad_loss: 18566.2969 normal_loss: 0.9567
[epoch 67][iter  250] loss: 147479.0312 RMSElog: 9.6781 grad_loss: 14737.2812 normal_loss: 0.9446
[epoch 67][iter  260] loss: 167455.8750 RMSElog: 9.7229 grad_loss: 16734.9395 normal_loss: 0.9256
[epoch 67][iter  270] loss: 193978.6562 RMSElog: 10.3530 grad_loss: 19386.5605 normal_loss: 0.9518
[epoch 67][iter  280] loss: 154705.2188 RMSElog: 9.9142 grad_loss: 15459.6543 normal_loss: 0.9527
[epoch 67][iter  290] loss: 105828.7812 RMSElog: 10.1032 grad_loss: 10571.8545 normal_loss: 0.9195
[epoch 67][iter  300] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 67][iter  310] loss: 167211.6250 RMSElog: 10.0285 grad_loss: 16710.1777 normal_loss: 0.9542
[epoch 67][iter  320] loss: 177934.3750 RMSElog: 9.8386 grad_loss: 17782.6445 normal_loss: 0.9542
[epoch 67][iter  330] loss: 115452.5781 RMSElog: 9.2301 grad_loss: 11535.1230 normal_loss: 0.9042
[epoch 67][iter  340] loss: 190972.3281 RMSElog: 10.1152 grad_loss: 19086.1523 normal_loss: 0.9647
[epoch 67][iter  350] loss: 141962.4844 RMSElog: 9.7918 grad_loss: 14185.5273 normal_loss: 0.9289
[epoch 67][iter  360] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 67][iter  370] loss: 141228.9219 RMSElog: 9.9926 grad_loss: 14111.9531 normal_loss: 0.9477
[epoch 67][iter  380] loss: 117061.6250 RMSElog: 9.2141 grad_loss: 11696.0439 normal_loss: 0.9046
[epoch 67][iter  390] loss: 180425.2344 RMSElog: 10.0354 grad_loss: 18031.5332 normal_loss: 0.9552
[epoch 67][iter  400] loss: 204650.3281 RMSElog: 10.1934 grad_loss: 20453.8633 normal_loss: 0.9763
[epoch 67][iter  410] loss: 142005.0781 RMSElog: 9.9168 grad_loss: 14189.6533 normal_loss: 0.9371
[epoch 67][iter  420] loss: 218547.0156 RMSElog: 10.4419 grad_loss: 21843.3086 normal_loss: 0.9515
[epoch 67][iter  430] loss: 129205.9375 RMSElog: 9.8851 grad_loss: 12909.7734 normal_loss: 0.9356
[epoch 67][iter  440] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 67][iter  450] loss: 216232.0312 RMSElog: 10.2147 grad_loss: 21612.0234 normal_loss: 0.9640
[epoch 67][iter  460] loss: 177814.3125 RMSElog: 10.0854 grad_loss: 17770.3887 normal_loss: 0.9571
[epoch 67][iter  470] loss: 100663.8984 RMSElog: 9.9598 grad_loss: 10055.5020 normal_loss: 0.9277
[epoch 67][iter  480] loss: 161084.5469 RMSElog: 9.9606 grad_loss: 16097.5430 normal_loss: 0.9512
[epoch 67][iter  490] loss: 188662.5156 RMSElog: 10.2592 grad_loss: 18855.0352 normal_loss: 0.9574
[epoch 67][iter  500] loss: 150323.7656 RMSElog: 10.0510 grad_loss: 15021.3848 normal_loss: 0.9410
[epoch 67][iter  510] loss: 109441.5234 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.9300
[epoch 67][iter  520] loss: 117693.8984 RMSElog: 9.6527 grad_loss: 11758.8105 normal_loss: 0.9267
[epoch 67][iter  530] loss: 232771.8594 RMSElog: 10.2938 grad_loss: 23265.9453 normal_loss: 0.9464
[epoch 67][iter  540] loss: 186049.0312 RMSElog: 10.0165 grad_loss: 18593.9277 normal_loss: 0.9585
[epoch 67][iter  550] loss: 104456.8438 RMSElog: 10.0170 grad_loss: 10434.7461 normal_loss: 0.9214
[epoch 67][iter  560] loss: 162892.2969 RMSElog: 9.8252 grad_loss: 16278.4717 normal_loss: 0.9331
[epoch 67][iter  570] loss: 181465.8125 RMSElog: 10.1136 grad_loss: 18135.5117 normal_loss: 0.9572
[epoch 67][iter  580] loss: 239768.0938 RMSElog: 10.2366 grad_loss: 23965.6250 normal_loss: 0.9466
[epoch 67][iter  590] loss: 212239.7031 RMSElog: 10.2690 grad_loss: 21212.7383 normal_loss: 0.9638
[epoch 68][iter    0] loss: 133024.8594 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.9261
[epoch 68][iter   10] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 68][iter   20] loss: 208184.3125 RMSElog: 10.4061 grad_loss: 20807.0781 normal_loss: 0.9472
[epoch 68][iter   30] loss: 139154.8594 RMSElog: 9.5986 grad_loss: 13904.9707 normal_loss: 0.9164
[epoch 68][iter   40] loss: 211925.8438 RMSElog: 10.1863 grad_loss: 21181.4551 normal_loss: 0.9436
[epoch 68][iter   50] loss: 185902.4219 RMSElog: 9.8998 grad_loss: 18579.3711 normal_loss: 0.9705
[epoch 68][iter   60] loss: 166542.4219 RMSElog: 9.8913 grad_loss: 16643.4043 normal_loss: 0.9482
[epoch 68][iter   70] loss: 115738.1953 RMSElog: 9.6968 grad_loss: 11563.1836 normal_loss: 0.9382
[epoch 68][iter   80] loss: 129166.5312 RMSElog: 9.7364 grad_loss: 12905.9775 normal_loss: 0.9391
[epoch 68][iter   90] loss: 103355.8203 RMSElog: 9.7106 grad_loss: 10324.9463 normal_loss: 0.9244
[epoch 68][iter  100] loss: 158924.9062 RMSElog: 9.8027 grad_loss: 15881.7363 normal_loss: 0.9524
[epoch 68][iter  110] loss: 196437.8125 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.9584
[epoch 68][iter  120] loss: 100749.6875 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.9377
[epoch 68][iter  130] loss: 148793.9688 RMSElog: 10.1047 grad_loss: 14868.3447 normal_loss: 0.9480
[epoch 68][iter  140] loss: 186053.2969 RMSElog: 10.1470 grad_loss: 18594.2324 normal_loss: 0.9504
[epoch 68][iter  150] loss: 221089.3594 RMSElog: 10.3457 grad_loss: 22097.6465 normal_loss: 0.9439
[epoch 68][iter  160] loss: 149128.2188 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.9419
[epoch 68][iter  170] loss: 161646.4688 RMSElog: 10.1105 grad_loss: 16153.5762 normal_loss: 0.9608
[epoch 68][iter  180] loss: 213401.8906 RMSElog: 10.0568 grad_loss: 21329.1582 normal_loss: 0.9749
[epoch 68][iter  190] loss: 185495.4062 RMSElog: 9.9310 grad_loss: 18538.6641 normal_loss: 0.9455
[epoch 68][iter  200] loss: 144657.9844 RMSElog: 9.9197 grad_loss: 14454.9258 normal_loss: 0.9518
[epoch 68][iter  210] loss: 167794.0469 RMSElog: 9.8335 grad_loss: 16768.6211 normal_loss: 0.9500
[epoch 68][iter  220] loss: 128488.4375 RMSElog: 9.7402 grad_loss: 12838.1719 normal_loss: 0.9319
[epoch 68][iter  230] loss: 144987.0938 RMSElog: 9.8653 grad_loss: 14487.9062 normal_loss: 0.9378
[epoch 68][iter  240] loss: 203093.2969 RMSElog: 10.1238 grad_loss: 20298.2598 normal_loss: 0.9478
[epoch 68][iter  250] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 68][iter  260] loss: 136507.7344 RMSElog: 10.0223 grad_loss: 13639.7900 normal_loss: 0.9608
[epoch 68][iter  270] loss: 241971.8750 RMSElog: 10.2390 grad_loss: 24186.0000 normal_loss: 0.9488
[epoch 68][iter  280] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch 68][iter  290] loss: 154626.7656 RMSElog: 9.9098 grad_loss: 15451.8066 normal_loss: 0.9596
[epoch 68][iter  300] loss: 174629.2812 RMSElog: 9.9405 grad_loss: 17452.0625 normal_loss: 0.9229
[epoch 68][iter  310] loss: 146576.9219 RMSElog: 9.6520 grad_loss: 14647.1045 normal_loss: 0.9356
[epoch 68][iter  320] loss: 103305.2500 RMSElog: 9.5543 grad_loss: 10320.0684 normal_loss: 0.9024
[epoch 68][iter  330] loss: 129205.9375 RMSElog: 9.8851 grad_loss: 12909.7734 normal_loss: 0.9356
[epoch 68][iter  340] loss: 154705.2344 RMSElog: 9.9142 grad_loss: 15459.6562 normal_loss: 0.9527
[epoch 68][iter  350] loss: 141962.4844 RMSElog: 9.7918 grad_loss: 14185.5273 normal_loss: 0.9289
[epoch 68][iter  360] loss: 165326.5625 RMSElog: 9.8832 grad_loss: 16521.8086 normal_loss: 0.9647
[epoch 68][iter  370] loss: 142138.5156 RMSElog: 9.7967 grad_loss: 14203.1260 normal_loss: 0.9291
[epoch 68][iter  380] loss: 228338.7500 RMSElog: 10.2936 grad_loss: 22822.6348 normal_loss: 0.9477
[epoch 68][iter  390] loss: 139061.3750 RMSElog: 9.6201 grad_loss: 13895.5771 normal_loss: 0.9401
[epoch 68][iter  400] loss: 115500.4766 RMSElog: 9.9924 grad_loss: 11539.1230 normal_loss: 0.9328
[epoch 68][iter  410] loss: 110235.3906 RMSElog: 9.7805 grad_loss: 11012.8271 normal_loss: 0.9312
[epoch 68][iter  420] loss: 154290.2500 RMSElog: 9.8471 grad_loss: 15418.2334 normal_loss: 0.9458
[epoch 68][iter  430] loss: 137296.6406 RMSElog: 9.9750 grad_loss: 13718.7402 normal_loss: 0.9495
[epoch 68][iter  440] loss: 182005.7031 RMSElog: 10.0998 grad_loss: 18189.5195 normal_loss: 0.9507
[epoch 68][iter  450] loss: 100116.4922 RMSElog: 9.9235 grad_loss: 10000.7998 normal_loss: 0.9258
[epoch 68][iter  460] loss: 103514.7734 RMSElog: 9.3451 grad_loss: 10341.2100 normal_loss: 0.9229
[epoch 68][iter  470] loss: 132012.6719 RMSElog: 9.6802 grad_loss: 13190.6582 normal_loss: 0.9291
[epoch 68][iter  480] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 68][iter  490] loss: 206083.5156 RMSElog: 10.2501 grad_loss: 20597.1445 normal_loss: 0.9562
[epoch 68][iter  500] loss: 190938.1250 RMSElog: 10.3028 grad_loss: 19082.5566 normal_loss: 0.9541
[epoch 68][iter  510] loss: 196277.7188 RMSElog: 10.2453 grad_loss: 19616.5664 normal_loss: 0.9595
[epoch 68][iter  520] loss: 193978.6250 RMSElog: 10.3530 grad_loss: 19386.5586 normal_loss: 0.9518
[epoch 68][iter  530] loss: 197714.9844 RMSElog: 10.4355 grad_loss: 19760.1094 normal_loss: 0.9532
[epoch 68][iter  540] loss: 149387.5625 RMSElog: 9.9550 grad_loss: 14927.8525 normal_loss: 0.9483
[epoch 68][iter  550] loss: 127463.1875 RMSElog: 9.4952 grad_loss: 12735.9082 normal_loss: 0.9153
[epoch 68][iter  560] loss: 176217.8125 RMSElog: 10.1087 grad_loss: 17610.7246 normal_loss: 0.9466
[epoch 68][iter  570] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 68][iter  580] loss: 149540.3750 RMSElog: 9.7408 grad_loss: 14943.3740 normal_loss: 0.9229
[epoch 68][iter  590] loss: 152593.5000 RMSElog: 9.8773 grad_loss: 15248.5439 normal_loss: 0.9283
[epoch 69][iter    0] loss: 105877.8750 RMSElog: 9.7638 grad_loss: 10577.0986 normal_loss: 0.9249
[epoch 69][iter   10] loss: 181983.5312 RMSElog: 10.0741 grad_loss: 18187.3320 normal_loss: 0.9464
[epoch 69][iter   20] loss: 173339.3594 RMSElog: 9.8230 grad_loss: 17323.1914 normal_loss: 0.9212
[epoch 69][iter   30] loss: 179298.9062 RMSElog: 9.7220 grad_loss: 17919.2227 normal_loss: 0.9453
[epoch 69][iter   40] loss: 130527.6172 RMSElog: 9.8914 grad_loss: 13041.9189 normal_loss: 0.9509
[epoch 69][iter   50] loss: 125486.8672 RMSElog: 9.7758 grad_loss: 12537.9834 normal_loss: 0.9281
[epoch 69][iter   60] loss: 167008.4531 RMSElog: 10.0165 grad_loss: 16689.8750 normal_loss: 0.9557
[epoch 69][iter   70] loss: 176217.8125 RMSElog: 10.1087 grad_loss: 17610.7246 normal_loss: 0.9466
[epoch 69][iter   80] loss: 160788.1406 RMSElog: 9.7539 grad_loss: 16068.1289 normal_loss: 0.9318
[epoch 69][iter   90] loss: 152149.7500 RMSElog: 9.9062 grad_loss: 15204.1230 normal_loss: 0.9462
[epoch 69][iter  100] loss: 191371.4375 RMSElog: 10.1918 grad_loss: 19126.0020 normal_loss: 0.9504
[epoch 69][iter  110] loss: 161088.9688 RMSElog: 9.9258 grad_loss: 16098.0254 normal_loss: 0.9455
[epoch 69][iter  120] loss: 173574.0781 RMSElog: 10.1780 grad_loss: 17346.2734 normal_loss: 0.9575
[epoch 69][iter  130] loss: 174761.2344 RMSElog: 9.7333 grad_loss: 17465.4512 normal_loss: 0.9393
[epoch 69][iter  140] loss: 105742.0391 RMSElog: 9.7582 grad_loss: 10563.5234 normal_loss: 0.9230
[epoch 69][iter  150] loss: 152332.5469 RMSElog: 9.9813 grad_loss: 15222.3486 normal_loss: 0.9245
[epoch 69][iter  160] loss: 218949.8281 RMSElog: 10.4462 grad_loss: 21883.5918 normal_loss: 0.9447
[epoch 69][iter  170] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 69][iter  180] loss: 143460.8594 RMSElog: 9.7520 grad_loss: 14335.3848 normal_loss: 0.9489
[epoch 69][iter  190] loss: 152549.8750 RMSElog: 9.9928 grad_loss: 15244.0293 normal_loss: 0.9654
[epoch 69][iter  200] loss: 160743.4062 RMSElog: 9.7965 grad_loss: 16063.6025 normal_loss: 0.9413
[epoch 69][iter  210] loss: 155762.3438 RMSElog: 9.8487 grad_loss: 15565.4404 normal_loss: 0.9448
[epoch 69][iter  220] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 69][iter  230] loss: 200470.3906 RMSElog: 10.2414 grad_loss: 20035.8379 normal_loss: 0.9585
[epoch 69][iter  240] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 69][iter  250] loss: 119923.2031 RMSElog: 9.5699 grad_loss: 11981.8154 normal_loss: 0.9342
[epoch 69][iter  260] loss: 196677.7812 RMSElog: 10.0486 grad_loss: 19656.7715 normal_loss: 0.9571
[epoch 69][iter  270] loss: 99107.7500 RMSElog: 9.5230 grad_loss: 9900.3428 normal_loss: 0.9094
[epoch 69][iter  280] loss: 115495.2188 RMSElog: 9.6084 grad_loss: 11538.9688 normal_loss: 0.9442
[epoch 69][iter  290] loss: 119429.4609 RMSElog: 9.6388 grad_loss: 11932.3740 normal_loss: 0.9339
[epoch 69][iter  300] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 69][iter  310] loss: 163272.7031 RMSElog: 10.0261 grad_loss: 16316.3037 normal_loss: 0.9400
[epoch 69][iter  320] loss: 218757.0312 RMSElog: 10.1228 grad_loss: 21864.6270 normal_loss: 0.9524
[epoch 69][iter  330] loss: 130145.6250 RMSElog: 9.7206 grad_loss: 13003.9072 normal_loss: 0.9344
[epoch 69][iter  340] loss: 147915.7812 RMSElog: 10.0131 grad_loss: 14780.6104 normal_loss: 0.9547
[epoch 69][iter  350] loss: 114310.3047 RMSElog: 9.4026 grad_loss: 11420.7217 normal_loss: 0.9063
[epoch 69][iter  360] loss: 100650.2734 RMSElog: 9.7441 grad_loss: 10054.3555 normal_loss: 0.9279
[epoch 69][iter  370] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 69][iter  380] loss: 175301.7344 RMSElog: 9.8017 grad_loss: 17519.4180 normal_loss: 0.9555
[epoch 69][iter  390] loss: 153099.1094 RMSElog: 9.8355 grad_loss: 15299.1445 normal_loss: 0.9304
[epoch 69][iter  400] loss: 196920.5938 RMSElog: 10.2474 grad_loss: 19680.8340 normal_loss: 0.9760
[epoch 69][iter  410] loss: 122386.0234 RMSElog: 9.6688 grad_loss: 12227.9971 normal_loss: 0.9366
[epoch 69][iter  420] loss: 147207.9844 RMSElog: 9.9779 grad_loss: 14709.8789 normal_loss: 0.9413
[epoch 69][iter  430] loss: 114924.9844 RMSElog: 9.6925 grad_loss: 11481.8691 normal_loss: 0.9360
[epoch 69][iter  440] loss: 176223.4531 RMSElog: 9.9872 grad_loss: 17611.4141 normal_loss: 0.9446
[epoch 69][iter  450] loss: 201162.4062 RMSElog: 9.9531 grad_loss: 20105.3164 normal_loss: 0.9706
[epoch 69][iter  460] loss: 114827.1016 RMSElog: 9.7767 grad_loss: 11472.0010 normal_loss: 0.9329
[epoch 69][iter  470] loss: 128979.7188 RMSElog: 9.7049 grad_loss: 12887.3340 normal_loss: 0.9327
[epoch 69][iter  480] loss: 120745.8203 RMSElog: 9.7706 grad_loss: 12063.8691 normal_loss: 0.9428
[epoch 69][iter  490] loss: 224077.6719 RMSElog: 10.3869 grad_loss: 22396.4219 normal_loss: 0.9584
[epoch 69][iter  500] loss: 196842.3281 RMSElog: 10.1249 grad_loss: 19673.1543 normal_loss: 0.9534
[epoch 69][iter  510] loss: 122331.3906 RMSElog: 9.7180 grad_loss: 12222.4795 normal_loss: 0.9418
[epoch 69][iter  520] loss: 218457.8281 RMSElog: 10.1255 grad_loss: 21834.7168 normal_loss: 0.9418
[epoch 69][iter  530] loss: 103355.8203 RMSElog: 9.7106 grad_loss: 10324.9463 normal_loss: 0.9244
[epoch 69][iter  540] loss: 224257.9844 RMSElog: 10.2842 grad_loss: 22414.5625 normal_loss: 0.9521
[epoch 69][iter  550] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 69][iter  560] loss: 162711.9688 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.9427
[epoch 69][iter  570] loss: 228053.0312 RMSElog: 10.2288 grad_loss: 22794.1328 normal_loss: 0.9422
[epoch 69][iter  580] loss: 160825.5938 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.9491
[epoch 69][iter  590] loss: 208821.7500 RMSElog: 10.1565 grad_loss: 20871.0762 normal_loss: 0.9431
[epoch 70][iter    0] loss: 182315.9688 RMSElog: 10.1291 grad_loss: 18220.5039 normal_loss: 0.9652
[epoch 70][iter   10] loss: 113426.9688 RMSElog: 9.7682 grad_loss: 11331.9922 normal_loss: 0.9362
[epoch 70][iter   20] loss: 214493.2031 RMSElog: 10.3525 grad_loss: 21438.0059 normal_loss: 0.9611
[epoch 70][iter   30] loss: 117693.8984 RMSElog: 9.6527 grad_loss: 11758.8105 normal_loss: 0.9267
[epoch 70][iter   40] loss: 215542.7500 RMSElog: 10.4358 grad_loss: 21542.8887 normal_loss: 0.9514
[epoch 70][iter   50] loss: 149369.9062 RMSElog: 10.0930 grad_loss: 14925.9756 normal_loss: 0.9225
[epoch 70][iter   60] loss: 163389.5469 RMSElog: 9.7702 grad_loss: 16328.2637 normal_loss: 0.9208
[epoch 70][iter   70] loss: 149128.2188 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.9419
[epoch 70][iter   80] loss: 116582.6172 RMSElog: 9.7871 grad_loss: 11647.5430 normal_loss: 0.9314
[epoch 70][iter   90] loss: 183095.1562 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.9696
[epoch 70][iter  100] loss: 150296.1562 RMSElog: 9.8188 grad_loss: 15018.8564 normal_loss: 0.9407
[epoch 70][iter  110] loss: 143460.8594 RMSElog: 9.7520 grad_loss: 14335.3848 normal_loss: 0.9489
[epoch 70][iter  120] loss: 206764.1875 RMSElog: 10.2849 grad_loss: 20665.1777 normal_loss: 0.9549
[epoch 70][iter  130] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch 70][iter  140] loss: 156985.6250 RMSElog: 9.5765 grad_loss: 15688.0479 normal_loss: 0.9385
[epoch 70][iter  150] loss: 142696.6875 RMSElog: 9.9612 grad_loss: 14258.7588 normal_loss: 0.9493
[epoch 70][iter  160] loss: 213417.0312 RMSElog: 10.3416 grad_loss: 21330.4082 normal_loss: 0.9536
[epoch 70][iter  170] loss: 160074.2031 RMSElog: 9.7506 grad_loss: 15996.7432 normal_loss: 0.9257
[epoch 70][iter  180] loss: 131213.2969 RMSElog: 9.6860 grad_loss: 13110.7217 normal_loss: 0.9217
[epoch 70][iter  190] loss: 156253.7812 RMSElog: 9.8231 grad_loss: 15614.6230 normal_loss: 0.9316
[epoch 70][iter  200] loss: 165750.3750 RMSElog: 9.8971 grad_loss: 16564.1895 normal_loss: 0.9518
[epoch 70][iter  210] loss: 166010.9531 RMSElog: 9.9249 grad_loss: 16590.2227 normal_loss: 0.9481
[epoch 70][iter  220] loss: 155762.3594 RMSElog: 9.8487 grad_loss: 15565.4414 normal_loss: 0.9448
[epoch 70][iter  230] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 70][iter  240] loss: 174565.0781 RMSElog: 9.7759 grad_loss: 17445.7832 normal_loss: 0.9484
[epoch 70][iter  250] loss: 105628.3594 RMSElog: 10.0899 grad_loss: 10551.8252 normal_loss: 0.9213
[epoch 70][iter  260] loss: 157274.4688 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.9461
[epoch 70][iter  270] loss: 184374.1875 RMSElog: 10.2641 grad_loss: 18426.1953 normal_loss: 0.9596
[epoch 70][iter  280] loss: 175486.0156 RMSElog: 10.0393 grad_loss: 17537.6055 normal_loss: 0.9563
[epoch 70][iter  290] loss: 191320.1250 RMSElog: 10.0978 grad_loss: 19120.9512 normal_loss: 0.9627
[epoch 70][iter  300] loss: 154626.7656 RMSElog: 9.9098 grad_loss: 15451.8066 normal_loss: 0.9596
[epoch 70][iter  310] loss: 151401.7188 RMSElog: 9.4414 grad_loss: 15129.7939 normal_loss: 0.9361
[epoch 70][iter  320] loss: 142138.5312 RMSElog: 9.7967 grad_loss: 14203.1270 normal_loss: 0.9291
[epoch 70][iter  330] loss: 134471.5938 RMSElog: 9.9200 grad_loss: 13436.3281 normal_loss: 0.9111
[epoch 70][iter  340] loss: 217174.7656 RMSElog: 10.2254 grad_loss: 21706.2891 normal_loss: 0.9635
[epoch 70][iter  350] loss: 139878.0781 RMSElog: 9.8515 grad_loss: 13977.0234 normal_loss: 0.9327
[epoch 70][iter  360] loss: 167084.9219 RMSElog: 9.8660 grad_loss: 16697.6582 normal_loss: 0.9689
[epoch 70][iter  370] loss: 127061.7500 RMSElog: 9.6726 grad_loss: 12695.5654 normal_loss: 0.9369
[epoch 70][iter  380] loss: 142544.5156 RMSElog: 10.1645 grad_loss: 14243.3457 normal_loss: 0.9425
[epoch 70][iter  390] loss: 227080.5938 RMSElog: 10.4127 grad_loss: 22696.6992 normal_loss: 0.9482
[epoch 70][iter  400] loss: 99107.7500 RMSElog: 9.5230 grad_loss: 9900.3428 normal_loss: 0.9094
[epoch 70][iter  410] loss: 135114.8750 RMSElog: 9.9265 grad_loss: 13500.6055 normal_loss: 0.9548
[epoch 70][iter  420] loss: 195440.9062 RMSElog: 9.7403 grad_loss: 19533.3926 normal_loss: 0.9572
[epoch 70][iter  430] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 70][iter  440] loss: 152517.4844 RMSElog: 9.8233 grad_loss: 15241.0010 normal_loss: 0.9249
[epoch 70][iter  450] loss: 115651.6406 RMSElog: 9.1877 grad_loss: 11555.0664 normal_loss: 0.9106
[epoch 70][iter  460] loss: 152593.5000 RMSElog: 9.8773 grad_loss: 15248.5449 normal_loss: 0.9283
[epoch 70][iter  470] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 70][iter  480] loss: 141118.5312 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.9477
[epoch 70][iter  490] loss: 139061.3750 RMSElog: 9.6201 grad_loss: 13895.5771 normal_loss: 0.9401
[epoch 70][iter  500] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 70][iter  510] loss: 177936.2812 RMSElog: 10.0381 grad_loss: 17782.6348 normal_loss: 0.9545
[epoch 70][iter  520] loss: 176260.7500 RMSElog: 10.0638 grad_loss: 17615.0703 normal_loss: 0.9395
[epoch 70][iter  530] loss: 144987.0938 RMSElog: 9.8653 grad_loss: 14487.9062 normal_loss: 0.9378
[epoch 70][iter  540] loss: 156982.7188 RMSElog: 10.0093 grad_loss: 15687.3193 normal_loss: 0.9438
[epoch 70][iter  550] loss: 185495.4062 RMSElog: 9.9310 grad_loss: 18538.6641 normal_loss: 0.9455
[epoch 70][iter  560] loss: 177063.6250 RMSElog: 10.1532 grad_loss: 17695.2383 normal_loss: 0.9719
[epoch 70][iter  570] loss: 128979.7266 RMSElog: 9.7049 grad_loss: 12887.3350 normal_loss: 0.9327
[epoch 70][iter  580] loss: 107073.5156 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.9313
[epoch 70][iter  590] loss: 241971.8750 RMSElog: 10.2390 grad_loss: 24186.0000 normal_loss: 0.9488
[epoch 71][iter    0] loss: 127463.1875 RMSElog: 9.4952 grad_loss: 12735.9082 normal_loss: 0.9153
[epoch 71][iter   10] loss: 160782.5156 RMSElog: 9.7710 grad_loss: 16067.5547 normal_loss: 0.9244
[epoch 71][iter   20] loss: 165326.5625 RMSElog: 9.8832 grad_loss: 16521.8086 normal_loss: 0.9647
[epoch 71][iter   30] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 71][iter   40] loss: 164767.1875 RMSElog: 9.8398 grad_loss: 16465.9102 normal_loss: 0.9691
[epoch 71][iter   50] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch 71][iter   60] loss: 105896.9375 RMSElog: 9.7662 grad_loss: 10578.9961 normal_loss: 0.9310
[epoch 71][iter   70] loss: 127776.8359 RMSElog: 10.0947 grad_loss: 12766.6396 normal_loss: 0.9490
[epoch 71][iter   80] loss: 177664.5312 RMSElog: 9.7808 grad_loss: 17755.7344 normal_loss: 0.9369
[epoch 71][iter   90] loss: 147371.3906 RMSElog: 9.6635 grad_loss: 14726.5488 normal_loss: 0.9280
[epoch 71][iter  100] loss: 157119.7500 RMSElog: 9.8959 grad_loss: 15701.1318 normal_loss: 0.9480
[epoch 71][iter  110] loss: 190034.7188 RMSElog: 9.9619 grad_loss: 18992.5625 normal_loss: 0.9485
[epoch 71][iter  120] loss: 176217.8125 RMSElog: 10.1087 grad_loss: 17610.7246 normal_loss: 0.9466
[epoch 71][iter  130] loss: 122331.3906 RMSElog: 9.7180 grad_loss: 12222.4795 normal_loss: 0.9418
[epoch 71][iter  140] loss: 218457.8281 RMSElog: 10.1255 grad_loss: 21834.7168 normal_loss: 0.9418
[epoch 71][iter  150] loss: 106516.8047 RMSElog: 9.6966 grad_loss: 10641.0557 normal_loss: 0.9285
[epoch 71][iter  160] loss: 136533.4688 RMSElog: 9.6756 grad_loss: 13642.7363 normal_loss: 0.9359
[epoch 71][iter  170] loss: 162363.8906 RMSElog: 9.7464 grad_loss: 16225.6777 normal_loss: 0.9661
[epoch 71][iter  180] loss: 122386.0156 RMSElog: 9.6688 grad_loss: 12227.9961 normal_loss: 0.9366
[epoch 71][iter  190] loss: 154855.9062 RMSElog: 9.8054 grad_loss: 15474.8340 normal_loss: 0.9510
[epoch 71][iter  200] loss: 106952.9219 RMSElog: 10.0294 grad_loss: 10684.3398 normal_loss: 0.9231
[epoch 71][iter  210] loss: 140645.6875 RMSElog: 10.1118 grad_loss: 14053.4873 normal_loss: 0.9695
[epoch 71][iter  220] loss: 208184.3125 RMSElog: 10.4061 grad_loss: 20807.0781 normal_loss: 0.9472
[epoch 71][iter  230] loss: 173574.0781 RMSElog: 10.1780 grad_loss: 17346.2734 normal_loss: 0.9575
[epoch 71][iter  240] loss: 182476.7344 RMSElog: 9.9672 grad_loss: 18236.7656 normal_loss: 0.9407
[epoch 71][iter  250] loss: 138057.5156 RMSElog: 9.5188 grad_loss: 13795.3184 normal_loss: 0.9138
[epoch 71][iter  260] loss: 160024.9375 RMSElog: 9.8489 grad_loss: 15991.7236 normal_loss: 0.9215
[epoch 71][iter  270] loss: 100749.6875 RMSElog: 9.9914 grad_loss: 10064.0400 normal_loss: 0.9377
[epoch 71][iter  280] loss: 208770.3906 RMSElog: 10.1964 grad_loss: 20865.8984 normal_loss: 0.9442
[epoch 71][iter  290] loss: 154290.2500 RMSElog: 9.8471 grad_loss: 15418.2334 normal_loss: 0.9458
[epoch 71][iter  300] loss: 224077.6719 RMSElog: 10.3869 grad_loss: 22396.4219 normal_loss: 0.9584
[epoch 71][iter  310] loss: 194578.5781 RMSElog: 10.2312 grad_loss: 19446.6680 normal_loss: 0.9596
[epoch 71][iter  320] loss: 132935.3906 RMSElog: 9.9640 grad_loss: 13282.6172 normal_loss: 0.9581
[epoch 71][iter  330] loss: 161285.2188 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.9476
[epoch 71][iter  340] loss: 162976.7812 RMSElog: 9.6016 grad_loss: 16287.1572 normal_loss: 0.9201
[epoch 71][iter  350] loss: 174629.2812 RMSElog: 9.9405 grad_loss: 17452.0625 normal_loss: 0.9229
[epoch 71][iter  360] loss: 154626.7656 RMSElog: 9.9098 grad_loss: 15451.8066 normal_loss: 0.9596
[epoch 71][iter  370] loss: 216232.0312 RMSElog: 10.2147 grad_loss: 21612.0234 normal_loss: 0.9640
[epoch 71][iter  380] loss: 107956.6094 RMSElog: 10.0900 grad_loss: 10784.6504 normal_loss: 0.9209
[epoch 71][iter  390] loss: 122359.4531 RMSElog: 9.7683 grad_loss: 12225.2402 normal_loss: 0.9361
[epoch 71][iter  400] loss: 228053.0312 RMSElog: 10.2288 grad_loss: 22794.1328 normal_loss: 0.9422
[epoch 71][iter  410] loss: 142138.5156 RMSElog: 9.7967 grad_loss: 14203.1260 normal_loss: 0.9291
[epoch 71][iter  420] loss: 167730.9688 RMSElog: 9.9663 grad_loss: 16762.1816 normal_loss: 0.9501
[epoch 71][iter  430] loss: 141442.1250 RMSElog: 9.6437 grad_loss: 14133.6191 normal_loss: 0.9495
[epoch 71][iter  440] loss: 166069.7812 RMSElog: 9.6813 grad_loss: 16596.3574 normal_loss: 0.9393
[epoch 71][iter  450] loss: 150699.3750 RMSElog: 9.8567 grad_loss: 15059.1328 normal_loss: 0.9486
[epoch 71][iter  460] loss: 153594.7031 RMSElog: 9.8426 grad_loss: 15348.6826 normal_loss: 0.9453
[epoch 71][iter  470] loss: 155762.3594 RMSElog: 9.8487 grad_loss: 15565.4414 normal_loss: 0.9448
[epoch 71][iter  480] loss: 132425.4375 RMSElog: 10.0155 grad_loss: 13231.5801 normal_loss: 0.9468
[epoch 71][iter  490] loss: 175524.1250 RMSElog: 10.2056 grad_loss: 17541.2441 normal_loss: 0.9625
[epoch 71][iter  500] loss: 234945.1719 RMSElog: 10.0015 grad_loss: 23483.5664 normal_loss: 0.9500
[epoch 71][iter  510] loss: 165453.0938 RMSElog: 9.9262 grad_loss: 16534.4160 normal_loss: 0.9660
[epoch 71][iter  520] loss: 150459.7656 RMSElog: 9.9429 grad_loss: 15035.0986 normal_loss: 0.9347
[epoch 71][iter  530] loss: 212429.2969 RMSElog: 10.2794 grad_loss: 21231.6719 normal_loss: 0.9784
[epoch 71][iter  540] loss: 167211.6250 RMSElog: 10.0285 grad_loss: 16710.1777 normal_loss: 0.9542
[epoch 71][iter  550] loss: 133024.8594 RMSElog: 9.6937 grad_loss: 13291.8662 normal_loss: 0.9261
[epoch 71][iter  560] loss: 226949.5156 RMSElog: 10.2029 grad_loss: 22683.8047 normal_loss: 0.9430
[epoch 71][iter  570] loss: 185071.7031 RMSElog: 10.0456 grad_loss: 18496.1699 normal_loss: 0.9557
[epoch 71][iter  580] loss: 102223.4531 RMSElog: 9.4278 grad_loss: 10212.0010 normal_loss: 0.9169
[epoch 71][iter  590] loss: 179901.4844 RMSElog: 9.8267 grad_loss: 17979.3633 normal_loss: 0.9589
[epoch 72][iter    0] loss: 176914.4531 RMSElog: 10.3802 grad_loss: 17680.1094 normal_loss: 0.9546
[epoch 72][iter   10] loss: 201503.0625 RMSElog: 10.3149 grad_loss: 20139.0410 normal_loss: 0.9514
[epoch 72][iter   20] loss: 107948.0156 RMSElog: 9.7377 grad_loss: 10784.1299 normal_loss: 0.9342
[epoch 72][iter   30] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 72][iter   40] loss: 133045.7969 RMSElog: 9.8765 grad_loss: 13293.7490 normal_loss: 0.9538
[epoch 72][iter   50] loss: 135203.5938 RMSElog: 9.4545 grad_loss: 13509.9697 normal_loss: 0.9356
[epoch 72][iter   60] loss: 114924.9844 RMSElog: 9.6925 grad_loss: 11481.8691 normal_loss: 0.9360
[epoch 72][iter   70] loss: 213417.0312 RMSElog: 10.3416 grad_loss: 21330.4082 normal_loss: 0.9536
[epoch 72][iter   80] loss: 180425.2344 RMSElog: 10.0354 grad_loss: 18031.5332 normal_loss: 0.9552
[epoch 72][iter   90] loss: 182859.0469 RMSElog: 9.8110 grad_loss: 18275.1250 normal_loss: 0.9678
[epoch 72][iter  100] loss: 113921.7891 RMSElog: 9.7251 grad_loss: 11381.5186 normal_loss: 0.9357
[epoch 72][iter  110] loss: 105794.8828 RMSElog: 9.7676 grad_loss: 10568.7939 normal_loss: 0.9267
[epoch 72][iter  120] loss: 127061.7500 RMSElog: 9.6726 grad_loss: 12695.5654 normal_loss: 0.9369
[epoch 72][iter  130] loss: 197520.7500 RMSElog: 10.1663 grad_loss: 19740.9414 normal_loss: 0.9662
[epoch 72][iter  140] loss: 175002.7344 RMSElog: 9.8652 grad_loss: 17489.4648 normal_loss: 0.9436
[epoch 72][iter  150] loss: 149135.0000 RMSElog: 10.0932 grad_loss: 14902.4570 normal_loss: 0.9500
[epoch 72][iter  160] loss: 194578.5781 RMSElog: 10.2312 grad_loss: 19446.6680 normal_loss: 0.9596
[epoch 72][iter  170] loss: 181942.5625 RMSElog: 10.0291 grad_loss: 18183.2793 normal_loss: 0.9464
[epoch 72][iter  180] loss: 138606.5781 RMSElog: 9.6389 grad_loss: 13850.0977 normal_loss: 0.9205
[epoch 72][iter  190] loss: 149387.5625 RMSElog: 9.9550 grad_loss: 14927.8525 normal_loss: 0.9483
[epoch 72][iter  200] loss: 152540.7500 RMSElog: 9.9175 grad_loss: 15243.2090 normal_loss: 0.9474
[epoch 72][iter  210] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch 72][iter  220] loss: 137764.4062 RMSElog: 9.8227 grad_loss: 13765.6748 normal_loss: 0.9442
[epoch 72][iter  230] loss: 177292.4062 RMSElog: 10.1195 grad_loss: 17718.1602 normal_loss: 0.9615
[epoch 72][iter  240] loss: 168545.0938 RMSElog: 9.6168 grad_loss: 16843.9434 normal_loss: 0.9495
[epoch 72][iter  250] loss: 106952.9219 RMSElog: 10.0294 grad_loss: 10684.3398 normal_loss: 0.9231
[epoch 72][iter  260] loss: 103534.6562 RMSElog: 9.7670 grad_loss: 10342.7715 normal_loss: 0.9280
[epoch 72][iter  270] loss: 223018.5625 RMSElog: 10.3592 grad_loss: 22290.5508 normal_loss: 0.9462
[epoch 72][iter  280] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 72][iter  290] loss: 235211.2344 RMSElog: 10.3371 grad_loss: 23509.8398 normal_loss: 0.9452
[epoch 72][iter  300] loss: 228338.7500 RMSElog: 10.2936 grad_loss: 22822.6348 normal_loss: 0.9477
[epoch 72][iter  310] loss: 150699.3750 RMSElog: 9.8567 grad_loss: 15059.1328 normal_loss: 0.9486
[epoch 72][iter  320] loss: 182318.7812 RMSElog: 10.1008 grad_loss: 18220.8398 normal_loss: 0.9384
[epoch 72][iter  330] loss: 188662.5156 RMSElog: 10.2592 grad_loss: 18855.0352 normal_loss: 0.9574
[epoch 72][iter  340] loss: 162372.7500 RMSElog: 9.8226 grad_loss: 16226.4922 normal_loss: 0.9603
[epoch 72][iter  350] loss: 136796.3438 RMSElog: 9.6524 grad_loss: 13669.0273 normal_loss: 0.9549
[epoch 72][iter  360] loss: 154626.7656 RMSElog: 9.9098 grad_loss: 15451.8066 normal_loss: 0.9596
[epoch 72][iter  370] loss: 160782.5156 RMSElog: 9.7710 grad_loss: 16067.5547 normal_loss: 0.9244
[epoch 72][iter  380] loss: 204037.7500 RMSElog: 10.1754 grad_loss: 20392.6582 normal_loss: 0.9420
[epoch 72][iter  390] loss: 214067.1875 RMSElog: 10.0580 grad_loss: 21395.7207 normal_loss: 0.9394
[epoch 72][iter  400] loss: 160743.4062 RMSElog: 9.7965 grad_loss: 16063.6025 normal_loss: 0.9413
[epoch 72][iter  410] loss: 158875.5625 RMSElog: 9.5853 grad_loss: 15877.0449 normal_loss: 0.9260
[epoch 72][iter  420] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 72][iter  430] loss: 188717.5625 RMSElog: 10.0336 grad_loss: 18860.7715 normal_loss: 0.9509
[epoch 72][iter  440] loss: 139433.9219 RMSElog: 9.8139 grad_loss: 13932.6191 normal_loss: 0.9591
[epoch 72][iter  450] loss: 208184.3438 RMSElog: 10.4061 grad_loss: 20807.0801 normal_loss: 0.9472
[epoch 72][iter  460] loss: 123525.9062 RMSElog: 9.3524 grad_loss: 12342.2930 normal_loss: 0.9450
[epoch 72][iter  470] loss: 109260.8984 RMSElog: 9.7819 grad_loss: 10915.3799 normal_loss: 0.9279
[epoch 72][iter  480] loss: 188116.2812 RMSElog: 10.0888 grad_loss: 18800.5703 normal_loss: 0.9711
[epoch 72][iter  490] loss: 132623.8750 RMSElog: 9.3325 grad_loss: 13252.1152 normal_loss: 0.9391
[epoch 72][iter  500] loss: 110603.0781 RMSElog: 9.8046 grad_loss: 11049.5664 normal_loss: 0.9364
[epoch 72][iter  510] loss: 129743.7969 RMSElog: 9.9523 grad_loss: 12963.4785 normal_loss: 0.9492
[epoch 72][iter  520] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 72][iter  530] loss: 149807.1562 RMSElog: 9.9060 grad_loss: 14969.8613 normal_loss: 0.9481
[epoch 72][iter  540] loss: 167745.5625 RMSElog: 9.8817 grad_loss: 16763.7129 normal_loss: 0.9621
[epoch 72][iter  550] loss: 214808.7344 RMSElog: 10.1872 grad_loss: 21469.7441 normal_loss: 0.9423
[epoch 72][iter  560] loss: 159340.4219 RMSElog: 9.9507 grad_loss: 15923.1406 normal_loss: 0.9500
[epoch 72][iter  570] loss: 128277.9766 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.9518
[epoch 72][iter  580] loss: 168688.8125 RMSElog: 9.8493 grad_loss: 16858.0781 normal_loss: 0.9524
[epoch 72][iter  590] loss: 150608.8906 RMSElog: 10.0680 grad_loss: 15049.8750 normal_loss: 0.9460
[epoch 73][iter    0] loss: 194408.7812 RMSElog: 10.2924 grad_loss: 19429.6328 normal_loss: 0.9537
[epoch 73][iter   10] loss: 142016.3906 RMSElog: 9.9191 grad_loss: 14190.7676 normal_loss: 0.9526
[epoch 73][iter   20] loss: 218757.0312 RMSElog: 10.1228 grad_loss: 21864.6270 normal_loss: 0.9524
[epoch 73][iter   30] loss: 147544.5000 RMSElog: 9.8913 grad_loss: 14743.6045 normal_loss: 0.9534
[epoch 73][iter   40] loss: 173086.7031 RMSElog: 10.4992 grad_loss: 17297.2227 normal_loss: 0.9480
[epoch 73][iter   50] loss: 109101.1250 RMSElog: 9.7363 grad_loss: 10899.4590 normal_loss: 0.9167
[epoch 73][iter   60] loss: 153997.7188 RMSElog: 9.7620 grad_loss: 15389.0713 normal_loss: 0.9383
[epoch 73][iter   70] loss: 144657.9844 RMSElog: 9.9197 grad_loss: 14454.9258 normal_loss: 0.9518
[epoch 73][iter   80] loss: 143613.7656 RMSElog: 9.8882 grad_loss: 14350.5566 normal_loss: 0.9315
[epoch 73][iter   90] loss: 137249.3438 RMSElog: 9.7342 grad_loss: 13714.2764 normal_loss: 0.9239
[epoch 73][iter  100] loss: 110235.3906 RMSElog: 9.7805 grad_loss: 11012.8271 normal_loss: 0.9312
[epoch 73][iter  110] loss: 119655.7969 RMSElog: 9.6110 grad_loss: 11955.0312 normal_loss: 0.9378
[epoch 73][iter  120] loss: 113195.8125 RMSElog: 9.1761 grad_loss: 11309.5039 normal_loss: 0.9012
[epoch 73][iter  130] loss: 131213.2969 RMSElog: 9.6860 grad_loss: 13110.7217 normal_loss: 0.9217
[epoch 73][iter  140] loss: 204037.7500 RMSElog: 10.1754 grad_loss: 20392.6582 normal_loss: 0.9420
[epoch 73][iter  150] loss: 139016.5781 RMSElog: 9.6276 grad_loss: 13891.1045 normal_loss: 0.9261
[epoch 73][iter  160] loss: 115534.3672 RMSElog: 9.7196 grad_loss: 11542.7842 normal_loss: 0.9325
[epoch 73][iter  170] loss: 150153.5000 RMSElog: 10.0554 grad_loss: 15004.3457 normal_loss: 0.9478
[epoch 73][iter  180] loss: 105896.9375 RMSElog: 9.7662 grad_loss: 10578.9961 normal_loss: 0.9310
[epoch 73][iter  190] loss: 176217.8125 RMSElog: 10.1087 grad_loss: 17610.7246 normal_loss: 0.9466
[epoch 73][iter  200] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 73][iter  210] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 73][iter  220] loss: 168688.7812 RMSElog: 9.8493 grad_loss: 16858.0762 normal_loss: 0.9524
[epoch 73][iter  230] loss: 108409.6484 RMSElog: 9.2105 grad_loss: 10830.8506 normal_loss: 0.9033
[epoch 73][iter  240] loss: 201162.4062 RMSElog: 9.9531 grad_loss: 20105.3164 normal_loss: 0.9706
[epoch 73][iter  250] loss: 107948.0156 RMSElog: 9.7377 grad_loss: 10784.1299 normal_loss: 0.9342
[epoch 73][iter  260] loss: 160024.9375 RMSElog: 9.8489 grad_loss: 15991.7236 normal_loss: 0.9215
[epoch 73][iter  270] loss: 130527.6094 RMSElog: 9.8914 grad_loss: 13041.9180 normal_loss: 0.9509
[epoch 73][iter  280] loss: 172966.9375 RMSElog: 9.9430 grad_loss: 17285.8008 normal_loss: 0.9485
[epoch 73][iter  290] loss: 175299.8438 RMSElog: 10.1975 grad_loss: 17518.8301 normal_loss: 0.9576
[epoch 73][iter  300] loss: 170357.3438 RMSElog: 9.9687 grad_loss: 17024.8008 normal_loss: 0.9644
[epoch 73][iter  310] loss: 132425.4375 RMSElog: 10.0155 grad_loss: 13231.5801 normal_loss: 0.9468
[epoch 73][iter  320] loss: 182318.7812 RMSElog: 10.1008 grad_loss: 18220.8398 normal_loss: 0.9384
[epoch 73][iter  330] loss: 149807.1562 RMSElog: 9.9060 grad_loss: 14969.8613 normal_loss: 0.9481
[epoch 73][iter  340] loss: 115651.6406 RMSElog: 9.1877 grad_loss: 11555.0664 normal_loss: 0.9106
[epoch 73][iter  350] loss: 120765.1875 RMSElog: 9.5441 grad_loss: 12066.0400 normal_loss: 0.9348
[epoch 73][iter  360] loss: 154705.2344 RMSElog: 9.9142 grad_loss: 15459.6562 normal_loss: 0.9527
[epoch 73][iter  370] loss: 148057.2500 RMSElog: 9.9895 grad_loss: 14794.7803 normal_loss: 0.9555
[epoch 73][iter  380] loss: 153099.1094 RMSElog: 9.8355 grad_loss: 15299.1445 normal_loss: 0.9304
[epoch 73][iter  390] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 73][iter  400] loss: 132707.3594 RMSElog: 9.7842 grad_loss: 13260.0049 normal_loss: 0.9472
[epoch 73][iter  410] loss: 116073.5938 RMSElog: 9.6844 grad_loss: 11596.7324 normal_loss: 0.9429
[epoch 73][iter  420] loss: 146444.9062 RMSElog: 10.1139 grad_loss: 14633.4365 normal_loss: 0.9403
[epoch 73][iter  430] loss: 224257.9688 RMSElog: 10.2842 grad_loss: 22414.5605 normal_loss: 0.9521
[epoch 73][iter  440] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 73][iter  450] loss: 136796.3438 RMSElog: 9.6524 grad_loss: 13669.0273 normal_loss: 0.9549
[epoch 73][iter  460] loss: 195999.5625 RMSElog: 10.1749 grad_loss: 19588.8047 normal_loss: 0.9756
[epoch 73][iter  470] loss: 156173.3594 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.9482
[epoch 73][iter  480] loss: 224077.6719 RMSElog: 10.3869 grad_loss: 22396.4219 normal_loss: 0.9584
[epoch 73][iter  490] loss: 110579.5391 RMSElog: 9.3019 grad_loss: 11047.7109 normal_loss: 0.9413
[epoch 73][iter  500] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 73][iter  510] loss: 149128.2188 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.9419
[epoch 73][iter  520] loss: 206526.4062 RMSElog: 10.1531 grad_loss: 20641.5449 normal_loss: 0.9425
[epoch 73][iter  530] loss: 145615.4531 RMSElog: 9.8847 grad_loss: 14550.7207 normal_loss: 0.9406
[epoch 73][iter  540] loss: 135814.7656 RMSElog: 9.5386 grad_loss: 13571.0107 normal_loss: 0.9281
[epoch 73][iter  550] loss: 177699.9688 RMSElog: 9.4851 grad_loss: 17759.5488 normal_loss: 0.9621
[epoch 73][iter  560] loss: 130739.4062 RMSElog: 9.5471 grad_loss: 13063.4434 normal_loss: 0.9498
[epoch 73][iter  570] loss: 227080.5938 RMSElog: 10.4127 grad_loss: 22696.6992 normal_loss: 0.9482
[epoch 73][iter  580] loss: 133045.7969 RMSElog: 9.8765 grad_loss: 13293.7490 normal_loss: 0.9538
[epoch 73][iter  590] loss: 115495.2188 RMSElog: 9.6084 grad_loss: 11538.9688 normal_loss: 0.9442
[epoch 74][iter    0] loss: 119655.7969 RMSElog: 9.6110 grad_loss: 11955.0312 normal_loss: 0.9378
[epoch 74][iter   10] loss: 162556.3906 RMSElog: 9.9091 grad_loss: 16244.7939 normal_loss: 0.9368
[epoch 74][iter   20] loss: 116073.6016 RMSElog: 9.6844 grad_loss: 11596.7334 normal_loss: 0.9429
[epoch 74][iter   30] loss: 201162.3750 RMSElog: 9.9531 grad_loss: 20105.3145 normal_loss: 0.9706
[epoch 74][iter   40] loss: 114509.4531 RMSElog: 9.7409 grad_loss: 11440.2627 normal_loss: 0.9413
[epoch 74][iter   50] loss: 175486.0625 RMSElog: 10.0393 grad_loss: 17537.6094 normal_loss: 0.9563
[epoch 74][iter   60] loss: 158875.5625 RMSElog: 9.5853 grad_loss: 15877.0449 normal_loss: 0.9260
[epoch 74][iter   70] loss: 196277.7188 RMSElog: 10.2453 grad_loss: 19616.5664 normal_loss: 0.9595
[epoch 74][iter   80] loss: 223875.4062 RMSElog: 10.3929 grad_loss: 22376.1953 normal_loss: 0.9536
[epoch 74][iter   90] loss: 191371.4375 RMSElog: 10.1918 grad_loss: 19126.0020 normal_loss: 0.9504
[epoch 74][iter  100] loss: 107073.5156 RMSElog: 9.7289 grad_loss: 10696.6914 normal_loss: 0.9313
[epoch 74][iter  110] loss: 100990.1562 RMSElog: 9.7350 grad_loss: 10088.3584 normal_loss: 0.9222
[epoch 74][iter  120] loss: 122670.8984 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.9331
[epoch 74][iter  130] loss: 167794.0469 RMSElog: 9.8335 grad_loss: 16768.6211 normal_loss: 0.9500
[epoch 74][iter  140] loss: 155762.3594 RMSElog: 9.8487 grad_loss: 15565.4414 normal_loss: 0.9448
[epoch 74][iter  150] loss: 206400.7812 RMSElog: 10.3027 grad_loss: 20628.8281 normal_loss: 0.9467
[epoch 74][iter  160] loss: 142261.5781 RMSElog: 9.7627 grad_loss: 14215.4639 normal_loss: 0.9304
[epoch 74][iter  170] loss: 126821.0234 RMSElog: 10.1398 grad_loss: 12671.0410 normal_loss: 0.9215
[epoch 74][iter  180] loss: 112851.7266 RMSElog: 9.4205 grad_loss: 11274.8320 normal_loss: 0.9199
[epoch 74][iter  190] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 74][iter  200] loss: 115766.5312 RMSElog: 9.7467 grad_loss: 11565.9717 normal_loss: 0.9344
[epoch 74][iter  210] loss: 180318.6719 RMSElog: 9.9530 grad_loss: 18020.9785 normal_loss: 0.9357
[epoch 74][iter  220] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 74][iter  230] loss: 167008.4531 RMSElog: 10.0165 grad_loss: 16689.8750 normal_loss: 0.9557
[epoch 74][iter  240] loss: 151723.8750 RMSElog: 9.9680 grad_loss: 15161.4746 normal_loss: 0.9449
[epoch 74][iter  250] loss: 183095.1562 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.9696
[epoch 74][iter  260] loss: 168688.7812 RMSElog: 9.8493 grad_loss: 16858.0762 normal_loss: 0.9524
[epoch 74][iter  270] loss: 191320.0938 RMSElog: 10.0978 grad_loss: 19120.9492 normal_loss: 0.9627
[epoch 74][iter  280] loss: 206083.5312 RMSElog: 10.2501 grad_loss: 20597.1465 normal_loss: 0.9562
[epoch 74][iter  290] loss: 138606.5781 RMSElog: 9.6389 grad_loss: 13850.0977 normal_loss: 0.9205
[epoch 74][iter  300] loss: 220695.7969 RMSElog: 10.2208 grad_loss: 22058.4082 normal_loss: 0.9520
[epoch 74][iter  310] loss: 232982.0469 RMSElog: 10.2845 grad_loss: 23286.9707 normal_loss: 0.9500
[epoch 74][iter  320] loss: 162976.7812 RMSElog: 9.6016 grad_loss: 16287.1572 normal_loss: 0.9201
[epoch 74][iter  330] loss: 177292.4062 RMSElog: 10.1195 grad_loss: 17718.1602 normal_loss: 0.9615
[epoch 74][iter  340] loss: 145389.9375 RMSElog: 9.8784 grad_loss: 14528.1660 normal_loss: 0.9489
[epoch 74][iter  350] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 74][iter  360] loss: 177664.5312 RMSElog: 9.7808 grad_loss: 17755.7344 normal_loss: 0.9369
[epoch 74][iter  370] loss: 104340.6328 RMSElog: 9.7692 grad_loss: 10423.3701 normal_loss: 0.9234
[epoch 74][iter  380] loss: 103355.8125 RMSElog: 9.7106 grad_loss: 10324.9453 normal_loss: 0.9244
[epoch 74][iter  390] loss: 138950.6406 RMSElog: 9.9777 grad_loss: 13884.1387 normal_loss: 0.9482
[epoch 74][iter  400] loss: 156557.3594 RMSElog: 9.6970 grad_loss: 15645.1025 normal_loss: 0.9363
[epoch 74][iter  410] loss: 142596.2344 RMSElog: 9.8922 grad_loss: 14248.7793 normal_loss: 0.9508
[epoch 74][iter  420] loss: 107472.2578 RMSElog: 9.0654 grad_loss: 10737.2480 normal_loss: 0.9124
[epoch 74][iter  430] loss: 212429.2969 RMSElog: 10.2794 grad_loss: 21231.6719 normal_loss: 0.9784
[epoch 74][iter  440] loss: 190034.7188 RMSElog: 9.9619 grad_loss: 18992.5625 normal_loss: 0.9485
[epoch 74][iter  450] loss: 102998.8984 RMSElog: 9.8140 grad_loss: 10289.1318 normal_loss: 0.9431
[epoch 74][iter  460] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 74][iter  470] loss: 218757.0312 RMSElog: 10.1228 grad_loss: 21864.6270 normal_loss: 0.9524
[epoch 74][iter  480] loss: 180208.2188 RMSElog: 10.0490 grad_loss: 18009.8223 normal_loss: 0.9517
[epoch 74][iter  490] loss: 176798.0469 RMSElog: 9.8176 grad_loss: 17669.0312 normal_loss: 0.9559
[epoch 74][iter  500] loss: 146576.9219 RMSElog: 9.6520 grad_loss: 14647.1045 normal_loss: 0.9356
[epoch 74][iter  510] loss: 153447.6875 RMSElog: 9.9051 grad_loss: 15333.9209 normal_loss: 0.9425
[epoch 74][iter  520] loss: 125683.7969 RMSElog: 9.8131 grad_loss: 12557.6123 normal_loss: 0.9537
[epoch 74][iter  530] loss: 214493.2031 RMSElog: 10.3525 grad_loss: 21438.0059 normal_loss: 0.9611
[epoch 74][iter  540] loss: 122359.4531 RMSElog: 9.7683 grad_loss: 12225.2402 normal_loss: 0.9361
[epoch 74][iter  550] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 74][iter  560] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 74][iter  570] loss: 122446.5469 RMSElog: 9.6438 grad_loss: 12234.0742 normal_loss: 0.9366
[epoch 74][iter  580] loss: 152562.3750 RMSElog: 9.8216 grad_loss: 15245.4775 normal_loss: 0.9391
[epoch 74][iter  590] loss: 143534.0938 RMSElog: 9.7662 grad_loss: 14342.7061 normal_loss: 0.9374
[epoch 75][iter    0] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 75][iter   10] loss: 189017.5781 RMSElog: 10.1390 grad_loss: 18890.6602 normal_loss: 0.9589
[epoch 75][iter   20] loss: 167794.0469 RMSElog: 9.8335 grad_loss: 16768.6211 normal_loss: 0.9500
[epoch 75][iter   30] loss: 175004.6719 RMSElog: 10.1774 grad_loss: 17489.3320 normal_loss: 0.9561
[epoch 75][iter   40] loss: 155482.2031 RMSElog: 10.0818 grad_loss: 15537.1826 normal_loss: 0.9552
[epoch 75][iter   50] loss: 105896.6094 RMSElog: 9.6983 grad_loss: 10579.0293 normal_loss: 0.9335
[epoch 75][iter   60] loss: 138934.7188 RMSElog: 9.8450 grad_loss: 13882.6904 normal_loss: 0.9370
[epoch 75][iter   70] loss: 158924.9062 RMSElog: 9.8027 grad_loss: 15881.7363 normal_loss: 0.9524
[epoch 75][iter   80] loss: 146465.6875 RMSElog: 10.2283 grad_loss: 14635.4062 normal_loss: 0.9337
[epoch 75][iter   90] loss: 135215.1250 RMSElog: 9.9407 grad_loss: 13510.6152 normal_loss: 0.9572
[epoch 75][iter  100] loss: 115534.3750 RMSElog: 9.7196 grad_loss: 11542.7852 normal_loss: 0.9325
[epoch 75][iter  110] loss: 218625.8750 RMSElog: 10.2839 grad_loss: 21851.3457 normal_loss: 0.9592
[epoch 75][iter  120] loss: 118746.3359 RMSElog: 9.7278 grad_loss: 11863.9629 normal_loss: 0.9433
[epoch 75][iter  130] loss: 211925.8438 RMSElog: 10.1863 grad_loss: 21181.4551 normal_loss: 0.9436
[epoch 75][iter  140] loss: 144657.9844 RMSElog: 9.9197 grad_loss: 14454.9258 normal_loss: 0.9518
[epoch 75][iter  150] loss: 195777.0469 RMSElog: 10.1280 grad_loss: 19566.6035 normal_loss: 0.9726
[epoch 75][iter  160] loss: 191825.0781 RMSElog: 10.3012 grad_loss: 19171.2500 normal_loss: 0.9570
[epoch 75][iter  170] loss: 142138.5312 RMSElog: 9.7967 grad_loss: 14203.1270 normal_loss: 0.9291
[epoch 75][iter  180] loss: 167084.9219 RMSElog: 9.8660 grad_loss: 16697.6582 normal_loss: 0.9689
[epoch 75][iter  190] loss: 138469.0469 RMSElog: 9.4787 grad_loss: 13836.4834 normal_loss: 0.9438
[epoch 75][iter  200] loss: 224943.8906 RMSElog: 10.1206 grad_loss: 22483.3125 normal_loss: 0.9551
[epoch 75][iter  210] loss: 190938.1250 RMSElog: 10.3028 grad_loss: 19082.5566 normal_loss: 0.9541
[epoch 75][iter  220] loss: 194578.5781 RMSElog: 10.2312 grad_loss: 19446.6680 normal_loss: 0.9596
[epoch 75][iter  230] loss: 157061.8906 RMSElog: 9.9892 grad_loss: 15695.2461 normal_loss: 0.9531
[epoch 75][iter  240] loss: 142596.2344 RMSElog: 9.8922 grad_loss: 14248.7793 normal_loss: 0.9508
[epoch 75][iter  250] loss: 152562.3906 RMSElog: 9.8216 grad_loss: 15245.4785 normal_loss: 0.9391
[epoch 75][iter  260] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 75][iter  270] loss: 197714.9844 RMSElog: 10.4355 grad_loss: 19760.1094 normal_loss: 0.9532
[epoch 75][iter  280] loss: 140645.6875 RMSElog: 10.1118 grad_loss: 14053.4873 normal_loss: 0.9695
[epoch 75][iter  290] loss: 168409.1562 RMSElog: 9.7031 grad_loss: 16830.2910 normal_loss: 0.9228
[epoch 75][iter  300] loss: 165020.2344 RMSElog: 9.7791 grad_loss: 16491.2910 normal_loss: 0.9530
[epoch 75][iter  310] loss: 141865.3906 RMSElog: 9.7199 grad_loss: 14175.8896 normal_loss: 0.9298
[epoch 75][iter  320] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 75][iter  330] loss: 124323.5234 RMSElog: 9.7543 grad_loss: 12421.6660 normal_loss: 0.9322
[epoch 75][iter  340] loss: 109441.5234 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.9300
[epoch 75][iter  350] loss: 179298.9062 RMSElog: 9.7220 grad_loss: 17919.2227 normal_loss: 0.9453
[epoch 75][iter  360] loss: 161646.4688 RMSElog: 10.1105 grad_loss: 16153.5762 normal_loss: 0.9608
[epoch 75][iter  370] loss: 137252.6406 RMSElog: 9.3538 grad_loss: 13714.9795 normal_loss: 0.9319
[epoch 75][iter  380] loss: 157274.4688 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.9461
[epoch 75][iter  390] loss: 157810.1406 RMSElog: 9.9254 grad_loss: 15770.1621 normal_loss: 0.9253
[epoch 75][iter  400] loss: 217845.5000 RMSElog: 10.3597 grad_loss: 21773.2148 normal_loss: 0.9774
[epoch 75][iter  410] loss: 203023.3438 RMSElog: 10.3036 grad_loss: 20291.0723 normal_loss: 0.9583
[epoch 75][iter  420] loss: 132425.4375 RMSElog: 10.0155 grad_loss: 13231.5801 normal_loss: 0.9468
[epoch 75][iter  430] loss: 186053.2812 RMSElog: 10.1470 grad_loss: 18594.2305 normal_loss: 0.9504
[epoch 75][iter  440] loss: 103355.8125 RMSElog: 9.7106 grad_loss: 10324.9453 normal_loss: 0.9244
[epoch 75][iter  450] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 75][iter  460] loss: 153724.0000 RMSElog: 9.9609 grad_loss: 15361.4922 normal_loss: 0.9475
[epoch 75][iter  470] loss: 227323.8281 RMSElog: 10.4159 grad_loss: 22721.0195 normal_loss: 0.9477
[epoch 75][iter  480] loss: 114173.8984 RMSElog: 9.3600 grad_loss: 11407.1230 normal_loss: 0.9061
[epoch 75][iter  490] loss: 139098.6406 RMSElog: 9.8619 grad_loss: 13899.0508 normal_loss: 0.9510
[epoch 75][iter  500] loss: 186960.2969 RMSElog: 10.2468 grad_loss: 18684.8457 normal_loss: 0.9380
[epoch 75][iter  510] loss: 207919.9844 RMSElog: 10.2783 grad_loss: 20780.7637 normal_loss: 0.9578
[epoch 75][iter  520] loss: 154029.7812 RMSElog: 9.8645 grad_loss: 15392.1729 normal_loss: 0.9405
[epoch 75][iter  530] loss: 200953.4062 RMSElog: 10.1163 grad_loss: 20084.2598 normal_loss: 0.9623
[epoch 75][iter  540] loss: 220695.8125 RMSElog: 10.2208 grad_loss: 22058.4102 normal_loss: 0.9520
[epoch 75][iter  550] loss: 179901.4844 RMSElog: 9.8267 grad_loss: 17979.3633 normal_loss: 0.9589
[epoch 75][iter  560] loss: 127776.8359 RMSElog: 10.0947 grad_loss: 12766.6396 normal_loss: 0.9490
[epoch 75][iter  570] loss: 189582.6719 RMSElog: 9.9918 grad_loss: 18947.3223 normal_loss: 0.9523
[epoch 75][iter  580] loss: 170542.9531 RMSElog: 9.7855 grad_loss: 17043.5410 normal_loss: 0.9688
[epoch 75][iter  590] loss: 120440.5938 RMSElog: 9.1890 grad_loss: 12033.9463 normal_loss: 0.9240
[epoch 76][iter    0] loss: 184374.2188 RMSElog: 10.2641 grad_loss: 18426.1992 normal_loss: 0.9596
[epoch 76][iter   10] loss: 205362.7344 RMSElog: 10.1686 grad_loss: 20525.1582 normal_loss: 0.9475
[epoch 76][iter   20] loss: 198036.3750 RMSElog: 10.2619 grad_loss: 19792.4219 normal_loss: 0.9529
[epoch 76][iter   30] loss: 217174.7812 RMSElog: 10.2254 grad_loss: 21706.2910 normal_loss: 0.9635
[epoch 76][iter   40] loss: 173855.4375 RMSElog: 10.0769 grad_loss: 17374.5098 normal_loss: 0.9566
[epoch 76][iter   50] loss: 160051.0156 RMSElog: 9.8405 grad_loss: 15994.3105 normal_loss: 0.9506
[epoch 76][iter   60] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 76][iter   70] loss: 164181.7344 RMSElog: 10.0104 grad_loss: 16407.1973 normal_loss: 0.9660
[epoch 76][iter   80] loss: 157810.1406 RMSElog: 9.9254 grad_loss: 15770.1621 normal_loss: 0.9253
[epoch 76][iter   90] loss: 140645.6875 RMSElog: 10.1118 grad_loss: 14053.4873 normal_loss: 0.9695
[epoch 76][iter  100] loss: 165020.2344 RMSElog: 9.7791 grad_loss: 16491.2910 normal_loss: 0.9530
[epoch 76][iter  110] loss: 160667.2500 RMSElog: 9.9014 grad_loss: 16055.8711 normal_loss: 0.9534
[epoch 76][iter  120] loss: 188717.5625 RMSElog: 10.0336 grad_loss: 18860.7715 normal_loss: 0.9509
[epoch 76][iter  130] loss: 162892.2969 RMSElog: 9.8252 grad_loss: 16278.4717 normal_loss: 0.9331
[epoch 76][iter  140] loss: 127110.9297 RMSElog: 9.5273 grad_loss: 12700.6055 normal_loss: 0.9604
[epoch 76][iter  150] loss: 163253.2500 RMSElog: 9.8740 grad_loss: 16314.5010 normal_loss: 0.9499
[epoch 76][iter  160] loss: 155482.1875 RMSElog: 10.0818 grad_loss: 15537.1816 normal_loss: 0.9552
[epoch 76][iter  170] loss: 102096.6484 RMSElog: 9.8437 grad_loss: 10198.8926 normal_loss: 0.9290
[epoch 76][iter  180] loss: 125315.5625 RMSElog: 9.7124 grad_loss: 12520.9131 normal_loss: 0.9309
[epoch 76][iter  190] loss: 176223.4531 RMSElog: 9.9872 grad_loss: 17611.4141 normal_loss: 0.9446
[epoch 76][iter  200] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 76][iter  210] loss: 122359.4531 RMSElog: 9.7683 grad_loss: 12225.2402 normal_loss: 0.9361
[epoch 76][iter  220] loss: 108800.2422 RMSElog: 9.7538 grad_loss: 10869.3369 normal_loss: 0.9334
[epoch 76][iter  230] loss: 133013.4531 RMSElog: 9.5635 grad_loss: 13290.8457 normal_loss: 0.9356
[epoch 76][iter  240] loss: 165453.0938 RMSElog: 9.9262 grad_loss: 16534.4160 normal_loss: 0.9660
[epoch 76][iter  250] loss: 162556.3906 RMSElog: 9.9091 grad_loss: 16244.7939 normal_loss: 0.9368
[epoch 76][iter  260] loss: 166093.7344 RMSElog: 10.4480 grad_loss: 16597.9766 normal_loss: 0.9489
[epoch 76][iter  270] loss: 121838.3672 RMSElog: 9.7453 grad_loss: 12173.1494 normal_loss: 0.9425
[epoch 76][iter  280] loss: 117693.8984 RMSElog: 9.6527 grad_loss: 11758.8105 normal_loss: 0.9267
[epoch 76][iter  290] loss: 138469.0469 RMSElog: 9.4787 grad_loss: 13836.4834 normal_loss: 0.9438
[epoch 76][iter  300] loss: 124246.3594 RMSElog: 9.7165 grad_loss: 12413.9834 normal_loss: 0.9360
[epoch 76][iter  310] loss: 137764.4062 RMSElog: 9.8227 grad_loss: 13765.6748 normal_loss: 0.9442
[epoch 76][iter  320] loss: 147479.0312 RMSElog: 9.6781 grad_loss: 14737.2812 normal_loss: 0.9446
[epoch 76][iter  330] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 76][iter  340] loss: 121866.5156 RMSElog: 9.8422 grad_loss: 12175.8965 normal_loss: 0.9131
[epoch 76][iter  350] loss: 232158.2188 RMSElog: 10.1898 grad_loss: 23204.6875 normal_loss: 0.9455
[epoch 76][iter  360] loss: 160782.5156 RMSElog: 9.7710 grad_loss: 16067.5547 normal_loss: 0.9244
[epoch 76][iter  370] loss: 128277.9766 RMSElog: 9.7565 grad_loss: 12817.0889 normal_loss: 0.9518
[epoch 76][iter  380] loss: 163272.7188 RMSElog: 10.0261 grad_loss: 16316.3047 normal_loss: 0.9400
[epoch 76][iter  390] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 76][iter  400] loss: 105816.5000 RMSElog: 9.4266 grad_loss: 10571.3066 normal_loss: 0.9171
[epoch 76][iter  410] loss: 167455.8750 RMSElog: 9.7229 grad_loss: 16734.9395 normal_loss: 0.9256
[epoch 76][iter  420] loss: 110603.0625 RMSElog: 9.8046 grad_loss: 11049.5654 normal_loss: 0.9364
[epoch 76][iter  430] loss: 167730.9531 RMSElog: 9.9663 grad_loss: 16762.1797 normal_loss: 0.9501
[epoch 76][iter  440] loss: 183095.1562 RMSElog: 9.9762 grad_loss: 18298.5703 normal_loss: 0.9696
[epoch 76][iter  450] loss: 145321.5469 RMSElog: 9.7332 grad_loss: 14521.4590 normal_loss: 0.9632
[epoch 76][iter  460] loss: 231973.6719 RMSElog: 10.2099 grad_loss: 23186.2090 normal_loss: 0.9490
[epoch 76][iter  470] loss: 135699.4688 RMSElog: 9.6754 grad_loss: 13559.3340 normal_loss: 0.9364
[epoch 76][iter  480] loss: 154029.7812 RMSElog: 9.8645 grad_loss: 15392.1729 normal_loss: 0.9405
[epoch 76][iter  490] loss: 128319.4141 RMSElog: 9.6733 grad_loss: 12821.3398 normal_loss: 0.9287
[epoch 76][iter  500] loss: 220695.7969 RMSElog: 10.2208 grad_loss: 22058.4082 normal_loss: 0.9520
[epoch 76][iter  510] loss: 119470.5156 RMSElog: 9.6196 grad_loss: 11936.5020 normal_loss: 0.9297
[epoch 76][iter  520] loss: 167784.2500 RMSElog: 9.9330 grad_loss: 16767.5391 normal_loss: 0.9539
[epoch 76][iter  530] loss: 122670.8984 RMSElog: 9.4365 grad_loss: 12256.7207 normal_loss: 0.9331
[epoch 76][iter  540] loss: 111712.9062 RMSElog: 9.7826 grad_loss: 11160.5801 normal_loss: 0.9290
[epoch 76][iter  550] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 76][iter  560] loss: 109148.7344 RMSElog: 10.1172 grad_loss: 10903.8262 normal_loss: 0.9294
[epoch 76][iter  570] loss: 235211.2344 RMSElog: 10.3371 grad_loss: 23509.8398 normal_loss: 0.9452
[epoch 76][iter  580] loss: 173086.7031 RMSElog: 10.4992 grad_loss: 17297.2227 normal_loss: 0.9480
[epoch 76][iter  590] loss: 110874.4688 RMSElog: 9.2829 grad_loss: 11077.2607 normal_loss: 0.9034
[epoch 77][iter    0] loss: 146444.9062 RMSElog: 10.1139 grad_loss: 14633.4365 normal_loss: 0.9403
[epoch 77][iter   10] loss: 157810.1406 RMSElog: 9.9254 grad_loss: 15770.1621 normal_loss: 0.9253
[epoch 77][iter   20] loss: 138469.0469 RMSElog: 9.4787 grad_loss: 13836.4834 normal_loss: 0.9438
[epoch 77][iter   30] loss: 163268.1250 RMSElog: 9.9218 grad_loss: 16315.9277 normal_loss: 0.9630
[epoch 77][iter   40] loss: 226865.1406 RMSElog: 10.2887 grad_loss: 22675.2832 normal_loss: 0.9418
[epoch 77][iter   50] loss: 103305.2422 RMSElog: 9.5543 grad_loss: 10320.0674 normal_loss: 0.9024
[epoch 77][iter   60] loss: 127499.3281 RMSElog: 9.2769 grad_loss: 12739.7178 normal_loss: 0.9374
[epoch 77][iter   70] loss: 124563.3672 RMSElog: 9.9514 grad_loss: 12445.4453 normal_loss: 0.9400
[epoch 77][iter   80] loss: 109441.5234 RMSElog: 9.7466 grad_loss: 10933.4756 normal_loss: 0.9300
[epoch 77][iter   90] loss: 204650.3281 RMSElog: 10.1934 grad_loss: 20453.8633 normal_loss: 0.9762
[epoch 77][iter  100] loss: 158630.9688 RMSElog: 9.8321 grad_loss: 15852.3232 normal_loss: 0.9428
[epoch 77][iter  110] loss: 144440.4531 RMSElog: 9.8843 grad_loss: 14433.2314 normal_loss: 0.9296
[epoch 77][iter  120] loss: 154310.0938 RMSElog: 9.9148 grad_loss: 15420.1445 normal_loss: 0.9495
[epoch 77][iter  130] loss: 163389.5469 RMSElog: 9.7702 grad_loss: 16328.2637 normal_loss: 0.9208
[epoch 77][iter  140] loss: 145389.9375 RMSElog: 9.8784 grad_loss: 14528.1660 normal_loss: 0.9489
[epoch 77][iter  150] loss: 161285.2188 RMSElog: 9.8339 grad_loss: 16117.7402 normal_loss: 0.9476
[epoch 77][iter  160] loss: 164843.6719 RMSElog: 9.7972 grad_loss: 16473.6348 normal_loss: 0.9360
[epoch 77][iter  170] loss: 167412.9688 RMSElog: 9.7311 grad_loss: 16730.6406 normal_loss: 0.9260
[epoch 77][iter  180] loss: 153447.6875 RMSElog: 9.9051 grad_loss: 15333.9209 normal_loss: 0.9425
[epoch 77][iter  190] loss: 100980.7812 RMSElog: 9.6528 grad_loss: 10087.5176 normal_loss: 0.9085
[epoch 77][iter  200] loss: 213417.0312 RMSElog: 10.3416 grad_loss: 21330.4082 normal_loss: 0.9536
[epoch 77][iter  210] loss: 202119.8125 RMSElog: 10.2544 grad_loss: 20200.7715 normal_loss: 0.9549
[epoch 77][iter  220] loss: 159340.4375 RMSElog: 9.9507 grad_loss: 15923.1426 normal_loss: 0.9500
[epoch 77][iter  230] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 77][iter  240] loss: 217174.7656 RMSElog: 10.2254 grad_loss: 21706.2891 normal_loss: 0.9635
[epoch 77][iter  250] loss: 90482.6875 RMSElog: 9.3127 grad_loss: 9038.0186 normal_loss: 0.9378
[epoch 77][iter  260] loss: 172683.9219 RMSElog: 9.9061 grad_loss: 17257.5312 normal_loss: 0.9550
[epoch 77][iter  270] loss: 143534.0938 RMSElog: 9.7662 grad_loss: 14342.7061 normal_loss: 0.9374
[epoch 77][iter  280] loss: 141118.5312 RMSElog: 10.0520 grad_loss: 14100.8545 normal_loss: 0.9477
[epoch 77][iter  290] loss: 179740.0625 RMSElog: 10.1206 grad_loss: 17962.9453 normal_loss: 0.9397
[epoch 77][iter  300] loss: 175008.6562 RMSElog: 9.9496 grad_loss: 17489.9434 normal_loss: 0.9734
[epoch 77][iter  310] loss: 195671.7031 RMSElog: 10.1080 grad_loss: 19556.1133 normal_loss: 0.9494
[epoch 77][iter  320] loss: 156985.6250 RMSElog: 9.5765 grad_loss: 15688.0479 normal_loss: 0.9385
[epoch 77][iter  330] loss: 172868.6875 RMSElog: 10.0539 grad_loss: 17275.8652 normal_loss: 0.9500
[epoch 77][iter  340] loss: 172966.9375 RMSElog: 9.9430 grad_loss: 17285.8008 normal_loss: 0.9485
[epoch 77][iter  350] loss: 115452.5781 RMSElog: 9.2301 grad_loss: 11535.1230 normal_loss: 0.9042
[epoch 77][iter  360] loss: 180318.6719 RMSElog: 9.9530 grad_loss: 18020.9785 normal_loss: 0.9357
[epoch 77][iter  370] loss: 194987.6250 RMSElog: 9.8416 grad_loss: 19487.9453 normal_loss: 0.9748
[epoch 77][iter  380] loss: 103955.0000 RMSElog: 9.6256 grad_loss: 10384.9521 normal_loss: 0.9222
[epoch 77][iter  390] loss: 188502.1875 RMSElog: 10.1669 grad_loss: 18839.0801 normal_loss: 0.9722
[epoch 77][iter  400] loss: 161813.2500 RMSElog: 9.9875 grad_loss: 16170.3857 normal_loss: 0.9508
[epoch 77][iter  410] loss: 153724.0000 RMSElog: 9.9609 grad_loss: 15361.4922 normal_loss: 0.9475
[epoch 77][iter  420] loss: 150699.3750 RMSElog: 9.8567 grad_loss: 15059.1328 normal_loss: 0.9486
[epoch 77][iter  430] loss: 144589.9531 RMSElog: 9.7438 grad_loss: 14448.3340 normal_loss: 0.9167
[epoch 77][iter  440] loss: 96006.2500 RMSElog: 9.5560 grad_loss: 9590.1396 normal_loss: 0.9294
[epoch 77][iter  450] loss: 184016.5469 RMSElog: 9.9468 grad_loss: 18390.7363 normal_loss: 0.9712
[epoch 77][iter  460] loss: 142596.2344 RMSElog: 9.8922 grad_loss: 14248.7793 normal_loss: 0.9508
[epoch 77][iter  470] loss: 154609.8281 RMSElog: 9.8745 grad_loss: 15450.1855 normal_loss: 0.9220
[epoch 77][iter  480] loss: 195507.4062 RMSElog: 10.1854 grad_loss: 19539.6016 normal_loss: 0.9533
[epoch 77][iter  490] loss: 199070.3125 RMSElog: 9.9947 grad_loss: 19896.0605 normal_loss: 0.9757
[epoch 77][iter  500] loss: 135215.1250 RMSElog: 9.9407 grad_loss: 13510.6152 normal_loss: 0.9572
[epoch 77][iter  510] loss: 122912.0625 RMSElog: 9.7328 grad_loss: 12280.5225 normal_loss: 0.9509
[epoch 77][iter  520] loss: 146161.1562 RMSElog: 10.0682 grad_loss: 14605.1279 normal_loss: 0.9190
[epoch 77][iter  530] loss: 160825.5938 RMSElog: 9.9290 grad_loss: 16071.6816 normal_loss: 0.9491
[epoch 77][iter  540] loss: 194408.7812 RMSElog: 10.2924 grad_loss: 19429.6328 normal_loss: 0.9537
[epoch 77][iter  550] loss: 113921.7891 RMSElog: 9.7251 grad_loss: 11381.5186 normal_loss: 0.9357
[epoch 77][iter  560] loss: 149036.1562 RMSElog: 9.7728 grad_loss: 14892.8887 normal_loss: 0.9547
[epoch 77][iter  570] loss: 112851.7109 RMSElog: 9.4205 grad_loss: 11274.8301 normal_loss: 0.9199
[epoch 77][iter  580] loss: 114893.3984 RMSElog: 9.2562 grad_loss: 11479.1777 normal_loss: 0.9067
[epoch 77][iter  590] loss: 149807.1562 RMSElog: 9.9060 grad_loss: 14969.8613 normal_loss: 0.9481
[epoch 78][iter    0] loss: 127061.7500 RMSElog: 9.6726 grad_loss: 12695.5654 normal_loss: 0.9369
[epoch 78][iter   10] loss: 154290.2500 RMSElog: 9.8471 grad_loss: 15418.2334 normal_loss: 0.9458
[epoch 78][iter   20] loss: 143534.0938 RMSElog: 9.7662 grad_loss: 14342.7061 normal_loss: 0.9374
[epoch 78][iter   30] loss: 115500.4766 RMSElog: 9.9924 grad_loss: 11539.1230 normal_loss: 0.9328
[epoch 78][iter   40] loss: 149128.2188 RMSElog: 9.7262 grad_loss: 14902.1533 normal_loss: 0.9419
[epoch 78][iter   50] loss: 233395.7188 RMSElog: 10.2368 grad_loss: 23328.3906 normal_loss: 0.9452
[epoch 78][iter   60] loss: 140282.6250 RMSElog: 9.9822 grad_loss: 14017.3145 normal_loss: 0.9650
[epoch 78][iter   70] loss: 176260.7500 RMSElog: 10.0638 grad_loss: 17615.0703 normal_loss: 0.9395
[epoch 78][iter   80] loss: 139098.6406 RMSElog: 9.8619 grad_loss: 13899.0508 normal_loss: 0.9510
[epoch 78][iter   90] loss: 162711.9688 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.9427
[epoch 78][iter  100] loss: 177195.4844 RMSElog: 10.1516 grad_loss: 17708.4512 normal_loss: 0.9458
[epoch 78][iter  110] loss: 196025.7031 RMSElog: 10.2650 grad_loss: 19591.3496 normal_loss: 0.9559
[epoch 78][iter  120] loss: 178076.4688 RMSElog: 9.8778 grad_loss: 17796.8457 normal_loss: 0.9233
[epoch 78][iter  130] loss: 199607.1562 RMSElog: 10.1504 grad_loss: 19949.6133 normal_loss: 0.9517
[epoch 78][iter  140] loss: 165453.0938 RMSElog: 9.9262 grad_loss: 16534.4160 normal_loss: 0.9660
[epoch 78][iter  150] loss: 114924.9844 RMSElog: 9.6925 grad_loss: 11481.8691 normal_loss: 0.9360
[epoch 78][iter  160] loss: 129205.9375 RMSElog: 9.8851 grad_loss: 12909.7734 normal_loss: 0.9356
[epoch 78][iter  170] loss: 158230.6094 RMSElog: 9.9234 grad_loss: 15812.1895 normal_loss: 0.9483
[epoch 78][iter  180] loss: 119655.7969 RMSElog: 9.6110 grad_loss: 11955.0312 normal_loss: 0.9378
[epoch 78][iter  190] loss: 174629.2812 RMSElog: 9.9405 grad_loss: 17452.0625 normal_loss: 0.9229
[epoch 78][iter  200] loss: 114374.2344 RMSElog: 9.1913 grad_loss: 11427.3242 normal_loss: 0.9087
[epoch 78][iter  210] loss: 146960.1406 RMSElog: 10.0979 grad_loss: 14684.9941 normal_loss: 0.9220
[epoch 78][iter  220] loss: 157274.4688 RMSElog: 9.9277 grad_loss: 15716.5723 normal_loss: 0.9461
[epoch 78][iter  230] loss: 175359.1875 RMSElog: 10.1476 grad_loss: 17524.8125 normal_loss: 0.9571
[epoch 78][iter  240] loss: 120745.8203 RMSElog: 9.7706 grad_loss: 12063.8691 normal_loss: 0.9428
[epoch 78][iter  250] loss: 121838.3672 RMSElog: 9.7453 grad_loss: 12173.1494 normal_loss: 0.9425
[epoch 78][iter  260] loss: 111914.6406 RMSElog: 9.3004 grad_loss: 11181.2412 normal_loss: 0.9218
[epoch 78][iter  270] loss: 186960.2969 RMSElog: 10.2468 grad_loss: 18684.8457 normal_loss: 0.9380
[epoch 78][iter  280] loss: 154855.9062 RMSElog: 9.8054 grad_loss: 15474.8340 normal_loss: 0.9510
[epoch 78][iter  290] loss: 125486.8672 RMSElog: 9.7758 grad_loss: 12537.9834 normal_loss: 0.9281
[epoch 78][iter  300] loss: 227323.8281 RMSElog: 10.4159 grad_loss: 22721.0195 normal_loss: 0.9477
[epoch 78][iter  310] loss: 203023.3438 RMSElog: 10.3036 grad_loss: 20291.0723 normal_loss: 0.9583
[epoch 78][iter  320] loss: 115495.2188 RMSElog: 9.6084 grad_loss: 11538.9688 normal_loss: 0.9442
[epoch 78][iter  330] loss: 167345.2500 RMSElog: 9.8843 grad_loss: 16723.6777 normal_loss: 0.9620
[epoch 78][iter  340] loss: 204650.3281 RMSElog: 10.1934 grad_loss: 20453.8633 normal_loss: 0.9763
[epoch 78][iter  350] loss: 114893.3984 RMSElog: 9.2562 grad_loss: 11479.1777 normal_loss: 0.9067
[epoch 78][iter  360] loss: 156173.3594 RMSElog: 9.9681 grad_loss: 15606.4199 normal_loss: 0.9482
[epoch 78][iter  370] loss: 175122.9531 RMSElog: 9.9588 grad_loss: 17501.3789 normal_loss: 0.9573
[epoch 78][iter  380] loss: 157061.8906 RMSElog: 9.9892 grad_loss: 15695.2461 normal_loss: 0.9531
[epoch 78][iter  390] loss: 151354.1562 RMSElog: 9.8837 grad_loss: 15124.5889 normal_loss: 0.9428
[epoch 78][iter  400] loss: 125683.7969 RMSElog: 9.8131 grad_loss: 12557.6123 normal_loss: 0.9537
[epoch 78][iter  410] loss: 188502.1875 RMSElog: 10.1669 grad_loss: 18839.0801 normal_loss: 0.9722
[epoch 78][iter  420] loss: 104446.5625 RMSElog: 10.1932 grad_loss: 10433.5342 normal_loss: 0.9288
[epoch 78][iter  430] loss: 114173.8984 RMSElog: 9.3600 grad_loss: 11407.1230 normal_loss: 0.9061
[epoch 78][iter  440] loss: 117061.6250 RMSElog: 9.2141 grad_loss: 11696.0439 normal_loss: 0.9046
[epoch 78][iter  450] loss: 159284.2188 RMSElog: 9.6028 grad_loss: 15917.8828 normal_loss: 0.9361
[epoch 78][iter  460] loss: 162363.8906 RMSElog: 9.7464 grad_loss: 16225.6777 normal_loss: 0.9661
[epoch 78][iter  470] loss: 105816.5000 RMSElog: 9.4266 grad_loss: 10571.3066 normal_loss: 0.9171
[epoch 78][iter  480] loss: 148057.2500 RMSElog: 9.9895 grad_loss: 14794.7803 normal_loss: 0.9555
[epoch 78][iter  490] loss: 142261.5781 RMSElog: 9.7627 grad_loss: 14215.4639 normal_loss: 0.9304
[epoch 78][iter  500] loss: 119895.5000 RMSElog: 9.3187 grad_loss: 11979.3154 normal_loss: 0.9157
[epoch 78][iter  510] loss: 214808.7500 RMSElog: 10.1872 grad_loss: 21469.7461 normal_loss: 0.9423
[epoch 78][iter  520] loss: 189743.5625 RMSElog: 10.1862 grad_loss: 18963.2207 normal_loss: 0.9490
[epoch 78][iter  530] loss: 155911.2344 RMSElog: 9.7863 grad_loss: 15580.3965 normal_loss: 0.9403
[epoch 78][iter  540] loss: 173574.0781 RMSElog: 10.1780 grad_loss: 17346.2734 normal_loss: 0.9575
[epoch 78][iter  550] loss: 179901.4844 RMSElog: 9.8267 grad_loss: 17979.3633 normal_loss: 0.9589
[epoch 78][iter  560] loss: 160466.8750 RMSElog: 9.9086 grad_loss: 16035.8252 normal_loss: 0.9540
[epoch 78][iter  570] loss: 100116.4922 RMSElog: 9.9235 grad_loss: 10000.7998 normal_loss: 0.9258
[epoch 78][iter  580] loss: 107956.6094 RMSElog: 10.0900 grad_loss: 10784.6504 normal_loss: 0.9209
[epoch 78][iter  590] loss: 211640.2344 RMSElog: 10.2414 grad_loss: 21152.8145 normal_loss: 0.9675
[epoch 79][iter    0] loss: 121983.8203 RMSElog: 9.5225 grad_loss: 12187.9473 normal_loss: 0.9124
[epoch 79][iter   10] loss: 115348.2734 RMSElog: 9.7235 grad_loss: 11524.1562 normal_loss: 0.9470
[epoch 79][iter   20] loss: 232158.2188 RMSElog: 10.1898 grad_loss: 23204.6875 normal_loss: 0.9455
[epoch 79][iter   30] loss: 135966.2969 RMSElog: 9.6504 grad_loss: 13586.0273 normal_loss: 0.9522
[epoch 79][iter   40] loss: 124246.3594 RMSElog: 9.7165 grad_loss: 12413.9834 normal_loss: 0.9360
[epoch 79][iter   50] loss: 90482.6875 RMSElog: 9.3127 grad_loss: 9038.0186 normal_loss: 0.9378
[epoch 79][iter   60] loss: 196437.8125 RMSElog: 10.2319 grad_loss: 19632.5898 normal_loss: 0.9584
[epoch 79][iter   70] loss: 189507.2500 RMSElog: 10.2157 grad_loss: 18939.5586 normal_loss: 0.9510
[epoch 79][iter   80] loss: 137249.3438 RMSElog: 9.7342 grad_loss: 13714.2764 normal_loss: 0.9239
[epoch 79][iter   90] loss: 135814.7656 RMSElog: 9.5386 grad_loss: 13571.0107 normal_loss: 0.9281
[epoch 79][iter  100] loss: 125695.5391 RMSElog: 9.9422 grad_loss: 12558.6836 normal_loss: 0.9278
[epoch 79][iter  110] loss: 182005.7031 RMSElog: 10.0998 grad_loss: 18189.5195 normal_loss: 0.9507
[epoch 79][iter  120] loss: 234945.1719 RMSElog: 10.0015 grad_loss: 23483.5664 normal_loss: 0.9500
[epoch 79][iter  130] loss: 103514.7734 RMSElog: 9.3451 grad_loss: 10341.2100 normal_loss: 0.9229
[epoch 79][iter  140] loss: 162711.9688 RMSElog: 9.6160 grad_loss: 16260.6387 normal_loss: 0.9427
[epoch 79][iter  150] loss: 164597.1094 RMSElog: 9.8631 grad_loss: 16448.8984 normal_loss: 0.9502
[epoch 79][iter  160] loss: 152332.5469 RMSElog: 9.9813 grad_loss: 15222.3486 normal_loss: 0.9245
[epoch 79][iter  170] loss: 103305.2500 RMSElog: 9.5543 grad_loss: 10320.0684 normal_loss: 0.9024
[epoch 79][iter  180] loss: 163171.1562 RMSElog: 9.7905 grad_loss: 16306.3594 normal_loss: 0.9652
[epoch 79][iter  190] loss: 165453.0938 RMSElog: 9.9262 grad_loss: 16534.4160 normal_loss: 0.9660
[epoch 79][iter  200] loss: 215542.7500 RMSElog: 10.4358 grad_loss: 21542.8887 normal_loss: 0.9514
[epoch 79][iter  210] loss: 198293.9219 RMSElog: 10.2275 grad_loss: 19818.2148 normal_loss: 0.9521
[epoch 79][iter  220] loss: 158230.6094 RMSElog: 9.9234 grad_loss: 15812.1895 normal_loss: 0.9483
[epoch 79][iter  230] loss: 177934.3750 RMSElog: 9.8386 grad_loss: 17782.6445 normal_loss: 0.9542
[epoch 79][iter  240] loss: 167211.6250 RMSElog: 10.0285 grad_loss: 16710.1777 normal_loss: 0.9542
[epoch 79][iter  250] loss: 159340.4375 RMSElog: 9.9507 grad_loss: 15923.1426 normal_loss: 0.9500
[epoch 79][iter  260] loss: 104456.8438 RMSElog: 10.0170 grad_loss: 10434.7461 normal_loss: 0.9214
[epoch 79][iter  270] loss: 143904.7812 RMSElog: 10.0263 grad_loss: 14379.5068 normal_loss: 0.9457
[epoch 79][iter  280] loss: 227323.8281 RMSElog: 10.4159 grad_loss: 22721.0195 normal_loss: 0.9477
[epoch 79][iter  290] loss: 167784.2500 RMSElog: 9.9330 grad_loss: 16767.5391 normal_loss: 0.9539
[epoch 79][iter  300] loss: 191320.1250 RMSElog: 10.0978 grad_loss: 19120.9512 normal_loss: 0.9627
[epoch 79][iter  310] loss: 128488.4375 RMSElog: 9.7402 grad_loss: 12838.1719 normal_loss: 0.9319
[epoch 79][iter  320] loss: 169013.5625 RMSElog: 9.5880 grad_loss: 16890.8262 normal_loss: 0.9419
[epoch 79][iter  330] loss: 181293.3438 RMSElog: 10.0009 grad_loss: 18118.3809 normal_loss: 0.9531
[epoch 79][iter  340] loss: 217914.6094 RMSElog: 10.2786 grad_loss: 21780.2246 normal_loss: 0.9575
[epoch 79][iter  350] loss: 172755.6875 RMSElog: 10.0251 grad_loss: 17264.6016 normal_loss: 0.9419
[epoch 79][iter  360] loss: 165326.5625 RMSElog: 9.8832 grad_loss: 16521.8086 normal_loss: 0.9647
[epoch 79][iter  370] loss: 135042.2031 RMSElog: 9.6763 grad_loss: 13493.6074 normal_loss: 0.9366
[epoch 79][iter  380] loss: 213417.0312 RMSElog: 10.3416 grad_loss: 21330.4082 normal_loss: 0.9536
[epoch 79][iter  390] loss: 157425.7188 RMSElog: 9.9235 grad_loss: 15731.7012 normal_loss: 0.9477
[epoch 79][iter  400] loss: 127075.1875 RMSElog: 10.1217 grad_loss: 12696.4443 normal_loss: 0.9524
[epoch 79][iter  410] loss: 198743.4219 RMSElog: 10.0842 grad_loss: 19863.2930 normal_loss: 0.9643
[epoch 79][iter  420] loss: 132425.4375 RMSElog: 10.0155 grad_loss: 13231.5801 normal_loss: 0.9468
[epoch 79][iter  430] loss: 214493.2188 RMSElog: 10.3525 grad_loss: 21438.0078 normal_loss: 0.9611
[epoch 79][iter  440] loss: 160788.1406 RMSElog: 9.7539 grad_loss: 16068.1289 normal_loss: 0.9318
[epoch 79][iter  450] loss: 180929.5938 RMSElog: 10.0745 grad_loss: 18081.9297 normal_loss: 0.9546
[epoch 79][iter  460] loss: 160743.5156 RMSElog: 9.9654 grad_loss: 16063.4521 normal_loss: 0.9340
[epoch 79][iter  470] loss: 224077.7188 RMSElog: 10.3869 grad_loss: 22396.4258 normal_loss: 0.9584
[epoch 79][iter  480] loss: 165976.7500 RMSElog: 9.9385 grad_loss: 16586.7715 normal_loss: 0.9645
[epoch 79][iter  490] loss: 120745.8203 RMSElog: 9.7706 grad_loss: 12063.8691 normal_loss: 0.9428
[epoch 79][iter  500] loss: 174761.2344 RMSElog: 9.7333 grad_loss: 17465.4512 normal_loss: 0.9393
[epoch 79][iter  510] loss: 112697.1016 RMSElog: 9.7295 grad_loss: 11259.0449 normal_loss: 0.9352
[epoch 79][iter  520] loss: 149135.0000 RMSElog: 10.0932 grad_loss: 14902.4570 normal_loss: 0.9500
[epoch 79][iter  530] loss: 221089.3594 RMSElog: 10.3457 grad_loss: 22097.6465 normal_loss: 0.9439
[epoch 79][iter  540] loss: 188717.5625 RMSElog: 10.0336 grad_loss: 18860.7715 normal_loss: 0.9509
[epoch 79][iter  550] loss: 109260.8906 RMSElog: 9.7819 grad_loss: 10915.3789 normal_loss: 0.9279
[epoch 79][iter  560] loss: 189543.6719 RMSElog: 10.1592 grad_loss: 18943.2598 normal_loss: 0.9474
[epoch 79][iter  570] loss: 144191.5938 RMSElog: 9.6650 grad_loss: 14408.5654 normal_loss: 0.9284
[epoch 79][iter  580] loss: 183480.3438 RMSElog: 10.0091 grad_loss: 18337.0801 normal_loss: 0.9458
[epoch 79][iter  590] loss: 72289.2656 RMSElog: 9.4677 grad_loss: 7218.5376 normal_loss: 0.9211
##########################################
#epochs=40 different visualization method#
##########################################
[epoch  0][iter    0] loss: 106.3672 RMSElog: 10.6367 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   10] loss: 104.1168 RMSElog: 10.4117 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   20] loss: 103.3628 RMSElog: 10.3363 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   30] loss: 101.5076 RMSElog: 10.1508 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   40] loss: 98.9108 RMSElog: 9.8911 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   50] loss: 100.3239 RMSElog: 10.0324 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   60] loss: 97.1501 RMSElog: 9.7150 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   70] loss: 101.1979 RMSElog: 10.1198 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   80] loss: 102.1583 RMSElog: 10.2158 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   90] loss: 102.4894 RMSElog: 10.2489 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  100] loss: 101.6515 RMSElog: 10.1652 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  110] loss: 104.2017 RMSElog: 10.4202 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  120] loss: 101.3576 RMSElog: 10.1358 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  130] loss: 102.8540 RMSElog: 10.2854 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  140] loss: 96.4707 RMSElog: 9.6471 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  150] loss: 97.3189 RMSElog: 9.7319 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  160] loss: 93.1139 RMSElog: 9.3114 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  170] loss: 101.5659 RMSElog: 10.1566 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  180] loss: 100.4891 RMSElog: 10.0489 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  190] loss: 98.2268 RMSElog: 9.8227 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  200] loss: 99.6602 RMSElog: 9.9660 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  210] loss: 99.0657 RMSElog: 9.9066 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  220] loss: 98.1826 RMSElog: 9.8183 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  230] loss: 100.1353 RMSElog: 10.0135 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  240] loss: 97.9963 RMSElog: 9.7996 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  250] loss: 100.8528 RMSElog: 10.0853 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  260] loss: 99.3577 RMSElog: 9.9358 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  270] loss: 95.2002 RMSElog: 9.5200 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  280] loss: 96.8512 RMSElog: 9.6851 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  290] loss: 98.6493 RMSElog: 9.8649 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  300] loss: 99.7055 RMSElog: 9.9706 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  310] loss: 96.2169 RMSElog: 9.6217 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  320] loss: 98.7847 RMSElog: 9.8785 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  330] loss: 102.1732 RMSElog: 10.2173 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  340] loss: 99.2209 RMSElog: 9.9221 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  350] loss: 97.4640 RMSElog: 9.7464 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  360] loss: 100.2874 RMSElog: 10.0287 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  370] loss: 96.2056 RMSElog: 9.6206 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  380] loss: 101.2151 RMSElog: 10.1215 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  390] loss: 100.6420 RMSElog: 10.0642 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  400] loss: 97.9394 RMSElog: 9.7939 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  410] loss: 97.1292 RMSElog: 9.7129 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  420] loss: 98.1859 RMSElog: 9.8186 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  430] loss: 98.2781 RMSElog: 9.8278 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  440] loss: 98.2038 RMSElog: 9.8204 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  450] loss: 101.4248 RMSElog: 10.1425 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  460] loss: 98.7101 RMSElog: 9.8710 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  470] loss: 92.3269 RMSElog: 9.2327 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  480] loss: 96.8779 RMSElog: 9.6878 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  490] loss: 101.1042 RMSElog: 10.1104 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  500] loss: 99.6311 RMSElog: 9.9631 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  510] loss: 91.8277 RMSElog: 9.1828 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  520] loss: 96.4624 RMSElog: 9.6462 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  530] loss: 103.3186 RMSElog: 10.3319 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  540] loss: 96.1383 RMSElog: 9.6138 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  550] loss: 100.0328 RMSElog: 10.0033 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  560] loss: 102.3268 RMSElog: 10.2327 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  570] loss: 92.7761 RMSElog: 9.2776 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  580] loss: 94.6927 RMSElog: 9.4693 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  590] loss: 94.1786 RMSElog: 9.4179 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter    0] loss: 98.0551 RMSElog: 9.8055 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   10] loss: 100.4409 RMSElog: 10.0441 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   20] loss: 97.3942 RMSElog: 9.7394 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   30] loss: 101.1016 RMSElog: 10.1102 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   40] loss: 96.8305 RMSElog: 9.6831 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   50] loss: 96.3452 RMSElog: 9.6345 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   60] loss: 101.0571 RMSElog: 10.1057 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   70] loss: 102.1258 RMSElog: 10.2126 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   80] loss: 104.9280 RMSElog: 10.4928 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   90] loss: 98.3089 RMSElog: 9.8309 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  100] loss: 98.1685 RMSElog: 9.8168 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  110] loss: 101.5013 RMSElog: 10.1501 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  120] loss: 100.9407 RMSElog: 10.0941 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  130] loss: 104.0541 RMSElog: 10.4054 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  140] loss: 97.6036 RMSElog: 9.7604 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  150] loss: 94.6270 RMSElog: 9.4627 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  160] loss: 97.4828 RMSElog: 9.7483 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  170] loss: 100.7425 RMSElog: 10.0742 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  180] loss: 99.3261 RMSElog: 9.9326 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  190] loss: 97.7853 RMSElog: 9.7785 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  200] loss: 101.6853 RMSElog: 10.1685 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  210] loss: 101.8831 RMSElog: 10.1883 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  220] loss: 97.0899 RMSElog: 9.7090 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  230] loss: 98.9116 RMSElog: 9.8912 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  240] loss: 101.4962 RMSElog: 10.1496 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  250] loss: 97.2483 RMSElog: 9.7248 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  260] loss: 92.2803 RMSElog: 9.2280 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  270] loss: 96.8447 RMSElog: 9.6845 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  280] loss: 92.2147 RMSElog: 9.2215 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  290] loss: 101.6686 RMSElog: 10.1669 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  300] loss: 104.2558 RMSElog: 10.4256 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  310] loss: 98.5995 RMSElog: 9.8600 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  320] loss: 102.8049 RMSElog: 10.2805 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  330] loss: 99.5290 RMSElog: 9.9529 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  340] loss: 95.8178 RMSElog: 9.5818 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  350] loss: 100.2671 RMSElog: 10.0267 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  360] loss: 100.4115 RMSElog: 10.0411 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  370] loss: 103.0109 RMSElog: 10.3011 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  380] loss: 96.1076 RMSElog: 9.6108 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  390] loss: 98.1600 RMSElog: 9.8160 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  400] loss: 101.6493 RMSElog: 10.1649 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  410] loss: 98.1107 RMSElog: 9.8111 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  420] loss: 97.3524 RMSElog: 9.7352 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  430] loss: 96.6467 RMSElog: 9.6647 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  440] loss: 94.9256 RMSElog: 9.4926 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  450] loss: 97.8702 RMSElog: 9.7870 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  460] loss: 99.4006 RMSElog: 9.9401 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  470] loss: 99.3978 RMSElog: 9.9398 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  480] loss: 99.9151 RMSElog: 9.9915 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  490] loss: 96.6769 RMSElog: 9.6677 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  500] loss: 95.9962 RMSElog: 9.5996 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  510] loss: 98.3605 RMSElog: 9.8361 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  520] loss: 104.6344 RMSElog: 10.4634 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  530] loss: 99.7309 RMSElog: 9.9731 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  540] loss: 95.8752 RMSElog: 9.5875 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  550] loss: 101.8938 RMSElog: 10.1894 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  560] loss: 102.2814 RMSElog: 10.2281 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  570] loss: 102.5337 RMSElog: 10.2534 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  580] loss: 100.6047 RMSElog: 10.0605 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  590] loss: 101.3467 RMSElog: 10.1347 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter    0] loss: 97.2160 RMSElog: 9.7216 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   10] loss: 96.7464 RMSElog: 9.6746 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   20] loss: 97.8949 RMSElog: 9.7895 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   30] loss: 99.3255 RMSElog: 9.9325 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   40] loss: 96.6176 RMSElog: 9.6618 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   50] loss: 97.0385 RMSElog: 9.7039 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   60] loss: 96.8599 RMSElog: 9.6860 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   70] loss: 97.9539 RMSElog: 9.7954 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   80] loss: 103.2554 RMSElog: 10.3255 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   90] loss: 92.0886 RMSElog: 9.2089 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  100] loss: 96.7524 RMSElog: 9.6752 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  110] loss: 97.2404 RMSElog: 9.7240 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  120] loss: 97.4870 RMSElog: 9.7487 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  130] loss: 100.9606 RMSElog: 10.0961 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  140] loss: 102.2694 RMSElog: 10.2269 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  150] loss: 101.5016 RMSElog: 10.1502 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  160] loss: 93.1298 RMSElog: 9.3130 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  170] loss: 100.9229 RMSElog: 10.0923 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  180] loss: 98.9117 RMSElog: 9.8912 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  190] loss: 97.3861 RMSElog: 9.7386 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  200] loss: 101.0132 RMSElog: 10.1013 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  210] loss: 98.3253 RMSElog: 9.8325 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  220] loss: 93.0947 RMSElog: 9.3095 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  230] loss: 98.3214 RMSElog: 9.8321 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  240] loss: 98.9047 RMSElog: 9.8905 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  250] loss: 97.0423 RMSElog: 9.7042 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  260] loss: 96.2561 RMSElog: 9.6256 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  270] loss: 97.1714 RMSElog: 9.7171 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  280] loss: 97.7732 RMSElog: 9.7773 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  290] loss: 98.1811 RMSElog: 9.8181 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  300] loss: 102.0940 RMSElog: 10.2094 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  310] loss: 95.9716 RMSElog: 9.5972 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  320] loss: 98.2283 RMSElog: 9.8228 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  330] loss: 97.6926 RMSElog: 9.7693 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  340] loss: 98.5851 RMSElog: 9.8585 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  350] loss: 103.5823 RMSElog: 10.3582 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  360] loss: 95.5776 RMSElog: 9.5578 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  370] loss: 97.3324 RMSElog: 9.7332 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  380] loss: 100.6249 RMSElog: 10.0625 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  390] loss: 93.2609 RMSElog: 9.3261 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  400] loss: 100.7908 RMSElog: 10.0791 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  410] loss: 101.7247 RMSElog: 10.1725 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  420] loss: 98.2091 RMSElog: 9.8209 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  430] loss: 95.7532 RMSElog: 9.5753 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  440] loss: 95.9520 RMSElog: 9.5952 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  450] loss: 97.2775 RMSElog: 9.7277 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  460] loss: 95.1803 RMSElog: 9.5180 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  470] loss: 93.9751 RMSElog: 9.3975 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  480] loss: 88.5309 RMSElog: 8.8531 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  490] loss: 97.6540 RMSElog: 9.7654 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  500] loss: 97.5646 RMSElog: 9.7565 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  510] loss: 100.1850 RMSElog: 10.0185 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  520] loss: 87.9449 RMSElog: 8.7945 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  530] loss: 93.6247 RMSElog: 9.3625 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  540] loss: 89.1237 RMSElog: 8.9124 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  550] loss: 93.0119 RMSElog: 9.3012 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  560] loss: 89.7248 RMSElog: 8.9725 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  570] loss: 94.1910 RMSElog: 9.4191 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  580] loss: 93.4967 RMSElog: 9.3497 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  590] loss: 90.1257 RMSElog: 9.0126 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter    0] loss: 91.7230 RMSElog: 9.1723 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   10] loss: 92.6092 RMSElog: 9.2609 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   20] loss: 92.0673 RMSElog: 9.2067 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   30] loss: 91.2517 RMSElog: 9.1252 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   40] loss: 91.4161 RMSElog: 9.1416 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   50] loss: 90.8391 RMSElog: 9.0839 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   60] loss: 87.5054 RMSElog: 8.7505 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   70] loss: 92.0028 RMSElog: 9.2003 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   80] loss: 92.9462 RMSElog: 9.2946 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   90] loss: 86.3472 RMSElog: 8.6347 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  100] loss: 86.7764 RMSElog: 8.6776 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  110] loss: 90.0952 RMSElog: 9.0095 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  120] loss: 89.0629 RMSElog: 8.9063 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  130] loss: 90.4739 RMSElog: 9.0474 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  140] loss: 90.4832 RMSElog: 9.0483 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  150] loss: 90.1713 RMSElog: 9.0171 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  160] loss: 91.3720 RMSElog: 9.1372 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  170] loss: 91.4449 RMSElog: 9.1445 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  180] loss: 90.9336 RMSElog: 9.0934 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  190] loss: 91.2883 RMSElog: 9.1288 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  200] loss: 89.6542 RMSElog: 8.9654 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  210] loss: 89.6517 RMSElog: 8.9652 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  220] loss: 90.9366 RMSElog: 9.0937 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  230] loss: 90.0139 RMSElog: 9.0014 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  240] loss: 92.0744 RMSElog: 9.2074 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  250] loss: 85.0135 RMSElog: 8.5013 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  260] loss: 90.9548 RMSElog: 9.0955 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  270] loss: 86.0616 RMSElog: 8.6062 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  280] loss: 90.0648 RMSElog: 9.0065 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  290] loss: 84.1007 RMSElog: 8.4101 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  300] loss: 89.8205 RMSElog: 8.9820 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  310] loss: 88.5910 RMSElog: 8.8591 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  320] loss: 89.8820 RMSElog: 8.9882 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  330] loss: 87.6158 RMSElog: 8.7616 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  340] loss: 90.3237 RMSElog: 9.0324 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  350] loss: 88.3116 RMSElog: 8.8312 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  360] loss: 90.0627 RMSElog: 9.0063 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  370] loss: 87.4168 RMSElog: 8.7417 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  380] loss: 88.1726 RMSElog: 8.8173 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  390] loss: 86.7193 RMSElog: 8.6719 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  400] loss: 88.1165 RMSElog: 8.8116 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  410] loss: 87.6293 RMSElog: 8.7629 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  420] loss: 87.7144 RMSElog: 8.7714 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  430] loss: 88.7511 RMSElog: 8.8751 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  440] loss: 87.9773 RMSElog: 8.7977 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  450] loss: 88.7296 RMSElog: 8.8730 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  460] loss: 91.2967 RMSElog: 9.1297 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  470] loss: 91.2829 RMSElog: 9.1283 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  480] loss: 87.2507 RMSElog: 8.7251 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  490] loss: 92.5427 RMSElog: 9.2543 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  500] loss: 85.6565 RMSElog: 8.5656 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  510] loss: 90.0128 RMSElog: 9.0013 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  520] loss: 91.0625 RMSElog: 9.1062 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  530] loss: 90.1809 RMSElog: 9.0181 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  540] loss: 92.4052 RMSElog: 9.2405 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  550] loss: 89.2843 RMSElog: 8.9284 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  560] loss: 91.1303 RMSElog: 9.1130 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  570] loss: 88.6481 RMSElog: 8.8648 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  580] loss: 84.1352 RMSElog: 8.4135 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  590] loss: 84.2020 RMSElog: 8.4202 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  4][iter    0] loss: 110782.2812 RMSElog: 8.3691 grad_loss: 11069.8594 normal_loss: 0.0000
[epoch  4][iter   10] loss: 233372.0156 RMSElog: 9.0941 grad_loss: 23328.1074 normal_loss: 0.0000
[epoch  4][iter   20] loss: 131987.4219 RMSElog: 8.3942 grad_loss: 13190.3477 normal_loss: 0.0000
[epoch  4][iter   30] loss: 150273.0938 RMSElog: 8.7221 grad_loss: 15018.5879 normal_loss: 0.0000
[epoch  4][iter   40] loss: 239429.0625 RMSElog: 9.1767 grad_loss: 23933.7305 normal_loss: 0.0000
[epoch  4][iter   50] loss: 172230.0000 RMSElog: 8.8609 grad_loss: 17214.1387 normal_loss: 0.0000
[epoch  4][iter   60] loss: 214468.2812 RMSElog: 9.0858 grad_loss: 21437.7422 normal_loss: 0.0000
[epoch  4][iter   70] loss: 170519.3594 RMSElog: 8.7236 grad_loss: 17043.2129 normal_loss: 0.0000
[epoch  4][iter   80] loss: 146554.4219 RMSElog: 8.6408 grad_loss: 14646.8018 normal_loss: 0.0000
[epoch  4][iter   90] loss: 217889.2969 RMSElog: 9.0253 grad_loss: 21779.9043 normal_loss: 0.0000
[epoch  4][iter  100] loss: 95201.4531 RMSElog: 8.4013 grad_loss: 9511.7441 normal_loss: 0.0000
[epoch  4][iter  110] loss: 118719.9141 RMSElog: 8.3871 grad_loss: 11863.6045 normal_loss: 0.0000
[epoch  4][iter  120] loss: 183989.6562 RMSElog: 8.6115 grad_loss: 18390.3535 normal_loss: 0.0000
[epoch  4][iter  130] loss: 122307.4062 RMSElog: 8.6442 grad_loss: 12222.0957 normal_loss: 0.0000
[epoch  4][iter  140] loss: 174326.3750 RMSElog: 8.8431 grad_loss: 17423.7930 normal_loss: 0.0000
[epoch  4][iter  150] loss: 121962.0938 RMSElog: 8.4904 grad_loss: 12187.7188 normal_loss: 0.0000
[epoch  4][iter  160] loss: 182165.1562 RMSElog: 9.0113 grad_loss: 18207.5039 normal_loss: 0.0000
[epoch  4][iter  170] loss: 186023.8281 RMSElog: 8.8458 grad_loss: 18593.5371 normal_loss: 0.0000
[epoch  4][iter  180] loss: 126849.2812 RMSElog: 8.5646 grad_loss: 12676.3633 normal_loss: 0.0000
[epoch  4][iter  190] loss: 109234.2344 RMSElog: 8.4033 grad_loss: 10915.0205 normal_loss: 0.0000
[epoch  4][iter  200] loss: 188637.0312 RMSElog: 9.0457 grad_loss: 18854.6582 normal_loss: 0.0000
[epoch  4][iter  210] loss: 124913.4219 RMSElog: 8.6939 grad_loss: 12482.6475 normal_loss: 0.0000
[epoch  4][iter  220] loss: 163764.8125 RMSElog: 8.8625 grad_loss: 16367.6191 normal_loss: 0.0000
[epoch  4][iter  230] loss: 138035.9375 RMSElog: 8.5701 grad_loss: 13795.0234 normal_loss: 0.0000
[epoch  4][iter  240] loss: 228314.0000 RMSElog: 9.0776 grad_loss: 22822.3223 normal_loss: 0.0000
[epoch  4][iter  250] loss: 144562.1562 RMSElog: 8.1274 grad_loss: 14448.0879 normal_loss: 0.0000
[epoch  4][iter  260] loss: 109077.3438 RMSElog: 8.5608 grad_loss: 10899.1738 normal_loss: 0.0000
[epoch  4][iter  270] loss: 152515.7031 RMSElog: 8.7561 grad_loss: 15242.8145 normal_loss: 0.0000
[epoch  4][iter  280] loss: 183848.3594 RMSElog: 9.0644 grad_loss: 18375.7715 normal_loss: 0.0000
[epoch  4][iter  290] loss: 104416.5703 RMSElog: 8.4489 grad_loss: 10433.2080 normal_loss: 0.0000
[epoch  4][iter  300] loss: 163245.6094 RMSElog: 8.9367 grad_loss: 16315.6240 normal_loss: 0.0000
[epoch  4][iter  310] loss: 222993.4688 RMSElog: 9.1142 grad_loss: 22290.2344 normal_loss: 0.0000
[epoch  4][iter  320] loss: 149520.3906 RMSElog: 8.9937 grad_loss: 14943.0449 normal_loss: 0.0000
[epoch  4][iter  330] loss: 177642.6719 RMSElog: 8.8297 grad_loss: 17755.4375 normal_loss: 0.0000
[epoch  4][iter  340] loss: 182838.8125 RMSElog: 9.0246 grad_loss: 18274.8555 normal_loss: 0.0000
[epoch  4][iter  350] loss: 145297.4062 RMSElog: 8.6263 grad_loss: 14521.1152 normal_loss: 0.0000
[epoch  4][iter  360] loss: 108393.1250 RMSElog: 8.6586 grad_loss: 10830.6543 normal_loss: 0.0000
[epoch  4][iter  370] loss: 171564.8281 RMSElog: 8.7078 grad_loss: 17147.7754 normal_loss: 0.0000
[epoch  4][iter  380] loss: 123508.3594 RMSElog: 8.7495 grad_loss: 12342.0859 normal_loss: 0.0000
[epoch  4][iter  390] loss: 211511.1094 RMSElog: 8.8538 grad_loss: 21142.2578 normal_loss: 0.0000
[epoch  4][iter  400] loss: 78491.6875 RMSElog: 8.7285 grad_loss: 7840.4399 normal_loss: 0.0000
[epoch  4][iter  410] loss: 217820.3281 RMSElog: 9.1789 grad_loss: 21772.8535 normal_loss: 0.0000
[epoch  4][iter  420] loss: 123271.4141 RMSElog: 8.7845 grad_loss: 12318.3574 normal_loss: 0.0000
[epoch  4][iter  430] loss: 215928.4375 RMSElog: 8.9377 grad_loss: 21583.9062 normal_loss: 0.0000
[epoch  4][iter  440] loss: 141981.2500 RMSElog: 8.8084 grad_loss: 14189.3164 normal_loss: 0.0000
[epoch  4][iter  450] loss: 217148.1875 RMSElog: 8.9393 grad_loss: 21705.8789 normal_loss: 0.0000
[epoch  4][iter  460] loss: 127477.2500 RMSElog: 8.3320 grad_loss: 12739.3926 normal_loss: 0.0000
[epoch  4][iter  470] loss: 102972.2188 RMSElog: 8.4810 grad_loss: 10288.7412 normal_loss: 0.0000
[epoch  4][iter  480] loss: 182454.7500 RMSElog: 9.0076 grad_loss: 18236.4668 normal_loss: 0.0000
[epoch  4][iter  490] loss: 176775.5469 RMSElog: 8.8373 grad_loss: 17668.7168 normal_loss: 0.0000
[epoch  4][iter  500] loss: 109118.3125 RMSElog: 8.3646 grad_loss: 10903.4668 normal_loss: 0.0000
[epoch  4][iter  510] loss: 175098.6094 RMSElog: 8.8295 grad_loss: 17501.0312 normal_loss: 0.0000
[epoch  4][iter  520] loss: 149012.9375 RMSElog: 8.6971 grad_loss: 14892.5967 normal_loss: 0.0000
[epoch  4][iter  530] loss: 162349.5000 RMSElog: 8.8457 grad_loss: 16226.1045 normal_loss: 0.0000
[epoch  4][iter  540] loss: 99086.9922 RMSElog: 8.6374 grad_loss: 9900.0615 normal_loss: 0.0000
[epoch  4][iter  550] loss: 210628.5781 RMSElog: 9.1964 grad_loss: 21053.6602 normal_loss: 0.0000
[epoch  4][iter  560] loss: 191181.0000 RMSElog: 8.8662 grad_loss: 19109.2344 normal_loss: 0.0000
[epoch  4][iter  570] loss: 158855.9062 RMSElog: 8.8088 grad_loss: 15876.7822 normal_loss: 0.0000
[epoch  4][iter  580] loss: 235186.0000 RMSElog: 9.1436 grad_loss: 23509.4551 normal_loss: 0.0000
[epoch  4][iter  590] loss: 180906.4219 RMSElog: 9.0262 grad_loss: 18081.6172 normal_loss: 0.0000
[epoch  5][iter    0] loss: 100622.1250 RMSElog: 8.2717 grad_loss: 10053.9414 normal_loss: 0.0000
[epoch  5][iter   10] loss: 227054.4062 RMSElog: 9.1295 grad_loss: 22696.3125 normal_loss: 0.0000
[epoch  5][iter   20] loss: 114481.5703 RMSElog: 8.3088 grad_loss: 11439.8486 normal_loss: 0.0000
[epoch  5][iter   30] loss: 150341.4062 RMSElog: 8.8967 grad_loss: 15025.2441 normal_loss: 0.0000
[epoch  5][iter   40] loss: 134608.9219 RMSElog: 8.7653 grad_loss: 13452.1270 normal_loss: 0.0000
[epoch  5][iter   50] loss: 120420.4062 RMSElog: 8.3809 grad_loss: 12033.6602 normal_loss: 0.0000
[epoch  5][iter   60] loss: 205336.9062 RMSElog: 8.8948 grad_loss: 20524.7969 normal_loss: 0.0000
[epoch  5][iter   70] loss: 161063.0312 RMSElog: 8.7028 grad_loss: 16097.5996 normal_loss: 0.0000
[epoch  5][iter   80] loss: 111684.2109 RMSElog: 8.2530 grad_loss: 11160.1680 normal_loss: 0.0000
[epoch  5][iter   90] loss: 99087.4297 RMSElog: 8.6762 grad_loss: 9900.0674 normal_loss: 0.0000
[epoch  5][iter  100] loss: 196814.5000 RMSElog: 8.7371 grad_loss: 19672.7129 normal_loss: 0.0000
[epoch  5][iter  110] loss: 182542.5156 RMSElog: 8.9392 grad_loss: 18245.3125 normal_loss: 0.0000
[epoch  5][iter  120] loss: 143817.6406 RMSElog: 8.8323 grad_loss: 14372.9316 normal_loss: 0.0000
[epoch  5][iter  130] loss: 115435.5391 RMSElog: 8.6690 grad_loss: 11534.8848 normal_loss: 0.0000
[epoch  5][iter  140] loss: 166469.9219 RMSElog: 8.8637 grad_loss: 16638.1289 normal_loss: 0.0000
[epoch  5][iter  150] loss: 182454.2500 RMSElog: 8.9780 grad_loss: 18236.4473 normal_loss: 0.0000
[epoch  5][iter  160] loss: 181267.3281 RMSElog: 8.7714 grad_loss: 18117.9609 normal_loss: 0.0000
[epoch  5][iter  170] loss: 181959.5938 RMSElog: 8.9677 grad_loss: 18186.9922 normal_loss: 0.0000
[epoch  5][iter  180] loss: 188635.7656 RMSElog: 8.9925 grad_loss: 18854.5840 normal_loss: 0.0000
[epoch  5][iter  190] loss: 147519.3750 RMSElog: 8.7490 grad_loss: 14743.1885 normal_loss: 0.0000
[epoch  5][iter  200] loss: 127048.9688 RMSElog: 8.7914 grad_loss: 12696.1055 normal_loss: 0.0000
[epoch  5][iter  210] loss: 156846.8906 RMSElog: 8.8003 grad_loss: 15675.8896 normal_loss: 0.0000
[epoch  5][iter  220] loss: 124247.9062 RMSElog: 8.6229 grad_loss: 12416.1680 normal_loss: 0.0000
[epoch  5][iter  230] loss: 179276.4375 RMSElog: 8.7478 grad_loss: 17918.8965 normal_loss: 0.0000
[epoch  5][iter  240] loss: 214465.3125 RMSElog: 8.9413 grad_loss: 21437.5898 normal_loss: 0.0000
[epoch  5][iter  250] loss: 95200.5078 RMSElog: 8.3430 grad_loss: 9511.7080 normal_loss: 0.0000
[epoch  5][iter  260] loss: 122421.6562 RMSElog: 8.3909 grad_loss: 12233.7754 normal_loss: 0.0000
[epoch  5][iter  270] loss: 196249.0781 RMSElog: 8.7767 grad_loss: 19616.1309 normal_loss: 0.0000
[epoch  5][iter  280] loss: 90460.8438 RMSElog: 8.3654 grad_loss: 9037.7188 normal_loss: 0.0000
[epoch  5][iter  290] loss: 175910.6562 RMSElog: 9.0576 grad_loss: 17582.0098 normal_loss: 0.0000
[epoch  5][iter  300] loss: 239742.3125 RMSElog: 8.9786 grad_loss: 23965.2520 normal_loss: 0.0000
[epoch  5][iter  310] loss: 147456.8594 RMSElog: 8.7567 grad_loss: 14736.9297 normal_loss: 0.0000
[epoch  5][iter  320] loss: 158009.8281 RMSElog: 8.8606 grad_loss: 15792.1230 normal_loss: 0.0000
[epoch  5][iter  330] loss: 125291.5000 RMSElog: 8.6519 grad_loss: 12520.4980 normal_loss: 0.0000
[epoch  5][iter  340] loss: 111739.7578 RMSElog: 8.5154 grad_loss: 11165.4600 normal_loss: 0.0000
[epoch  5][iter  350] loss: 174739.0469 RMSElog: 8.7743 grad_loss: 17465.1309 normal_loss: 0.0000
[epoch  5][iter  360] loss: 115320.7031 RMSElog: 8.3359 grad_loss: 11523.7344 normal_loss: 0.0000
[epoch  5][iter  370] loss: 183848.0000 RMSElog: 9.0618 grad_loss: 18375.7383 normal_loss: 0.0000
[epoch  5][iter  380] loss: 102971.3750 RMSElog: 8.4347 grad_loss: 10288.7031 normal_loss: 0.0000
[epoch  5][iter  390] loss: 100723.2734 RMSElog: 8.6757 grad_loss: 10063.6514 normal_loss: 0.0000
[epoch  5][iter  400] loss: 140255.0312 RMSElog: 8.5908 grad_loss: 14016.9121 normal_loss: 0.0000
[epoch  5][iter  410] loss: 161787.9844 RMSElog: 8.8780 grad_loss: 16169.9209 normal_loss: 0.0000
[epoch  5][iter  420] loss: 103493.8750 RMSElog: 8.5534 grad_loss: 10340.8340 normal_loss: 0.0000
[epoch  5][iter  430] loss: 191295.6875 RMSElog: 8.9724 grad_loss: 19120.5957 normal_loss: 0.0000
[epoch  5][iter  440] loss: 109412.4375 RMSElog: 8.1892 grad_loss: 10933.0547 normal_loss: 0.0000
[epoch  5][iter  450] loss: 147887.9219 RMSElog: 8.6547 grad_loss: 14780.1377 normal_loss: 0.0000
[epoch  5][iter  460] loss: 162534.0625 RMSElog: 8.9740 grad_loss: 16244.4326 normal_loss: 0.0000
[epoch  5][iter  470] loss: 103785.5938 RMSElog: 8.1495 grad_loss: 10370.4102 normal_loss: 0.0000
[epoch  5][iter  480] loss: 104951.6250 RMSElog: 8.6199 grad_loss: 10486.5420 normal_loss: 0.0000
[epoch  5][iter  490] loss: 111638.8984 RMSElog: 8.6564 grad_loss: 11155.2334 normal_loss: 0.0000
[epoch  5][iter  500] loss: 167716.5625 RMSElog: 8.8345 grad_loss: 16762.8223 normal_loss: 0.0000
[epoch  5][iter  510] loss: 143879.9375 RMSElog: 8.8054 grad_loss: 14379.1875 normal_loss: 0.0000
[epoch  5][iter  520] loss: 154833.6406 RMSElog: 8.8772 grad_loss: 15474.4873 normal_loss: 0.0000
[epoch  5][iter  530] loss: 172229.4062 RMSElog: 8.8325 grad_loss: 17214.1094 normal_loss: 0.0000
[epoch  5][iter  540] loss: 139134.6250 RMSElog: 8.8251 grad_loss: 13904.6367 normal_loss: 0.0000
[epoch  5][iter  550] loss: 179623.2031 RMSElog: 8.9335 grad_loss: 17953.3867 normal_loss: 0.0000
[epoch  5][iter  560] loss: 173059.0469 RMSElog: 9.0906 grad_loss: 17296.8145 normal_loss: 0.0000
[epoch  5][iter  570] loss: 181983.1875 RMSElog: 9.0615 grad_loss: 18189.2559 normal_loss: 0.0000
[epoch  5][iter  580] loss: 122654.0781 RMSElog: 8.7818 grad_loss: 12256.6260 normal_loss: 0.0000
[epoch  5][iter  590] loss: 214747.5625 RMSElog: 8.8453 grad_loss: 21465.9102 normal_loss: 0.0000
[epoch  6][iter    0] loss: 134443.9375 RMSElog: 8.3094 grad_loss: 13436.0850 normal_loss: 0.0000
[epoch  6][iter   10] loss: 152493.6719 RMSElog: 8.7146 grad_loss: 15240.6523 normal_loss: 0.0000
[epoch  6][iter   20] loss: 188090.0312 RMSElog: 8.9341 grad_loss: 18800.0703 normal_loss: 0.0000
[epoch  6][iter   30] loss: 162409.5000 RMSElog: 8.8365 grad_loss: 16232.1133 normal_loss: 0.0000
[epoch  6][iter   40] loss: 205206.5312 RMSElog: 8.8183 grad_loss: 20511.8340 normal_loss: 0.0000
[epoch  6][iter   50] loss: 186026.2500 RMSElog: 8.8684 grad_loss: 18593.7559 normal_loss: 0.0000
[epoch  6][iter   60] loss: 103930.6641 RMSElog: 8.4389 grad_loss: 10384.6279 normal_loss: 0.0000
[epoch  6][iter   70] loss: 220668.7344 RMSElog: 8.8495 grad_loss: 22058.0234 normal_loss: 0.0000
[epoch  6][iter   80] loss: 105867.1875 RMSElog: 8.1687 grad_loss: 10578.5498 normal_loss: 0.0000
[epoch  6][iter   90] loss: 100640.2422 RMSElog: 8.7958 grad_loss: 10055.2285 normal_loss: 0.0000
[epoch  6][iter  100] loss: 128534.9688 RMSElog: 8.6441 grad_loss: 12844.8525 normal_loss: 0.0000
[epoch  6][iter  110] loss: 177641.7969 RMSElog: 8.7824 grad_loss: 17755.3965 normal_loss: 0.0000
[epoch  6][iter  120] loss: 159398.6875 RMSElog: 8.6330 grad_loss: 15931.2354 normal_loss: 0.0000
[epoch  6][iter  130] loss: 152537.2344 RMSElog: 8.6544 grad_loss: 15245.0693 normal_loss: 0.0000
[epoch  6][iter  140] loss: 114897.0391 RMSElog: 8.2782 grad_loss: 11481.4258 normal_loss: 0.0000
[epoch  6][iter  150] loss: 177265.8594 RMSElog: 8.8775 grad_loss: 17717.7090 normal_loss: 0.0000
[epoch  6][iter  160] loss: 132680.4375 RMSElog: 8.4990 grad_loss: 13259.5449 normal_loss: 0.0000
[epoch  6][iter  170] loss: 146933.7500 RMSElog: 8.6251 grad_loss: 14684.7500 normal_loss: 0.0000
[epoch  6][iter  180] loss: 227297.0312 RMSElog: 9.1214 grad_loss: 22720.5820 normal_loss: 0.0000
[epoch  6][iter  190] loss: 142112.0156 RMSElog: 8.4888 grad_loss: 14202.7129 normal_loss: 0.0000
[epoch  6][iter  200] loss: 165626.3281 RMSElog: 8.7890 grad_loss: 16553.8438 normal_loss: 0.0000
[epoch  6][iter  210] loss: 114154.0000 RMSElog: 8.5153 grad_loss: 11406.8848 normal_loss: 0.0000
[epoch  6][iter  220] loss: 202994.9844 RMSElog: 8.8660 grad_loss: 20290.6328 normal_loss: 0.0000
[epoch  6][iter  230] loss: 138993.6719 RMSElog: 8.6342 grad_loss: 13890.7334 normal_loss: 0.0000
[epoch  6][iter  240] loss: 201347.0625 RMSElog: 9.0776 grad_loss: 20125.6289 normal_loss: 0.0000
[epoch  6][iter  250] loss: 220561.4219 RMSElog: 9.0153 grad_loss: 22047.1270 normal_loss: 0.0000
[epoch  6][iter  260] loss: 188690.4062 RMSElog: 8.7273 grad_loss: 18860.3145 normal_loss: 0.0000
[epoch  6][iter  270] loss: 166519.7656 RMSElog: 8.9497 grad_loss: 16643.0273 normal_loss: 0.0000
[epoch  6][iter  280] loss: 143588.3281 RMSElog: 8.6092 grad_loss: 14350.2236 normal_loss: 0.0000
[epoch  6][iter  290] loss: 146920.9062 RMSElog: 8.5545 grad_loss: 14683.5361 normal_loss: 0.0000
[epoch  6][iter  300] loss: 130719.2344 RMSElog: 8.7677 grad_loss: 13063.1562 normal_loss: 0.0000
[epoch  6][iter  310] loss: 196650.4688 RMSElog: 8.7388 grad_loss: 19656.3086 normal_loss: 0.0000
[epoch  6][iter  320] loss: 162955.5625 RMSElog: 8.7257 grad_loss: 16286.8301 normal_loss: 0.0000
[epoch  6][iter  330] loss: 147348.1406 RMSElog: 8.6175 grad_loss: 14726.1963 normal_loss: 0.0000
[epoch  6][iter  340] loss: 213376.7031 RMSElog: 8.8976 grad_loss: 21328.7715 normal_loss: 0.0000
[epoch  6][iter  350] loss: 158607.5938 RMSElog: 8.8324 grad_loss: 15851.9277 normal_loss: 0.0000
[epoch  6][iter  360] loss: 165302.9531 RMSElog: 8.8686 grad_loss: 16521.4258 normal_loss: 0.0000
[epoch  6][iter  370] loss: 135867.4062 RMSElog: 8.6247 grad_loss: 13578.1152 normal_loss: 0.0000
[epoch  6][iter  380] loss: 160800.4844 RMSElog: 8.8144 grad_loss: 16071.2344 normal_loss: 0.0000
[epoch  6][iter  390] loss: 191532.3281 RMSElog: 8.6386 grad_loss: 19144.5938 normal_loss: 0.0000
[epoch  6][iter  400] loss: 163243.7344 RMSElog: 8.8495 grad_loss: 16315.5234 normal_loss: 0.0000
[epoch  6][iter  410] loss: 124223.2031 RMSElog: 8.6714 grad_loss: 12413.6484 normal_loss: 0.0000
[epoch  6][iter  420] loss: 167391.8906 RMSElog: 8.8153 grad_loss: 16730.3750 normal_loss: 0.0000
[epoch  6][iter  430] loss: 145385.3438 RMSElog: 8.7288 grad_loss: 14529.8066 normal_loss: 0.0000
[epoch  6][iter  440] loss: 141419.5156 RMSElog: 8.6759 grad_loss: 14133.2754 normal_loss: 0.0000
[epoch  6][iter  450] loss: 162554.2031 RMSElog: 8.9207 grad_loss: 16246.5000 normal_loss: 0.0000
[epoch  6][iter  460] loss: 201137.8281 RMSElog: 8.8340 grad_loss: 20104.9492 normal_loss: 0.0000
[epoch  6][iter  470] loss: 148029.3438 RMSElog: 8.6484 grad_loss: 14794.2861 normal_loss: 0.0000
[epoch  6][iter  480] loss: 185877.4219 RMSElog: 8.7813 grad_loss: 18578.9609 normal_loss: 0.0000
[epoch  6][iter  490] loss: 119445.1250 RMSElog: 8.3954 grad_loss: 11936.1172 normal_loss: 0.0000
[epoch  6][iter  500] loss: 163568.7344 RMSElog: 8.7582 grad_loss: 16348.1162 normal_loss: 0.0000
[epoch  6][iter  510] loss: 151329.9219 RMSElog: 8.7477 grad_loss: 15124.2441 normal_loss: 0.0000
[epoch  6][iter  520] loss: 117669.2500 RMSElog: 8.4727 grad_loss: 11758.4521 normal_loss: 0.0000
[epoch  6][iter  530] loss: 106152.0469 RMSElog: 8.0959 grad_loss: 10607.1094 normal_loss: 0.0000
[epoch  6][iter  540] loss: 158854.7500 RMSElog: 8.7247 grad_loss: 15876.7500 normal_loss: 0.0000
[epoch  6][iter  550] loss: 163249.0781 RMSElog: 8.9799 grad_loss: 16315.9277 normal_loss: 0.0000
[epoch  6][iter  560] loss: 109076.3438 RMSElog: 8.5061 grad_loss: 10899.1289 normal_loss: 0.0000
[epoch  6][iter  570] loss: 152307.7500 RMSElog: 8.6889 grad_loss: 15222.0859 normal_loss: 0.0000
[epoch  6][iter  580] loss: 164743.5781 RMSElog: 8.7635 grad_loss: 16465.5938 normal_loss: 0.0000
[epoch  6][iter  590] loss: 148766.7188 RMSElog: 8.7788 grad_loss: 14867.8926 normal_loss: 0.0000
[epoch  7][iter    0] loss: 218739.0938 RMSElog: 9.4009 grad_loss: 21864.5098 normal_loss: 0.0000
[epoch  7][iter   10] loss: 158513.0938 RMSElog: 8.7265 grad_loss: 15842.5820 normal_loss: 0.0000
[epoch  7][iter   20] loss: 163568.7188 RMSElog: 8.7580 grad_loss: 16348.1133 normal_loss: 0.0000
[epoch  7][iter   30] loss: 134608.1562 RMSElog: 8.7235 grad_loss: 13452.0918 normal_loss: 0.0000
[epoch  7][iter   40] loss: 141839.3125 RMSElog: 8.4345 grad_loss: 14175.4971 normal_loss: 0.0000
[epoch  7][iter   50] loss: 160617.1875 RMSElog: 8.7874 grad_loss: 16052.9316 normal_loss: 0.0000
[epoch  7][iter   60] loss: 176194.2812 RMSElog: 9.0392 grad_loss: 17610.3887 normal_loss: 0.0000
[epoch  7][iter   70] loss: 115741.0469 RMSElog: 8.4465 grad_loss: 11565.6582 normal_loss: 0.0000
[epoch  7][iter   80] loss: 104428.0469 RMSElog: 8.4396 grad_loss: 10434.3652 normal_loss: 0.0000
[epoch  7][iter   90] loss: 121937.0625 RMSElog: 8.7373 grad_loss: 12184.9688 normal_loss: 0.0000
[epoch  7][iter  100] loss: 142517.0312 RMSElog: 8.8132 grad_loss: 14242.8896 normal_loss: 0.0000
[epoch  7][iter  110] loss: 189480.1562 RMSElog: 8.9398 grad_loss: 18939.0762 normal_loss: 0.0000
[epoch  7][iter  120] loss: 140029.5938 RMSElog: 8.6418 grad_loss: 13994.3184 normal_loss: 0.0000
[epoch  7][iter  130] loss: 107876.7500 RMSElog: 8.0805 grad_loss: 10779.5947 normal_loss: 0.0000
[epoch  7][iter  140] loss: 165930.2188 RMSElog: 8.8832 grad_loss: 16584.1387 normal_loss: 0.0000
[epoch  7][iter  150] loss: 115634.0312 RMSElog: 8.5837 grad_loss: 11554.8193 normal_loss: 0.0000
[epoch  7][iter  160] loss: 174980.3281 RMSElog: 9.0206 grad_loss: 17489.0117 normal_loss: 0.0000
[epoch  7][iter  170] loss: 138908.9688 RMSElog: 8.6295 grad_loss: 13882.2666 normal_loss: 0.0000
[epoch  7][iter  180] loss: 120716.5000 RMSElog: 8.2666 grad_loss: 12063.3838 normal_loss: 0.0000
[epoch  7][iter  190] loss: 131189.9688 RMSElog: 8.5908 grad_loss: 13110.4062 normal_loss: 0.0000
[epoch  7][iter  200] loss: 125258.4297 RMSElog: 8.4400 grad_loss: 12517.4023 normal_loss: 0.0000
[epoch  7][iter  210] loss: 189556.4375 RMSElog: 8.7652 grad_loss: 18946.8789 normal_loss: 0.0000
[epoch  7][iter  220] loss: 173058.5312 RMSElog: 9.0577 grad_loss: 17296.7949 normal_loss: 0.0000
[epoch  7][iter  230] loss: 221186.8906 RMSElog: 8.8920 grad_loss: 22109.7969 normal_loss: 0.0000
[epoch  7][iter  240] loss: 144167.7656 RMSElog: 8.5838 grad_loss: 14408.1924 normal_loss: 0.0000
[epoch  7][iter  250] loss: 179276.2344 RMSElog: 8.7391 grad_loss: 17918.8848 normal_loss: 0.0000
[epoch  7][iter  260] loss: 165950.8594 RMSElog: 8.7510 grad_loss: 16586.3340 normal_loss: 0.0000
[epoch  7][iter  270] loss: 189515.6250 RMSElog: 8.7910 grad_loss: 18942.7715 normal_loss: 0.0000
[epoch  7][iter  280] loss: 149518.5781 RMSElog: 8.8691 grad_loss: 14942.9883 normal_loss: 0.0000
[epoch  7][iter  290] loss: 173830.7188 RMSElog: 8.9431 grad_loss: 17374.1289 normal_loss: 0.0000
[epoch  7][iter  300] loss: 140438.8750 RMSElog: 8.7871 grad_loss: 14035.0996 normal_loss: 0.0000
[epoch  7][iter  310] loss: 166064.9062 RMSElog: 8.9685 grad_loss: 16597.5215 normal_loss: 0.0000
[epoch  7][iter  320] loss: 174978.9375 RMSElog: 8.8178 grad_loss: 17489.0762 normal_loss: 0.0000
[epoch  7][iter  330] loss: 141980.9062 RMSElog: 8.8072 grad_loss: 14189.2832 normal_loss: 0.0000
[epoch  7][iter  340] loss: 122420.7891 RMSElog: 8.3593 grad_loss: 12233.7197 normal_loss: 0.0000
[epoch  7][iter  350] loss: 235185.0312 RMSElog: 9.0898 grad_loss: 23509.4141 normal_loss: 0.0000
[epoch  7][iter  360] loss: 164821.2188 RMSElog: 8.7585 grad_loss: 16473.3633 normal_loss: 0.0000
[epoch  7][iter  370] loss: 141203.9531 RMSElog: 8.7917 grad_loss: 14111.6035 normal_loss: 0.0000
[epoch  7][iter  380] loss: 118477.2812 RMSElog: 8.6023 grad_loss: 11839.1260 normal_loss: 0.0000
[epoch  7][iter  390] loss: 191795.6094 RMSElog: 8.7619 grad_loss: 19170.7988 normal_loss: 0.0000
[epoch  7][iter  400] loss: 171564.2500 RMSElog: 8.6693 grad_loss: 17147.7559 normal_loss: 0.0000
[epoch  7][iter  410] loss: 153569.0781 RMSElog: 8.6546 grad_loss: 15348.2529 normal_loss: 0.0000
[epoch  7][iter  420] loss: 178570.0781 RMSElog: 8.8665 grad_loss: 17848.1406 normal_loss: 0.0000
[epoch  7][iter  430] loss: 135015.4844 RMSElog: 8.3364 grad_loss: 13493.2119 normal_loss: 0.0000
[epoch  7][iter  440] loss: 105711.3359 RMSElog: 8.0270 grad_loss: 10563.1064 normal_loss: 0.0000
[epoch  7][iter  450] loss: 160910.6875 RMSElog: 8.7880 grad_loss: 16082.2812 normal_loss: 0.0000
[epoch  7][iter  460] loss: 147584.2500 RMSElog: 8.6155 grad_loss: 14749.8096 normal_loss: 0.0000
[epoch  7][iter  470] loss: 134788.9375 RMSElog: 8.3204 grad_loss: 13470.5742 normal_loss: 0.0000
[epoch  7][iter  480] loss: 181982.9688 RMSElog: 9.0510 grad_loss: 18189.2461 normal_loss: 0.0000
[epoch  7][iter  490] loss: 152137.3438 RMSElog: 8.7203 grad_loss: 15205.0137 normal_loss: 0.0000
[epoch  7][iter  500] loss: 218520.1406 RMSElog: 9.0918 grad_loss: 21842.9219 normal_loss: 0.0000
[epoch  7][iter  510] loss: 124296.6797 RMSElog: 8.3791 grad_loss: 12421.2891 normal_loss: 0.0000
[epoch  7][iter  520] loss: 154753.9688 RMSElog: 8.8066 grad_loss: 15466.5898 normal_loss: 0.0000
[epoch  7][iter  530] loss: 177680.6562 RMSElog: 8.8071 grad_loss: 17759.2598 normal_loss: 0.0000
[epoch  7][iter  540] loss: 124246.3984 RMSElog: 8.5284 grad_loss: 12416.1113 normal_loss: 0.0000
[epoch  7][iter  550] loss: 160764.9219 RMSElog: 8.7591 grad_loss: 16067.7334 normal_loss: 0.0000
[epoch  7][iter  560] loss: 119445.1406 RMSElog: 8.3960 grad_loss: 11936.1172 normal_loss: 0.0000
[epoch  7][iter  570] loss: 232955.1719 RMSElog: 8.9703 grad_loss: 23286.5469 normal_loss: 0.0000
[epoch  7][iter  580] loss: 148516.8594 RMSElog: 8.7974 grad_loss: 14842.8887 normal_loss: 0.0000
[epoch  7][iter  590] loss: 224050.1406 RMSElog: 9.0380 grad_loss: 22395.9766 normal_loss: 0.0000
[epoch  8][iter    0] loss: 196415.8594 RMSElog: 8.7536 grad_loss: 19632.1406 normal_loss: 0.6920
[epoch  8][iter   10] loss: 177179.5000 RMSElog: 9.1138 grad_loss: 17708.1094 normal_loss: 0.7269
[epoch  8][iter   20] loss: 158861.7344 RMSElog: 8.7156 grad_loss: 15876.7383 normal_loss: 0.7193
[epoch  8][iter   30] loss: 103290.0000 RMSElog: 8.5848 grad_loss: 10319.7344 normal_loss: 0.6803
[epoch  8][iter   40] loss: 166191.1875 RMSElog: 8.8430 grad_loss: 16609.5664 normal_loss: 0.7089
[epoch  8][iter   50] loss: 186028.9219 RMSElog: 8.7649 grad_loss: 18593.4434 normal_loss: 0.6833
[epoch  8][iter   60] loss: 162562.2344 RMSElog: 8.9618 grad_loss: 16246.5293 normal_loss: 0.7324
[epoch  8][iter   70] loss: 206505.5625 RMSElog: 8.8262 grad_loss: 20641.0625 normal_loss: 0.6670
[epoch  8][iter   80] loss: 126005.5781 RMSElog: 8.4776 grad_loss: 12591.3916 normal_loss: 0.6880
[epoch  8][iter   90] loss: 208750.7188 RMSElog: 8.8662 grad_loss: 20865.5117 normal_loss: 0.6952
[epoch  8][iter  100] loss: 177916.3438 RMSElog: 8.7888 grad_loss: 17782.1660 normal_loss: 0.6800
[epoch  8][iter  110] loss: 174987.5938 RMSElog: 9.0349 grad_loss: 17489.0000 normal_loss: 0.7249
[epoch  8][iter  120] loss: 147190.1406 RMSElog: 8.8181 grad_loss: 14709.5156 normal_loss: 0.6807
[epoch  8][iter  130] loss: 182296.5781 RMSElog: 8.9556 grad_loss: 18220.0371 normal_loss: 0.6657
[epoch  8][iter  140] loss: 139810.9531 RMSElog: 8.5006 grad_loss: 13971.9189 normal_loss: 0.6760
[epoch  8][iter  150] loss: 135680.0000 RMSElog: 8.3902 grad_loss: 13558.9102 normal_loss: 0.6992
[epoch  8][iter  160] loss: 172236.8594 RMSElog: 8.8315 grad_loss: 17214.0918 normal_loss: 0.7625
[epoch  8][iter  170] loss: 167192.3125 RMSElog: 8.8124 grad_loss: 16709.7266 normal_loss: 0.6923
[epoch  8][iter  180] loss: 218930.2188 RMSElog: 9.1456 grad_loss: 21883.1953 normal_loss: 0.6803
[epoch  8][iter  190] loss: 115513.8984 RMSElog: 8.3357 grad_loss: 11542.3613 normal_loss: 0.6921
[epoch  8][iter  200] loss: 177688.2812 RMSElog: 8.8101 grad_loss: 17759.2539 normal_loss: 0.7643
[epoch  8][iter  210] loss: 136045.7500 RMSElog: 8.3365 grad_loss: 13595.5381 normal_loss: 0.6996
[epoch  8][iter  220] loss: 200935.2812 RMSElog: 8.9371 grad_loss: 20083.8672 normal_loss: 0.7232
[epoch  8][iter  230] loss: 154607.0312 RMSElog: 8.7376 grad_loss: 15451.2998 normal_loss: 0.6665
[epoch  8][iter  240] loss: 110567.1953 RMSElog: 8.6112 grad_loss: 11047.3838 normal_loss: 0.7250
[epoch  8][iter  250] loss: 125664.7734 RMSElog: 8.5851 grad_loss: 12557.1934 normal_loss: 0.6993
[epoch  8][iter  260] loss: 127613.5781 RMSElog: 8.4932 grad_loss: 12752.1055 normal_loss: 0.7591
[epoch  8][iter  270] loss: 146560.0156 RMSElog: 8.5821 grad_loss: 14646.7080 normal_loss: 0.7113
[epoch  8][iter  280] loss: 167728.0938 RMSElog: 8.8401 grad_loss: 16763.2656 normal_loss: 0.7032
[epoch  8][iter  290] loss: 221070.5625 RMSElog: 9.0956 grad_loss: 22097.2676 normal_loss: 0.6926
[epoch  8][iter  300] loss: 221194.8594 RMSElog: 8.9426 grad_loss: 22109.8418 normal_loss: 0.7014
[epoch  8][iter  310] loss: 222999.0469 RMSElog: 9.0699 grad_loss: 22290.1582 normal_loss: 0.6752
[epoch  8][iter  320] loss: 182171.6875 RMSElog: 8.9875 grad_loss: 18207.4434 normal_loss: 0.7369
[epoch  8][iter  330] loss: 112370.7656 RMSElog: 8.1933 grad_loss: 11228.1797 normal_loss: 0.7027
[epoch  8][iter  340] loss: 157687.5312 RMSElog: 8.9185 grad_loss: 15759.1709 normal_loss: 0.6644
[epoch  8][iter  350] loss: 133267.5000 RMSElog: 8.6341 grad_loss: 13317.4600 normal_loss: 0.6558
[epoch  8][iter  360] loss: 134615.8750 RMSElog: 8.7702 grad_loss: 13452.1172 normal_loss: 0.7001
[epoch  8][iter  370] loss: 104420.5312 RMSElog: 8.2993 grad_loss: 10433.0918 normal_loss: 0.6618
[epoch  8][iter  380] loss: 215933.3594 RMSElog: 8.8900 grad_loss: 21583.7930 normal_loss: 0.6517
[epoch  8][iter  390] loss: 122367.0156 RMSElog: 8.5563 grad_loss: 12227.4990 normal_loss: 0.6457
[epoch  8][iter  400] loss: 163758.6250 RMSElog: 8.6862 grad_loss: 16366.4609 normal_loss: 0.7144
[epoch  8][iter  410] loss: 103779.2578 RMSElog: 8.3553 grad_loss: 10368.9062 normal_loss: 0.6641
[epoch  8][iter  420] loss: 208801.3125 RMSElog: 8.8299 grad_loss: 20870.6367 normal_loss: 0.6647
[epoch  8][iter  430] loss: 174359.8438 RMSElog: 9.0492 grad_loss: 17426.2266 normal_loss: 0.7084
[epoch  8][iter  440] loss: 129689.6094 RMSElog: 8.5132 grad_loss: 12959.7695 normal_loss: 0.6776
[epoch  8][iter  450] loss: 148035.9531 RMSElog: 8.6705 grad_loss: 14794.2656 normal_loss: 0.6585
[epoch  8][iter  460] loss: 160806.9062 RMSElog: 8.8267 grad_loss: 16071.2061 normal_loss: 0.6573
[epoch  8][iter  470] loss: 191539.2344 RMSElog: 8.6539 grad_loss: 19144.5781 normal_loss: 0.6915
[epoch  8][iter  480] loss: 167399.2188 RMSElog: 8.8169 grad_loss: 16730.3691 normal_loss: 0.7359
[epoch  8][iter  490] loss: 106159.2656 RMSElog: 8.1092 grad_loss: 10607.1367 normal_loss: 0.6807
[epoch  8][iter  500] loss: 172730.4375 RMSElog: 8.9177 grad_loss: 17263.4297 normal_loss: 0.6962
[epoch  8][iter  510] loss: 166073.1875 RMSElog: 9.0395 grad_loss: 16597.5820 normal_loss: 0.6967
[epoch  8][iter  520] loss: 147464.3750 RMSElog: 8.7687 grad_loss: 14736.9375 normal_loss: 0.7317
[epoch  8][iter  530] loss: 198424.5156 RMSElog: 8.9299 grad_loss: 19832.8477 normal_loss: 0.6739
[epoch  8][iter  540] loss: 104316.8125 RMSElog: 8.0600 grad_loss: 10422.9531 normal_loss: 0.6685
[epoch  8][iter  550] loss: 132686.9688 RMSElog: 8.5050 grad_loss: 13259.5273 normal_loss: 0.6644
[epoch  8][iter  560] loss: 106182.8047 RMSElog: 8.4386 grad_loss: 10609.1104 normal_loss: 0.7316
[epoch  8][iter  570] loss: 120723.1875 RMSElog: 8.2859 grad_loss: 12063.3779 normal_loss: 0.6542
[epoch  8][iter  580] loss: 121943.1250 RMSElog: 8.7094 grad_loss: 12184.9238 normal_loss: 0.6801
[epoch  8][iter  590] loss: 124302.2812 RMSElog: 8.3063 grad_loss: 12421.2383 normal_loss: 0.6835
[epoch  9][iter    0] loss: 148222.3281 RMSElog: 8.7881 grad_loss: 14812.7734 normal_loss: 0.6719
[epoch  9][iter   10] loss: 131991.9375 RMSElog: 8.2753 grad_loss: 13190.2236 normal_loss: 0.6948
[epoch  9][iter   20] loss: 233376.7812 RMSElog: 9.0123 grad_loss: 23327.9902 normal_loss: 0.6750
[epoch  9][iter   30] loss: 196899.5156 RMSElog: 8.9539 grad_loss: 19680.3359 normal_loss: 0.6624
[epoch  9][iter   40] loss: 170040.2344 RMSElog: 8.7718 grad_loss: 16994.5586 normal_loss: 0.6926
[epoch  9][iter   50] loss: 124229.8359 RMSElog: 8.6653 grad_loss: 12413.6318 normal_loss: 0.6868
[epoch  9][iter   60] loss: 104436.0938 RMSElog: 8.5054 grad_loss: 10434.4043 normal_loss: 0.6995
[epoch  9][iter   70] loss: 148773.3750 RMSElog: 8.7849 grad_loss: 14867.8789 normal_loss: 0.6725
[epoch  9][iter   80] loss: 205341.1875 RMSElog: 8.8178 grad_loss: 20524.6484 normal_loss: 0.6520
[epoch  9][iter   90] loss: 162962.7344 RMSElog: 8.7242 grad_loss: 16286.8242 normal_loss: 0.7251
[epoch  9][iter  100] loss: 179884.4688 RMSElog: 8.7807 grad_loss: 17978.9570 normal_loss: 0.7095
[epoch  9][iter  110] loss: 140447.0938 RMSElog: 8.7885 grad_loss: 14035.0977 normal_loss: 0.8240
[epoch  9][iter  120] loss: 141097.3125 RMSElog: 8.7311 grad_loss: 14100.3535 normal_loss: 0.6455
[epoch  9][iter  130] loss: 128864.5625 RMSElog: 8.6654 grad_loss: 12877.1133 normal_loss: 0.6779
[epoch  9][iter  140] loss: 164750.3906 RMSElog: 8.7631 grad_loss: 16465.5781 normal_loss: 0.6975
[epoch  9][iter  150] loss: 160575.7656 RMSElog: 8.7974 grad_loss: 16048.1191 normal_loss: 0.6593
[epoch  9][iter  160] loss: 115480.1641 RMSElog: 8.5442 grad_loss: 11538.7979 normal_loss: 0.6747
[epoch  9][iter  170] loss: 127445.4062 RMSElog: 8.3916 grad_loss: 12735.4775 normal_loss: 0.6714
[epoch  9][iter  180] loss: 141149.9531 RMSElog: 8.3889 grad_loss: 14105.9004 normal_loss: 0.7059
[epoch  9][iter  190] loss: 114883.3203 RMSElog: 8.6490 grad_loss: 11478.9355 normal_loss: 0.7472
[epoch  9][iter  200] loss: 185127.2656 RMSElog: 8.9055 grad_loss: 18503.0684 normal_loss: 0.7513
[epoch  9][iter  210] loss: 137275.5312 RMSElog: 8.5479 grad_loss: 13718.3301 normal_loss: 0.6757
[epoch  9][iter  220] loss: 163251.6875 RMSElog: 8.8929 grad_loss: 16315.5654 normal_loss: 0.7109
[epoch  9][iter  230] loss: 154687.5625 RMSElog: 8.8171 grad_loss: 15459.2598 normal_loss: 0.6794
[epoch  9][iter  240] loss: 126950.0781 RMSElog: 8.4582 grad_loss: 12685.8730 normal_loss: 0.6770
[epoch  9][iter  250] loss: 160449.6562 RMSElog: 8.8464 grad_loss: 16035.4346 normal_loss: 0.6840
[epoch  9][iter  260] loss: 141210.6562 RMSElog: 8.8110 grad_loss: 14111.5879 normal_loss: 0.6679
[epoch  9][iter  270] loss: 165633.2500 RMSElog: 8.7946 grad_loss: 16553.8203 normal_loss: 0.7093
[epoch  9][iter  280] loss: 152315.3125 RMSElog: 8.6970 grad_loss: 15222.0879 normal_loss: 0.7462
[epoch  9][iter  290] loss: 154290.8906 RMSElog: 8.6791 grad_loss: 15419.7285 normal_loss: 0.6813
[epoch  9][iter  300] loss: 173837.7500 RMSElog: 8.9368 grad_loss: 17374.1133 normal_loss: 0.7237
[epoch  9][iter  310] loss: 139857.4688 RMSElog: 8.2225 grad_loss: 13976.7686 normal_loss: 0.7551
[epoch  9][iter  320] loss: 221194.5000 RMSElog: 8.9278 grad_loss: 22109.8262 normal_loss: 0.6953
[epoch  9][iter  330] loss: 122368.0625 RMSElog: 8.5922 grad_loss: 12227.5439 normal_loss: 0.6713
[epoch  9][iter  340] loss: 197499.9844 RMSElog: 8.9005 grad_loss: 19740.4375 normal_loss: 0.6610
[epoch  9][iter  350] loss: 147581.1094 RMSElog: 8.7858 grad_loss: 14748.6426 normal_loss: 0.6829
[epoch  9][iter  360] loss: 130125.8516 RMSElog: 8.3623 grad_loss: 13003.5205 normal_loss: 0.7023
[epoch  9][iter  370] loss: 191539.2188 RMSElog: 8.6487 grad_loss: 19144.5801 normal_loss: 0.6932
[epoch  9][iter  380] loss: 146927.3281 RMSElog: 8.5188 grad_loss: 14683.4980 normal_loss: 0.7156
[epoch  9][iter  390] loss: 154761.2969 RMSElog: 8.7973 grad_loss: 15466.5830 normal_loss: 0.7497
[epoch  9][iter  400] loss: 194556.1875 RMSElog: 8.7774 grad_loss: 19446.1816 normal_loss: 0.6601
[epoch  9][iter  410] loss: 196496.2812 RMSElog: 8.7151 grad_loss: 19640.2129 normal_loss: 0.7021
[epoch  9][iter  420] loss: 220675.6250 RMSElog: 8.8677 grad_loss: 22058.0078 normal_loss: 0.6869
[epoch  9][iter  430] loss: 175282.9375 RMSElog: 8.6476 grad_loss: 17518.9492 normal_loss: 0.6950
[epoch  9][iter  440] loss: 140317.0156 RMSElog: 8.8008 grad_loss: 14022.2090 normal_loss: 0.6912
[epoch  9][iter  450] loss: 177919.5469 RMSElog: 8.9722 grad_loss: 17782.2676 normal_loss: 0.7151
[epoch  9][iter  460] loss: 131922.4688 RMSElog: 8.5649 grad_loss: 13183.0293 normal_loss: 0.6519
[epoch  9][iter  470] loss: 200448.1094 RMSElog: 8.7777 grad_loss: 20035.3789 normal_loss: 0.6535
[epoch  9][iter  480] loss: 129149.0703 RMSElog: 8.9028 grad_loss: 12905.3184 normal_loss: 0.6861
[epoch  9][iter  490] loss: 196821.4062 RMSElog: 8.7621 grad_loss: 19672.7031 normal_loss: 0.6752
[epoch  9][iter  500] loss: 188998.6875 RMSElog: 8.9223 grad_loss: 18890.2461 normal_loss: 0.7005
[epoch  9][iter  510] loss: 160918.4688 RMSElog: 8.8383 grad_loss: 16082.2773 normal_loss: 0.7310
[epoch  9][iter  520] loss: 125676.1328 RMSElog: 8.4039 grad_loss: 12558.4482 normal_loss: 0.7608
[epoch  9][iter  530] loss: 102976.9688 RMSElog: 8.3469 grad_loss: 10288.6758 normal_loss: 0.6752
[epoch  9][iter  540] loss: 150347.5781 RMSElog: 8.8705 grad_loss: 15025.1963 normal_loss: 0.6919
[epoch  9][iter  550] loss: 195393.8750 RMSElog: 8.9388 grad_loss: 19529.7871 normal_loss: 0.6605
[epoch  9][iter  560] loss: 210635.4531 RMSElog: 9.1915 grad_loss: 21053.6484 normal_loss: 0.7060
[epoch  9][iter  570] loss: 202097.4062 RMSElog: 8.7619 grad_loss: 20200.3203 normal_loss: 0.6586
[epoch  9][iter  580] loss: 110864.5234 RMSElog: 8.6761 grad_loss: 11077.0400 normal_loss: 0.7360
[epoch  9][iter  590] loss: 177688.1562 RMSElog: 8.8144 grad_loss: 17759.2500 normal_loss: 0.7519
[epoch  0][iter    0] loss: 119.8144 RMSElog: 11.9814 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   10] loss: 86.7535 RMSElog: 8.6754 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   20] loss: 95.9883 RMSElog: 9.5988 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   30] loss: 102.6667 RMSElog: 10.2667 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   40] loss: 101.5664 RMSElog: 10.1566 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   50] loss: 109.4667 RMSElog: 10.9467 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   60] loss: 108.4899 RMSElog: 10.8490 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   70] loss: 109.5366 RMSElog: 10.9537 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   80] loss: 105.7939 RMSElog: 10.5794 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   90] loss: 117.7827 RMSElog: 11.7783 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  100] loss: 106.2094 RMSElog: 10.6209 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  110] loss: 100.5064 RMSElog: 10.0506 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  120] loss: 91.4008 RMSElog: 9.1401 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  130] loss: 90.0873 RMSElog: 9.0087 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  140] loss: 88.1611 RMSElog: 8.8161 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  150] loss: 88.2217 RMSElog: 8.8222 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  160] loss: 86.4745 RMSElog: 8.6475 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  170] loss: 74.7805 RMSElog: 7.4780 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  180] loss: 76.5847 RMSElog: 7.6585 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  190] loss: 74.7382 RMSElog: 7.4738 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  200] loss: 70.1263 RMSElog: 7.0126 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  210] loss: 69.4451 RMSElog: 6.9445 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  220] loss: 68.2000 RMSElog: 6.8200 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  230] loss: 62.9610 RMSElog: 6.2961 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  240] loss: 70.8677 RMSElog: 7.0868 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  250] loss: 62.5178 RMSElog: 6.2518 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  260] loss: 64.1126 RMSElog: 6.4113 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  270] loss: 67.1145 RMSElog: 6.7114 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  280] loss: 62.6315 RMSElog: 6.2631 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  290] loss: 61.1101 RMSElog: 6.1110 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  300] loss: 63.1320 RMSElog: 6.3132 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  310] loss: 61.1307 RMSElog: 6.1131 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  320] loss: 62.3732 RMSElog: 6.2373 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  330] loss: 55.4602 RMSElog: 5.5460 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  340] loss: 67.0981 RMSElog: 6.7098 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  350] loss: 54.7265 RMSElog: 5.4727 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  360] loss: 53.9895 RMSElog: 5.3989 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  370] loss: 55.0737 RMSElog: 5.5074 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  380] loss: 54.3650 RMSElog: 5.4365 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  390] loss: 56.4663 RMSElog: 5.6466 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  400] loss: 64.9593 RMSElog: 6.4959 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  410] loss: 53.6038 RMSElog: 5.3604 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  420] loss: 55.4982 RMSElog: 5.5498 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  430] loss: 65.5004 RMSElog: 6.5500 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  440] loss: 52.9555 RMSElog: 5.2955 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  450] loss: 58.6055 RMSElog: 5.8606 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  460] loss: 62.1660 RMSElog: 6.2166 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  470] loss: 59.7864 RMSElog: 5.9786 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  480] loss: 52.9331 RMSElog: 5.2933 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  490] loss: 52.7509 RMSElog: 5.2751 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  500] loss: 59.7227 RMSElog: 5.9723 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  510] loss: 48.7297 RMSElog: 4.8730 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  520] loss: 60.1499 RMSElog: 6.0150 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  530] loss: 60.5296 RMSElog: 6.0530 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  540] loss: 53.2751 RMSElog: 5.3275 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  550] loss: 52.2124 RMSElog: 5.2212 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  560] loss: 58.0389 RMSElog: 5.8039 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  570] loss: 56.4653 RMSElog: 5.6465 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  580] loss: 50.6578 RMSElog: 5.0658 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  590] loss: 56.2901 RMSElog: 5.6290 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter    0] loss: 55.7410 RMSElog: 5.5741 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   10] loss: 50.1344 RMSElog: 5.0134 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   20] loss: 50.2915 RMSElog: 5.0291 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   30] loss: 53.4704 RMSElog: 5.3470 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   40] loss: 65.2900 RMSElog: 6.5290 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   50] loss: 55.0087 RMSElog: 5.5009 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   60] loss: 55.8321 RMSElog: 5.5832 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   70] loss: 61.0733 RMSElog: 6.1073 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   80] loss: 57.5449 RMSElog: 5.7545 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   90] loss: 48.3050 RMSElog: 4.8305 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  100] loss: 59.6777 RMSElog: 5.9678 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  110] loss: 54.2150 RMSElog: 5.4215 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  120] loss: 57.5910 RMSElog: 5.7591 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  130] loss: 47.4229 RMSElog: 4.7423 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  140] loss: 59.6557 RMSElog: 5.9656 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  150] loss: 49.0537 RMSElog: 4.9054 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  160] loss: 52.3778 RMSElog: 5.2378 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  170] loss: 53.5800 RMSElog: 5.3580 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  180] loss: 51.5256 RMSElog: 5.1526 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  190] loss: 60.3353 RMSElog: 6.0335 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  200] loss: 60.0410 RMSElog: 6.0041 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  210] loss: 58.7069 RMSElog: 5.8707 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  220] loss: 52.5191 RMSElog: 5.2519 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  230] loss: 57.7992 RMSElog: 5.7799 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  240] loss: 50.6269 RMSElog: 5.0627 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  250] loss: 55.3594 RMSElog: 5.5359 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  260] loss: 57.3758 RMSElog: 5.7376 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  270] loss: 61.4870 RMSElog: 6.1487 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  280] loss: 53.4405 RMSElog: 5.3440 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  290] loss: 47.4400 RMSElog: 4.7440 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  300] loss: 57.8588 RMSElog: 5.7859 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  310] loss: 55.8621 RMSElog: 5.5862 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  320] loss: 54.8674 RMSElog: 5.4867 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  330] loss: 53.7480 RMSElog: 5.3748 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  340] loss: 46.9657 RMSElog: 4.6966 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  350] loss: 48.6217 RMSElog: 4.8622 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  360] loss: 53.2431 RMSElog: 5.3243 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  370] loss: 62.0760 RMSElog: 6.2076 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  380] loss: 51.7306 RMSElog: 5.1731 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  390] loss: 46.3470 RMSElog: 4.6347 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  400] loss: 45.9434 RMSElog: 4.5943 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  410] loss: 48.6665 RMSElog: 4.8667 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  420] loss: 45.1148 RMSElog: 4.5115 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  430] loss: 54.9492 RMSElog: 5.4949 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  440] loss: 50.5993 RMSElog: 5.0599 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  450] loss: 53.7283 RMSElog: 5.3728 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  460] loss: 51.2328 RMSElog: 5.1233 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  470] loss: 47.5088 RMSElog: 4.7509 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  480] loss: 61.9910 RMSElog: 6.1991 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  490] loss: 64.0480 RMSElog: 6.4048 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  500] loss: 50.9834 RMSElog: 5.0983 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  510] loss: 46.9033 RMSElog: 4.6903 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  520] loss: 60.4814 RMSElog: 6.0481 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  530] loss: 51.9186 RMSElog: 5.1919 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  540] loss: 45.7350 RMSElog: 4.5735 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  550] loss: 45.9820 RMSElog: 4.5982 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  560] loss: 52.9004 RMSElog: 5.2900 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  570] loss: 48.3043 RMSElog: 4.8304 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  580] loss: 51.2759 RMSElog: 5.1276 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  590] loss: 52.5482 RMSElog: 5.2548 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter    0] loss: 49.0786 RMSElog: 4.9079 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   10] loss: 47.9798 RMSElog: 4.7980 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   20] loss: 51.6779 RMSElog: 5.1678 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   30] loss: 42.3575 RMSElog: 4.2357 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   40] loss: 45.3039 RMSElog: 4.5304 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   50] loss: 55.2073 RMSElog: 5.5207 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   60] loss: 47.2171 RMSElog: 4.7217 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   70] loss: 59.5954 RMSElog: 5.9595 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   80] loss: 40.9501 RMSElog: 4.0950 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   90] loss: 54.3690 RMSElog: 5.4369 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  100] loss: 48.7571 RMSElog: 4.8757 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  110] loss: 48.0395 RMSElog: 4.8039 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  120] loss: 40.6613 RMSElog: 4.0661 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  130] loss: 50.0541 RMSElog: 5.0054 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  140] loss: 51.0801 RMSElog: 5.1080 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  150] loss: 48.7213 RMSElog: 4.8721 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  160] loss: 43.3036 RMSElog: 4.3304 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  170] loss: 60.6167 RMSElog: 6.0617 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  180] loss: 50.3260 RMSElog: 5.0326 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  190] loss: 59.5050 RMSElog: 5.9505 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  200] loss: 52.9962 RMSElog: 5.2996 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  210] loss: 59.5888 RMSElog: 5.9589 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  220] loss: 48.1701 RMSElog: 4.8170 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  230] loss: 43.2018 RMSElog: 4.3202 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  240] loss: 51.8683 RMSElog: 5.1868 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  250] loss: 58.1346 RMSElog: 5.8135 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  260] loss: 48.8040 RMSElog: 4.8804 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  270] loss: 55.6794 RMSElog: 5.5679 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  280] loss: 52.8132 RMSElog: 5.2813 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  290] loss: 54.7494 RMSElog: 5.4749 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  300] loss: 55.1682 RMSElog: 5.5168 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  310] loss: 48.9279 RMSElog: 4.8928 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  320] loss: 45.7312 RMSElog: 4.5731 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  330] loss: 51.7108 RMSElog: 5.1711 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  340] loss: 51.8537 RMSElog: 5.1854 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  350] loss: 46.4623 RMSElog: 4.6462 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  360] loss: 48.4451 RMSElog: 4.8445 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  370] loss: 48.3251 RMSElog: 4.8325 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  380] loss: 45.8563 RMSElog: 4.5856 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  390] loss: 46.6867 RMSElog: 4.6687 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  400] loss: 54.8470 RMSElog: 5.4847 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  410] loss: 41.7174 RMSElog: 4.1717 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  420] loss: 46.3116 RMSElog: 4.6312 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  430] loss: 43.9855 RMSElog: 4.3985 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  440] loss: 52.5015 RMSElog: 5.2501 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  450] loss: 52.5229 RMSElog: 5.2523 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  460] loss: 56.4038 RMSElog: 5.6404 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  470] loss: 42.1576 RMSElog: 4.2158 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  480] loss: 46.1473 RMSElog: 4.6147 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  490] loss: 52.3140 RMSElog: 5.2314 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  500] loss: 50.3655 RMSElog: 5.0365 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  510] loss: 53.4172 RMSElog: 5.3417 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  520] loss: 53.4742 RMSElog: 5.3474 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  530] loss: 50.9419 RMSElog: 5.0942 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  540] loss: 40.9114 RMSElog: 4.0911 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  550] loss: 57.0887 RMSElog: 5.7089 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  560] loss: 53.2554 RMSElog: 5.3255 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  570] loss: 57.9160 RMSElog: 5.7916 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  580] loss: 53.4399 RMSElog: 5.3440 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  590] loss: 51.0678 RMSElog: 5.1068 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter    0] loss: 43.9151 RMSElog: 4.3915 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   10] loss: 37.7049 RMSElog: 3.7705 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   20] loss: 49.6123 RMSElog: 4.9612 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   30] loss: 50.6872 RMSElog: 5.0687 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   40] loss: 47.1178 RMSElog: 4.7118 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   50] loss: 49.0527 RMSElog: 4.9053 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   60] loss: 47.9475 RMSElog: 4.7948 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   70] loss: 62.7900 RMSElog: 6.2790 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   80] loss: 47.7990 RMSElog: 4.7799 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   90] loss: 50.3167 RMSElog: 5.0317 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  100] loss: 52.2046 RMSElog: 5.2205 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  110] loss: 58.6719 RMSElog: 5.8672 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  120] loss: 56.8166 RMSElog: 5.6817 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  130] loss: 49.7394 RMSElog: 4.9739 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  140] loss: 46.3468 RMSElog: 4.6347 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  150] loss: 53.6117 RMSElog: 5.3612 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  160] loss: 57.8014 RMSElog: 5.7801 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  170] loss: 49.2035 RMSElog: 4.9204 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  180] loss: 54.9784 RMSElog: 5.4978 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  190] loss: 45.9815 RMSElog: 4.5981 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  200] loss: 61.9305 RMSElog: 6.1930 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  210] loss: 51.7487 RMSElog: 5.1749 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  220] loss: 49.5051 RMSElog: 4.9505 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  230] loss: 51.0272 RMSElog: 5.1027 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  240] loss: 47.6664 RMSElog: 4.7666 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  250] loss: 49.0225 RMSElog: 4.9023 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  260] loss: 47.4297 RMSElog: 4.7430 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  270] loss: 49.9612 RMSElog: 4.9961 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  280] loss: 62.1906 RMSElog: 6.2191 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  290] loss: 48.7873 RMSElog: 4.8787 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  300] loss: 57.8414 RMSElog: 5.7841 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  310] loss: 47.1386 RMSElog: 4.7139 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  320] loss: 49.7729 RMSElog: 4.9773 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  330] loss: 49.6648 RMSElog: 4.9665 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  340] loss: 42.9890 RMSElog: 4.2989 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  350] loss: 48.0289 RMSElog: 4.8029 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  360] loss: 56.6504 RMSElog: 5.6650 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  370] loss: 53.6649 RMSElog: 5.3665 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  380] loss: 51.0358 RMSElog: 5.1036 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  390] loss: 60.0182 RMSElog: 6.0018 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  400] loss: 50.8324 RMSElog: 5.0832 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  410] loss: 52.5052 RMSElog: 5.2505 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  420] loss: 41.7009 RMSElog: 4.1701 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  430] loss: 38.8998 RMSElog: 3.8900 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  440] loss: 49.7746 RMSElog: 4.9775 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  450] loss: 47.9874 RMSElog: 4.7987 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  460] loss: 54.6588 RMSElog: 5.4659 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  470] loss: 48.0826 RMSElog: 4.8083 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  480] loss: 45.8909 RMSElog: 4.5891 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  490] loss: 43.0751 RMSElog: 4.3075 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  500] loss: 47.3313 RMSElog: 4.7331 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  510] loss: 40.3885 RMSElog: 4.0388 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  520] loss: 53.9713 RMSElog: 5.3971 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  530] loss: 61.9362 RMSElog: 6.1936 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  540] loss: 42.2935 RMSElog: 4.2294 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  550] loss: 45.1758 RMSElog: 4.5176 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  560] loss: 51.2561 RMSElog: 5.1256 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  570] loss: 57.0595 RMSElog: 5.7059 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  580] loss: 45.9352 RMSElog: 4.5935 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  590] loss: 50.8543 RMSElog: 5.0854 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  4][iter    0] loss: 349601.8125 RMSElog: 5.3938 grad_loss: 34954.7852 normal_loss: 0.0000
[epoch  4][iter   10] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   20] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   30] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   40] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   50] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   60] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   70] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   80] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   90] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  100] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  110] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  120] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  130] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  140] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  150] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  160] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  170] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  180] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  190] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  200] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  210] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  220] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  230] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  240] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  250] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  260] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  270] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  280] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  290] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  300] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  310] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  320] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  330] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  340] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  350] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  360] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  370] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  380] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  390] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  400] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  410] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  420] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  430] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  440] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  450] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  460] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  470] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  480] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  490] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  500] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  510] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  520] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  530] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  540] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  550] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  560] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  570] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  580] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  590] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter    0] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter   10] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter   20] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter   30] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter   40] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter   50] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter   60] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter   70] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter   80] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter   90] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  100] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  110] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  120] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  130] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  140] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  150] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  160] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  170] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  180] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  190] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  200] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  210] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  220] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  230] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  240] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  250] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  260] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  270] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  280] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  290] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  300] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  310] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  320] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  330] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  340] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  350] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  360] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  370] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  380] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  390] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  400] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  410] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  420] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  430] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  440] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  450] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  460] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  470] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  480] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  490] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  500] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  510] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  520] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  530] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  540] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  550] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  560] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  570] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  580] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  5][iter  590] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  0][iter    0] loss: 116.9774 RMSElog: 11.6977 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   10] loss: 96.5521 RMSElog: 9.6552 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   20] loss: 116.6785 RMSElog: 11.6679 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   30] loss: 100.7046 RMSElog: 10.0705 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   40] loss: 115.4609 RMSElog: 11.5461 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   50] loss: 104.6641 RMSElog: 10.4664 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   60] loss: 120.2594 RMSElog: 12.0259 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   70] loss: 106.8238 RMSElog: 10.6824 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   80] loss: 110.4321 RMSElog: 11.0432 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   90] loss: 119.4931 RMSElog: 11.9493 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  100] loss: 97.3881 RMSElog: 9.7388 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  110] loss: 91.3262 RMSElog: 9.1326 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  120] loss: 90.3958 RMSElog: 9.0396 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  130] loss: 79.7931 RMSElog: 7.9793 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  140] loss: 84.2581 RMSElog: 8.4258 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  150] loss: 92.3882 RMSElog: 9.2388 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  160] loss: 74.5239 RMSElog: 7.4524 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  170] loss: 59.8597 RMSElog: 5.9860 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  180] loss: 67.5429 RMSElog: 6.7543 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  190] loss: 62.8745 RMSElog: 6.2875 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  200] loss: 62.6870 RMSElog: 6.2687 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  210] loss: 70.0541 RMSElog: 7.0054 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  220] loss: 63.4903 RMSElog: 6.3490 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  230] loss: 75.5202 RMSElog: 7.5520 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  240] loss: 65.4342 RMSElog: 6.5434 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  250] loss: 73.4149 RMSElog: 7.3415 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  260] loss: 62.3842 RMSElog: 6.2384 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  270] loss: 63.3066 RMSElog: 6.3307 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  280] loss: 60.2381 RMSElog: 6.0238 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  290] loss: 63.2563 RMSElog: 6.3256 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  300] loss: 62.7461 RMSElog: 6.2746 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  310] loss: 67.4078 RMSElog: 6.7408 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  320] loss: 62.1012 RMSElog: 6.2101 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  330] loss: 72.9707 RMSElog: 7.2971 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  340] loss: 55.7758 RMSElog: 5.5776 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  350] loss: 53.8858 RMSElog: 5.3886 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  360] loss: 57.8730 RMSElog: 5.7873 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  370] loss: 54.1998 RMSElog: 5.4200 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  380] loss: 66.2824 RMSElog: 6.6282 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  390] loss: 52.2624 RMSElog: 5.2262 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  400] loss: 54.7404 RMSElog: 5.4740 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  410] loss: 60.3795 RMSElog: 6.0379 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  420] loss: 56.6720 RMSElog: 5.6672 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  430] loss: 58.9629 RMSElog: 5.8963 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  440] loss: 64.6775 RMSElog: 6.4677 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  450] loss: 61.4853 RMSElog: 6.1485 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  460] loss: 51.4693 RMSElog: 5.1469 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  470] loss: 56.4837 RMSElog: 5.6484 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  480] loss: 59.3184 RMSElog: 5.9318 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  490] loss: 48.3470 RMSElog: 4.8347 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  500] loss: 55.1060 RMSElog: 5.5106 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  510] loss: 63.6193 RMSElog: 6.3619 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  520] loss: 54.8557 RMSElog: 5.4856 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  530] loss: 63.0582 RMSElog: 6.3058 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  540] loss: 58.8023 RMSElog: 5.8802 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter    0] loss: 10.8523 RMSElog: 10.8523 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   10] loss: 11.0142 RMSElog: 11.0142 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   20] loss: 10.9749 RMSElog: 10.9749 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   30] loss: 11.0116 RMSElog: 11.0116 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   40] loss: 10.7812 RMSElog: 10.7812 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   50] loss: 10.4441 RMSElog: 10.4441 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   60] loss: 11.8125 RMSElog: 11.8125 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   70] loss: 12.1052 RMSElog: 12.1052 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   80] loss: 12.1267 RMSElog: 12.1267 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   90] loss: 10.8825 RMSElog: 10.8825 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  100] loss: 10.8149 RMSElog: 10.8149 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  110] loss: 10.6320 RMSElog: 10.6320 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  120] loss: 11.4505 RMSElog: 11.4505 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  130] loss: 11.9446 RMSElog: 11.9446 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  140] loss: 11.0685 RMSElog: 11.0685 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  150] loss: 11.9996 RMSElog: 11.9996 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  160] loss: 10.1847 RMSElog: 10.1847 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  170] loss: 12.5099 RMSElog: 12.5099 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  180] loss: 11.2828 RMSElog: 11.2828 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  190] loss: 10.4142 RMSElog: 10.4142 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  200] loss: 10.6743 RMSElog: 10.6743 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  210] loss: 11.3082 RMSElog: 11.3082 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  220] loss: 10.7871 RMSElog: 10.7871 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  230] loss: 10.7878 RMSElog: 10.7878 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  240] loss: 10.9243 RMSElog: 10.9243 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  250] loss: 11.0710 RMSElog: 11.0710 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  260] loss: 10.3765 RMSElog: 10.3765 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  270] loss: 10.9250 RMSElog: 10.9250 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  280] loss: 11.3647 RMSElog: 11.3647 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  290] loss: 11.1548 RMSElog: 11.1548 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  300] loss: 11.8700 RMSElog: 11.8700 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  310] loss: 10.8479 RMSElog: 10.8479 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  320] loss: 12.2529 RMSElog: 12.2529 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  330] loss: 8.8541 RMSElog: 8.8541 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  340] loss: 10.5474 RMSElog: 10.5474 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  350] loss: 11.5536 RMSElog: 11.5536 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  360] loss: 11.6674 RMSElog: 11.6674 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  370] loss: 11.8002 RMSElog: 11.8002 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  380] loss: 10.8577 RMSElog: 10.8577 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  390] loss: 11.3393 RMSElog: 11.3393 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  400] loss: 11.5040 RMSElog: 11.5040 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  410] loss: 8.9602 RMSElog: 8.9602 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  420] loss: 11.1110 RMSElog: 11.1110 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  430] loss: 12.0584 RMSElog: 12.0584 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  440] loss: 9.7662 RMSElog: 9.7662 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  450] loss: 8.7253 RMSElog: 8.7253 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  460] loss: 10.4582 RMSElog: 10.4582 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  470] loss: 11.4873 RMSElog: 11.4873 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  480] loss: 11.1096 RMSElog: 11.1096 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  490] loss: 9.9817 RMSElog: 9.9817 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  500] loss: 10.6901 RMSElog: 10.6901 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  510] loss: 12.1638 RMSElog: 12.1638 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  520] loss: 10.6334 RMSElog: 10.6334 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  530] loss: 10.2396 RMSElog: 10.2396 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  540] loss: 8.7880 RMSElog: 8.7880 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  550] loss: 11.8099 RMSElog: 11.8099 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  560] loss: 12.2331 RMSElog: 12.2331 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  570] loss: 12.6580 RMSElog: 12.6580 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  580] loss: 11.8329 RMSElog: 11.8329 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  590] loss: 10.8951 RMSElog: 10.8951 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter    0] loss: 12.0980 RMSElog: 12.0980 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   10] loss: 11.5178 RMSElog: 11.5178 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   20] loss: 12.2340 RMSElog: 12.2340 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   30] loss: 9.7164 RMSElog: 9.7164 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   40] loss: 11.9938 RMSElog: 11.9938 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   50] loss: 12.0038 RMSElog: 12.0038 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   60] loss: 10.3919 RMSElog: 10.3919 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   70] loss: 10.8700 RMSElog: 10.8700 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   80] loss: 8.8760 RMSElog: 8.8760 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   90] loss: 9.8111 RMSElog: 9.8111 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  100] loss: 10.1057 RMSElog: 10.1057 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  110] loss: 10.8165 RMSElog: 10.8165 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  120] loss: 10.3826 RMSElog: 10.3826 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  130] loss: 10.8550 RMSElog: 10.8550 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  140] loss: 11.1325 RMSElog: 11.1325 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  150] loss: 10.9922 RMSElog: 10.9922 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  160] loss: 9.9332 RMSElog: 9.9332 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  170] loss: 9.6493 RMSElog: 9.6493 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  180] loss: 11.0457 RMSElog: 11.0457 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  190] loss: 8.9362 RMSElog: 8.9362 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  200] loss: 9.8241 RMSElog: 9.8241 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  210] loss: 9.2740 RMSElog: 9.2740 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  220] loss: 9.1725 RMSElog: 9.1725 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  230] loss: 8.9208 RMSElog: 8.9208 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  240] loss: 8.9338 RMSElog: 8.9338 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  250] loss: 7.0662 RMSElog: 7.0662 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  260] loss: 9.5030 RMSElog: 9.5030 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  270] loss: 8.9622 RMSElog: 8.9622 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  280] loss: 8.8332 RMSElog: 8.8332 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  290] loss: 9.7358 RMSElog: 9.7358 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  300] loss: 8.6248 RMSElog: 8.6248 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  310] loss: 8.7739 RMSElog: 8.7739 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  320] loss: 9.2474 RMSElog: 9.2474 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  330] loss: 8.6712 RMSElog: 8.6712 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  340] loss: 8.4141 RMSElog: 8.4141 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  350] loss: 8.5306 RMSElog: 8.5306 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  360] loss: 7.6575 RMSElog: 7.6575 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  370] loss: 9.6329 RMSElog: 9.6329 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  380] loss: 8.0817 RMSElog: 8.0817 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  390] loss: 8.6905 RMSElog: 8.6905 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  400] loss: 7.4984 RMSElog: 7.4984 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  410] loss: 7.7403 RMSElog: 7.7403 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  420] loss: 8.7674 RMSElog: 8.7674 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  430] loss: 8.2931 RMSElog: 8.2931 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  440] loss: 7.6851 RMSElog: 7.6851 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  450] loss: 9.3255 RMSElog: 9.3255 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  460] loss: 8.5581 RMSElog: 8.5581 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  470] loss: 8.4941 RMSElog: 8.4941 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  480] loss: 7.8337 RMSElog: 7.8337 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  490] loss: 7.6443 RMSElog: 7.6443 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  500] loss: 9.0478 RMSElog: 9.0478 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  510] loss: 7.3261 RMSElog: 7.3261 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  520] loss: 8.8917 RMSElog: 8.8917 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  530] loss: 7.7742 RMSElog: 7.7742 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  540] loss: 8.2157 RMSElog: 8.2157 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  550] loss: 8.2826 RMSElog: 8.2826 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  560] loss: 7.3348 RMSElog: 7.3348 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  570] loss: 7.1193 RMSElog: 7.1193 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  580] loss: 7.4739 RMSElog: 7.4739 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  590] loss: 7.8251 RMSElog: 7.8251 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter    0] loss: 8.4347 RMSElog: 8.4347 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   10] loss: 7.8245 RMSElog: 7.8245 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   20] loss: 7.9514 RMSElog: 7.9514 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   30] loss: 6.6163 RMSElog: 6.6163 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   40] loss: 7.4375 RMSElog: 7.4375 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   50] loss: 7.0388 RMSElog: 7.0388 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   60] loss: 8.1579 RMSElog: 8.1579 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   70] loss: 7.4603 RMSElog: 7.4603 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   80] loss: 6.4717 RMSElog: 6.4717 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   90] loss: 7.2061 RMSElog: 7.2061 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  100] loss: 6.7304 RMSElog: 6.7304 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  110] loss: 7.6772 RMSElog: 7.6772 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  120] loss: 7.2146 RMSElog: 7.2146 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  130] loss: 7.1014 RMSElog: 7.1014 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  140] loss: 6.8638 RMSElog: 6.8638 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  150] loss: 7.3099 RMSElog: 7.3099 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  160] loss: 7.6049 RMSElog: 7.6049 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  170] loss: 6.7709 RMSElog: 6.7709 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  180] loss: 7.0581 RMSElog: 7.0581 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  190] loss: 6.6858 RMSElog: 6.6858 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  200] loss: 6.6160 RMSElog: 6.6160 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  210] loss: 7.3772 RMSElog: 7.3772 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  220] loss: 6.5541 RMSElog: 6.5541 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  230] loss: 6.9982 RMSElog: 6.9982 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  240] loss: 6.1369 RMSElog: 6.1369 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  250] loss: 6.6161 RMSElog: 6.6161 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  260] loss: 6.9573 RMSElog: 6.9573 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  270] loss: 6.2288 RMSElog: 6.2288 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  280] loss: 7.2564 RMSElog: 7.2564 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  290] loss: 7.8713 RMSElog: 7.8713 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  300] loss: 7.0825 RMSElog: 7.0825 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  310] loss: 7.0302 RMSElog: 7.0302 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  320] loss: 6.0108 RMSElog: 6.0108 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  330] loss: 7.8153 RMSElog: 7.8153 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  340] loss: 6.8597 RMSElog: 6.8597 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  350] loss: 6.6740 RMSElog: 6.6740 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  360] loss: 7.1805 RMSElog: 7.1805 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  370] loss: 6.8890 RMSElog: 6.8890 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  380] loss: 7.3831 RMSElog: 7.3831 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  390] loss: 6.4870 RMSElog: 6.4870 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  400] loss: 6.9226 RMSElog: 6.9226 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  410] loss: 7.2771 RMSElog: 7.2771 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  420] loss: 6.1524 RMSElog: 6.1524 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  430] loss: 6.1425 RMSElog: 6.1425 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  440] loss: 6.1572 RMSElog: 6.1572 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  450] loss: 6.6351 RMSElog: 6.6351 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  460] loss: 6.0785 RMSElog: 6.0785 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  470] loss: 6.4888 RMSElog: 6.4888 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  480] loss: 6.5820 RMSElog: 6.5820 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  490] loss: 6.3998 RMSElog: 6.3998 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  500] loss: 7.4830 RMSElog: 7.4830 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  510] loss: 6.2585 RMSElog: 6.2585 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  520] loss: 5.6838 RMSElog: 5.6838 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  530] loss: 6.0056 RMSElog: 6.0056 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  540] loss: 6.8452 RMSElog: 6.8452 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  550] loss: 6.2707 RMSElog: 6.2707 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  560] loss: 5.9982 RMSElog: 5.9982 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  570] loss: 6.4191 RMSElog: 6.4191 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  580] loss: 5.6277 RMSElog: 5.6277 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  590] loss: 6.5887 RMSElog: 6.5887 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter    0] loss: 6.3265 RMSElog: 6.3265 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   10] loss: 5.3727 RMSElog: 5.3727 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   20] loss: 6.7140 RMSElog: 6.7140 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   30] loss: 7.0225 RMSElog: 7.0225 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   40] loss: 6.5093 RMSElog: 6.5093 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   50] loss: 5.5489 RMSElog: 5.5489 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   60] loss: 5.6337 RMSElog: 5.6337 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   70] loss: 6.7773 RMSElog: 6.7773 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   80] loss: 6.3528 RMSElog: 6.3528 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   90] loss: 6.5933 RMSElog: 6.5933 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  100] loss: 5.5924 RMSElog: 5.5924 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  110] loss: 6.1618 RMSElog: 6.1618 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  120] loss: 6.1038 RMSElog: 6.1038 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  130] loss: 6.4116 RMSElog: 6.4116 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  140] loss: 6.2281 RMSElog: 6.2281 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  150] loss: 7.3784 RMSElog: 7.3784 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  160] loss: 6.1589 RMSElog: 6.1589 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  170] loss: 6.2272 RMSElog: 6.2272 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  180] loss: 6.5438 RMSElog: 6.5438 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  190] loss: 6.9129 RMSElog: 6.9129 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  200] loss: 6.0219 RMSElog: 6.0219 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  210] loss: 6.1208 RMSElog: 6.1208 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  220] loss: 5.5268 RMSElog: 5.5268 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  230] loss: 6.8500 RMSElog: 6.8500 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  240] loss: 6.4343 RMSElog: 6.4343 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  250] loss: 6.1580 RMSElog: 6.1580 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  260] loss: 4.9729 RMSElog: 4.9729 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  270] loss: 5.5221 RMSElog: 5.5221 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  280] loss: 6.1089 RMSElog: 6.1089 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  290] loss: 6.3496 RMSElog: 6.3496 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  300] loss: 6.2072 RMSElog: 6.2072 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  310] loss: 5.9135 RMSElog: 5.9135 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  320] loss: 6.1143 RMSElog: 6.1143 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  330] loss: 6.6399 RMSElog: 6.6399 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  340] loss: 6.7669 RMSElog: 6.7669 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  350] loss: 5.2983 RMSElog: 5.2983 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  360] loss: 6.2145 RMSElog: 6.2145 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  370] loss: 5.5595 RMSElog: 5.5595 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  380] loss: 6.3928 RMSElog: 6.3928 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  390] loss: 5.9468 RMSElog: 5.9468 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  400] loss: 5.9875 RMSElog: 5.9875 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  410] loss: 6.5524 RMSElog: 6.5524 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  420] loss: 6.0307 RMSElog: 6.0307 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  430] loss: 6.0528 RMSElog: 6.0528 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  440] loss: 6.6874 RMSElog: 6.6874 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  450] loss: 5.9108 RMSElog: 5.9108 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  460] loss: 5.9925 RMSElog: 5.9925 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  470] loss: 6.2941 RMSElog: 6.2941 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  480] loss: 6.6052 RMSElog: 6.6052 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  490] loss: 5.6557 RMSElog: 5.6557 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  500] loss: 5.6470 RMSElog: 5.6470 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  510] loss: 6.2821 RMSElog: 6.2821 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  520] loss: 6.2556 RMSElog: 6.2556 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  530] loss: 6.2633 RMSElog: 6.2633 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  540] loss: 6.5446 RMSElog: 6.5446 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  550] loss: 5.9140 RMSElog: 5.9140 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  560] loss: 5.4778 RMSElog: 5.4778 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  570] loss: 6.3971 RMSElog: 6.3971 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  580] loss: 5.3987 RMSElog: 5.3987 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  590] loss: 5.5230 RMSElog: 5.5230 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  4][iter    0] loss: 22912.0508 RMSElog: 6.3004 grad_loss: 22905.7500 normal_loss: 0.0000
[epoch  0][iter    0] loss: 10.8945 RMSElog: 10.8945 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   10] loss: 8.5938 RMSElog: 8.5938 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   20] loss: 9.8682 RMSElog: 9.8682 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   30] loss: 11.6927 RMSElog: 11.6927 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   40] loss: 10.5110 RMSElog: 10.5110 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   50] loss: 11.1462 RMSElog: 11.1462 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   60] loss: 12.2400 RMSElog: 12.2400 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   70] loss: 11.5270 RMSElog: 11.5270 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   80] loss: 11.4623 RMSElog: 11.4623 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter   90] loss: 11.8692 RMSElog: 11.8692 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  100] loss: 12.4822 RMSElog: 12.4822 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  110] loss: 11.1781 RMSElog: 11.1781 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  120] loss: 11.4523 RMSElog: 11.4523 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  130] loss: 11.4320 RMSElog: 11.4320 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  140] loss: 11.4097 RMSElog: 11.4097 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  150] loss: 10.6569 RMSElog: 10.6569 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  160] loss: 11.9808 RMSElog: 11.9808 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  170] loss: 10.4364 RMSElog: 10.4364 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  180] loss: 11.9397 RMSElog: 11.9397 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  190] loss: 11.1849 RMSElog: 11.1849 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  200] loss: 12.1841 RMSElog: 12.1841 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  210] loss: 12.0019 RMSElog: 12.0019 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  220] loss: 11.8406 RMSElog: 11.8406 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  230] loss: 11.1429 RMSElog: 11.1429 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  240] loss: 10.6353 RMSElog: 10.6353 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  250] loss: 11.5388 RMSElog: 11.5388 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  260] loss: 10.4402 RMSElog: 10.4402 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  270] loss: 10.2703 RMSElog: 10.2703 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  280] loss: 10.5986 RMSElog: 10.5986 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  290] loss: 10.9371 RMSElog: 10.9371 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  300] loss: 10.4918 RMSElog: 10.4918 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  310] loss: 10.5037 RMSElog: 10.5037 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  320] loss: 10.6456 RMSElog: 10.6456 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  330] loss: 11.4664 RMSElog: 11.4664 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  340] loss: 10.2728 RMSElog: 10.2728 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  350] loss: 11.1316 RMSElog: 11.1316 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  360] loss: 11.4523 RMSElog: 11.4523 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  370] loss: 8.6012 RMSElog: 8.6012 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  380] loss: 10.2078 RMSElog: 10.2078 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  390] loss: 10.6761 RMSElog: 10.6761 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  400] loss: 12.0543 RMSElog: 12.0543 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  410] loss: 10.0198 RMSElog: 10.0198 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  420] loss: 9.2610 RMSElog: 9.2610 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  430] loss: 9.4805 RMSElog: 9.4805 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  440] loss: 10.2251 RMSElog: 10.2251 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  450] loss: 10.6130 RMSElog: 10.6130 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  460] loss: 10.7829 RMSElog: 10.7829 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  470] loss: 10.7460 RMSElog: 10.7460 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  480] loss: 10.7956 RMSElog: 10.7956 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  490] loss: 8.4770 RMSElog: 8.4770 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  500] loss: 11.0857 RMSElog: 11.0857 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  510] loss: 12.0350 RMSElog: 12.0350 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  520] loss: 12.1487 RMSElog: 12.1487 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  530] loss: 10.3317 RMSElog: 10.3317 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  540] loss: 10.3647 RMSElog: 10.3647 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  550] loss: 9.4786 RMSElog: 9.4786 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  560] loss: 10.9807 RMSElog: 10.9807 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  570] loss: 11.8707 RMSElog: 11.8707 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  580] loss: 11.2274 RMSElog: 11.2274 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  0][iter  590] loss: 10.8176 RMSElog: 10.8176 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter    0] loss: 10.3674 RMSElog: 10.3674 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   10] loss: 10.5560 RMSElog: 10.5560 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   20] loss: 11.8256 RMSElog: 11.8256 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   30] loss: 11.2828 RMSElog: 11.2828 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   40] loss: 11.2756 RMSElog: 11.2756 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   50] loss: 11.9717 RMSElog: 11.9717 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   60] loss: 11.5390 RMSElog: 11.5390 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   70] loss: 12.2182 RMSElog: 12.2182 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   80] loss: 10.6883 RMSElog: 10.6883 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter   90] loss: 12.1341 RMSElog: 12.1341 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  100] loss: 10.8267 RMSElog: 10.8267 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  110] loss: 10.4621 RMSElog: 10.4621 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  120] loss: 10.8727 RMSElog: 10.8727 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  130] loss: 10.7445 RMSElog: 10.7445 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  140] loss: 9.8274 RMSElog: 9.8274 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  150] loss: 11.4335 RMSElog: 11.4335 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  160] loss: 11.8345 RMSElog: 11.8345 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  170] loss: 10.8457 RMSElog: 10.8457 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  180] loss: 9.2661 RMSElog: 9.2661 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  190] loss: 8.8381 RMSElog: 8.8381 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  200] loss: 9.6913 RMSElog: 9.6913 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  210] loss: 9.7657 RMSElog: 9.7657 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  220] loss: 9.3421 RMSElog: 9.3421 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  230] loss: 8.0432 RMSElog: 8.0432 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  240] loss: 7.5323 RMSElog: 7.5323 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  250] loss: 8.7123 RMSElog: 8.7123 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  260] loss: 9.6690 RMSElog: 9.6690 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  270] loss: 7.8090 RMSElog: 7.8090 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  280] loss: 9.2763 RMSElog: 9.2763 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  290] loss: 9.6042 RMSElog: 9.6042 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  300] loss: 8.1888 RMSElog: 8.1888 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  310] loss: 7.4159 RMSElog: 7.4159 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  320] loss: 9.8133 RMSElog: 9.8133 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  330] loss: 9.2902 RMSElog: 9.2902 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  340] loss: 7.4792 RMSElog: 7.4792 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  350] loss: 7.1718 RMSElog: 7.1718 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  360] loss: 8.7095 RMSElog: 8.7095 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  370] loss: 8.6974 RMSElog: 8.6974 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  380] loss: 8.4613 RMSElog: 8.4613 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  390] loss: 7.3268 RMSElog: 7.3268 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  400] loss: 8.7703 RMSElog: 8.7703 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  410] loss: 7.6503 RMSElog: 7.6503 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  420] loss: 7.4645 RMSElog: 7.4645 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  430] loss: 8.0858 RMSElog: 8.0858 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  440] loss: 7.5990 RMSElog: 7.5990 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  450] loss: 9.0216 RMSElog: 9.0216 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  460] loss: 7.7828 RMSElog: 7.7828 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  470] loss: 6.9514 RMSElog: 6.9514 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  480] loss: 8.0272 RMSElog: 8.0272 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  490] loss: 8.1005 RMSElog: 8.1005 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  500] loss: 8.5882 RMSElog: 8.5882 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  510] loss: 8.3838 RMSElog: 8.3838 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  520] loss: 7.8661 RMSElog: 7.8661 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  530] loss: 7.0984 RMSElog: 7.0984 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  540] loss: 6.5845 RMSElog: 6.5845 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  550] loss: 6.5944 RMSElog: 6.5944 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  560] loss: 8.3439 RMSElog: 8.3439 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  570] loss: 7.8107 RMSElog: 7.8107 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  580] loss: 7.1958 RMSElog: 7.1958 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  1][iter  590] loss: 7.4414 RMSElog: 7.4414 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter    0] loss: 6.2954 RMSElog: 6.2954 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   10] loss: 7.3011 RMSElog: 7.3011 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   20] loss: 6.2412 RMSElog: 6.2412 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   30] loss: 7.5136 RMSElog: 7.5136 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   40] loss: 7.7167 RMSElog: 7.7167 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   50] loss: 7.8523 RMSElog: 7.8523 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   60] loss: 7.1370 RMSElog: 7.1370 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   70] loss: 7.2982 RMSElog: 7.2982 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   80] loss: 6.9284 RMSElog: 6.9284 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter   90] loss: 6.6279 RMSElog: 6.6279 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  100] loss: 6.7330 RMSElog: 6.7330 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  110] loss: 6.9581 RMSElog: 6.9581 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  120] loss: 6.6583 RMSElog: 6.6583 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  130] loss: 7.5279 RMSElog: 7.5279 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  140] loss: 7.1870 RMSElog: 7.1870 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  150] loss: 6.6268 RMSElog: 6.6268 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  160] loss: 6.7344 RMSElog: 6.7344 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  170] loss: 7.4234 RMSElog: 7.4234 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  180] loss: 6.2114 RMSElog: 6.2114 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  190] loss: 6.6965 RMSElog: 6.6965 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  200] loss: 6.7441 RMSElog: 6.7441 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  210] loss: 6.8069 RMSElog: 6.8069 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  220] loss: 7.2270 RMSElog: 7.2270 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  230] loss: 6.6405 RMSElog: 6.6405 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  240] loss: 6.5222 RMSElog: 6.5222 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  250] loss: 6.8152 RMSElog: 6.8152 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  260] loss: 6.4606 RMSElog: 6.4606 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  270] loss: 6.1284 RMSElog: 6.1284 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  280] loss: 6.2099 RMSElog: 6.2099 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  290] loss: 7.3874 RMSElog: 7.3874 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  300] loss: 7.8532 RMSElog: 7.8532 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  310] loss: 6.4045 RMSElog: 6.4045 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  320] loss: 6.8380 RMSElog: 6.8380 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  330] loss: 6.3409 RMSElog: 6.3409 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  340] loss: 6.4472 RMSElog: 6.4472 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  350] loss: 6.3456 RMSElog: 6.3456 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  360] loss: 7.0185 RMSElog: 7.0185 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  370] loss: 6.4930 RMSElog: 6.4930 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  380] loss: 5.7740 RMSElog: 5.7740 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  390] loss: 6.9376 RMSElog: 6.9376 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  400] loss: 6.0605 RMSElog: 6.0605 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  410] loss: 5.7620 RMSElog: 5.7620 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  420] loss: 6.3328 RMSElog: 6.3328 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  430] loss: 6.8107 RMSElog: 6.8107 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  440] loss: 5.7541 RMSElog: 5.7541 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  450] loss: 6.7247 RMSElog: 6.7247 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  460] loss: 6.7560 RMSElog: 6.7560 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  470] loss: 6.6056 RMSElog: 6.6056 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  480] loss: 6.8267 RMSElog: 6.8267 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  490] loss: 6.6981 RMSElog: 6.6981 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  500] loss: 6.4742 RMSElog: 6.4742 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  510] loss: 5.8060 RMSElog: 5.8060 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  520] loss: 5.9327 RMSElog: 5.9327 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  530] loss: 5.5487 RMSElog: 5.5487 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  540] loss: 6.1560 RMSElog: 6.1560 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  550] loss: 6.4028 RMSElog: 6.4028 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  560] loss: 6.1640 RMSElog: 6.1640 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  570] loss: 5.9434 RMSElog: 5.9434 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  580] loss: 6.0337 RMSElog: 6.0337 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  2][iter  590] loss: 5.5369 RMSElog: 5.5369 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter    0] loss: 6.1729 RMSElog: 6.1729 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   10] loss: 6.4496 RMSElog: 6.4496 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   20] loss: 6.7847 RMSElog: 6.7847 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   30] loss: 6.6564 RMSElog: 6.6564 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   40] loss: 6.2708 RMSElog: 6.2708 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   50] loss: 6.2421 RMSElog: 6.2421 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   60] loss: 6.0610 RMSElog: 6.0610 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   70] loss: 6.4036 RMSElog: 6.4036 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   80] loss: 6.1285 RMSElog: 6.1285 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter   90] loss: 6.1769 RMSElog: 6.1769 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  100] loss: 5.9580 RMSElog: 5.9580 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  110] loss: 5.9847 RMSElog: 5.9847 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  120] loss: 7.1165 RMSElog: 7.1165 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  130] loss: 5.2882 RMSElog: 5.2882 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  140] loss: 5.3315 RMSElog: 5.3315 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  150] loss: 6.1941 RMSElog: 6.1941 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  160] loss: 5.9375 RMSElog: 5.9375 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  170] loss: 6.9324 RMSElog: 6.9324 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  180] loss: 6.4094 RMSElog: 6.4094 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  190] loss: 5.4459 RMSElog: 5.4459 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  200] loss: 6.6328 RMSElog: 6.6328 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  210] loss: 6.9397 RMSElog: 6.9397 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  220] loss: 6.9158 RMSElog: 6.9158 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  230] loss: 6.1166 RMSElog: 6.1166 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  240] loss: 6.4843 RMSElog: 6.4843 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  250] loss: 5.2311 RMSElog: 5.2311 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  260] loss: 6.0894 RMSElog: 6.0894 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  270] loss: 6.2211 RMSElog: 6.2211 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  280] loss: 5.8465 RMSElog: 5.8465 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  290] loss: 6.2024 RMSElog: 6.2024 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  300] loss: 5.5441 RMSElog: 5.5441 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  310] loss: 6.0857 RMSElog: 6.0857 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  320] loss: 6.1206 RMSElog: 6.1206 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  330] loss: 6.5826 RMSElog: 6.5826 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  340] loss: 5.6505 RMSElog: 5.6505 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  350] loss: 7.1665 RMSElog: 7.1665 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  360] loss: 5.9202 RMSElog: 5.9202 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  370] loss: 6.5746 RMSElog: 6.5746 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  380] loss: 5.5413 RMSElog: 5.5413 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  390] loss: 6.3895 RMSElog: 6.3895 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  400] loss: 6.6537 RMSElog: 6.6537 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  410] loss: 6.3610 RMSElog: 6.3610 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  420] loss: 5.8067 RMSElog: 5.8067 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  430] loss: 5.8556 RMSElog: 5.8556 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  440] loss: 5.0541 RMSElog: 5.0541 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  450] loss: 5.6311 RMSElog: 5.6311 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  460] loss: 5.7770 RMSElog: 5.7770 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  470] loss: 5.9588 RMSElog: 5.9588 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  480] loss: 5.4749 RMSElog: 5.4749 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  490] loss: 5.6685 RMSElog: 5.6685 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  500] loss: 5.4812 RMSElog: 5.4812 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  510] loss: 5.9043 RMSElog: 5.9043 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  520] loss: 6.1922 RMSElog: 6.1922 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  530] loss: 5.6475 RMSElog: 5.6475 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  540] loss: 6.7071 RMSElog: 6.7071 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  550] loss: 5.7466 RMSElog: 5.7466 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  560] loss: 5.7849 RMSElog: 5.7849 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  570] loss: 6.9475 RMSElog: 6.9475 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  580] loss: 6.7762 RMSElog: 6.7762 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  3][iter  590] loss: 5.8207 RMSElog: 5.8207 grad_loss: 0.0000 normal_loss: 0.0000
[epoch  4][iter    0] loss: 24342.2910 RMSElog: 5.4837 grad_loss: 24336.8066 normal_loss: 0.0000
[epoch  4][iter   10] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   20] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   30] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   40] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   50] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   60] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   70] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   80] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter   90] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  100] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  110] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  120] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  130] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  140] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  150] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  160] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  170] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  180] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  190] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  200] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  210] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  4][iter  220] loss: nan RMSElog: nan grad_loss: nan normal_loss: nan
[epoch  0][iter    0] loss: 11.1957 RMSElog: 11.1957 grad_loss: 0.0000
[epoch  0][iter   10] loss: 11.0371 RMSElog: 11.0371 grad_loss: 0.0000
[epoch  0][iter   20] loss: 10.8905 RMSElog: 10.8905 grad_loss: 0.0000
[epoch  0][iter   30] loss: 12.4209 RMSElog: 12.4209 grad_loss: 0.0000
[epoch  0][iter   40] loss: 11.2556 RMSElog: 11.2556 grad_loss: 0.0000
[epoch  0][iter   50] loss: 11.3813 RMSElog: 11.3813 grad_loss: 0.0000
[epoch  0][iter   60] loss: 11.9251 RMSElog: 11.9251 grad_loss: 0.0000
[epoch  0][iter   70] loss: 11.4563 RMSElog: 11.4563 grad_loss: 0.0000
[epoch  0][iter   80] loss: 10.5322 RMSElog: 10.5322 grad_loss: 0.0000
[epoch  0][iter   90] loss: 10.6142 RMSElog: 10.6142 grad_loss: 0.0000
[epoch  0][iter  100] loss: 11.9000 RMSElog: 11.9000 grad_loss: 0.0000
[epoch  0][iter  110] loss: 11.9872 RMSElog: 11.9872 grad_loss: 0.0000
[epoch  0][iter  120] loss: 10.9485 RMSElog: 10.9485 grad_loss: 0.0000
[epoch  0][iter  130] loss: 10.5197 RMSElog: 10.5197 grad_loss: 0.0000
[epoch  0][iter  140] loss: 10.5851 RMSElog: 10.5851 grad_loss: 0.0000
[epoch  0][iter  150] loss: 10.7791 RMSElog: 10.7791 grad_loss: 0.0000
[epoch  0][iter  160] loss: 9.4633 RMSElog: 9.4633 grad_loss: 0.0000
[epoch  0][iter  170] loss: 10.4955 RMSElog: 10.4955 grad_loss: 0.0000
[epoch  0][iter  180] loss: 11.3003 RMSElog: 11.3003 grad_loss: 0.0000
[epoch  0][iter  190] loss: 10.6097 RMSElog: 10.6097 grad_loss: 0.0000
[epoch  0][iter  200] loss: 10.5966 RMSElog: 10.5966 grad_loss: 0.0000
[epoch  0][iter  210] loss: 9.8846 RMSElog: 9.8846 grad_loss: 0.0000
[epoch  0][iter  220] loss: 11.3983 RMSElog: 11.3983 grad_loss: 0.0000
[epoch  0][iter  230] loss: 11.0081 RMSElog: 11.0081 grad_loss: 0.0000
[epoch  0][iter  240] loss: 11.5356 RMSElog: 11.5356 grad_loss: 0.0000
[epoch  0][iter  250] loss: 10.9653 RMSElog: 10.9653 grad_loss: 0.0000
[epoch  0][iter  260] loss: 11.0360 RMSElog: 11.0360 grad_loss: 0.0000
[epoch  0][iter  270] loss: 11.8445 RMSElog: 11.8445 grad_loss: 0.0000
[epoch  0][iter  280] loss: 10.3288 RMSElog: 10.3288 grad_loss: 0.0000
[epoch  0][iter  290] loss: 11.0434 RMSElog: 11.0434 grad_loss: 0.0000
[epoch  0][iter  300] loss: 9.2131 RMSElog: 9.2131 grad_loss: 0.0000
[epoch  0][iter  310] loss: 10.5473 RMSElog: 10.5473 grad_loss: 0.0000
[epoch  0][iter  320] loss: 11.8383 RMSElog: 11.8383 grad_loss: 0.0000
[epoch  0][iter  330] loss: 10.2424 RMSElog: 10.2424 grad_loss: 0.0000
[epoch  0][iter  340] loss: 11.1079 RMSElog: 11.1079 grad_loss: 0.0000
[epoch  0][iter  350] loss: 11.8980 RMSElog: 11.8980 grad_loss: 0.0000
[epoch  0][iter  360] loss: 10.7410 RMSElog: 10.7410 grad_loss: 0.0000
[epoch  0][iter  370] loss: 10.9432 RMSElog: 10.9432 grad_loss: 0.0000
[epoch  0][iter  380] loss: 10.9241 RMSElog: 10.9241 grad_loss: 0.0000
[epoch  0][iter  390] loss: 11.1447 RMSElog: 11.1447 grad_loss: 0.0000
[epoch  0][iter  400] loss: 11.0384 RMSElog: 11.0384 grad_loss: 0.0000
[epoch  0][iter  410] loss: 10.8530 RMSElog: 10.8530 grad_loss: 0.0000
[epoch  0][iter  420] loss: 11.4025 RMSElog: 11.4025 grad_loss: 0.0000
[epoch  0][iter  430] loss: 11.4247 RMSElog: 11.4247 grad_loss: 0.0000
[epoch  0][iter  440] loss: 12.2477 RMSElog: 12.2477 grad_loss: 0.0000
[epoch  0][iter  450] loss: 11.6331 RMSElog: 11.6331 grad_loss: 0.0000
[epoch  0][iter  460] loss: 10.3697 RMSElog: 10.3697 grad_loss: 0.0000
[epoch  0][iter  470] loss: 11.0633 RMSElog: 11.0633 grad_loss: 0.0000
[epoch  0][iter  480] loss: 10.9488 RMSElog: 10.9488 grad_loss: 0.0000
[epoch  0][iter  490] loss: 10.3827 RMSElog: 10.3827 grad_loss: 0.0000
[epoch  0][iter  500] loss: 11.3430 RMSElog: 11.3430 grad_loss: 0.0000
[epoch  0][iter  510] loss: 11.5257 RMSElog: 11.5257 grad_loss: 0.0000
[epoch  0][iter  520] loss: 10.8239 RMSElog: 10.8239 grad_loss: 0.0000
[epoch  0][iter  530] loss: 11.4405 RMSElog: 11.4405 grad_loss: 0.0000
[epoch  0][iter  540] loss: 10.8456 RMSElog: 10.8456 grad_loss: 0.0000
[epoch  0][iter  550] loss: 11.4529 RMSElog: 11.4529 grad_loss: 0.0000
[epoch  0][iter  560] loss: 10.6735 RMSElog: 10.6735 grad_loss: 0.0000
[epoch  0][iter  570] loss: 8.7023 RMSElog: 8.7023 grad_loss: 0.0000
[epoch  0][iter  580] loss: 11.5330 RMSElog: 11.5330 grad_loss: 0.0000
[epoch  0][iter  590] loss: 10.7656 RMSElog: 10.7656 grad_loss: 0.0000
[epoch  1][iter    0] loss: 10.7312 RMSElog: 10.7312 grad_loss: 0.0000
[epoch  1][iter   10] loss: 11.1506 RMSElog: 11.1506 grad_loss: 0.0000
[epoch  1][iter   20] loss: 11.3814 RMSElog: 11.3814 grad_loss: 0.0000
[epoch  1][iter   30] loss: 11.2925 RMSElog: 11.2925 grad_loss: 0.0000
[epoch  1][iter   40] loss: 11.1614 RMSElog: 11.1614 grad_loss: 0.0000
[epoch  1][iter   50] loss: 10.7266 RMSElog: 10.7266 grad_loss: 0.0000
[epoch  1][iter   60] loss: 10.6465 RMSElog: 10.6465 grad_loss: 0.0000
[epoch  1][iter   70] loss: 10.2000 RMSElog: 10.2000 grad_loss: 0.0000
[epoch  1][iter   80] loss: 11.1271 RMSElog: 11.1271 grad_loss: 0.0000
[epoch  1][iter   90] loss: 12.2858 RMSElog: 12.2858 grad_loss: 0.0000
[epoch  1][iter  100] loss: 11.1179 RMSElog: 11.1179 grad_loss: 0.0000
[epoch  1][iter  110] loss: 10.7478 RMSElog: 10.7478 grad_loss: 0.0000
[epoch  1][iter  120] loss: 11.0121 RMSElog: 11.0121 grad_loss: 0.0000
[epoch  1][iter  130] loss: 11.2253 RMSElog: 11.2253 grad_loss: 0.0000
[epoch  1][iter  140] loss: 11.6853 RMSElog: 11.6853 grad_loss: 0.0000
[epoch  1][iter  150] loss: 10.9351 RMSElog: 10.9351 grad_loss: 0.0000
[epoch  1][iter  160] loss: 10.8475 RMSElog: 10.8475 grad_loss: 0.0000
[epoch  1][iter  170] loss: 10.1686 RMSElog: 10.1686 grad_loss: 0.0000
[epoch  1][iter  180] loss: 11.8709 RMSElog: 11.8709 grad_loss: 0.0000
[epoch  1][iter  190] loss: 10.4453 RMSElog: 10.4453 grad_loss: 0.0000
[epoch  1][iter  200] loss: 9.2943 RMSElog: 9.2943 grad_loss: 0.0000
[epoch  1][iter  210] loss: 8.6911 RMSElog: 8.6911 grad_loss: 0.0000
[epoch  1][iter  220] loss: 9.9490 RMSElog: 9.9490 grad_loss: 0.0000
[epoch  1][iter  230] loss: 9.8961 RMSElog: 9.8961 grad_loss: 0.0000
[epoch  1][iter  240] loss: 8.7479 RMSElog: 8.7479 grad_loss: 0.0000
[epoch  1][iter  250] loss: 8.4516 RMSElog: 8.4516 grad_loss: 0.0000
[epoch  1][iter  260] loss: 8.8870 RMSElog: 8.8870 grad_loss: 0.0000
[epoch  1][iter  270] loss: 9.0482 RMSElog: 9.0482 grad_loss: 0.0000
[epoch  1][iter  280] loss: 8.5194 RMSElog: 8.5194 grad_loss: 0.0000
[epoch  1][iter  290] loss: 9.4215 RMSElog: 9.4215 grad_loss: 0.0000
[epoch  1][iter  300] loss: 8.6342 RMSElog: 8.6342 grad_loss: 0.0000
[epoch  1][iter  310] loss: 8.1311 RMSElog: 8.1311 grad_loss: 0.0000
[epoch  1][iter  320] loss: 9.0471 RMSElog: 9.0471 grad_loss: 0.0000
[epoch  1][iter  330] loss: 8.5471 RMSElog: 8.5471 grad_loss: 0.0000
[epoch  1][iter  340] loss: 8.1881 RMSElog: 8.1881 grad_loss: 0.0000
[epoch  1][iter  350] loss: 8.1046 RMSElog: 8.1046 grad_loss: 0.0000
[epoch  1][iter  360] loss: 8.0251 RMSElog: 8.0251 grad_loss: 0.0000
[epoch  1][iter  370] loss: 8.4367 RMSElog: 8.4367 grad_loss: 0.0000
[epoch  1][iter  380] loss: 8.4275 RMSElog: 8.4275 grad_loss: 0.0000
[epoch  1][iter  390] loss: 9.2016 RMSElog: 9.2016 grad_loss: 0.0000
[epoch  1][iter  400] loss: 9.2577 RMSElog: 9.2577 grad_loss: 0.0000
[epoch  1][iter  410] loss: 7.1403 RMSElog: 7.1403 grad_loss: 0.0000
[epoch  1][iter  420] loss: 7.7147 RMSElog: 7.7147 grad_loss: 0.0000
[epoch  1][iter  430] loss: 7.3673 RMSElog: 7.3673 grad_loss: 0.0000
[epoch  1][iter  440] loss: 9.5207 RMSElog: 9.5207 grad_loss: 0.0000
[epoch  1][iter  450] loss: 7.8472 RMSElog: 7.8472 grad_loss: 0.0000
[epoch  1][iter  460] loss: 7.9394 RMSElog: 7.9394 grad_loss: 0.0000
[epoch  1][iter  470] loss: 8.7663 RMSElog: 8.7663 grad_loss: 0.0000
[epoch  1][iter  480] loss: 7.9221 RMSElog: 7.9221 grad_loss: 0.0000
[epoch  1][iter  490] loss: 8.3553 RMSElog: 8.3553 grad_loss: 0.0000
[epoch  1][iter  500] loss: 9.3547 RMSElog: 9.3547 grad_loss: 0.0000
[epoch  1][iter  510] loss: 8.2233 RMSElog: 8.2233 grad_loss: 0.0000
[epoch  1][iter  520] loss: 7.5266 RMSElog: 7.5266 grad_loss: 0.0000
[epoch  1][iter  530] loss: 9.2234 RMSElog: 9.2234 grad_loss: 0.0000
[epoch  1][iter  540] loss: 8.9572 RMSElog: 8.9572 grad_loss: 0.0000
[epoch  1][iter  550] loss: 8.6142 RMSElog: 8.6142 grad_loss: 0.0000
[epoch  1][iter  560] loss: 8.5031 RMSElog: 8.5031 grad_loss: 0.0000
[epoch  1][iter  570] loss: 8.0167 RMSElog: 8.0167 grad_loss: 0.0000
[epoch  1][iter  580] loss: 7.6326 RMSElog: 7.6326 grad_loss: 0.0000
[epoch  1][iter  590] loss: 8.8663 RMSElog: 8.8663 grad_loss: 0.0000
[epoch  2][iter    0] loss: 7.2041 RMSElog: 7.2041 grad_loss: 0.0000
[epoch  2][iter   10] loss: 8.2070 RMSElog: 8.2070 grad_loss: 0.0000
[epoch  2][iter   20] loss: 6.5232 RMSElog: 6.5232 grad_loss: 0.0000
[epoch  2][iter   30] loss: 7.4434 RMSElog: 7.4434 grad_loss: 0.0000
[epoch  2][iter   40] loss: 6.9749 RMSElog: 6.9749 grad_loss: 0.0000
[epoch  2][iter   50] loss: 8.0983 RMSElog: 8.0983 grad_loss: 0.0000
[epoch  2][iter   60] loss: 8.9548 RMSElog: 8.9548 grad_loss: 0.0000
[epoch  2][iter   70] loss: 8.9119 RMSElog: 8.9119 grad_loss: 0.0000
[epoch  2][iter   80] loss: 7.4293 RMSElog: 7.4293 grad_loss: 0.0000
[epoch  2][iter   90] loss: 7.7088 RMSElog: 7.7088 grad_loss: 0.0000
[epoch  2][iter  100] loss: 7.8179 RMSElog: 7.8179 grad_loss: 0.0000
[epoch  2][iter  110] loss: 7.5412 RMSElog: 7.5412 grad_loss: 0.0000
[epoch  2][iter  120] loss: 7.3627 RMSElog: 7.3627 grad_loss: 0.0000
[epoch  2][iter  130] loss: 7.9206 RMSElog: 7.9206 grad_loss: 0.0000
[epoch  2][iter  140] loss: 6.9797 RMSElog: 6.9797 grad_loss: 0.0000
[epoch  2][iter  150] loss: 7.1065 RMSElog: 7.1065 grad_loss: 0.0000
[epoch  2][iter  160] loss: 6.9950 RMSElog: 6.9950 grad_loss: 0.0000
[epoch  2][iter  170] loss: 7.2046 RMSElog: 7.2046 grad_loss: 0.0000
[epoch  2][iter  180] loss: 8.1838 RMSElog: 8.1838 grad_loss: 0.0000
[epoch  2][iter  190] loss: 7.6237 RMSElog: 7.6237 grad_loss: 0.0000
[epoch  2][iter  200] loss: 7.7291 RMSElog: 7.7291 grad_loss: 0.0000
[epoch  2][iter  210] loss: 7.8443 RMSElog: 7.8443 grad_loss: 0.0000
[epoch  2][iter  220] loss: 7.5290 RMSElog: 7.5290 grad_loss: 0.0000
[epoch  2][iter  230] loss: 7.6695 RMSElog: 7.6695 grad_loss: 0.0000
[epoch  2][iter  240] loss: 6.9827 RMSElog: 6.9827 grad_loss: 0.0000
[epoch  2][iter  250] loss: 6.5625 RMSElog: 6.5625 grad_loss: 0.0000
[epoch  2][iter  260] loss: 6.7871 RMSElog: 6.7871 grad_loss: 0.0000
[epoch  2][iter  270] loss: 7.4883 RMSElog: 7.4883 grad_loss: 0.0000
[epoch  2][iter  280] loss: 8.0506 RMSElog: 8.0506 grad_loss: 0.0000
[epoch  2][iter  290] loss: 6.8131 RMSElog: 6.8131 grad_loss: 0.0000
[epoch  2][iter  300] loss: 6.2535 RMSElog: 6.2535 grad_loss: 0.0000
[epoch  2][iter  310] loss: 7.2884 RMSElog: 7.2884 grad_loss: 0.0000
[epoch  2][iter  320] loss: 7.2519 RMSElog: 7.2519 grad_loss: 0.0000
[epoch  2][iter  330] loss: 6.6292 RMSElog: 6.6292 grad_loss: 0.0000
[epoch  2][iter  340] loss: 6.6527 RMSElog: 6.6527 grad_loss: 0.0000
[epoch  2][iter  350] loss: 6.0648 RMSElog: 6.0648 grad_loss: 0.0000
[epoch  2][iter  360] loss: 6.3167 RMSElog: 6.3167 grad_loss: 0.0000
[epoch  2][iter  370] loss: 6.6469 RMSElog: 6.6469 grad_loss: 0.0000
[epoch  2][iter  380] loss: 7.0449 RMSElog: 7.0449 grad_loss: 0.0000
[epoch  2][iter  390] loss: 6.4196 RMSElog: 6.4196 grad_loss: 0.0000
[epoch  2][iter  400] loss: 6.6718 RMSElog: 6.6718 grad_loss: 0.0000
[epoch  2][iter  410] loss: 6.3947 RMSElog: 6.3947 grad_loss: 0.0000
[epoch  2][iter  420] loss: 6.6503 RMSElog: 6.6503 grad_loss: 0.0000
[epoch  2][iter  430] loss: 7.1229 RMSElog: 7.1229 grad_loss: 0.0000
[epoch  2][iter  440] loss: 6.6510 RMSElog: 6.6510 grad_loss: 0.0000
[epoch  2][iter  450] loss: 6.3558 RMSElog: 6.3558 grad_loss: 0.0000
[epoch  2][iter  460] loss: 6.3470 RMSElog: 6.3470 grad_loss: 0.0000
[epoch  2][iter  470] loss: 6.3677 RMSElog: 6.3677 grad_loss: 0.0000
[epoch  2][iter  480] loss: 6.3327 RMSElog: 6.3327 grad_loss: 0.0000
[epoch  2][iter  490] loss: 6.6754 RMSElog: 6.6754 grad_loss: 0.0000
[epoch  2][iter  500] loss: 6.5835 RMSElog: 6.5835 grad_loss: 0.0000
[epoch  2][iter  510] loss: 6.0541 RMSElog: 6.0541 grad_loss: 0.0000
[epoch  2][iter  520] loss: 6.1233 RMSElog: 6.1233 grad_loss: 0.0000
[epoch  2][iter  530] loss: 6.1982 RMSElog: 6.1982 grad_loss: 0.0000
[epoch  2][iter  540] loss: 7.1160 RMSElog: 7.1160 grad_loss: 0.0000
[epoch  2][iter  550] loss: 6.7408 RMSElog: 6.7408 grad_loss: 0.0000
[epoch  2][iter  560] loss: 6.4613 RMSElog: 6.4613 grad_loss: 0.0000
[epoch  2][iter  570] loss: 6.6071 RMSElog: 6.6071 grad_loss: 0.0000
[epoch  2][iter  580] loss: 6.9930 RMSElog: 6.9930 grad_loss: 0.0000
[epoch  2][iter  590] loss: 6.3655 RMSElog: 6.3655 grad_loss: 0.0000
[epoch  3][iter    0] loss: 6.9059 RMSElog: 6.9059 grad_loss: 0.0000
[epoch  3][iter   10] loss: 6.4629 RMSElog: 6.4629 grad_loss: 0.0000
[epoch  3][iter   20] loss: 6.4605 RMSElog: 6.4605 grad_loss: 0.0000
[epoch  3][iter   30] loss: 6.2923 RMSElog: 6.2923 grad_loss: 0.0000
[epoch  3][iter   40] loss: 6.0951 RMSElog: 6.0951 grad_loss: 0.0000
[epoch  3][iter   50] loss: 5.4646 RMSElog: 5.4646 grad_loss: 0.0000
[epoch  3][iter   60] loss: 5.9659 RMSElog: 5.9659 grad_loss: 0.0000
[epoch  3][iter   70] loss: 5.6446 RMSElog: 5.6446 grad_loss: 0.0000
[epoch  3][iter   80] loss: 5.8932 RMSElog: 5.8932 grad_loss: 0.0000
[epoch  3][iter   90] loss: 6.2066 RMSElog: 6.2066 grad_loss: 0.0000
[epoch  3][iter  100] loss: 6.7059 RMSElog: 6.7059 grad_loss: 0.0000
[epoch  3][iter  110] loss: 5.7159 RMSElog: 5.7159 grad_loss: 0.0000
[epoch  3][iter  120] loss: 6.4529 RMSElog: 6.4529 grad_loss: 0.0000
[epoch  3][iter  130] loss: 6.0240 RMSElog: 6.0240 grad_loss: 0.0000
[epoch  3][iter  140] loss: 6.8298 RMSElog: 6.8298 grad_loss: 0.0000
[epoch  3][iter  150] loss: 5.6596 RMSElog: 5.6596 grad_loss: 0.0000
[epoch  3][iter  160] loss: 6.0827 RMSElog: 6.0827 grad_loss: 0.0000
[epoch  3][iter  170] loss: 5.4941 RMSElog: 5.4941 grad_loss: 0.0000
[epoch  3][iter  180] loss: 6.1004 RMSElog: 6.1004 grad_loss: 0.0000
[epoch  3][iter  190] loss: 5.2310 RMSElog: 5.2310 grad_loss: 0.0000
[epoch  3][iter  200] loss: 5.9761 RMSElog: 5.9761 grad_loss: 0.0000
[epoch  3][iter  210] loss: 6.3452 RMSElog: 6.3452 grad_loss: 0.0000
[epoch  3][iter  220] loss: 5.9012 RMSElog: 5.9012 grad_loss: 0.0000
[epoch  3][iter  230] loss: 6.7351 RMSElog: 6.7351 grad_loss: 0.0000
[epoch  3][iter  240] loss: 6.1750 RMSElog: 6.1750 grad_loss: 0.0000
[epoch  3][iter  250] loss: 6.7887 RMSElog: 6.7887 grad_loss: 0.0000
[epoch  3][iter  260] loss: 6.1810 RMSElog: 6.1810 grad_loss: 0.0000
[epoch  3][iter  270] loss: 6.6383 RMSElog: 6.6383 grad_loss: 0.0000
[epoch  3][iter  280] loss: 7.2613 RMSElog: 7.2613 grad_loss: 0.0000
[epoch  3][iter  290] loss: 6.5420 RMSElog: 6.5420 grad_loss: 0.0000
[epoch  3][iter  300] loss: 6.1767 RMSElog: 6.1767 grad_loss: 0.0000
[epoch  3][iter  310] loss: 6.4741 RMSElog: 6.4741 grad_loss: 0.0000
[epoch  3][iter  320] loss: 5.9629 RMSElog: 5.9629 grad_loss: 0.0000
[epoch  3][iter  330] loss: 5.8882 RMSElog: 5.8882 grad_loss: 0.0000
[epoch  3][iter  340] loss: 5.7543 RMSElog: 5.7543 grad_loss: 0.0000
[epoch  3][iter  350] loss: 5.8656 RMSElog: 5.8656 grad_loss: 0.0000
[epoch  3][iter  360] loss: 5.9839 RMSElog: 5.9839 grad_loss: 0.0000
[epoch  3][iter  370] loss: 6.2519 RMSElog: 6.2519 grad_loss: 0.0000
[epoch  3][iter  380] loss: 6.2733 RMSElog: 6.2733 grad_loss: 0.0000
[epoch  3][iter  390] loss: 5.6556 RMSElog: 5.6556 grad_loss: 0.0000
[epoch  3][iter  400] loss: 5.6277 RMSElog: 5.6277 grad_loss: 0.0000
[epoch  3][iter  410] loss: 5.5856 RMSElog: 5.5856 grad_loss: 0.0000
[epoch  3][iter  420] loss: 5.8393 RMSElog: 5.8393 grad_loss: 0.0000
[epoch  3][iter  430] loss: 5.8889 RMSElog: 5.8889 grad_loss: 0.0000
[epoch  3][iter  440] loss: 6.0663 RMSElog: 6.0663 grad_loss: 0.0000
[epoch  3][iter  450] loss: 5.1728 RMSElog: 5.1728 grad_loss: 0.0000
[epoch  3][iter  460] loss: 6.7854 RMSElog: 6.7854 grad_loss: 0.0000
[epoch  3][iter  470] loss: 5.2157 RMSElog: 5.2157 grad_loss: 0.0000
[epoch  3][iter  480] loss: 5.6241 RMSElog: 5.6241 grad_loss: 0.0000
[epoch  3][iter  490] loss: 6.1298 RMSElog: 6.1298 grad_loss: 0.0000
[epoch  3][iter  500] loss: 6.3022 RMSElog: 6.3022 grad_loss: 0.0000
[epoch  3][iter  510] loss: 5.3058 RMSElog: 5.3058 grad_loss: 0.0000
[epoch  3][iter  520] loss: 6.6846 RMSElog: 6.6846 grad_loss: 0.0000
[epoch  3][iter  530] loss: 5.1986 RMSElog: 5.1986 grad_loss: 0.0000
[epoch  3][iter  540] loss: 6.2031 RMSElog: 6.2031 grad_loss: 0.0000
[epoch  3][iter  550] loss: 6.2135 RMSElog: 6.2135 grad_loss: 0.0000
[epoch  3][iter  560] loss: 6.0751 RMSElog: 6.0751 grad_loss: 0.0000
[epoch  3][iter  570] loss: 5.8289 RMSElog: 5.8289 grad_loss: 0.0000
[epoch  3][iter  580] loss: 6.3170 RMSElog: 6.3170 grad_loss: 0.0000
[epoch  3][iter  590] loss: 5.9236 RMSElog: 5.9236 grad_loss: 0.0000
[epoch  4][iter    0] loss: 25578.6289 RMSElog: 6.3605 grad_loss: 25572.2676
[epoch  4][iter   10] loss: 15698.1230 RMSElog: 21.9671 grad_loss: 15676.1562
[epoch  4][iter   20] loss: 16254.8906 RMSElog: 22.3943 grad_loss: 16232.4961
[epoch  4][iter   30] loss: 19552.2500 RMSElog: 22.0339 grad_loss: 19530.2168
[epoch  4][iter   40] loss: 10705.9990 RMSElog: 21.7233 grad_loss: 10684.2754
[epoch  4][iter   50] loss: 13026.0264 RMSElog: 22.1734 grad_loss: 13003.8525
[epoch  4][iter   60] loss: 16384.5215 RMSElog: 22.5049 grad_loss: 16362.0166
[epoch  4][iter   70] loss: 19654.1309 RMSElog: 21.6239 grad_loss: 19632.5078
[epoch  4][iter   80] loss: 16336.5967 RMSElog: 22.1805 grad_loss: 16314.4160
[epoch  4][iter   90] loss: 14914.9971 RMSElog: 22.1891 grad_loss: 14892.8076
[epoch  4][iter  100] loss: 18076.7949 RMSElog: 21.7684 grad_loss: 18055.0273
[epoch  4][iter  110] loss: 16471.0078 RMSElog: 22.1925 grad_loss: 16448.8145
[epoch  4][iter  120] loss: 17565.6152 RMSElog: 21.9615 grad_loss: 17543.6543
[epoch  4][iter  130] loss: 13458.3604 RMSElog: 22.0835 grad_loss: 13436.2773
[epoch  4][iter  140] loss: 14543.8340 RMSElog: 22.4611 grad_loss: 14521.3730
[epoch  4][iter  150] loss: 16731.9941 RMSElog: 21.9069 grad_loss: 16710.0879
[epoch  4][iter  160] loss: 13474.6904 RMSElog: 22.3032 grad_loss: 13452.3867
[epoch  4][iter  170] loss: 12708.7344 RMSElog: 22.4809 grad_loss: 12686.2539
[epoch  4][iter  180] loss: 10955.3848 RMSElog: 21.9632 grad_loss: 10933.4219
[epoch  4][iter  190] loss: 14787.4365 RMSElog: 21.8862 grad_loss: 14765.5508
[epoch  4][iter  200] loss: 11182.4375 RMSElog: 21.9090 grad_loss: 11160.5283
[epoch  4][iter  210] loss: 16089.8467 RMSElog: 22.3412 grad_loss: 16067.5059
[epoch  4][iter  220] loss: 11561.1162 RMSElog: 22.2163 grad_loss: 11538.9004
[epoch  4][iter  230] loss: 13558.0010 RMSElog: 22.2498 grad_loss: 13535.7510
[epoch  4][iter  240] loss: 20366.7676 RMSElog: 21.6885 grad_loss: 20345.0781
[epoch  4][iter  250] loss: 15723.3916 RMSElog: 22.3165 grad_loss: 15701.0752
[epoch  4][iter  260] loss: 16757.3555 RMSElog: 22.4607 grad_loss: 16734.8945
[epoch  4][iter  270] loss: 11071.4268 RMSElog: 21.9285 grad_loss: 11049.4980
[epoch  4][iter  280] loss: 17716.9492 RMSElog: 21.8011 grad_loss: 17695.1484
[epoch  4][iter  290] loss: 10110.3613 RMSElog: 22.0540 grad_loss: 10088.3076
[epoch  4][iter  300] loss: 14813.9316 RMSElog: 22.4322 grad_loss: 14791.4990
[epoch  4][iter  310] loss: 18882.4941 RMSElog: 21.8079 grad_loss: 18860.6855
[epoch  4][iter  320] loss: 10593.4023 RMSElog: 21.5971 grad_loss: 10571.8057
[epoch  4][iter  330] loss: 13340.1289 RMSElog: 22.3168 grad_loss: 13317.8125
[epoch  4][iter  340] loss: 16513.6621 RMSElog: 22.4288 grad_loss: 16491.2324
[epoch  4][iter  350] loss: 13358.1504 RMSElog: 22.3307 grad_loss: 13335.8193
[epoch  4][iter  360] loss: 22815.8379 RMSElog: 21.7656 grad_loss: 22794.0723
[epoch  4][iter  370] loss: 16543.9004 RMSElog: 22.1643 grad_loss: 16521.7363
[epoch  4][iter  380] loss: 19510.0527 RMSElog: 22.2054 grad_loss: 19487.8477
[epoch  4][iter  390] loss: 12692.8389 RMSElog: 21.8668 grad_loss: 12670.9717
[epoch  4][iter  400] loss: 18874.9258 RMSElog: 21.6270 grad_loss: 18853.2988
[epoch  4][iter  410] loss: 10220.8213 RMSElog: 21.9959 grad_loss: 10198.8252
[epoch  4][iter  420] loss: 13522.5098 RMSElog: 21.9733 grad_loss: 13500.5361
[epoch  4][iter  430] loss: 12774.1328 RMSElog: 21.8663 grad_loss: 12752.2666
[epoch  4][iter  440] loss: 10076.2764 RMSElog: 21.9740 grad_loss: 10054.3027
[epoch  4][iter  450] loss: 20414.3086 RMSElog: 21.7094 grad_loss: 20392.5996
[epoch  4][iter  460] loss: 12793.6846 RMSElog: 21.8961 grad_loss: 12771.7881
[epoch  4][iter  470] loss: 13691.3535 RMSElog: 22.4035 grad_loss: 13668.9502
[epoch  4][iter  480] loss: 12788.3779 RMSElog: 21.8046 grad_loss: 12766.5732
[epoch  4][iter  490] loss: 20802.1914 RMSElog: 21.5040 grad_loss: 20780.6875
[epoch  4][iter  500] loss: 20136.9844 RMSElog: 21.6372 grad_loss: 20115.3477
[epoch  4][iter  510] loss: 11781.0146 RMSElog: 22.2659 grad_loss: 11758.7490
[epoch  4][iter  520] loss: 14765.7324 RMSElog: 22.2036 grad_loss: 14743.5293
[epoch  4][iter  530] loss: 19917.9766 RMSElog: 22.0089 grad_loss: 19895.9668
[epoch  4][iter  540] loss: 18525.7852 RMSElog: 22.5035 grad_loss: 18503.2812
[epoch  4][iter  550] loss: 19451.0391 RMSElog: 21.4770 grad_loss: 19429.5625
[epoch  4][iter  560] loss: 20533.7461 RMSElog: 21.4964 grad_loss: 20512.2500
[epoch  4][iter  570] loss: 14016.8301 RMSElog: 22.1016 grad_loss: 13994.7285
[epoch  4][iter  580] loss: 16104.8672 RMSElog: 22.2520 grad_loss: 16082.6152
[epoch  4][iter  590] loss: 11618.8252 RMSElog: 22.1655 grad_loss: 11596.6602
[epoch  5][iter    0] loss: 13026.0254 RMSElog: 22.1734 grad_loss: 13003.8516
[epoch  5][iter   10] loss: 21864.7383 RMSElog: 21.5041 grad_loss: 21843.2344
[epoch  5][iter   20] loss: 18140.1094 RMSElog: 21.8160 grad_loss: 18118.2930
[epoch  5][iter   30] loss: 18964.8262 RMSElog: 21.6466 grad_loss: 18943.1797
[epoch  5][iter   40] loss: 15723.3926 RMSElog: 22.3165 grad_loss: 15701.0762
[epoch  5][iter   50] loss: 10629.4453 RMSElog: 21.9627 grad_loss: 10607.4824
[epoch  5][iter   60] loss: 21459.3047 RMSElog: 21.3704 grad_loss: 21437.9336
[epoch  5][iter   70] loss: 13478.9395 RMSElog: 22.0585 grad_loss: 13456.8809
[epoch  5][iter   80] loss: 19839.6543 RMSElog: 21.4992 grad_loss: 19818.1543
[epoch  5][iter   90] loss: 18615.9023 RMSElog: 21.7485 grad_loss: 18594.1543
[epoch  5][iter  100] loss: 12002.1279 RMSElog: 22.8689 grad_loss: 11979.2588
[epoch  5][iter  110] loss: 16099.7061 RMSElog: 22.4832 grad_loss: 16077.2227
[epoch  5][iter  120] loss: 21801.6484 RMSElog: 21.4933 grad_loss: 21780.1543
[epoch  5][iter  130] loss: 7240.6953 RMSElog: 22.2166 grad_loss: 7218.4785
[epoch  5][iter  140] loss: 18560.8379 RMSElog: 22.2386 grad_loss: 18538.5996
[epoch  5][iter  150] loss: 16665.5879 RMSElog: 22.2613 grad_loss: 16643.3262
[epoch  5][iter  160] loss: 21794.6582 RMSElog: 21.5453 grad_loss: 21773.1133
[epoch  5][iter  170] loss: 11503.9414 RMSElog: 22.1337 grad_loss: 11481.8076
[epoch  5][iter  180] loss: 11781.0146 RMSElog: 22.2659 grad_loss: 11758.7490
[epoch  5][iter  190] loss: 16263.4551 RMSElog: 22.2032 grad_loss: 16241.2520
[epoch  5][iter  200] loss: 10364.6689 RMSElog: 21.9487 grad_loss: 10342.7207
[epoch  5][iter  210] loss: 13282.0986 RMSElog: 22.1484 grad_loss: 13259.9502
[epoch  5][iter  220] loss: 11100.1045 RMSElog: 22.9031 grad_loss: 11077.2012
[epoch  5][iter  230] loss: 18205.2773 RMSElog: 22.0693 grad_loss: 18183.2090
[epoch  5][iter  240] loss: 13340.1289 RMSElog: 22.3168 grad_loss: 13317.8125
[epoch  5][iter  250] loss: 14434.6523 RMSElog: 22.1286 grad_loss: 14412.5234
[epoch  5][iter  260] loss: 21633.5410 RMSElog: 21.5865 grad_loss: 21611.9551
[epoch  5][iter  270] loss: 15940.3037 RMSElog: 22.4777 grad_loss: 15917.8262
[epoch  5][iter  280] loss: 14669.4023 RMSElog: 22.3611 grad_loss: 14647.0410
[epoch  5][iter  290] loss: 16070.8145 RMSElog: 22.2550 grad_loss: 16048.5596
[epoch  5][iter  300] loss: 17974.2539 RMSElog: 21.9157 grad_loss: 17952.3379
[epoch  5][iter  310] loss: 17448.6074 RMSElog: 22.1118 grad_loss: 17426.4961
[epoch  5][iter  320] loss: 15903.9248 RMSElog: 22.2688 grad_loss: 15881.6562
[epoch  5][iter  330] loss: 16055.0850 RMSElog: 22.2261 grad_loss: 16032.8594
[epoch  5][iter  340] loss: 16381.1963 RMSElog: 22.3792 grad_loss: 16358.8174
[epoch  5][iter  350] loss: 16336.5967 RMSElog: 22.1805 grad_loss: 16314.4160
[epoch  5][iter  360] loss: 10806.2002 RMSElog: 21.5992 grad_loss: 10784.6006
[epoch  5][iter  370] loss: 12207.5547 RMSElog: 22.3085 grad_loss: 12185.2461
[epoch  5][iter  380] loss: 15497.0068 RMSElog: 22.2522 grad_loss: 15474.7549
[epoch  5][iter  390] loss: 18517.8379 RMSElog: 21.7559 grad_loss: 18496.0820
[epoch  5][iter  400] loss: 13691.3535 RMSElog: 22.4035 grad_loss: 13668.9502
[epoch  5][iter  410] loss: 20147.5176 RMSElog: 21.5509 grad_loss: 20125.9668
[epoch  5][iter  420] loss: 11501.9922 RMSElog: 22.8750 grad_loss: 11479.1172
[epoch  5][iter  430] loss: 17804.3477 RMSElog: 21.8006 grad_loss: 17782.5469
[epoch  5][iter  440] loss: 13532.4980 RMSElog: 21.9594 grad_loss: 13510.5391
[epoch  5][iter  450] loss: 11546.1953 RMSElog: 22.1126 grad_loss: 11524.0830
[epoch  5][iter  460] loss: 10310.9590 RMSElog: 21.9116 grad_loss: 10289.0479
[epoch  5][iter  470] loss: 10121.0781 RMSElog: 21.8473 grad_loss: 10099.2305
[epoch  5][iter  480] loss: 16350.6143 RMSElog: 22.3914 grad_loss: 16328.2227
[epoch  5][iter  490] loss: 14706.4570 RMSElog: 22.6665 grad_loss: 14683.7910
[epoch  5][iter  500] loss: 15043.3838 RMSElog: 22.0522 grad_loss: 15021.3320
[epoch  5][iter  510] loss: 19638.0684 RMSElog: 21.5803 grad_loss: 19616.4883
[epoch  5][iter  520] loss: 10456.4092 RMSElog: 21.7164 grad_loss: 10434.6924
[epoch  5][iter  530] loss: 22918.5391 RMSElog: 21.6809 grad_loss: 22896.8574
[epoch  5][iter  540] loss: 13451.7432 RMSElog: 22.0906 grad_loss: 13429.6523
[epoch  5][iter  550] loss: 12774.1328 RMSElog: 21.8663 grad_loss: 12752.2666
[epoch  5][iter  560] loss: 16085.4404 RMSElog: 22.0468 grad_loss: 16063.3936
[epoch  5][iter  570] loss: 16388.9141 RMSElog: 22.1070 grad_loss: 16366.8066
[epoch  5][iter  580] loss: 18822.2168 RMSElog: 21.7273 grad_loss: 18800.4902
[epoch  5][iter  590] loss: 16556.4727 RMSElog: 22.1328 grad_loss: 16534.3398
[epoch  6][iter    0] loss: 17792.2129 RMSElog: 21.9089 grad_loss: 17770.3047
[epoch  6][iter   10] loss: 19179.8477 RMSElog: 21.7444 grad_loss: 19158.1035
[epoch  6][iter   20] loss: 10581.9248 RMSElog: 21.9920 grad_loss: 10559.9326
[epoch  6][iter   30] loss: 14657.0234 RMSElog: 21.6932 grad_loss: 14635.3301
[epoch  6][iter   40] loss: 13054.3652 RMSElog: 22.1394 grad_loss: 13032.2256
[epoch  6][iter   50] loss: 16586.4004 RMSElog: 22.2611 grad_loss: 16564.1387
[epoch  6][iter   60] loss: 17716.9492 RMSElog: 21.8011 grad_loss: 17695.1484
[epoch  6][iter   70] loss: 20127.2949 RMSElog: 22.0687 grad_loss: 20105.2266
[epoch  6][iter   80] loss: 20319.9648 RMSElog: 21.7737 grad_loss: 20298.1914
[epoch  6][iter   90] loss: 18297.3379 RMSElog: 22.3078 grad_loss: 18275.0293
[epoch  6][iter  100] loss: 15899.5410 RMSElog: 22.5299 grad_loss: 15877.0107
[epoch  6][iter  110] loss: 13618.0439 RMSElog: 22.1530 grad_loss: 13595.8906
[epoch  6][iter  120] loss: 16711.7051 RMSElog: 21.9208 grad_loss: 16689.7852
[epoch  6][iter  130] loss: 17468.0371 RMSElog: 22.3194 grad_loss: 17445.7168
[epoch  6][iter  140] loss: 9060.5049 RMSElog: 22.5649 grad_loss: 9037.9404
[epoch  6][iter  150] loss: 18205.2773 RMSElog: 22.0693 grad_loss: 18183.2090
[epoch  6][iter  160] loss: 10955.3848 RMSElog: 21.9632 grad_loss: 10933.4219
[epoch  6][iter  170] loss: 19638.0684 RMSElog: 21.5803 grad_loss: 19616.4883
[epoch  6][iter  180] loss: 23226.4277 RMSElog: 21.8006 grad_loss: 23204.6270
[epoch  6][iter  190] loss: 17889.5645 RMSElog: 22.1220 grad_loss: 17867.4434
[epoch  6][iter  200] loss: 15709.4541 RMSElog: 22.1900 grad_loss: 15687.2637
[epoch  6][iter  210] loss: 15628.6094 RMSElog: 22.2444 grad_loss: 15606.3652
[epoch  6][iter  220] loss: 20160.6426 RMSElog: 21.6751 grad_loss: 20138.9668
[epoch  6][iter  230] loss: 14947.7529 RMSElog: 21.8368 grad_loss: 14925.9160
[epoch  6][iter  240] loss: 9612.4600 RMSElog: 22.3855 grad_loss: 9590.0742
[epoch  6][iter  250] loss: 23179.9551 RMSElog: 21.6327 grad_loss: 23158.3223
[epoch  6][iter  260] loss: 10801.9521 RMSElog: 21.9799 grad_loss: 10779.9727
[epoch  6][iter  270] loss: 17541.4648 RMSElog: 22.1315 grad_loss: 17519.3340
[epoch  6][iter  280] loss: 15466.6660 RMSElog: 22.0324 grad_loss: 15444.6338
[epoch  6][iter  290] loss: 14265.1211 RMSElog: 21.8493 grad_loss: 14243.2715
[epoch  6][iter  300] loss: 12303.6348 RMSElog: 21.7453 grad_loss: 12281.8896
[epoch  6][iter  310] loss: 13532.4980 RMSElog: 21.9594 grad_loss: 13510.5391
[epoch  6][iter  320] loss: 19885.1465 RMSElog: 21.9077 grad_loss: 19863.2383
[epoch  6][iter  330] loss: 21605.7578 RMSElog: 21.5124 grad_loss: 21584.2461
[epoch  6][iter  340] loss: 16731.9941 RMSElog: 21.9069 grad_loss: 16710.0879
[epoch  6][iter  350] loss: 19192.6738 RMSElog: 21.4985 grad_loss: 19171.1758
[epoch  6][iter  360] loss: 16057.6494 RMSElog: 21.8972 grad_loss: 16035.7520
[epoch  6][iter  370] loss: 14122.7725 RMSElog: 21.9877 grad_loss: 14100.7852
[epoch  6][iter  380] loss: 16265.5156 RMSElog: 22.2633 grad_loss: 16243.2520
[epoch  6][iter  390] loss: 11546.1943 RMSElog: 22.1126 grad_loss: 11524.0820
[epoch  6][iter  400] loss: 20106.1152 RMSElog: 21.9197 grad_loss: 20084.1953
[epoch  6][iter  410] loss: 14543.8359 RMSElog: 22.4611 grad_loss: 14521.3750
[epoch  6][iter  420] loss: 12244.7295 RMSElog: 22.3218 grad_loss: 12222.4072
[epoch  6][iter  430] loss: 17974.2539 RMSElog: 21.9157 grad_loss: 17952.3379
[epoch  6][iter  440] loss: 12718.2236 RMSElog: 21.8542 grad_loss: 12696.3691
[epoch  6][iter  450] loss: 21564.3027 RMSElog: 21.4870 grad_loss: 21542.8164
[epoch  6][iter  460] loss: 14105.3555 RMSElog: 22.2171 grad_loss: 14083.1387
[epoch  6][iter  470] loss: 18822.2168 RMSElog: 21.7273 grad_loss: 18800.4902
[epoch  6][iter  480] loss: 16336.8701 RMSElog: 22.3951 grad_loss: 16314.4746
[epoch  6][iter  490] loss: 10346.9668 RMSElog: 22.0741 grad_loss: 10324.8926
[epoch  6][iter  500] loss: 16089.8467 RMSElog: 22.3412 grad_loss: 16067.5059
[epoch  6][iter  510] loss: 16556.4727 RMSElog: 22.1328 grad_loss: 16534.3398
[epoch  6][iter  520] loss: 12475.2803 RMSElog: 22.5546 grad_loss: 12452.7256
[epoch  6][iter  530] loss: 9534.7871 RMSElog: 22.8184 grad_loss: 9511.9688
[epoch  6][iter  540] loss: 12144.0195 RMSElog: 22.8755 grad_loss: 12121.1436
[epoch  6][iter  550] loss: 18984.9570 RMSElog: 21.8063 grad_loss: 18963.1504
[epoch  6][iter  560] loss: 16488.0684 RMSElog: 22.2431 grad_loss: 16465.8262
[epoch  6][iter  570] loss: 19552.2500 RMSElog: 22.0339 grad_loss: 19530.2168
[epoch  6][iter  580] loss: 10599.0117 RMSElog: 21.9689 grad_loss: 10577.0430
[epoch  6][iter  590] loss: 12867.4844 RMSElog: 22.3511 grad_loss: 12845.1328
[epoch  7][iter    0] loss: 14212.6387 RMSElog: 21.9529 grad_loss: 14190.6855
[epoch  7][iter   10] loss: 23179.9551 RMSElog: 21.6327 grad_loss: 23158.3223
[epoch  7][iter   20] loss: 18860.7266 RMSElog: 21.7316 grad_loss: 18838.9941
[epoch  7][iter   30] loss: 14401.2520 RMSElog: 21.8068 grad_loss: 14379.4453
[epoch  7][iter   40] loss: 15411.3115 RMSElog: 22.2989 grad_loss: 15389.0127
[epoch  7][iter   50] loss: 16104.8672 RMSElog: 22.2520 grad_loss: 16082.6152
[epoch  7][iter   60] loss: 10925.3408 RMSElog: 21.5798 grad_loss: 10903.7607
[epoch  7][iter   70] loss: 23987.3105 RMSElog: 21.7467 grad_loss: 23965.5645
[epoch  7][iter   80] loss: 18140.1094 RMSElog: 21.8160 grad_loss: 18118.2930
[epoch  7][iter   90] loss: 20663.2285 RMSElog: 21.7464 grad_loss: 20641.4824
[epoch  7][iter  100] loss: 10133.2959 RMSElog: 22.0859 grad_loss: 10111.2100
[epoch  7][iter  110] loss: 14211.7549 RMSElog: 22.1674 grad_loss: 14189.5879
[epoch  7][iter  120] loss: 20650.4102 RMSElog: 21.6416 grad_loss: 20628.7676
[epoch  7][iter  130] loss: 14122.7725 RMSElog: 21.9877 grad_loss: 14100.7852
[epoch  7][iter  140] loss: 20407.3809 RMSElog: 21.4767 grad_loss: 20385.9043
[epoch  7][iter  150] loss: 12927.5117 RMSElog: 22.2375 grad_loss: 12905.2744
[epoch  7][iter  160] loss: 16488.5059 RMSElog: 22.5717 grad_loss: 16465.9336
[epoch  7][iter  170] loss: 12718.2236 RMSElog: 21.8542 grad_loss: 12696.3691
[epoch  7][iter  180] loss: 15288.6055 RMSElog: 22.1986 grad_loss: 15266.4072
[epoch  7][iter  190] loss: 19971.2715 RMSElog: 21.6690 grad_loss: 19949.6016
[epoch  7][iter  200] loss: 19555.4375 RMSElog: 22.1325 grad_loss: 19533.3047
[epoch  7][iter  210] loss: 12788.3779 RMSElog: 21.8046 grad_loss: 12766.5732
[epoch  7][iter  220] loss: 21164.3770 RMSElog: 21.8139 grad_loss: 21142.5625
[epoch  7][iter  230] loss: 13215.5479 RMSElog: 22.3441 grad_loss: 13193.2041
[epoch  7][iter  240] loss: 16099.7061 RMSElog: 22.4832 grad_loss: 16077.2227
[epoch  7][iter  250] loss: 13458.3604 RMSElog: 22.0835 grad_loss: 13436.2773
[epoch  7][iter  260] loss: 11092.0938 RMSElog: 21.9884 grad_loss: 11070.1055
[epoch  7][iter  270] loss: 13927.3057 RMSElog: 22.3593 grad_loss: 13904.9463
[epoch  7][iter  280] loss: 18001.5156 RMSElog: 22.2327 grad_loss: 17979.2832
[epoch  7][iter  290] loss: 22844.2363 RMSElog: 21.6685 grad_loss: 22822.5684
[epoch  7][iter  300] loss: 13451.7432 RMSElog: 22.0906 grad_loss: 13429.6523
[epoch  7][iter  310] loss: 18984.9570 RMSElog: 21.8063 grad_loss: 18963.1504
[epoch  7][iter  320] loss: 12040.4424 RMSElog: 22.0285 grad_loss: 12018.4141
[epoch  7][iter  330] loss: 19207.9961 RMSElog: 21.9667 grad_loss: 19186.0293
[epoch  7][iter  340] loss: 13386.6914 RMSElog: 21.8137 grad_loss: 13364.8779
[epoch  7][iter  350] loss: 17565.6152 RMSElog: 21.9615 grad_loss: 17543.6543
[epoch  7][iter  360] loss: 19166.8535 RMSElog: 21.8639 grad_loss: 19144.9902
[epoch  7][iter  370] loss: 11588.0938 RMSElog: 22.1767 grad_loss: 11565.9170
[epoch  7][iter  380] loss: 23207.9414 RMSElog: 21.7930 grad_loss: 23186.1484
[epoch  7][iter  390] loss: 20802.1914 RMSElog: 21.5040 grad_loss: 20780.6875
[epoch  7][iter  400] loss: 11564.8018 RMSElog: 22.0723 grad_loss: 11542.7295
[epoch  7][iter  410] loss: 22131.9648 RMSElog: 21.7903 grad_loss: 22110.1738
[epoch  7][iter  420] loss: 23308.5801 RMSElog: 21.6750 grad_loss: 23286.9043
[epoch  7][iter  430] loss: 12302.7402 RMSElog: 22.3070 grad_loss: 12280.4336
[epoch  7][iter  440] loss: 16612.4570 RMSElog: 22.2810 grad_loss: 16590.1758
[epoch  7][iter  450] loss: 14965.6777 RMSElog: 22.3481 grad_loss: 14943.3301
[epoch  7][iter  460] loss: 18874.9258 RMSElog: 21.6270 grad_loss: 18853.2988
[epoch  7][iter  470] loss: 12438.5918 RMSElog: 22.1601 grad_loss: 12416.4316
[epoch  7][iter  480] loss: 10806.0508 RMSElog: 21.9743 grad_loss: 10784.0762
[epoch  7][iter  490] loss: 21459.3047 RMSElog: 21.3704 grad_loss: 21437.9336
[epoch  7][iter  500] loss: 15442.3652 RMSElog: 22.2892 grad_loss: 15420.0762
[epoch  7][iter  510] loss: 13282.0986 RMSElog: 22.1484 grad_loss: 13259.9502
[epoch  7][iter  520] loss: 15427.6660 RMSElog: 22.1635 grad_loss: 15405.5029
[epoch  7][iter  530] loss: 16055.0850 RMSElog: 22.2261 grad_loss: 16032.8594
[epoch  7][iter  540] loss: 20546.8242 RMSElog: 21.7307 grad_loss: 20525.0938
[epoch  7][iter  550] loss: 18320.3633 RMSElog: 21.8851 grad_loss: 18298.4785
[epoch  7][iter  560] loss: 21203.1270 RMSElog: 21.7281 grad_loss: 21181.3984
[epoch  7][iter  570] loss: 13917.9697 RMSElog: 22.4567 grad_loss: 13895.5127
[epoch  7][iter  580] loss: 14813.9316 RMSElog: 22.4322 grad_loss: 14791.4990
[epoch  7][iter  590] loss: 21905.0117 RMSElog: 21.4887 grad_loss: 21883.5234
[epoch  8][iter    0] loss: 10391.5771 RMSElog: 22.3595 grad_loss: 10369.2178
[epoch  8][iter   10] loss: 14748.8086 RMSElog: 22.3183 grad_loss: 14726.4902
[epoch  8][iter   20] loss: 16612.4590 RMSElog: 22.2810 grad_loss: 16590.1777
[epoch  8][iter   30] loss: 12438.5918 RMSElog: 22.1601 grad_loss: 12416.4316
[epoch  8][iter   40] loss: 10406.0840 RMSElog: 22.0099 grad_loss: 10384.0742
[epoch  8][iter   50] loss: 12860.3906 RMSElog: 22.2938 grad_loss: 12838.0967
[epoch  8][iter   60] loss: 11588.0938 RMSElog: 22.1767 grad_loss: 11565.9170
[epoch  8][iter   70] loss: 19762.3867 RMSElog: 21.5252 grad_loss: 19740.8613
[epoch  8][iter   80] loss: 17984.8984 RMSElog: 22.0206 grad_loss: 17962.8770
[epoch  8][iter   90] loss: 12867.4844 RMSElog: 22.3511 grad_loss: 12845.1328
[epoch  8][iter  100] loss: 14122.7705 RMSElog: 21.9877 grad_loss: 14100.7832
[epoch  8][iter  110] loss: 12056.8057 RMSElog: 22.9098 grad_loss: 12033.8955
[epoch  8][iter  120] loss: 10419.9678 RMSElog: 22.0824 grad_loss: 10397.8857
[epoch  8][iter  130] loss: 16078.0771 RMSElog: 22.2621 grad_loss: 16055.8154
[epoch  8][iter  140] loss: 14016.8320 RMSElog: 22.1016 grad_loss: 13994.7305
[epoch  8][iter  150] loss: 12436.1250 RMSElog: 22.2096 grad_loss: 12413.9150
[epoch  8][iter  160] loss: 13927.3057 RMSElog: 22.3593 grad_loss: 13904.9463
[epoch  8][iter  170] loss: 14706.4570 RMSElog: 22.6665 grad_loss: 14683.7910
[epoch  8][iter  180] loss: 16070.8154 RMSElog: 22.2550 grad_loss: 16048.5605
[epoch  8][iter  190] loss: 15266.0596 RMSElog: 22.1135 grad_loss: 15243.9463
[epoch  8][iter  200] loss: 14991.7773 RMSElog: 22.0004 grad_loss: 14969.7773
[epoch  8][iter  210] loss: 18517.8379 RMSElog: 21.7559 grad_loss: 18496.0820
[epoch  8][iter  220] loss: 16263.4551 RMSElog: 22.2032 grad_loss: 16241.2520
[epoch  8][iter  230] loss: 14128.4355 RMSElog: 22.1893 grad_loss: 14106.2461
[epoch  8][iter  240] loss: 10955.3848 RMSElog: 21.9632 grad_loss: 10933.4219
[epoch  8][iter  250] loss: 15953.7676 RMSElog: 22.2203 grad_loss: 15931.5469
[epoch  8][iter  260] loss: 14914.9971 RMSElog: 22.1891 grad_loss: 14892.8076
[epoch  8][iter  270] loss: 18615.9023 RMSElog: 21.7485 grad_loss: 18594.1543
[epoch  8][iter  280] loss: 17660.7305 RMSElog: 22.2054 grad_loss: 17638.5254
[epoch  8][iter  290] loss: 14706.7764 RMSElog: 21.8429 grad_loss: 14684.9336
[epoch  8][iter  300] loss: 10581.9248 RMSElog: 21.9920 grad_loss: 10559.9326
[epoch  8][iter  310] loss: 22696.9082 RMSElog: 21.6826 grad_loss: 22675.2266
[epoch  8][iter  320] loss: 16785.3730 RMSElog: 22.2078 grad_loss: 16763.1660
[epoch  8][iter  330] loss: 11546.1943 RMSElog: 22.1126 grad_loss: 11524.0820
[epoch  8][iter  340] loss: 16057.6494 RMSElog: 21.8972 grad_loss: 16035.7520
[epoch  8][iter  350] loss: 10342.4619 RMSElog: 22.4426 grad_loss: 10320.0195
[epoch  8][iter  360] loss: 12839.1963 RMSElog: 22.1739 grad_loss: 12817.0225
[epoch  8][iter  370] loss: 14543.8359 RMSElog: 22.4611 grad_loss: 14521.3750
[epoch  8][iter  380] loss: 15288.6055 RMSElog: 22.1986 grad_loss: 15266.4072
[epoch  8][iter  390] loss: 17445.8613 RMSElog: 21.8163 grad_loss: 17424.0449
[epoch  8][iter  400] loss: 19678.3965 RMSElog: 21.6956 grad_loss: 19656.7012
[epoch  8][iter  410] loss: 23349.3887 RMSElog: 21.7823 grad_loss: 23327.6055
[epoch  8][iter  420] loss: 15899.5410 RMSElog: 22.5299 grad_loss: 15877.0107
[epoch  8][iter  430] loss: 17691.2129 RMSElog: 22.2546 grad_loss: 17668.9590
[epoch  8][iter  440] loss: 15559.0273 RMSElog: 21.9165 grad_loss: 15537.1104
[epoch  8][iter  450] loss: 12202.9375 RMSElog: 22.0953 grad_loss: 12180.8418
[epoch  8][iter  460] loss: 21417.5742 RMSElog: 21.9101 grad_loss: 21395.6641
[epoch  8][iter  470] loss: 12303.6348 RMSElog: 21.7453 grad_loss: 12281.8896
[epoch  8][iter  480] loss: 10590.6865 RMSElog: 21.9406 grad_loss: 10568.7461
[epoch  8][iter  490] loss: 14835.5254 RMSElog: 22.4202 grad_loss: 14813.1055
[epoch  8][iter  500] loss: 12088.5303 RMSElog: 22.5544 grad_loss: 12065.9756
[epoch  8][iter  510] loss: 17819.0586 RMSElog: 22.2586 grad_loss: 17796.8008
[epoch  8][iter  520] loss: 13913.3496 RMSElog: 22.2931 grad_loss: 13891.0566
[epoch  8][iter  530] loss: 15628.6074 RMSElog: 22.2444 grad_loss: 15606.3633
[epoch  8][iter  540] loss: 21164.3770 RMSElog: 21.8139 grad_loss: 21142.5625
[epoch  8][iter  550] loss: 14632.6104 RMSElog: 22.0773 grad_loss: 14610.5332
[epoch  8][iter  560] loss: 20273.6172 RMSElog: 21.6839 grad_loss: 20251.9336
[epoch  8][iter  570] loss: 13358.1504 RMSElog: 22.3307 grad_loss: 13335.8193
[epoch  8][iter  580] loss: 16013.8447 RMSElog: 22.1837 grad_loss: 15991.6611
[epoch  8][iter  590] loss: 23350.0898 RMSElog: 21.7606 grad_loss: 23328.3301
[epoch  9][iter    0] loss: 16711.7051 RMSElog: 21.9208 grad_loss: 16689.7852
[epoch  9][iter   10] loss: 22815.8379 RMSElog: 21.7656 grad_loss: 22794.0723
[epoch  9][iter   20] loss: 12909.4697 RMSElog: 22.1940 grad_loss: 12887.2754
[epoch  9][iter   30] loss: 12540.1709 RMSElog: 22.5815 grad_loss: 12517.5898
[epoch  9][iter   40] loss: 15991.1875 RMSElog: 22.1013 grad_loss: 15969.0859
[epoch  9][iter   50] loss: 16192.5283 RMSElog: 22.1978 grad_loss: 16170.3301
[epoch  9][iter   60] loss: 20779.3477 RMSElog: 21.9625 grad_loss: 20757.3848
[epoch  9][iter   70] loss: 7240.6953 RMSElog: 22.2166 grad_loss: 7218.4785
[epoch  9][iter   80] loss: 18412.5664 RMSElog: 21.9219 grad_loss: 18390.6445
[epoch  9][iter   90] loss: 14706.7764 RMSElog: 21.8429 grad_loss: 14684.9336
[epoch  9][iter  100] loss: 16807.2051 RMSElog: 22.4491 grad_loss: 16784.7559
[epoch  9][iter  110] loss: 10937.2480 RMSElog: 21.9212 grad_loss: 10915.3271
[epoch  9][iter  120] loss: 12302.7402 RMSElog: 22.3070 grad_loss: 12280.4336
[epoch  9][iter  130] loss: 12774.1328 RMSElog: 21.8663 grad_loss: 12752.2666
[epoch  9][iter  140] loss: 12562.0244 RMSElog: 22.2237 grad_loss: 12539.8008
[epoch  9][iter  150] loss: 15953.7676 RMSElog: 22.2203 grad_loss: 15931.5469
[epoch  9][iter  160] loss: 14211.7529 RMSElog: 22.1674 grad_loss: 14189.5859
[epoch  9][iter  170] loss: 17889.5645 RMSElog: 22.1220 grad_loss: 17867.4434
[epoch  9][iter  180] loss: 20663.2266 RMSElog: 21.7464 grad_loss: 20641.4805
[epoch  9][iter  190] loss: 21856.5059 RMSElog: 21.8414 grad_loss: 21834.6641
[epoch  9][iter  200] loss: 17706.3105 RMSElog: 21.9350 grad_loss: 17684.3750
[epoch  9][iter  210] loss: 13451.7432 RMSElog: 22.0906 grad_loss: 13429.6523
[epoch  9][iter  220] loss: 16606.6113 RMSElog: 22.1389 grad_loss: 16584.4727
[epoch  9][iter  230] loss: 10599.0117 RMSElog: 21.9689 grad_loss: 10577.0430
[epoch  9][iter  240] loss: 15667.4561 RMSElog: 22.4037 grad_loss: 15645.0527
[epoch  9][iter  250] loss: 14395.5811 RMSElog: 22.3675 grad_loss: 14373.2139
[epoch  9][iter  260] loss: 16428.9785 RMSElog: 21.8621 grad_loss: 16407.1172
[epoch  9][iter  270] loss: 10364.6689 RMSElog: 21.9487 grad_loss: 10342.7207
[epoch  9][iter  280] loss: 14016.8320 RMSElog: 22.1016 grad_loss: 13994.7305
[epoch  9][iter  290] loss: 11561.1162 RMSElog: 22.2163 grad_loss: 11538.9004
[epoch  9][iter  300] loss: 16078.0771 RMSElog: 22.2621 grad_loss: 16055.8154
[epoch  9][iter  310] loss: 16731.9941 RMSElog: 21.9069 grad_loss: 16710.0879
[epoch  9][iter  320] loss: 18822.2148 RMSElog: 21.7273 grad_loss: 18800.4883
[epoch  9][iter  330] loss: 14865.3105 RMSElog: 22.0826 grad_loss: 14843.2275
[epoch  9][iter  340] loss: 12505.4629 RMSElog: 22.6739 grad_loss: 12482.7891
[epoch  9][iter  350] loss: 12788.3779 RMSElog: 21.8046 grad_loss: 12766.5732
[epoch  9][iter  360] loss: 14757.5967 RMSElog: 22.2996 grad_loss: 14735.2969
[epoch  9][iter  370] loss: 20273.6172 RMSElog: 21.6839 grad_loss: 20251.9336
[epoch  9][iter  380] loss: 13340.1289 RMSElog: 22.3168 grad_loss: 13317.8125
[epoch  9][iter  390] loss: 17474.1797 RMSElog: 22.1664 grad_loss: 17452.0137
[epoch  9][iter  400] loss: 15899.5410 RMSElog: 22.5299 grad_loss: 15877.0107
[epoch  9][iter  410] loss: 19971.2715 RMSElog: 21.6690 grad_loss: 19949.6016
[epoch  9][iter  420] loss: 19839.6543 RMSElog: 21.4992 grad_loss: 19818.1543
[epoch  9][iter  430] loss: 17279.6250 RMSElog: 22.1659 grad_loss: 17257.4590
[epoch  9][iter  440] loss: 17223.0312 RMSElog: 22.2631 grad_loss: 17200.7676
[epoch  9][iter  450] loss: 23505.4883 RMSElog: 21.9921 grad_loss: 23483.4961
[epoch  9][iter  460] loss: 11332.4707 RMSElog: 23.0198 grad_loss: 11309.4512
[epoch  9][iter  470] loss: 11203.8770 RMSElog: 22.6913 grad_loss: 11181.1855
[epoch  9][iter  480] loss: 15026.3145 RMSElog: 22.0267 grad_loss: 15004.2881
[epoch  9][iter  490] loss: 11503.9414 RMSElog: 22.1337 grad_loss: 11481.8076
[epoch  9][iter  500] loss: 14748.8086 RMSElog: 22.3183 grad_loss: 14726.4902
[epoch  9][iter  510] loss: 7862.5811 RMSElog: 21.9563 grad_loss: 7840.6250
[epoch  9][iter  520] loss: 17468.0371 RMSElog: 22.3194 grad_loss: 17445.7168
[epoch  9][iter  530] loss: 21459.3047 RMSElog: 21.3704 grad_loss: 21437.9336
[epoch  9][iter  540] loss: 16019.1475 RMSElog: 22.4382 grad_loss: 15996.7090
[epoch  9][iter  550] loss: 10688.0781 RMSElog: 21.9443 grad_loss: 10666.1338
[epoch  9][iter  560] loss: 16294.7266 RMSElog: 22.1110 grad_loss: 16272.6152
[epoch  9][iter  570] loss: 20147.5176 RMSElog: 21.5509 grad_loss: 20125.9668
[epoch  9][iter  580] loss: 11265.4131 RMSElog: 22.4405 grad_loss: 11242.9727
[epoch  9][iter  590] loss: 16789.4609 RMSElog: 22.0144 grad_loss: 16767.4473
[epoch 10][iter    0] loss: 16085.4404 RMSElog: 22.0468 grad_loss: 16063.3936
[epoch 10][iter   10] loss: 10424.4561 RMSElog: 22.2778 grad_loss: 10402.1777
[epoch 10][iter   20] loss: 11100.1045 RMSElog: 22.9031 grad_loss: 11077.2012
[epoch 10][iter   30] loss: 15899.5410 RMSElog: 22.5299 grad_loss: 15877.0107
[epoch 10][iter   40] loss: 13313.3154 RMSElog: 22.5324 grad_loss: 13290.7832
[epoch 10][iter   50] loss: 17445.8613 RMSElog: 21.8163 grad_loss: 17424.0449
[epoch 10][iter   60] loss: 16807.2051 RMSElog: 22.4491 grad_loss: 16784.7559
[epoch 10][iter   70] loss: 21864.7383 RMSElog: 21.5041 grad_loss: 21843.2344
[epoch 10][iter   80] loss: 23226.4277 RMSElog: 21.8006 grad_loss: 23204.6270
[epoch 10][iter   90] loss: 18822.2148 RMSElog: 21.7273 grad_loss: 18800.4883
[epoch 10][iter  100] loss: 17889.5645 RMSElog: 22.1220 grad_loss: 17867.4434
[epoch 10][iter  110] loss: 13994.5029 RMSElog: 22.2036 grad_loss: 13972.2988
[epoch 10][iter  120] loss: 15442.3652 RMSElog: 22.2892 grad_loss: 15420.0762
[epoch 10][iter  130] loss: 12040.4424 RMSElog: 22.0285 grad_loss: 12018.4141
[epoch 10][iter  140] loss: 10955.3848 RMSElog: 21.9632 grad_loss: 10933.4219
[epoch 10][iter  150] loss: 15723.3916 RMSElog: 22.3165 grad_loss: 15701.0752
[epoch 10][iter  160] loss: 13661.7227 RMSElog: 22.0156 grad_loss: 13639.7070
[epoch 10][iter  170] loss: 23062.2812 RMSElog: 21.6592 grad_loss: 23040.6230
[epoch 10][iter  180] loss: 13205.5215 RMSElog: 22.0783 grad_loss: 13183.4434
[epoch 10][iter  190] loss: 15041.0352 RMSElog: 22.2417 grad_loss: 15018.7939
[epoch 10][iter  200] loss: 16388.9141 RMSElog: 22.1070 grad_loss: 16366.8066
[epoch 10][iter  210] loss: 12981.6738 RMSElog: 21.8688 grad_loss: 12959.8047
[epoch 10][iter  220] loss: 16266.9102 RMSElog: 22.1735 grad_loss: 16244.7363
[epoch 10][iter  230] loss: 14155.9785 RMSElog: 22.4345 grad_loss: 14133.5439
[epoch 10][iter  240] loss: 15026.3145 RMSElog: 22.0267 grad_loss: 15004.2881
[epoch 10][iter  250] loss: 18397.8145 RMSElog: 21.8262 grad_loss: 18375.9883
[epoch 10][iter  260] loss: 15602.5879 RMSElog: 22.2483 grad_loss: 15580.3398
[epoch 10][iter  270] loss: 18615.9023 RMSElog: 21.7485 grad_loss: 18594.1543
[epoch 10][iter  280] loss: 17604.0879 RMSElog: 21.8651 grad_loss: 17582.2227
[epoch 10][iter  290] loss: 15940.3037 RMSElog: 22.4777 grad_loss: 15917.8262
[epoch 10][iter  300] loss: 16078.0771 RMSElog: 22.2621 grad_loss: 16055.8154
[epoch 10][iter  310] loss: 13691.3535 RMSElog: 22.4035 grad_loss: 13668.9502
[epoch 10][iter  320] loss: 10600.9111 RMSElog: 21.9743 grad_loss: 10578.9365
[epoch 10][iter  330] loss: 12244.7295 RMSElog: 22.3218 grad_loss: 12222.4072
[epoch 10][iter  340] loss: 17307.8145 RMSElog: 22.0890 grad_loss: 17285.7246
[epoch 10][iter  350] loss: 11577.9619 RMSElog: 22.9569 grad_loss: 11555.0049
[epoch 10][iter  360] loss: 19552.2500 RMSElog: 22.0339 grad_loss: 19530.2168
[epoch 10][iter  370] loss: 10925.3408 RMSElog: 21.5798 grad_loss: 10903.7607
[epoch 10][iter  380] loss: 18001.5156 RMSElog: 22.2327 grad_loss: 17979.2832
[epoch 10][iter  390] loss: 12540.1709 RMSElog: 22.5815 grad_loss: 12517.5898
[epoch 10][iter  400] loss: 11958.7285 RMSElog: 22.2950 grad_loss: 11936.4336
[epoch 10][iter  410] loss: 19702.3457 RMSElog: 21.6095 grad_loss: 19680.7363
[epoch 10][iter  420] loss: 16283.2080 RMSElog: 22.6413 grad_loss: 16260.5664
[epoch 10][iter  430] loss: 10456.4092 RMSElog: 21.7164 grad_loss: 10434.6924
[epoch 10][iter  440] loss: 13478.9395 RMSElog: 22.0585 grad_loss: 13456.8809
[epoch 10][iter  450] loss: 10076.2764 RMSElog: 21.9740 grad_loss: 10054.3027
[epoch 10][iter  460] loss: 21487.9648 RMSElog: 21.6544 grad_loss: 21466.3105
[epoch 10][iter  470] loss: 13026.0254 RMSElog: 22.1734 grad_loss: 13003.8516
[epoch 10][iter  480] loss: 16055.0850 RMSElog: 22.2261 grad_loss: 16032.8594
[epoch 10][iter  490] loss: 15781.8076 RMSElog: 22.1978 grad_loss: 15759.6094
[epoch 10][iter  500] loss: 11885.9707 RMSElog: 22.0764 grad_loss: 11863.8945
[epoch 10][iter  510] loss: 17974.2539 RMSElog: 21.9157 grad_loss: 17952.3379
[epoch 10][iter  520] loss: 17382.9980 RMSElog: 21.9453 grad_loss: 17361.0527
[epoch 10][iter  530] loss: 10573.4062 RMSElog: 21.6466 grad_loss: 10551.7598
[epoch 10][iter  540] loss: 18359.1230 RMSElog: 22.1083 grad_loss: 18337.0156
[epoch 10][iter  550] loss: 16338.2090 RMSElog: 21.9730 grad_loss: 16316.2363
[epoch 10][iter  560] loss: 15146.6279 RMSElog: 22.1059 grad_loss: 15124.5225
[epoch 10][iter  570] loss: 11427.6113 RMSElog: 22.9061 grad_loss: 11404.7051
[epoch 10][iter  580] loss: 12580.6309 RMSElog: 22.0270 grad_loss: 12558.6035
[epoch 10][iter  590] loss: 16085.8398 RMSElog: 22.3184 grad_loss: 16063.5215
[epoch 11][iter    0] loss: 21234.1953 RMSElog: 21.5372 grad_loss: 21212.6582
[epoch 11][iter   10] loss: 12594.3027 RMSElog: 22.1431 grad_loss: 12572.1592
[epoch 11][iter   20] loss: 14813.9316 RMSElog: 22.4322 grad_loss: 14791.4990
[epoch 11][iter   30] loss: 15991.1875 RMSElog: 22.1013 grad_loss: 15969.0859
[epoch 11][iter   40] loss: 12927.5127 RMSElog: 22.2375 grad_loss: 12905.2754
[epoch 11][iter   50] loss: 19577.7266 RMSElog: 21.6885 grad_loss: 19556.0371
[epoch 11][iter   60] loss: 12985.4912 RMSElog: 22.0834 grad_loss: 12963.4082
[epoch 11][iter   70] loss: 10521.1660 RMSElog: 22.0160 grad_loss: 10499.1504
[epoch 11][iter   80] loss: 14237.5977 RMSElog: 22.1813 grad_loss: 14215.4160
[epoch 11][iter   90] loss: 12302.7402 RMSElog: 22.3070 grad_loss: 12280.4336
[epoch 11][iter  100] loss: 19678.3965 RMSElog: 21.6956 grad_loss: 19656.7012
[epoch 11][iter  110] loss: 22918.5391 RMSElog: 21.6809 grad_loss: 22896.8574
[epoch 11][iter  120] loss: 15814.6943 RMSElog: 22.2418 grad_loss: 15792.4521
[epoch 11][iter  130] loss: 18560.8379 RMSElog: 22.2386 grad_loss: 18538.5996
[epoch 11][iter  140] loss: 17604.0879 RMSElog: 21.8651 grad_loss: 17582.2227
[epoch 11][iter  150] loss: 23349.3887 RMSElog: 21.7823 grad_loss: 23327.6055
[epoch 11][iter  160] loss: 15628.6094 RMSElog: 22.2444 grad_loss: 15606.3652
[epoch 11][iter  170] loss: 12088.5303 RMSElog: 22.5544 grad_loss: 12065.9756
[epoch 11][iter  180] loss: 14357.7197 RMSElog: 22.4031 grad_loss: 14335.3164
[epoch 11][iter  190] loss: 10363.8770 RMSElog: 22.7341 grad_loss: 10341.1426
[epoch 11][iter  200] loss: 14122.7725 RMSElog: 21.9877 grad_loss: 14100.7852
[epoch 11][iter  210] loss: 16254.8926 RMSElog: 22.3943 grad_loss: 16232.4980
[epoch 11][iter  220] loss: 10342.4619 RMSElog: 22.4426 grad_loss: 10320.0195
[epoch 11][iter  230] loss: 10133.2949 RMSElog: 22.0859 grad_loss: 10111.2090
[epoch 11][iter  240] loss: 9060.5049 RMSElog: 22.5649 grad_loss: 9037.9404
[epoch 11][iter  250] loss: 12839.1963 RMSElog: 22.1739 grad_loss: 12817.0225
[epoch 11][iter  260] loss: 17559.4824 RMSElog: 21.9559 grad_loss: 17537.5273
[epoch 11][iter  270] loss: 19207.9961 RMSElog: 21.9667 grad_loss: 19186.0293
[epoch 11][iter  280] loss: 16381.1963 RMSElog: 22.3792 grad_loss: 16358.8174
[epoch 11][iter  290] loss: 11100.1045 RMSElog: 22.9031 grad_loss: 11077.2012
[epoch 11][iter  300] loss: 17858.1953 RMSElog: 22.2174 grad_loss: 17835.9785
[epoch 11][iter  310] loss: 16175.3760 RMSElog: 21.8776 grad_loss: 16153.4980
[epoch 11][iter  320] loss: 16016.4756 RMSElog: 22.2513 grad_loss: 15994.2246
[epoch 11][iter  330] loss: 16745.7988 RMSElog: 22.1910 grad_loss: 16723.6074
[epoch 11][iter  340] loss: 18267.3340 RMSElog: 21.7248 grad_loss: 18245.6094
[epoch 11][iter  350] loss: 14829.3779 RMSElog: 22.0106 grad_loss: 14807.3672
[epoch 11][iter  360] loss: 11954.7510 RMSElog: 22.4423 grad_loss: 11932.3086
[epoch 11][iter  370] loss: 12210.5068 RMSElog: 22.6178 grad_loss: 12187.8887
[epoch 11][iter  380] loss: 16785.8418 RMSElog: 22.1992 grad_loss: 16763.6426
[epoch 11][iter  390] loss: 16283.2080 RMSElog: 22.6413 grad_loss: 16260.5664
[epoch 11][iter  400] loss: 11182.4365 RMSElog: 21.9090 grad_loss: 11160.5273
[epoch 11][iter  410] loss: 22131.9648 RMSElog: 21.7903 grad_loss: 22110.1738
[epoch 11][iter  420] loss: 13340.1289 RMSElog: 22.3168 grad_loss: 13317.8125
[epoch 11][iter  430] loss: 15361.1133 RMSElog: 22.0552 grad_loss: 15339.0586
[epoch 11][iter  440] loss: 15709.4541 RMSElog: 22.1900 grad_loss: 15687.2637
[epoch 11][iter  450] loss: 15587.6416 RMSElog: 22.2516 grad_loss: 15565.3896
[epoch 11][iter  460] loss: 14824.6377 RMSElog: 21.9379 grad_loss: 14802.7002
[epoch 11][iter  470] loss: 12320.8809 RMSElog: 22.1545 grad_loss: 12298.7266
[epoch  0][iter    0] loss: 11.4853 RMSElog: 11.4853
[epoch  0][iter   10] loss: 11.3043 RMSElog: 11.3043
[epoch  0][iter   20] loss: 11.1224 RMSElog: 11.1224
[epoch  0][iter   30] loss: 12.6791 RMSElog: 12.6791
[epoch  0][iter   40] loss: 10.5954 RMSElog: 10.5954
[epoch  0][iter   50] loss: 10.9723 RMSElog: 10.9723
[epoch  0][iter   60] loss: 10.2830 RMSElog: 10.2830
[epoch  0][iter   70] loss: 10.8010 RMSElog: 10.8010
[epoch  0][iter   80] loss: 11.5373 RMSElog: 11.5373
[epoch  0][iter   90] loss: 10.5749 RMSElog: 10.5749
[epoch  0][iter  100] loss: 12.3009 RMSElog: 12.3009
[epoch  0][iter  110] loss: 12.1549 RMSElog: 12.1549
[epoch  0][iter  120] loss: 10.7651 RMSElog: 10.7651
[epoch  0][iter  130] loss: 11.7406 RMSElog: 11.7406
[epoch  0][iter  140] loss: 10.7011 RMSElog: 10.7011
[epoch  0][iter  150] loss: 10.2836 RMSElog: 10.2836
[epoch  0][iter  160] loss: 10.2678 RMSElog: 10.2678
[epoch  0][iter  170] loss: 11.9932 RMSElog: 11.9932
[epoch  0][iter  180] loss: 11.6059 RMSElog: 11.6059
[epoch  0][iter  190] loss: 10.5166 RMSElog: 10.5166
[epoch  0][iter  200] loss: 12.2506 RMSElog: 12.2506
[epoch  0][iter  210] loss: 10.4998 RMSElog: 10.4998
[epoch  0][iter  220] loss: 10.8689 RMSElog: 10.8689
[epoch  0][iter  230] loss: 11.5967 RMSElog: 11.5967
[epoch  0][iter  240] loss: 11.4904 RMSElog: 11.4904
[epoch  0][iter  250] loss: 11.8704 RMSElog: 11.8704
[epoch  0][iter  260] loss: 11.8001 RMSElog: 11.8001
[epoch  0][iter  270] loss: 11.3304 RMSElog: 11.3304
[epoch  0][iter  280] loss: 11.3018 RMSElog: 11.3018
[epoch  0][iter  290] loss: 10.6542 RMSElog: 10.6542
[epoch  0][iter  300] loss: 10.6113 RMSElog: 10.6113
[epoch  0][iter  310] loss: 12.1147 RMSElog: 12.1147
[epoch  0][iter  320] loss: 12.4301 RMSElog: 12.4301
[epoch  0][iter  330] loss: 10.1968 RMSElog: 10.1968
[epoch  0][iter  340] loss: 11.2843 RMSElog: 11.2843
[epoch  0][iter  350] loss: 9.1019 RMSElog: 9.1019
[epoch  0][iter  360] loss: 10.8784 RMSElog: 10.8784
[epoch  0][iter  370] loss: 10.2700 RMSElog: 10.2700
[epoch  0][iter  380] loss: 11.0483 RMSElog: 11.0483
[epoch  0][iter  390] loss: 9.5149 RMSElog: 9.5149
[epoch  0][iter  400] loss: 11.8728 RMSElog: 11.8728
[epoch  0][iter  410] loss: 11.0061 RMSElog: 11.0061
[epoch  0][iter  420] loss: 11.2051 RMSElog: 11.2051
[epoch  0][iter  430] loss: 9.8529 RMSElog: 9.8529
[epoch  0][iter  440] loss: 10.2610 RMSElog: 10.2610
[epoch  0][iter  450] loss: 9.2554 RMSElog: 9.2554
[epoch  0][iter  460] loss: 10.7817 RMSElog: 10.7817
[epoch  0][iter  470] loss: 10.7397 RMSElog: 10.7397
[epoch  0][iter  480] loss: 10.4942 RMSElog: 10.4942
[epoch  0][iter  490] loss: 10.3983 RMSElog: 10.3983
[epoch  0][iter  500] loss: 10.6885 RMSElog: 10.6885
[epoch  0][iter  510] loss: 10.4262 RMSElog: 10.4262
[epoch  0][iter  520] loss: 12.1243 RMSElog: 12.1243
[epoch  0][iter  530] loss: 11.6290 RMSElog: 11.6290
[epoch  0][iter  540] loss: 9.8771 RMSElog: 9.8771
[epoch  0][iter  550] loss: 8.7852 RMSElog: 8.7852
[epoch  0][iter  560] loss: 10.2603 RMSElog: 10.2603
[epoch  0][iter  570] loss: 11.0731 RMSElog: 11.0731
[epoch  0][iter  580] loss: 10.5142 RMSElog: 10.5142
[epoch  0][iter  590] loss: 11.3436 RMSElog: 11.3436
[epoch  1][iter    0] loss: 11.1677 RMSElog: 11.1677
[epoch  1][iter   10] loss: 10.8231 RMSElog: 10.8231
[epoch  1][iter   20] loss: 10.6920 RMSElog: 10.6920
[epoch  1][iter   30] loss: 10.5555 RMSElog: 10.5555
[epoch  1][iter   40] loss: 10.9428 RMSElog: 10.9428
[epoch  1][iter   50] loss: 10.7747 RMSElog: 10.7747
[epoch  1][iter   60] loss: 11.7336 RMSElog: 11.7336
[epoch  1][iter   70] loss: 12.0463 RMSElog: 12.0463
[epoch  1][iter   80] loss: 10.5285 RMSElog: 10.5285
[epoch  1][iter   90] loss: 10.2210 RMSElog: 10.2210
[epoch  1][iter  100] loss: 8.8868 RMSElog: 8.8868
[epoch  1][iter  110] loss: 9.0043 RMSElog: 9.0043
[epoch  1][iter  120] loss: 11.2648 RMSElog: 11.2648
[epoch  1][iter  130] loss: 8.2009 RMSElog: 8.2009
[epoch  1][iter  140] loss: 9.2312 RMSElog: 9.2312
[epoch  1][iter  150] loss: 8.7642 RMSElog: 8.7642
[epoch  1][iter  160] loss: 9.2945 RMSElog: 9.2945
[epoch  1][iter  170] loss: 8.8702 RMSElog: 8.8702
[epoch  1][iter  180] loss: 9.5380 RMSElog: 9.5380
[epoch  1][iter  190] loss: 9.8026 RMSElog: 9.8026
[epoch  1][iter  200] loss: 7.8633 RMSElog: 7.8633
[epoch  1][iter  210] loss: 8.7638 RMSElog: 8.7638
[epoch  1][iter  220] loss: 7.5957 RMSElog: 7.5957
[epoch  1][iter  230] loss: 7.9361 RMSElog: 7.9361
[epoch  1][iter  240] loss: 9.7189 RMSElog: 9.7189
[epoch  1][iter  250] loss: 8.5704 RMSElog: 8.5704
[epoch  1][iter  260] loss: 7.5942 RMSElog: 7.5942
[epoch  1][iter  270] loss: 8.8199 RMSElog: 8.8199
[epoch  1][iter  280] loss: 9.7647 RMSElog: 9.7647
[epoch  1][iter  290] loss: 8.0695 RMSElog: 8.0695
[epoch  1][iter  300] loss: 9.3242 RMSElog: 9.3242
[epoch  1][iter  310] loss: 7.9987 RMSElog: 7.9987
[epoch  1][iter  320] loss: 8.6399 RMSElog: 8.6399
[epoch  1][iter  330] loss: 8.2092 RMSElog: 8.2092
[epoch  1][iter  340] loss: 9.2668 RMSElog: 9.2668
[epoch  1][iter  350] loss: 9.1257 RMSElog: 9.1257
[epoch  1][iter  360] loss: 7.3083 RMSElog: 7.3083
[epoch  1][iter  370] loss: 8.2468 RMSElog: 8.2468
[epoch  1][iter  380] loss: 8.1645 RMSElog: 8.1645
[epoch  1][iter  390] loss: 8.5666 RMSElog: 8.5666
[epoch  1][iter  400] loss: 7.4912 RMSElog: 7.4912
[epoch  1][iter  410] loss: 7.9566 RMSElog: 7.9566
[epoch  1][iter  420] loss: 7.9012 RMSElog: 7.9012
[epoch  1][iter  430] loss: 8.4932 RMSElog: 8.4932
[epoch  1][iter  440] loss: 7.4724 RMSElog: 7.4724
[epoch  1][iter  450] loss: 7.3397 RMSElog: 7.3397
[epoch  1][iter  460] loss: 8.1010 RMSElog: 8.1010
[epoch  1][iter  470] loss: 8.0158 RMSElog: 8.0158
[epoch  1][iter  480] loss: 7.6132 RMSElog: 7.6132
[epoch  1][iter  490] loss: 7.9198 RMSElog: 7.9198
[epoch  1][iter  500] loss: 8.0229 RMSElog: 8.0229
[epoch  1][iter  510] loss: 8.4781 RMSElog: 8.4781
[epoch  1][iter  520] loss: 8.4783 RMSElog: 8.4783
[epoch  1][iter  530] loss: 7.6145 RMSElog: 7.6145
[epoch  1][iter  540] loss: 7.2659 RMSElog: 7.2659
[epoch  1][iter  550] loss: 7.7402 RMSElog: 7.7402
[epoch  1][iter  560] loss: 7.8244 RMSElog: 7.8244
[epoch  1][iter  570] loss: 6.9314 RMSElog: 6.9314
[epoch  1][iter  580] loss: 6.8539 RMSElog: 6.8539
[epoch  1][iter  590] loss: 6.7607 RMSElog: 6.7607
[epoch  2][iter    0] loss: 7.3059 RMSElog: 7.3059
[epoch  2][iter   10] loss: 7.2381 RMSElog: 7.2381
[epoch  2][iter   20] loss: 8.0902 RMSElog: 8.0902
[epoch  2][iter   30] loss: 6.5403 RMSElog: 6.5403
[epoch  2][iter   40] loss: 6.9556 RMSElog: 6.9556
[epoch  2][iter   50] loss: 6.6547 RMSElog: 6.6547
[epoch  2][iter   60] loss: 7.0110 RMSElog: 7.0110
[epoch  2][iter   70] loss: 6.8127 RMSElog: 6.8127
[epoch  2][iter   80] loss: 8.0122 RMSElog: 8.0122
[epoch  2][iter   90] loss: 7.5896 RMSElog: 7.5896
[epoch  2][iter  100] loss: 7.3592 RMSElog: 7.3592
[epoch  2][iter  110] loss: 8.2809 RMSElog: 8.2809
[epoch  2][iter  120] loss: 8.0174 RMSElog: 8.0174
[epoch  2][iter  130] loss: 7.5284 RMSElog: 7.5284
[epoch  2][iter  140] loss: 7.2700 RMSElog: 7.2700
[epoch  2][iter  150] loss: 7.5596 RMSElog: 7.5596
[epoch  2][iter  160] loss: 6.9298 RMSElog: 6.9298
[epoch  2][iter  170] loss: 6.8665 RMSElog: 6.8665
[epoch  2][iter  180] loss: 7.0219 RMSElog: 7.0219
[epoch  2][iter  190] loss: 7.3646 RMSElog: 7.3646
[epoch  2][iter  200] loss: 6.8607 RMSElog: 6.8607
[epoch  2][iter  210] loss: 6.6196 RMSElog: 6.6196
[epoch  2][iter  220] loss: 7.0149 RMSElog: 7.0149
[epoch  2][iter  230] loss: 6.3849 RMSElog: 6.3849
[epoch  2][iter  240] loss: 6.6355 RMSElog: 6.6355
[epoch  2][iter  250] loss: 7.1866 RMSElog: 7.1866
[epoch  2][iter  260] loss: 6.8189 RMSElog: 6.8189
[epoch  2][iter  270] loss: 6.4762 RMSElog: 6.4762
[epoch  2][iter  280] loss: 6.2244 RMSElog: 6.2244
[epoch  2][iter  290] loss: 6.9740 RMSElog: 6.9740
[epoch  2][iter  300] loss: 6.1504 RMSElog: 6.1504
[epoch  2][iter  310] loss: 6.5336 RMSElog: 6.5336
[epoch  2][iter  320] loss: 5.6391 RMSElog: 5.6391
[epoch  2][iter  330] loss: 6.6238 RMSElog: 6.6238
[epoch  2][iter  340] loss: 6.1708 RMSElog: 6.1708
[epoch  2][iter  350] loss: 7.2006 RMSElog: 7.2006
[epoch  2][iter  360] loss: 6.2708 RMSElog: 6.2708
[epoch  2][iter  370] loss: 6.6475 RMSElog: 6.6475
[epoch  2][iter  380] loss: 6.6933 RMSElog: 6.6933
[epoch  2][iter  390] loss: 6.1026 RMSElog: 6.1026
[epoch  2][iter  400] loss: 6.2618 RMSElog: 6.2618
[epoch  2][iter  410] loss: 5.5076 RMSElog: 5.5076
[epoch  2][iter  420] loss: 6.4582 RMSElog: 6.4582
[epoch  2][iter  430] loss: 6.1373 RMSElog: 6.1373
[epoch  2][iter  440] loss: 6.4417 RMSElog: 6.4417
[epoch  2][iter  450] loss: 5.8935 RMSElog: 5.8935
[epoch  2][iter  460] loss: 6.4228 RMSElog: 6.4228
[epoch  2][iter  470] loss: 5.9333 RMSElog: 5.9333
[epoch  2][iter  480] loss: 7.2804 RMSElog: 7.2804
[epoch  2][iter  490] loss: 6.5133 RMSElog: 6.5133
[epoch  2][iter  500] loss: 6.4393 RMSElog: 6.4393
[epoch  2][iter  510] loss: 6.7900 RMSElog: 6.7900
[epoch  2][iter  520] loss: 6.5888 RMSElog: 6.5888
[epoch  2][iter  530] loss: 5.4792 RMSElog: 5.4792
[epoch  2][iter  540] loss: 5.9153 RMSElog: 5.9153
[epoch  2][iter  550] loss: 6.0061 RMSElog: 6.0061
[epoch  2][iter  560] loss: 6.9479 RMSElog: 6.9479
[epoch  2][iter  570] loss: 6.0260 RMSElog: 6.0260
[epoch  2][iter  580] loss: 5.7551 RMSElog: 5.7551
[epoch  2][iter  590] loss: 6.4477 RMSElog: 6.4477
[epoch  3][iter    0] loss: 6.2052 RMSElog: 6.2052
[epoch  3][iter   10] loss: 6.6836 RMSElog: 6.6836
[epoch  3][iter   20] loss: 5.7827 RMSElog: 5.7827
[epoch  3][iter   30] loss: 6.2119 RMSElog: 6.2119
[epoch  3][iter   40] loss: 6.6573 RMSElog: 6.6573
[epoch  3][iter   50] loss: 6.1243 RMSElog: 6.1243
[epoch  3][iter   60] loss: 5.6492 RMSElog: 5.6492
[epoch  3][iter   70] loss: 5.8806 RMSElog: 5.8806
[epoch  3][iter   80] loss: 6.2899 RMSElog: 6.2899
[epoch  3][iter   90] loss: 6.0462 RMSElog: 6.0462
[epoch  3][iter  100] loss: 6.1553 RMSElog: 6.1553
[epoch  3][iter  110] loss: 5.9717 RMSElog: 5.9717
[epoch  3][iter  120] loss: 6.1104 RMSElog: 6.1104
[epoch  3][iter  130] loss: 5.2113 RMSElog: 5.2113
[epoch  3][iter  140] loss: 5.6889 RMSElog: 5.6889
[epoch  3][iter  150] loss: 5.4275 RMSElog: 5.4275
[epoch  3][iter  160] loss: 6.1723 RMSElog: 6.1723
[epoch  3][iter  170] loss: 6.1166 RMSElog: 6.1166
[epoch  3][iter  180] loss: 5.7171 RMSElog: 5.7171
[epoch  3][iter  190] loss: 5.3952 RMSElog: 5.3952
[epoch  3][iter  200] loss: 5.9171 RMSElog: 5.9171
[epoch  3][iter  210] loss: 6.6464 RMSElog: 6.6464
[epoch  3][iter  220] loss: 6.8228 RMSElog: 6.8228
[epoch  3][iter  230] loss: 6.2652 RMSElog: 6.2652
[epoch  3][iter  240] loss: 6.9190 RMSElog: 6.9190
[epoch  3][iter  250] loss: 5.1716 RMSElog: 5.1716
[epoch  3][iter  260] loss: 5.8270 RMSElog: 5.8270
[epoch  3][iter  270] loss: 5.9408 RMSElog: 5.9408
[epoch  3][iter  280] loss: 5.9905 RMSElog: 5.9905
[epoch  3][iter  290] loss: 5.0539 RMSElog: 5.0539
[epoch  3][iter  300] loss: 5.1585 RMSElog: 5.1585
[epoch  3][iter  310] loss: 5.5144 RMSElog: 5.5144
[epoch  3][iter  320] loss: 7.1147 RMSElog: 7.1147
[epoch  3][iter  330] loss: 5.4715 RMSElog: 5.4715
[epoch  3][iter  340] loss: 6.4493 RMSElog: 6.4493
[epoch  3][iter  350] loss: 5.7186 RMSElog: 5.7186
[epoch  3][iter  360] loss: 6.2953 RMSElog: 6.2953
[epoch  3][iter  370] loss: 6.0744 RMSElog: 6.0744
[epoch  3][iter  380] loss: 7.1121 RMSElog: 7.1121
[epoch  3][iter  390] loss: 6.0913 RMSElog: 6.0913
[epoch  3][iter  400] loss: 6.6306 RMSElog: 6.6306
[epoch  3][iter  410] loss: 6.7964 RMSElog: 6.7964
[epoch  3][iter  420] loss: 5.7948 RMSElog: 5.7948
[epoch  3][iter  430] loss: 6.2882 RMSElog: 6.2882
[epoch  3][iter  440] loss: 5.5131 RMSElog: 5.5131
[epoch  3][iter  450] loss: 6.9347 RMSElog: 6.9347
[epoch  3][iter  460] loss: 6.1463 RMSElog: 6.1463
[epoch  3][iter  470] loss: 6.4575 RMSElog: 6.4575
[epoch  3][iter  480] loss: 5.9582 RMSElog: 5.9582
[epoch  3][iter  490] loss: 6.8396 RMSElog: 6.8396
[epoch  3][iter  500] loss: 6.0059 RMSElog: 6.0059
[epoch  3][iter  510] loss: 5.1268 RMSElog: 5.1268
[epoch  3][iter  520] loss: 6.8372 RMSElog: 6.8372
[epoch  3][iter  530] loss: 5.4893 RMSElog: 5.4893
[epoch  3][iter  540] loss: 5.5412 RMSElog: 5.5412
[epoch  3][iter  550] loss: 5.1395 RMSElog: 5.1395
[epoch  3][iter  560] loss: 5.9439 RMSElog: 5.9439
[epoch  3][iter  570] loss: 5.7445 RMSElog: 5.7445
[epoch  3][iter  580] loss: 5.7615 RMSElog: 5.7615
[epoch  3][iter  590] loss: 5.4210 RMSElog: 5.4210
[epoch  4][iter    0] loss: 6.6414 RMSElog: 6.6414
[epoch  4][iter   10] loss: 5.1636 RMSElog: 5.1636
[epoch  4][iter   20] loss: 5.3981 RMSElog: 5.3981
[epoch  4][iter   30] loss: 5.2679 RMSElog: 5.2679
[epoch  4][iter   40] loss: 6.0154 RMSElog: 6.0154
[epoch  4][iter   50] loss: 6.1305 RMSElog: 6.1305
[epoch  4][iter   60] loss: 6.5648 RMSElog: 6.5648
[epoch  4][iter   70] loss: 6.1077 RMSElog: 6.1077
[epoch  4][iter   80] loss: 5.4509 RMSElog: 5.4509
[epoch  4][iter   90] loss: 5.4115 RMSElog: 5.4115
[epoch  4][iter  100] loss: 6.1082 RMSElog: 6.1082
[epoch  4][iter  110] loss: 5.3696 RMSElog: 5.3696
[epoch  4][iter  120] loss: 5.7240 RMSElog: 5.7240
[epoch  4][iter  130] loss: 5.8511 RMSElog: 5.8511
[epoch  4][iter  140] loss: 6.1628 RMSElog: 6.1628
[epoch  4][iter  150] loss: 6.0477 RMSElog: 6.0477
[epoch  4][iter  160] loss: 5.7071 RMSElog: 5.7071
[epoch  4][iter  170] loss: 5.7842 RMSElog: 5.7842
[epoch  4][iter  180] loss: 5.9395 RMSElog: 5.9395
[epoch  4][iter  190] loss: 5.0805 RMSElog: 5.0805
[epoch  4][iter  200] loss: 5.7484 RMSElog: 5.7484
[epoch  4][iter  210] loss: 6.1010 RMSElog: 6.1010
[epoch  4][iter  220] loss: 6.1074 RMSElog: 6.1074
[epoch  4][iter  230] loss: 5.8011 RMSElog: 5.8011
[epoch  4][iter  240] loss: 5.3772 RMSElog: 5.3772
[epoch  4][iter  250] loss: 5.4910 RMSElog: 5.4910
[epoch  4][iter  260] loss: 7.0075 RMSElog: 7.0075
[epoch  4][iter  270] loss: 6.8663 RMSElog: 6.8663
[epoch  4][iter  280] loss: 6.2385 RMSElog: 6.2385
[epoch  4][iter  290] loss: 5.4339 RMSElog: 5.4339
[epoch  4][iter  300] loss: 5.5182 RMSElog: 5.5182
[epoch  4][iter  310] loss: 5.2589 RMSElog: 5.2589
[epoch  4][iter  320] loss: 5.1099 RMSElog: 5.1099
[epoch  4][iter  330] loss: 5.6094 RMSElog: 5.6094
[epoch  4][iter  340] loss: 5.4759 RMSElog: 5.4759
[epoch  4][iter  350] loss: 5.6739 RMSElog: 5.6739
[epoch  4][iter  360] loss: 5.8449 RMSElog: 5.8449
[epoch  4][iter  370] loss: 5.4638 RMSElog: 5.4638
[epoch  4][iter  380] loss: 6.1392 RMSElog: 6.1392
[epoch  4][iter  390] loss: 5.8367 RMSElog: 5.8367
[epoch  4][iter  400] loss: 6.1967 RMSElog: 6.1967
[epoch  4][iter  410] loss: 5.0104 RMSElog: 5.0104
[epoch  4][iter  420] loss: 6.2811 RMSElog: 6.2811
[epoch  4][iter  430] loss: 6.0872 RMSElog: 6.0872
[epoch  4][iter  440] loss: 5.6767 RMSElog: 5.6767
[epoch  4][iter  450] loss: 6.0812 RMSElog: 6.0812
[epoch  4][iter  460] loss: 5.5090 RMSElog: 5.5090
[epoch  4][iter  470] loss: 6.9991 RMSElog: 6.9991
[epoch  4][iter  480] loss: 6.1866 RMSElog: 6.1866
[epoch  4][iter  490] loss: 5.6333 RMSElog: 5.6333
[epoch  4][iter  500] loss: 6.0609 RMSElog: 6.0609
[epoch  4][iter  510] loss: 5.6544 RMSElog: 5.6544
[epoch  4][iter  520] loss: 5.8123 RMSElog: 5.8123
[epoch  4][iter  530] loss: 5.5600 RMSElog: 5.5600
[epoch  4][iter  540] loss: 5.5026 RMSElog: 5.5026
[epoch  4][iter  550] loss: 6.3512 RMSElog: 6.3512
[epoch  4][iter  560] loss: 5.5387 RMSElog: 5.5387
[epoch  4][iter  570] loss: 6.0458 RMSElog: 6.0458
[epoch  4][iter  580] loss: 5.5963 RMSElog: 5.5963
[epoch  4][iter  590] loss: 5.7454 RMSElog: 5.7454
[epoch  5][iter    0] loss: 4.8002 RMSElog: 4.8002
[epoch  5][iter   10] loss: 5.2709 RMSElog: 5.2709
[epoch  5][iter   20] loss: 5.6596 RMSElog: 5.6596
[epoch  5][iter   30] loss: 4.8475 RMSElog: 4.8475
[epoch  5][iter   40] loss: 6.5543 RMSElog: 6.5543
[epoch  5][iter   50] loss: 5.5289 RMSElog: 5.5289
[epoch  5][iter   60] loss: 6.2086 RMSElog: 6.2086
[epoch  5][iter   70] loss: 5.2048 RMSElog: 5.2048
[epoch  5][iter   80] loss: 5.5348 RMSElog: 5.5348
[epoch  5][iter   90] loss: 5.6463 RMSElog: 5.6463
[epoch  5][iter  100] loss: 5.6092 RMSElog: 5.6092
[epoch  5][iter  110] loss: 5.7252 RMSElog: 5.7252
[epoch  5][iter  120] loss: 5.7271 RMSElog: 5.7271
[epoch  5][iter  130] loss: 5.6613 RMSElog: 5.6613
[epoch  5][iter  140] loss: 4.8070 RMSElog: 4.8070
[epoch  5][iter  150] loss: 6.2420 RMSElog: 6.2420
[epoch  5][iter  160] loss: 5.5160 RMSElog: 5.5160
[epoch  5][iter  170] loss: 5.9160 RMSElog: 5.9160
[epoch  5][iter  180] loss: 5.1446 RMSElog: 5.1446
[epoch  5][iter  190] loss: 4.7007 RMSElog: 4.7007
[epoch  5][iter  200] loss: 5.7174 RMSElog: 5.7174
[epoch  5][iter  210] loss: 6.2362 RMSElog: 6.2362
[epoch  5][iter  220] loss: 5.4199 RMSElog: 5.4199
[epoch  5][iter  230] loss: 4.9257 RMSElog: 4.9257
[epoch  5][iter  240] loss: 5.0152 RMSElog: 5.0152
[epoch  5][iter  250] loss: 5.0542 RMSElog: 5.0542
[epoch  5][iter  260] loss: 6.2601 RMSElog: 6.2601
[epoch  5][iter  270] loss: 6.1462 RMSElog: 6.1462
[epoch  5][iter  280] loss: 5.9504 RMSElog: 5.9504
[epoch  5][iter  290] loss: 5.6144 RMSElog: 5.6144
[epoch  5][iter  300] loss: 5.0645 RMSElog: 5.0645
[epoch  5][iter  310] loss: 5.3860 RMSElog: 5.3860
[epoch  5][iter  320] loss: 5.1694 RMSElog: 5.1694
[epoch  5][iter  330] loss: 5.2036 RMSElog: 5.2036
[epoch  5][iter  340] loss: 5.1200 RMSElog: 5.1200
[epoch  5][iter  350] loss: 5.7989 RMSElog: 5.7989
[epoch  5][iter  360] loss: 5.6585 RMSElog: 5.6585
[epoch  5][iter  370] loss: 5.1410 RMSElog: 5.1410
[epoch  5][iter  380] loss: 5.8158 RMSElog: 5.8158
[epoch  5][iter  390] loss: 4.5841 RMSElog: 4.5841
[epoch  5][iter  400] loss: 5.9675 RMSElog: 5.9675
[epoch  5][iter  410] loss: 5.8208 RMSElog: 5.8208
[epoch  5][iter  420] loss: 5.5196 RMSElog: 5.5196
[epoch  5][iter  430] loss: 6.0567 RMSElog: 6.0567
[epoch  5][iter  440] loss: 5.0318 RMSElog: 5.0318
[epoch  5][iter  450] loss: 5.2930 RMSElog: 5.2930
[epoch  5][iter  460] loss: 5.2188 RMSElog: 5.2188
[epoch  5][iter  470] loss: 5.8413 RMSElog: 5.8413
[epoch  5][iter  480] loss: 5.2054 RMSElog: 5.2054
[epoch  5][iter  490] loss: 5.8031 RMSElog: 5.8031
[epoch  5][iter  500] loss: 5.0903 RMSElog: 5.0903
[epoch  5][iter  510] loss: 5.2837 RMSElog: 5.2837
[epoch  5][iter  520] loss: 4.9141 RMSElog: 4.9141
[epoch  5][iter  530] loss: 5.2677 RMSElog: 5.2677
[epoch  5][iter  540] loss: 5.7726 RMSElog: 5.7726
[epoch  5][iter  550] loss: 5.2475 RMSElog: 5.2475
[epoch  5][iter  560] loss: 5.8168 RMSElog: 5.8168
[epoch  5][iter  570] loss: 5.7852 RMSElog: 5.7852
[epoch  5][iter  580] loss: 5.0446 RMSElog: 5.0446
[epoch  5][iter  590] loss: 5.4802 RMSElog: 5.4802
[epoch  6][iter    0] loss: 5.0873 RMSElog: 5.0873
[epoch  6][iter   10] loss: 4.9962 RMSElog: 4.9962
[epoch  6][iter   20] loss: 5.7707 RMSElog: 5.7707
[epoch  6][iter   30] loss: 5.5003 RMSElog: 5.5003
[epoch  6][iter   40] loss: 4.7464 RMSElog: 4.7464
[epoch  6][iter   50] loss: 6.3937 RMSElog: 6.3937
[epoch  6][iter   60] loss: 4.5379 RMSElog: 4.5379
[epoch  6][iter   70] loss: 5.1598 RMSElog: 5.1598
[epoch  6][iter   80] loss: 6.0112 RMSElog: 6.0112
[epoch  6][iter   90] loss: 5.2009 RMSElog: 5.2009
[epoch  6][iter  100] loss: 4.3320 RMSElog: 4.3320
[epoch  6][iter  110] loss: 5.6569 RMSElog: 5.6569
[epoch  6][iter  120] loss: 5.2183 RMSElog: 5.2183
[epoch  6][iter  130] loss: 6.0907 RMSElog: 6.0907
[epoch  6][iter  140] loss: 4.6990 RMSElog: 4.6990
[epoch  6][iter  150] loss: 5.4308 RMSElog: 5.4308
[epoch  6][iter  160] loss: 4.2072 RMSElog: 4.2072
[epoch  6][iter  170] loss: 5.2965 RMSElog: 5.2965
[epoch  6][iter  180] loss: 4.9923 RMSElog: 4.9923
[epoch  6][iter  190] loss: 5.2633 RMSElog: 5.2633
[epoch  6][iter  200] loss: 5.9130 RMSElog: 5.9130
[epoch  6][iter  210] loss: 4.5716 RMSElog: 4.5716
[epoch  6][iter  220] loss: 5.5293 RMSElog: 5.5293
[epoch  6][iter  230] loss: 5.1250 RMSElog: 5.1250
[epoch  6][iter  240] loss: 4.4891 RMSElog: 4.4891
[epoch  6][iter  250] loss: 5.8056 RMSElog: 5.8056
[epoch  6][iter  260] loss: 5.6890 RMSElog: 5.6890
[epoch  6][iter  270] loss: 4.8817 RMSElog: 4.8817
[epoch  6][iter  280] loss: 4.6909 RMSElog: 4.6909
[epoch  6][iter  290] loss: 4.9495 RMSElog: 4.9495
[epoch  6][iter  300] loss: 5.0833 RMSElog: 5.0833
[epoch  6][iter  310] loss: 4.9346 RMSElog: 4.9346
[epoch  6][iter  320] loss: 4.9945 RMSElog: 4.9945
[epoch  6][iter  330] loss: 6.2338 RMSElog: 6.2338
[epoch  6][iter  340] loss: 5.8129 RMSElog: 5.8129
[epoch  6][iter  350] loss: 5.5655 RMSElog: 5.5655
[epoch  6][iter  360] loss: 5.8499 RMSElog: 5.8499
[epoch  6][iter  370] loss: 4.6450 RMSElog: 4.6450
[epoch  6][iter  380] loss: 5.4341 RMSElog: 5.4341
[epoch  6][iter  390] loss: 5.0572 RMSElog: 5.0572
[epoch  6][iter  400] loss: 5.8759 RMSElog: 5.8759
[epoch  6][iter  410] loss: 4.7861 RMSElog: 4.7861
[epoch  6][iter  420] loss: 5.6501 RMSElog: 5.6501
[epoch  6][iter  430] loss: 5.1958 RMSElog: 5.1958
[epoch  6][iter  440] loss: 5.5384 RMSElog: 5.5384
[epoch  6][iter  450] loss: 5.2626 RMSElog: 5.2626
[epoch  6][iter  460] loss: 5.4737 RMSElog: 5.4737
[epoch  6][iter  470] loss: 5.2024 RMSElog: 5.2024
[epoch  6][iter  480] loss: 5.0459 RMSElog: 5.0459
[epoch  6][iter  490] loss: 6.1842 RMSElog: 6.1842
[epoch  6][iter  500] loss: 5.2020 RMSElog: 5.2020
[epoch  6][iter  510] loss: 5.6652 RMSElog: 5.6652
[epoch  6][iter  520] loss: 5.2515 RMSElog: 5.2515
[epoch  6][iter  530] loss: 5.2627 RMSElog: 5.2627
[epoch  6][iter  540] loss: 6.3255 RMSElog: 6.3255
[epoch  6][iter  550] loss: 5.7310 RMSElog: 5.7310
[epoch  6][iter  560] loss: 6.2334 RMSElog: 6.2334
[epoch  6][iter  570] loss: 5.2664 RMSElog: 5.2664
[epoch  6][iter  580] loss: 5.4916 RMSElog: 5.4916
[epoch  6][iter  590] loss: 4.9486 RMSElog: 4.9486
[epoch  7][iter    0] loss: 5.2978 RMSElog: 5.2978
[epoch  7][iter   10] loss: 4.5241 RMSElog: 4.5241
[epoch  7][iter   20] loss: 5.5602 RMSElog: 5.5602
[epoch  7][iter   30] loss: 5.7203 RMSElog: 5.7203
[epoch  7][iter   40] loss: 5.2281 RMSElog: 5.2281
[epoch  7][iter   50] loss: 5.1690 RMSElog: 5.1690
[epoch  7][iter   60] loss: 5.2082 RMSElog: 5.2082
[epoch  7][iter   70] loss: 5.1259 RMSElog: 5.1259
[epoch  7][iter   80] loss: 5.1605 RMSElog: 5.1605
[epoch  7][iter   90] loss: 5.9491 RMSElog: 5.9491
[epoch  7][iter  100] loss: 4.9436 RMSElog: 4.9436
[epoch  7][iter  110] loss: 4.8377 RMSElog: 4.8377
[epoch  7][iter  120] loss: 5.8071 RMSElog: 5.8071
[epoch  7][iter  130] loss: 5.3612 RMSElog: 5.3612
[epoch  7][iter  140] loss: 4.8820 RMSElog: 4.8820
[epoch  7][iter  150] loss: 6.2866 RMSElog: 6.2866
[epoch  7][iter  160] loss: 5.2186 RMSElog: 5.2186
[epoch  7][iter  170] loss: 4.9592 RMSElog: 4.9592
[epoch  7][iter  180] loss: 5.0654 RMSElog: 5.0654
[epoch  7][iter  190] loss: 5.1919 RMSElog: 5.1919
[epoch  7][iter  200] loss: 5.4938 RMSElog: 5.4938
[epoch  7][iter  210] loss: 5.3367 RMSElog: 5.3367
[epoch  7][iter  220] loss: 4.8507 RMSElog: 4.8507
[epoch  7][iter  230] loss: 6.1804 RMSElog: 6.1804
[epoch  7][iter  240] loss: 5.7960 RMSElog: 5.7960
[epoch  7][iter  250] loss: 5.0672 RMSElog: 5.0672
[epoch  7][iter  260] loss: 5.4199 RMSElog: 5.4199
[epoch  7][iter  270] loss: 5.3407 RMSElog: 5.3407
[epoch  7][iter  280] loss: 5.7538 RMSElog: 5.7538
[epoch  7][iter  290] loss: 5.1394 RMSElog: 5.1394
[epoch  7][iter  300] loss: 5.5067 RMSElog: 5.5067
[epoch  7][iter  310] loss: 5.4716 RMSElog: 5.4716
[epoch  7][iter  320] loss: 5.7997 RMSElog: 5.7997
[epoch  7][iter  330] loss: 5.8848 RMSElog: 5.8848
[epoch  7][iter  340] loss: 5.3071 RMSElog: 5.3071
[epoch  7][iter  350] loss: 5.2495 RMSElog: 5.2495
[epoch  7][iter  360] loss: 4.8227 RMSElog: 4.8227
[epoch  7][iter  370] loss: 5.4544 RMSElog: 5.4544
[epoch  7][iter  380] loss: 5.4856 RMSElog: 5.4856
[epoch  7][iter  390] loss: 4.6008 RMSElog: 4.6008
[epoch  7][iter  400] loss: 5.2874 RMSElog: 5.2874
[epoch  7][iter  410] loss: 6.0944 RMSElog: 6.0944
[epoch  7][iter  420] loss: 5.3417 RMSElog: 5.3417
[epoch  7][iter  430] loss: 5.4090 RMSElog: 5.4090
[epoch  7][iter  440] loss: 5.5888 RMSElog: 5.5888
[epoch  7][iter  450] loss: 5.8728 RMSElog: 5.8728
[epoch  7][iter  460] loss: 6.1368 RMSElog: 6.1368
[epoch  7][iter  470] loss: 4.8368 RMSElog: 4.8368
[epoch  7][iter  480] loss: 5.0374 RMSElog: 5.0374
[epoch  7][iter  490] loss: 5.7336 RMSElog: 5.7336
[epoch  7][iter  500] loss: 5.5434 RMSElog: 5.5434
[epoch  7][iter  510] loss: 5.6546 RMSElog: 5.6546
[epoch  7][iter  520] loss: 5.4722 RMSElog: 5.4722
[epoch  7][iter  530] loss: 6.2276 RMSElog: 6.2276
[epoch  7][iter  540] loss: 5.8680 RMSElog: 5.8680
[epoch  7][iter  550] loss: 5.5427 RMSElog: 5.5427
[epoch  7][iter  560] loss: 5.4842 RMSElog: 5.4842
[epoch  7][iter  570] loss: 6.0466 RMSElog: 6.0466
[epoch  7][iter  580] loss: 4.9770 RMSElog: 4.9770
[epoch  7][iter  590] loss: 6.1451 RMSElog: 6.1451
[epoch  8][iter    0] loss: 6.2123 RMSElog: 6.2123
[epoch  8][iter   10] loss: 5.1346 RMSElog: 5.1346
[epoch  8][iter   20] loss: 5.7314 RMSElog: 5.7314
[epoch  8][iter   30] loss: 4.7348 RMSElog: 4.7348
[epoch  8][iter   40] loss: 5.3963 RMSElog: 5.3963
[epoch  8][iter   50] loss: 5.1033 RMSElog: 5.1033
[epoch  8][iter   60] loss: 5.5438 RMSElog: 5.5438
[epoch  8][iter   70] loss: 5.6445 RMSElog: 5.6445
[epoch  8][iter   80] loss: 5.3606 RMSElog: 5.3606
[epoch  8][iter   90] loss: 5.2243 RMSElog: 5.2243
[epoch  8][iter  100] loss: 4.6182 RMSElog: 4.6182
[epoch  8][iter  110] loss: 5.0513 RMSElog: 5.0513
[epoch  8][iter  120] loss: 5.2239 RMSElog: 5.2239
[epoch  8][iter  130] loss: 6.0249 RMSElog: 6.0249
[epoch  8][iter  140] loss: 5.3349 RMSElog: 5.3349
[epoch  8][iter  150] loss: 6.1006 RMSElog: 6.1006
[epoch  8][iter  160] loss: 4.9996 RMSElog: 4.9996
[epoch  8][iter  170] loss: 5.1650 RMSElog: 5.1650
[epoch  8][iter  180] loss: 5.2393 RMSElog: 5.2393
[epoch  8][iter  190] loss: 5.9446 RMSElog: 5.9446
[epoch  8][iter  200] loss: 5.1060 RMSElog: 5.1060
[epoch  8][iter  210] loss: 4.4147 RMSElog: 4.4147
[epoch  8][iter  220] loss: 5.2890 RMSElog: 5.2890
[epoch  8][iter  230] loss: 5.0345 RMSElog: 5.0345
[epoch  8][iter  240] loss: 5.2361 RMSElog: 5.2361
[epoch  8][iter  250] loss: 4.4309 RMSElog: 4.4309
[epoch  8][iter  260] loss: 5.2967 RMSElog: 5.2967
[epoch  8][iter  270] loss: 4.8284 RMSElog: 4.8284
[epoch  8][iter  280] loss: 5.4880 RMSElog: 5.4880
[epoch  8][iter  290] loss: 5.7615 RMSElog: 5.7615
[epoch  8][iter  300] loss: 6.1538 RMSElog: 6.1538
[epoch  8][iter  310] loss: 4.9350 RMSElog: 4.9350
[epoch  8][iter  320] loss: 5.6208 RMSElog: 5.6208
[epoch  8][iter  330] loss: 5.8076 RMSElog: 5.8076
[epoch  8][iter  340] loss: 5.5031 RMSElog: 5.5031
[epoch  8][iter  350] loss: 5.9266 RMSElog: 5.9266
[epoch  8][iter  360] loss: 5.9273 RMSElog: 5.9273
[epoch  8][iter  370] loss: 5.0374 RMSElog: 5.0374
[epoch  8][iter  380] loss: 5.1140 RMSElog: 5.1140
[epoch  8][iter  390] loss: 4.8735 RMSElog: 4.8735
[epoch  8][iter  400] loss: 5.6963 RMSElog: 5.6963
[epoch  8][iter  410] loss: 5.5852 RMSElog: 5.5852
[epoch  8][iter  420] loss: 5.0969 RMSElog: 5.0969
[epoch  8][iter  430] loss: 5.0675 RMSElog: 5.0675
[epoch  8][iter  440] loss: 5.4745 RMSElog: 5.4745
[epoch  8][iter  450] loss: 5.2474 RMSElog: 5.2474
[epoch  8][iter  460] loss: 5.8765 RMSElog: 5.8765
[epoch  8][iter  470] loss: 5.3567 RMSElog: 5.3567
[epoch  8][iter  480] loss: 5.5808 RMSElog: 5.5808
[epoch  8][iter  490] loss: 4.8113 RMSElog: 4.8113
[epoch  8][iter  500] loss: 5.7638 RMSElog: 5.7638
[epoch  8][iter  510] loss: 5.6225 RMSElog: 5.6225
[epoch  8][iter  520] loss: 5.4963 RMSElog: 5.4963
[epoch  8][iter  530] loss: 4.8931 RMSElog: 4.8931
[epoch  8][iter  540] loss: 5.3852 RMSElog: 5.3852
[epoch  8][iter  550] loss: 5.8276 RMSElog: 5.8276
[epoch  8][iter  560] loss: 5.3978 RMSElog: 5.3978
[epoch  8][iter  570] loss: 5.4551 RMSElog: 5.4551
[epoch  8][iter  580] loss: 5.2500 RMSElog: 5.2500
[epoch  8][iter  590] loss: 6.0952 RMSElog: 6.0952
[epoch  9][iter    0] loss: 5.2608 RMSElog: 5.2608
[epoch  9][iter   10] loss: 5.2012 RMSElog: 5.2012
[epoch  9][iter   20] loss: 5.7290 RMSElog: 5.7290
[epoch  9][iter   30] loss: 5.5106 RMSElog: 5.5106
[epoch  9][iter   40] loss: 4.9621 RMSElog: 4.9621
[epoch  9][iter   50] loss: 5.8247 RMSElog: 5.8247
[epoch  9][iter   60] loss: 5.3721 RMSElog: 5.3721
[epoch  9][iter   70] loss: 4.6701 RMSElog: 4.6701
[epoch  9][iter   80] loss: 5.9224 RMSElog: 5.9224
[epoch  9][iter   90] loss: 5.1172 RMSElog: 5.1172
[epoch  9][iter  100] loss: 5.3472 RMSElog: 5.3472
[epoch  9][iter  110] loss: 5.7000 RMSElog: 5.7000
[epoch  9][iter  120] loss: 5.5184 RMSElog: 5.5184
[epoch  9][iter  130] loss: 5.0179 RMSElog: 5.0179
[epoch  9][iter  140] loss: 5.9258 RMSElog: 5.9258
[epoch  9][iter  150] loss: 4.5670 RMSElog: 4.5670
[epoch  9][iter  160] loss: 4.8798 RMSElog: 4.8798
[epoch  9][iter  170] loss: 6.1504 RMSElog: 6.1504
[epoch  9][iter  180] loss: 5.7018 RMSElog: 5.7018
[epoch  9][iter  190] loss: 5.4350 RMSElog: 5.4350
[epoch  9][iter  200] loss: 6.1941 RMSElog: 6.1941
[epoch  9][iter  210] loss: 5.6169 RMSElog: 5.6169
[epoch  9][iter  220] loss: 5.4006 RMSElog: 5.4006
[epoch  9][iter  230] loss: 5.6909 RMSElog: 5.6909
[epoch  9][iter  240] loss: 4.6623 RMSElog: 4.6623
[epoch  9][iter  250] loss: 5.1319 RMSElog: 5.1319
[epoch  9][iter  260] loss: 4.6724 RMSElog: 4.6724
[epoch  9][iter  270] loss: 5.1386 RMSElog: 5.1386
[epoch  9][iter  280] loss: 5.4721 RMSElog: 5.4721
[epoch  9][iter  290] loss: 5.6441 RMSElog: 5.6441
[epoch  9][iter  300] loss: 5.3907 RMSElog: 5.3907
[epoch  9][iter  310] loss: 4.9222 RMSElog: 4.9222
[epoch  9][iter  320] loss: 4.4514 RMSElog: 4.4514
[epoch  9][iter  330] loss: 5.1193 RMSElog: 5.1193
[epoch  9][iter  340] loss: 4.5006 RMSElog: 4.5006
[epoch  9][iter  350] loss: 5.2038 RMSElog: 5.2038
[epoch  9][iter  360] loss: 5.6627 RMSElog: 5.6627
[epoch  9][iter  370] loss: 5.5789 RMSElog: 5.5789
[epoch  9][iter  380] loss: 4.9686 RMSElog: 4.9686
[epoch  9][iter  390] loss: 4.8054 RMSElog: 4.8054
[epoch  9][iter  400] loss: 5.0700 RMSElog: 5.0700
[epoch  9][iter  410] loss: 5.3897 RMSElog: 5.3897
[epoch  9][iter  420] loss: 4.7193 RMSElog: 4.7193
[epoch  9][iter  430] loss: 5.0106 RMSElog: 5.0106
[epoch  9][iter  440] loss: 5.7118 RMSElog: 5.7118
[epoch  9][iter  450] loss: 5.2686 RMSElog: 5.2686
[epoch  9][iter  460] loss: 5.6871 RMSElog: 5.6871
[epoch  9][iter  470] loss: 5.7542 RMSElog: 5.7542
[epoch  9][iter  480] loss: 5.5190 RMSElog: 5.5190
[epoch  9][iter  490] loss: 4.9680 RMSElog: 4.9680
[epoch  9][iter  500] loss: 4.9195 RMSElog: 4.9195
[epoch  9][iter  510] loss: 6.1657 RMSElog: 6.1657
[epoch  9][iter  520] loss: 5.0399 RMSElog: 5.0399
[epoch  9][iter  530] loss: 5.8317 RMSElog: 5.8317
[epoch  9][iter  540] loss: 5.3630 RMSElog: 5.3630
[epoch  9][iter  550] loss: 4.6785 RMSElog: 4.6785
[epoch  9][iter  560] loss: 4.5793 RMSElog: 4.5793
[epoch  9][iter  570] loss: 5.4561 RMSElog: 5.4561
[epoch  9][iter  580] loss: 5.1316 RMSElog: 5.1316
[epoch  9][iter  590] loss: 4.8236 RMSElog: 4.8236
[epoch 10][iter    0] loss: 5.1770 RMSElog: 5.1770
[epoch 10][iter   10] loss: 4.8869 RMSElog: 4.8869
[epoch 10][iter   20] loss: 5.1083 RMSElog: 5.1083
[epoch 10][iter   30] loss: 5.0273 RMSElog: 5.0273
[epoch 10][iter   40] loss: 5.3808 RMSElog: 5.3808
[epoch 10][iter   50] loss: 6.2824 RMSElog: 6.2824
[epoch 10][iter   60] loss: 5.6535 RMSElog: 5.6535
[epoch 10][iter   70] loss: 5.1987 RMSElog: 5.1987
[epoch 10][iter   80] loss: 5.6864 RMSElog: 5.6864
[epoch 10][iter   90] loss: 5.1694 RMSElog: 5.1694
[epoch 10][iter  100] loss: 4.4456 RMSElog: 4.4456
[epoch 10][iter  110] loss: 5.4358 RMSElog: 5.4358
[epoch 10][iter  120] loss: 5.3549 RMSElog: 5.3549
[epoch 10][iter  130] loss: 5.3039 RMSElog: 5.3039
[epoch 10][iter  140] loss: 5.5721 RMSElog: 5.5721
[epoch 10][iter  150] loss: 5.5175 RMSElog: 5.5175
[epoch 10][iter  160] loss: 5.0729 RMSElog: 5.0729
[epoch 10][iter  170] loss: 5.3275 RMSElog: 5.3275
[epoch 10][iter  180] loss: 4.4939 RMSElog: 4.4939
[epoch 10][iter  190] loss: 5.5858 RMSElog: 5.5858
[epoch 10][iter  200] loss: 5.6108 RMSElog: 5.6108
[epoch 10][iter  210] loss: 4.4569 RMSElog: 4.4569
[epoch 10][iter  220] loss: 5.9736 RMSElog: 5.9736
[epoch 10][iter  230] loss: 5.6771 RMSElog: 5.6771
[epoch 10][iter  240] loss: 5.0988 RMSElog: 5.0988
[epoch 10][iter  250] loss: 5.1977 RMSElog: 5.1977
[epoch 10][iter  260] loss: 5.3677 RMSElog: 5.3677
[epoch 10][iter  270] loss: 5.4463 RMSElog: 5.4463
[epoch 10][iter  280] loss: 4.7318 RMSElog: 4.7318
[epoch 10][iter  290] loss: 5.9675 RMSElog: 5.9675
[epoch 10][iter  300] loss: 5.0597 RMSElog: 5.0597
[epoch 10][iter  310] loss: 5.1321 RMSElog: 5.1321
[epoch 10][iter  320] loss: 4.4818 RMSElog: 4.4818
[epoch 10][iter  330] loss: 4.9530 RMSElog: 4.9530
[epoch 10][iter  340] loss: 4.8022 RMSElog: 4.8022
[epoch 10][iter  350] loss: 5.3760 RMSElog: 5.3760
[epoch 10][iter  360] loss: 5.8353 RMSElog: 5.8353
[epoch 10][iter  370] loss: 5.1508 RMSElog: 5.1508
[epoch 10][iter  380] loss: 5.1025 RMSElog: 5.1025
[epoch 10][iter  390] loss: 5.4598 RMSElog: 5.4598
[epoch 10][iter  400] loss: 5.2767 RMSElog: 5.2767
[epoch 10][iter  410] loss: 4.5046 RMSElog: 4.5046
[epoch 10][iter  420] loss: 4.7920 RMSElog: 4.7920
[epoch 10][iter  430] loss: 5.6700 RMSElog: 5.6700
[epoch 10][iter  440] loss: 5.0194 RMSElog: 5.0194
[epoch 10][iter  450] loss: 6.0469 RMSElog: 6.0469
[epoch 10][iter  460] loss: 5.7837 RMSElog: 5.7837
[epoch 10][iter  470] loss: 4.4930 RMSElog: 4.4930
[epoch 10][iter  480] loss: 4.8281 RMSElog: 4.8281
[epoch 10][iter  490] loss: 4.9783 RMSElog: 4.9783
[epoch 10][iter  500] loss: 5.3361 RMSElog: 5.3361
[epoch 10][iter  510] loss: 5.8681 RMSElog: 5.8681
[epoch 10][iter  520] loss: 5.6684 RMSElog: 5.6684
[epoch 10][iter  530] loss: 5.9909 RMSElog: 5.9909
[epoch 10][iter  540] loss: 5.0043 RMSElog: 5.0043
[epoch 10][iter  550] loss: 4.3956 RMSElog: 4.3956
[epoch 10][iter  560] loss: 5.3790 RMSElog: 5.3790
[epoch 10][iter  570] loss: 5.0467 RMSElog: 5.0467
[epoch 10][iter  580] loss: 4.9928 RMSElog: 4.9928
[epoch 10][iter  590] loss: 4.8024 RMSElog: 4.8024
[epoch 11][iter    0] loss: 5.7233 RMSElog: 5.7233
[epoch 11][iter   10] loss: 4.7057 RMSElog: 4.7057
[epoch 11][iter   20] loss: 5.4114 RMSElog: 5.4114
[epoch 11][iter   30] loss: 4.6650 RMSElog: 4.6650
[epoch 11][iter   40] loss: 4.2553 RMSElog: 4.2553
[epoch 11][iter   50] loss: 6.3173 RMSElog: 6.3173
[epoch 11][iter   60] loss: 4.6124 RMSElog: 4.6124
[epoch 11][iter   70] loss: 4.8537 RMSElog: 4.8537
[epoch 11][iter   80] loss: 6.2085 RMSElog: 6.2085
[epoch 11][iter   90] loss: 5.0211 RMSElog: 5.0211
[epoch 11][iter  100] loss: 4.7715 RMSElog: 4.7715
[epoch 11][iter  110] loss: 5.5169 RMSElog: 5.5169
[epoch 11][iter  120] loss: 5.5876 RMSElog: 5.5876
[epoch 11][iter  130] loss: 5.2360 RMSElog: 5.2360
[epoch 11][iter  140] loss: 5.2137 RMSElog: 5.2137
[epoch 11][iter  150] loss: 4.7477 RMSElog: 4.7477
[epoch 11][iter  160] loss: 5.5499 RMSElog: 5.5499
[epoch 11][iter  170] loss: 5.2494 RMSElog: 5.2494
[epoch 11][iter  180] loss: 5.0349 RMSElog: 5.0349
[epoch 11][iter  190] loss: 5.6955 RMSElog: 5.6955
[epoch 11][iter  200] loss: 5.8007 RMSElog: 5.8007
[epoch 11][iter  210] loss: 5.3904 RMSElog: 5.3904
[epoch 11][iter  220] loss: 5.2579 RMSElog: 5.2579
[epoch 11][iter  230] loss: 4.9766 RMSElog: 4.9766
[epoch 11][iter  240] loss: 5.0216 RMSElog: 5.0216
[epoch 11][iter  250] loss: 4.8996 RMSElog: 4.8996
[epoch 11][iter  260] loss: 5.6577 RMSElog: 5.6577
[epoch 11][iter  270] loss: 4.8914 RMSElog: 4.8914
[epoch 11][iter  280] loss: 5.6930 RMSElog: 5.6930
[epoch 11][iter  290] loss: 5.1354 RMSElog: 5.1354
[epoch 11][iter  300] loss: 5.6139 RMSElog: 5.6139
[epoch 11][iter  310] loss: 5.5339 RMSElog: 5.5339
[epoch 11][iter  320] loss: 5.2356 RMSElog: 5.2356
[epoch 11][iter  330] loss: 4.7269 RMSElog: 4.7269
[epoch 11][iter  340] loss: 4.8038 RMSElog: 4.8038
[epoch 11][iter  350] loss: 4.7082 RMSElog: 4.7082
[epoch 11][iter  360] loss: 4.7742 RMSElog: 4.7742
[epoch 11][iter  370] loss: 5.0975 RMSElog: 5.0975
[epoch 11][iter  380] loss: 5.5917 RMSElog: 5.5917
[epoch 11][iter  390] loss: 5.6697 RMSElog: 5.6697
[epoch 11][iter  400] loss: 5.4880 RMSElog: 5.4880
[epoch 11][iter  410] loss: 4.8170 RMSElog: 4.8170
[epoch 11][iter  420] loss: 4.9222 RMSElog: 4.9222
[epoch 11][iter  430] loss: 5.6667 RMSElog: 5.6667
[epoch 11][iter  440] loss: 5.2899 RMSElog: 5.2899
[epoch 11][iter  450] loss: 4.2832 RMSElog: 4.2832
[epoch 11][iter  460] loss: 5.4937 RMSElog: 5.4937
[epoch 11][iter  470] loss: 5.2625 RMSElog: 5.2625
[epoch 11][iter  480] loss: 5.0013 RMSElog: 5.0013
[epoch 11][iter  490] loss: 4.8930 RMSElog: 4.8930
[epoch 11][iter  500] loss: 4.9209 RMSElog: 4.9209
[epoch 11][iter  510] loss: 5.6604 RMSElog: 5.6604
[epoch 11][iter  520] loss: 6.1977 RMSElog: 6.1977
[epoch 11][iter  530] loss: 4.9095 RMSElog: 4.9095
[epoch 11][iter  540] loss: 4.8871 RMSElog: 4.8871
[epoch 11][iter  550] loss: 5.0090 RMSElog: 5.0090
[epoch 11][iter  560] loss: 6.3703 RMSElog: 6.3703
[epoch 11][iter  570] loss: 5.6234 RMSElog: 5.6234
[epoch 11][iter  580] loss: 5.7073 RMSElog: 5.7073
[epoch 11][iter  590] loss: 5.3737 RMSElog: 5.3737
[epoch 12][iter    0] loss: 5.2229 RMSElog: 5.2229
[epoch 12][iter   10] loss: 5.2898 RMSElog: 5.2898
[epoch 12][iter   20] loss: 5.3199 RMSElog: 5.3199
[epoch 12][iter   30] loss: 5.3848 RMSElog: 5.3848
[epoch 12][iter   40] loss: 5.2812 RMSElog: 5.2812
[epoch 12][iter   50] loss: 5.0215 RMSElog: 5.0215
[epoch 12][iter   60] loss: 5.7341 RMSElog: 5.7341
[epoch 12][iter   70] loss: 4.8494 RMSElog: 4.8494
[epoch 12][iter   80] loss: 5.3711 RMSElog: 5.3711
[epoch 12][iter   90] loss: 5.1324 RMSElog: 5.1324
[epoch 12][iter  100] loss: 6.0239 RMSElog: 6.0239
[epoch 12][iter  110] loss: 4.9687 RMSElog: 4.9687
[epoch 12][iter  120] loss: 5.4618 RMSElog: 5.4618
[epoch 12][iter  130] loss: 6.2024 RMSElog: 6.2024
[epoch 12][iter  140] loss: 5.4678 RMSElog: 5.4678
[epoch 12][iter  150] loss: 6.1355 RMSElog: 6.1355
[epoch 12][iter  160] loss: 5.8534 RMSElog: 5.8534
[epoch 12][iter  170] loss: 5.8939 RMSElog: 5.8939
[epoch 12][iter  180] loss: 4.6107 RMSElog: 4.6107
[epoch 12][iter  190] loss: 5.1048 RMSElog: 5.1048
[epoch 12][iter  200] loss: 5.8482 RMSElog: 5.8482
[epoch 12][iter  210] loss: 5.5650 RMSElog: 5.5650
[epoch 12][iter  220] loss: 4.4230 RMSElog: 4.4230
[epoch 12][iter  230] loss: 5.2951 RMSElog: 5.2951
[epoch 12][iter  240] loss: 4.5931 RMSElog: 4.5931
[epoch 12][iter  250] loss: 5.0609 RMSElog: 5.0609
[epoch 12][iter  260] loss: 5.2239 RMSElog: 5.2239
[epoch 12][iter  270] loss: 4.4863 RMSElog: 4.4863
[epoch 12][iter  280] loss: 5.1414 RMSElog: 5.1414
[epoch 12][iter  290] loss: 4.8527 RMSElog: 4.8527
[epoch 12][iter  300] loss: 4.8747 RMSElog: 4.8747
[epoch 12][iter  310] loss: 5.3208 RMSElog: 5.3208
[epoch 12][iter  320] loss: 5.0035 RMSElog: 5.0035
[epoch 12][iter  330] loss: 5.5009 RMSElog: 5.5009
[epoch 12][iter  340] loss: 4.5848 RMSElog: 4.5848
[epoch 12][iter  350] loss: 4.3947 RMSElog: 4.3947
[epoch 12][iter  360] loss: 6.1339 RMSElog: 6.1339
[epoch 12][iter  370] loss: 4.3873 RMSElog: 4.3873
[epoch 12][iter  380] loss: 5.7149 RMSElog: 5.7149
[epoch 12][iter  390] loss: 5.6497 RMSElog: 5.6497
[epoch 12][iter  400] loss: 5.0231 RMSElog: 5.0231
[epoch 12][iter  410] loss: 4.5344 RMSElog: 4.5344
[epoch 12][iter  420] loss: 4.7228 RMSElog: 4.7228
[epoch 12][iter  430] loss: 6.2573 RMSElog: 6.2573
[epoch 12][iter  440] loss: 5.4107 RMSElog: 5.4107
[epoch 12][iter  450] loss: 5.6378 RMSElog: 5.6378
[epoch 12][iter  460] loss: 5.5507 RMSElog: 5.5507
[epoch 12][iter  470] loss: 5.4442 RMSElog: 5.4442
[epoch 12][iter  480] loss: 5.2076 RMSElog: 5.2076
[epoch 12][iter  490] loss: 4.9192 RMSElog: 4.9192
[epoch 12][iter  500] loss: 5.1703 RMSElog: 5.1703
[epoch 12][iter  510] loss: 5.3492 RMSElog: 5.3492
[epoch 12][iter  520] loss: 5.1085 RMSElog: 5.1085
[epoch 12][iter  530] loss: 4.9770 RMSElog: 4.9770
[epoch 12][iter  540] loss: 5.7065 RMSElog: 5.7065
[epoch 12][iter  550] loss: 5.4364 RMSElog: 5.4364
[epoch 12][iter  560] loss: 5.4563 RMSElog: 5.4563
[epoch 12][iter  570] loss: 5.7892 RMSElog: 5.7892
[epoch 12][iter  580] loss: 5.0171 RMSElog: 5.0171
[epoch 12][iter  590] loss: 5.3475 RMSElog: 5.3475
[epoch 13][iter    0] loss: 5.6902 RMSElog: 5.6902
[epoch 13][iter   10] loss: 5.6578 RMSElog: 5.6578
[epoch 13][iter   20] loss: 4.8489 RMSElog: 4.8489
[epoch 13][iter   30] loss: 4.5705 RMSElog: 4.5705
[epoch 13][iter   40] loss: 5.1517 RMSElog: 5.1517
[epoch 13][iter   50] loss: 4.7169 RMSElog: 4.7169
[epoch 13][iter   60] loss: 4.8370 RMSElog: 4.8370
[epoch 13][iter   70] loss: 5.6132 RMSElog: 5.6132
[epoch 13][iter   80] loss: 5.8692 RMSElog: 5.8692
[epoch 13][iter   90] loss: 4.9988 RMSElog: 4.9988
[epoch 13][iter  100] loss: 6.1844 RMSElog: 6.1844
[epoch 13][iter  110] loss: 5.3085 RMSElog: 5.3085
[epoch 13][iter  120] loss: 5.3728 RMSElog: 5.3728
[epoch 13][iter  130] loss: 4.8112 RMSElog: 4.8112
[epoch 13][iter  140] loss: 5.1708 RMSElog: 5.1708
[epoch 13][iter  150] loss: 4.9399 RMSElog: 4.9399
[epoch 13][iter  160] loss: 4.3606 RMSElog: 4.3606
[epoch 13][iter  170] loss: 5.4238 RMSElog: 5.4238
[epoch 13][iter  180] loss: 5.2518 RMSElog: 5.2518
[epoch 13][iter  190] loss: 5.0300 RMSElog: 5.0300
[epoch 13][iter  200] loss: 5.8638 RMSElog: 5.8638
[epoch 13][iter  210] loss: 5.8568 RMSElog: 5.8568
[epoch 13][iter  220] loss: 6.1258 RMSElog: 6.1258
[epoch 13][iter  230] loss: 4.4181 RMSElog: 4.4181
[epoch 13][iter  240] loss: 6.2755 RMSElog: 6.2755
[epoch 13][iter  250] loss: 4.4987 RMSElog: 4.4987
[epoch 13][iter  260] loss: 5.2454 RMSElog: 5.2454
[epoch 13][iter  270] loss: 4.8604 RMSElog: 4.8604
[epoch 13][iter  280] loss: 5.8668 RMSElog: 5.8668
[epoch 13][iter  290] loss: 4.2139 RMSElog: 4.2139
[epoch 13][iter  300] loss: 5.2283 RMSElog: 5.2283
[epoch 13][iter  310] loss: 4.7929 RMSElog: 4.7929
[epoch 13][iter  320] loss: 5.7959 RMSElog: 5.7959
[epoch 13][iter  330] loss: 5.8067 RMSElog: 5.8067
[epoch 13][iter  340] loss: 5.3555 RMSElog: 5.3555
[epoch 13][iter  350] loss: 5.6229 RMSElog: 5.6229
[epoch 13][iter  360] loss: 4.8421 RMSElog: 4.8421
[epoch 13][iter  370] loss: 5.6189 RMSElog: 5.6189
[epoch 13][iter  380] loss: 4.9754 RMSElog: 4.9754
[epoch 13][iter  390] loss: 6.3565 RMSElog: 6.3565
[epoch 13][iter  400] loss: 5.2483 RMSElog: 5.2483
[epoch 13][iter  410] loss: 4.8606 RMSElog: 4.8606
[epoch 13][iter  420] loss: 5.5845 RMSElog: 5.5845
[epoch 13][iter  430] loss: 5.0082 RMSElog: 5.0082
[epoch 13][iter  440] loss: 4.9571 RMSElog: 4.9571
[epoch 13][iter  450] loss: 5.1555 RMSElog: 5.1555
[epoch 13][iter  460] loss: 4.8384 RMSElog: 4.8384
[epoch 13][iter  470] loss: 4.3991 RMSElog: 4.3991
[epoch 13][iter  480] loss: 5.3204 RMSElog: 5.3204
[epoch 13][iter  490] loss: 4.7485 RMSElog: 4.7485
[epoch 13][iter  500] loss: 5.6631 RMSElog: 5.6631