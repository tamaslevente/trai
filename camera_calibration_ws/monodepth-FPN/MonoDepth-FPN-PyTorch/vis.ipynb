{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(source ../.venv_mono_depth/bin/activate)\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from constants import *\n",
    "import argparse, time\n",
    "# from utils.net_utils import adjust_learning_rate\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "# from dataset.kitti_dataset import KittiDataset\n",
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "from dataset.dataloader import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "# from path import Path\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from dataset.nyuv2_dataset import NYUv2Dataset\n",
    "from model_fpn import I2D\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "\n",
    "class SLlog(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SLlog, self).__init__()\n",
    "    \n",
    "    def forward(self, fake, real):\n",
    "        if not fake.shape == real.shape:\n",
    "            _,_,H,W = real.shape\n",
    "            fake = F.upsample(fake, size=(H,W), mode='bilinear')\n",
    "            \n",
    "        # filter out invalid pixels\n",
    "        N = (real>0).float().sum()\n",
    "        mask = (real==0)        \n",
    "        fake[mask] = 1.\n",
    "        real[mask] = 1.\n",
    "        \n",
    "        loss = 100.* torch.sum( torch.abs(torch.log(real)-torch.log(fake)) ) / N\n",
    "        return loss\n",
    "\n",
    "    \n",
    "class RMSE_log(nn.Module):\n",
    "    def __init__(self, use_cuda):\n",
    "        super(RMSE_log, self).__init__()\n",
    "        self.eps = 1e-8\n",
    "        self.use_cuda = use_cuda\n",
    "    \n",
    "    def forward(self, fake, real):\n",
    "        mask = real<1.\n",
    "        n,_,h,w = real.size()\n",
    "        fake = F.upsample(fake, size=(h,w), mode='bilinear')\n",
    "        fake += self.eps\n",
    "\n",
    "        N = len(real[mask])\n",
    "        loss = torch.sqrt( torch.sum( torch.abs(torch.log(real[mask])-torch.log(fake[mask])) ** 2 ) / N )\n",
    "        return loss\n",
    "\n",
    "class iRMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(iRMSE, self).__init__()\n",
    "        self.eps = 1e-8\n",
    "    \n",
    "    def forward(self, fake, real):\n",
    "        n,_,h,w = real.size()\n",
    "        fake = F.upsample(fake, size=(h,w), mode='bilinear')\n",
    "        mask = real<1.\n",
    "        n = len(real[mask])\n",
    "        loss = torch.sqrt( torch.sum( torch.abs(1./real[mask] - 1./(fake[mask]+self.eps) ) ** 2 ) / n )\n",
    "        return loss\n",
    "\n",
    "def get_acc(output, target):\n",
    "    # takes in two tensors to compute accuracy\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct_mask = pred.eq(target.data.view_as(pred))\n",
    "    correct = correct_mask.cpu().sum()\n",
    "    print(\"Target: \", Counter(target.data.cpu().numpy()))\n",
    "    print(\"Pred: \", Counter(pred.cpu().numpy().flatten().tolist()))\n",
    "    return float(correct)*100 / target.size(0) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network initialization\n",
    "print('Initializing model...')\n",
    "i2d = I2D(fixed_feature_weights=False)\n",
    "i2d = i2d.cuda()\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "reg_criterion = RMSE_log(use_cuda=True)\n",
    "eval_metric = iRMSE()\n",
    "\n",
    "# resume\n",
    "\n",
    "load_name = \"/home/marian/calibration_ws/monodepth-FPN/saved_models/i2d_1_20.pth\"\n",
    "# print(\"loading checkpoint %s\" % (load_name))\n",
    "state = i2d.state_dict()\n",
    "checkpoint = torch.load(load_name)\n",
    "state.update(checkpoint['model'])\n",
    "i2d.load_state_dict(state)\n",
    "\n",
    "del checkpoint\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# setting to train mode\n",
    "i2d.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Variable(torch.FloatTensor(1), volatile=True).cuda()\n",
    "# z = Variable(torch.FloatTensor(1), volatile=True).cuda()\n",
    "\n",
    "# test_loss = 0.\n",
    "# for idx, (image, gt) in enumerate(train_dataloader):\n",
    "#     img.data.resize_(image.size()).copy_(image)\n",
    "#     z.data.resize_(gt.size()).copy_(gt)\n",
    "\n",
    "#     d1,d2,d3,d4,d5 = i2d(img, None)\n",
    "#     loss = reg_criterion(d1, z)\n",
    "#     test_loss += loss.data[0]\n",
    "#     print(\"Iter: %d/%d logRMSE: %.4f\" \\\n",
    "#                     % (idx*bs, len(train_dataloader.dataset), loss))\n",
    "    \n",
    "# test_loss = test_loss * bs / len(train_dataloader.dataset)\n",
    "# print('\\nTest set: Average loss: {:.14f}'.format(test_loss))\n",
    "\n",
    "vis_dataset = KittiDataset(train=False)\n",
    "train_size = len(vis_dataset)\n",
    "\n",
    "bs = 10\n",
    "vis_dataloader = torch.utils.data.DataLoader(vis_dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Variable(torch.FloatTensor(1), volatile=True).cuda()\n",
    "z = Variable(torch.FloatTensor(1), volatile=True).cuda()\n",
    "\n",
    "vis_data_iter = iter(vis_dataloader)\n",
    "\n",
    "data = vis_data_iter.next()\n",
    "\n",
    "img.data.resize_(data[0].size()).copy_(data[0])\n",
    "z.data.resize_(data[1].size()).copy_(data[1])\n",
    "\n",
    "z_fake = i2d(img)\n",
    "# loss3 = reg_criterion(d1, z)\n",
    "# loss = loss3\n",
    "\n",
    "# metric = eval_metric(d1, z)\n",
    "\n",
    "# print(d1.size())\n",
    "\n",
    "# print(\"logRMSE: %.4f iRMSE: %.4f\" \\\n",
    "#                 % (loss, metric))\n",
    "\n",
    "imgs = img.data.cpu().numpy()\n",
    "depth = z_fake.data.cpu().numpy()\n",
    "gt = z.data.cpu().numpy()\n",
    "print(gt.shape)\n",
    "\n",
    "plt.set_cmap('jet')\n",
    "\n",
    "sl_log = SLlog()\n",
    "print(sl_log(z_fake, z), z_fake.mean(), z.mean())\n",
    "for i in range(imgs.shape[0]):\n",
    "    plt.imshow(np.transpose(imgs[i], (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    vmin, vmax = 0,10000/65536.\n",
    "    plt.imshow(depth[i][0], vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(gt[i][0], vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_loss)\n",
    "# print(len(train_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mono-depth",
   "display_name": "mono-depth",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}