{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 26 09:31:57 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.38       Driver Version: 455.38       CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 3080    Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 53%   31C    P8    36W / 340W |    281MiB / 10018MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1650      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      1798      G   /usr/bin/gnome-shell               54MiB |\r\n",
      "|    0   N/A  N/A      2565      G   /usr/lib/xorg/Xorg                124MiB |\r\n",
      "|    0   N/A  N/A      2723      G   ...mviewer/tv_bin/TeamViewer       18MiB |\r\n",
      "|    0   N/A  N/A     10930      G   /usr/lib/firefox/firefox            4MiB |\r\n",
      "|    0   N/A  N/A     11195      G   /usr/lib/firefox/firefox            4MiB |\r\n",
      "|    0   N/A  N/A     12563      G   /usr/lib/firefox/firefox            4MiB |\r\n",
      "|    0   N/A  N/A     16582      G   /usr/bin/gnome-shell               38MiB |\r\n",
      "|    0   N/A  N/A     31058      G   gnome-control-center                4MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in Progress\n",
    "\n",
    "This is an implementation of RGCNN from the paper https://github.com/tegusi/RGCNN\n",
    "\n",
    "Initial testing will be done on the GeometricShapes dataset from PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole dataset:       \t GeometricShapes(40)\n",
      "Example from the dataset:\t Data(pos=[32, 3], face=[3, 30], y=[1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import GeometricShapes\n",
    "\n",
    "dataset = GeometricShapes(root='data/GeometricShapes')\n",
    "print(\"The whole dataset:       \\t\", dataset)\n",
    "print(\"Example from the dataset:\\t\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the Meshes from the dataset to a PointCloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of Point Cloud: \t Data(pos=[1024, 3], y=[1])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import SamplePoints\n",
    "\n",
    "# For reproductibility\n",
    "torch.manual_seed(42)\n",
    "points_number = 1024 \n",
    "dataset.transform =  SamplePoints(num=points_number)\n",
    "print(\"Example of Point Cloud: \\t\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following classes are defined as in the RGCNN github:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GetGraph(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GetGraph, self).__init__()\n",
    "\n",
    "    def forward(self, point_cloud):\n",
    "        point_cloud_transpose = point_cloud.permute(0, 2, 1)\n",
    "        point_cloud_inner = torch.matmul(point_cloud, point_cloud_transpose)\n",
    "        point_cloud_inner = -2 * point_cloud_inner\n",
    "        point_cloud_square = torch.sum(torch.mul(point_cloud, point_cloud), dim=2, keepdim=True)\n",
    "        point_cloud_square_tranpose = point_cloud_square.permute(0, 2, 1)\n",
    "        adj_matrix = point_cloud_square + point_cloud_inner + point_cloud_square_tranpose\n",
    "        adj_matrix = torch.exp(-adj_matrix)\n",
    "        return adj_matrix\n",
    "\n",
    "\n",
    "class GetLaplacian(nn.Module):\n",
    "    def __init__(self, normalize=True):\n",
    "        super(GetLaplacian, self).__init__()\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def diag(self, mat):\n",
    "        # input is batch x vertices\n",
    "        d = []\n",
    "        for vec in mat:\n",
    "            d.append(torch.diag(vec))\n",
    "        return torch.stack(d)\n",
    "\n",
    "    def forward(self, adj_matrix):\n",
    "        if self.normalize:\n",
    "            D = torch.sum(adj_matrix, dim=2)\n",
    "            eye = torch.ones_like(D)\n",
    "            eye = self.diag(eye)\n",
    "            D = 1 / torch.sqrt(D)\n",
    "            D = self.diag(D)\n",
    "            L = eye - torch.matmul(torch.matmul(D, adj_matrix), D)\n",
    "        else:\n",
    "            D = torch.sum(adj_matrix, dim=1)\n",
    "            D = torch.matrix_diag(D)\n",
    "            L = D - adj_matrix\n",
    "        return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset points: \t torch.Size([1024, 3])\n",
      "New shape:                   \t torch.Size([1, 1024, 3])\n",
      "Graph shape:                 \t torch.Size([1, 1024, 1024])\n",
      "Reduction of the data dimension:\t torch.Size([1024, 1024])\n",
      "Graph:                       \t tensor([[1.0000, 0.5828, 0.9376,  ..., 0.1363, 0.3722, 0.7379],\n",
      "        [0.5828, 1.0000, 0.6627,  ..., 0.5064, 0.2619, 0.6291],\n",
      "        [0.9376, 0.6627, 1.0000,  ..., 0.2344, 0.5538, 0.9149],\n",
      "        ...,\n",
      "        [0.1363, 0.5064, 0.2344,  ..., 1.0000, 0.2453, 0.3585],\n",
      "        [0.3722, 0.2619, 0.5538,  ..., 0.2453, 1.0000, 0.7663],\n",
      "        [0.7379, 0.6291, 0.9149,  ..., 0.3585, 0.7663, 1.0000]])\n",
      "Laplacian shape:             \t torch.Size([1, 1024, 1024])\n",
      "Squeezed Laplacian shape     \t torch.Size([1024, 1024])\n",
      "Laplacian                    \t tensor([[ 9.9728e-01, -1.5304e-03, -2.2361e-03,  ..., -3.4304e-04,\n",
      "         -7.8977e-04, -1.5904e-03],\n",
      "        [-1.5304e-03,  9.9746e-01, -1.5274e-03,  ..., -1.2321e-03,\n",
      "         -5.3711e-04, -1.3104e-03],\n",
      "        [-2.2361e-03, -1.5274e-03,  9.9791e-01,  ..., -5.1798e-04,\n",
      "         -1.0316e-03, -1.7307e-03],\n",
      "        ...,\n",
      "        [-3.4304e-04, -1.2321e-03, -5.1798e-04,  ...,  9.9767e-01,\n",
      "         -4.8236e-04, -7.1595e-04],\n",
      "        [-7.8977e-04, -5.3711e-04, -1.0316e-03,  ..., -4.8236e-04,\n",
      "          9.9834e-01, -1.2901e-03],\n",
      "        [-1.5904e-03, -1.3104e-03, -1.7307e-03,  ..., -7.1595e-04,\n",
      "         -1.2901e-03,  9.9829e-01]])\n"
     ]
    }
   ],
   "source": [
    "get_graph = GetGraph()\n",
    "print(\"Shape of the dataset points: \\t\", dataset[0].pos.shape)\n",
    "data=dataset[0].pos\n",
    "data=data.reshape([1,data.shape[0], data.shape[1]])\n",
    "print(\"New shape:                   \\t\", data.shape)\n",
    "x=data\n",
    "W = get_graph(data)\n",
    "\n",
    "W_torch = W\n",
    "print(\"Graph shape:                 \\t\", W_torch.shape)\n",
    "W=torch.squeeze(W)\n",
    "print(\"Reduction of the data dimension:\\t\", W.shape)\n",
    "print(\"Graph:                       \\t\", W)\n",
    "\n",
    "\n",
    "getter_laplacian = GetLaplacian()\n",
    "L_torch = getter_laplacian(W_torch)\n",
    "L = torch.squeeze(L_torch)\n",
    "print(\"Laplacian shape:             \\t\", L_torch.shape)\n",
    "print(\"Squeezed Laplacian shape     \\t\", L.shape)\n",
    "print(\"Laplacian                    \\t\", L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Chebyshev approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def find_eigmax(L):\n",
    "    with torch.no_grad():\n",
    "        e1, _ = torch.eig(L, eigenvectors=False)\n",
    "        return torch.max(e1[:, 0]).item()\n",
    "\n",
    "def chebyshev_Lapl(X, Lapl, thetas, order):\n",
    "    list_powers = []\n",
    "    nodes = Lapl.shape[0]\n",
    "\n",
    "    T0 = X.float()\n",
    "\n",
    "    eigmax = find_eigmax(Lapl)\n",
    "    L_rescaled = (2 * Lapl / eigmax) - torch.eye(1024)\n",
    "\n",
    "    y = T0 * thetas[0]\n",
    "    list_powers.append(y)\n",
    "    T1 = torch.matmul(L_rescaled, T0)\n",
    "    list_powers.append(T1 * thetas[1])\n",
    "\n",
    "    # Computation of: T_k = 2*L_rescaled*T_k-1  -  T_k-2\n",
    "    for k in range(2, order):\n",
    "        T2 = 2 * torch.matmul(L_rescaled, T1) - T0\n",
    "        list_powers.append((T2 * thetas[k]))\n",
    "        T0, T1 = T1, T2\n",
    "    y_out = torch.stack(list_powers, dim=-1)\n",
    "    # the powers may be summed or concatenated. i use concatenation here\n",
    "    y_out = y_out.view(nodes, -1) # -1 = order* features_of_signal\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Chebyshev approx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheb approx out powers concatenated: torch.Size([1024, 18])\n",
      "Layers output: torch.Size([1024, 128])\n"
     ]
    }
   ],
   "source": [
    "features_1 = 3          # input features number for the 'model'\n",
    "out_features_1 = 128    # output features number from the first convolutional layer\n",
    "K1 = 6                  # order of the Chebyshev Polynomial\n",
    "thetas_1 = nn.Parameter(torch.rand(points_number))  # initialization of the parameters of the model for the first conv layer\n",
    "out = chebyshev_Lapl(x,L,thetas_1,K1)           # computing the approximate polynomial\n",
    "print('cheb approx out powers concatenated:', out.shape)    \n",
    "linear_1 = nn.Linear(K1*features_1, out_features_1)     # MLP == Linear\n",
    "layer_out_1 = linear_1(out)\n",
    "print('Layers output:', layer_out_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will try to define a convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn.conv as cnv\n",
    "import torch_geometric.utils as tgu\n",
    "\n",
    "class RGCNN_Conv(nn.Module):\n",
    "    def __init__(self, F_in, K, F_out):\n",
    "        super(RGCNN_Conv, self).__init__()\n",
    "        self.F_in = F_in\n",
    "        self.K = K\n",
    "        self.F_out = F_out\n",
    "\n",
    "        self.W = nn.Parameter(torch.Tensor(self.K * self.F_in, self.F_out))\n",
    "        nn.init.normal_(self.W, mean=0, std=0.2)\n",
    "\n",
    "        self.B = nn.Parameter(torch.Tensor(self.F_out))\n",
    "        nn.init.normal_(self.B, mean=0, std=0.2)\n",
    "\n",
    "        self.cheb_conv = cnv.ChebConv(in_channels=F_in, out_channels=F_out, K=K, normalization=\"sym\", bias=True)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, W):\n",
    "        N, M, F_in = list(x.size())\n",
    "        edge_index, edge_weight = tgu.dense_to_sparse(W)\n",
    "        x = self.cheb_conv(x=x, edge_index=edge_index, edge_weight=edge_weight)\n",
    "        x = self.relu(x)\n",
    "        return x.reshape(N, M, self.F_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('W', tensor([[-0.4086, -0.1569, -0.1427,  ..., -0.0811, -0.0623,  0.0787],\n",
      "        [ 0.0311, -0.1582, -0.0621,  ..., -0.0046,  0.0769, -0.1732],\n",
      "        [-0.3296,  0.2379, -0.1198,  ...,  0.3813,  0.0613, -0.1485],\n",
      "        ...,\n",
      "        [-0.0922, -0.2568,  0.2475,  ...,  0.1912, -0.3486, -0.1763],\n",
      "        [ 0.0580,  0.2378, -0.0808,  ..., -0.1897,  0.3070,  0.0199],\n",
      "        [ 0.0563, -0.0326,  0.3251,  ...,  0.2126, -0.2054,  0.4179]])), ('B', tensor([-0.5937, -0.0998,  0.1442, -0.3224, -0.1982,  0.1147,  0.0350,  0.3240,\n",
      "        -0.3171, -0.1003,  0.0058,  0.1605,  0.0485,  0.5452, -0.1594, -0.0728,\n",
      "        -0.0137, -0.2377,  0.1565,  0.1457,  0.3290,  0.0669,  0.1576, -0.3050,\n",
      "         0.5961,  0.3220, -0.1121, -0.0196,  0.1485, -0.4267, -0.0749, -0.2158,\n",
      "         0.1623, -0.0470, -0.0533,  0.2456, -0.1200, -0.1967, -0.0663, -0.1569,\n",
      "         0.2635, -0.3162,  0.2360, -0.2630,  0.0182, -0.0955, -0.1706, -0.2998,\n",
      "         0.2625,  0.2627,  0.0269,  0.1118, -0.2047,  0.0248, -0.2597,  0.0842,\n",
      "        -0.1902, -0.2550,  0.1925,  0.1260,  0.2174,  0.0148, -0.0935, -0.3077,\n",
      "         0.0066,  0.0282, -0.2985, -0.0618, -0.1250,  0.0427,  0.1168, -0.1179,\n",
      "         0.3492, -0.0209,  0.0893, -0.1403,  0.1042, -0.1034,  0.1461,  0.1200,\n",
      "         0.0664,  0.1049, -0.1489, -0.0373,  0.2191,  0.0088,  0.0221, -0.0636,\n",
      "        -0.1173,  0.0866,  0.1012,  0.0197,  0.0793, -0.0367, -0.2547, -0.2647,\n",
      "         0.0555,  0.1816,  0.2660, -0.0755, -0.1812,  0.2943,  0.0481, -0.1452,\n",
      "         0.2081,  0.1789, -0.2425,  0.1430,  0.2464,  0.0830, -0.0207,  0.0636,\n",
      "         0.4304,  0.1178,  0.0301, -0.0718,  0.2950, -0.3214, -0.1153, -0.0751,\n",
      "        -0.0079, -0.4114,  0.1585, -0.2294,  0.1570, -0.4195, -0.1772,  0.1595])), ('cheb_conv.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('cheb_conv.lins.0.weight', tensor([[-0.1319,  0.0794, -0.0761],\n",
      "        [-0.1147, -0.1601, -0.1844],\n",
      "        [-0.1219, -0.1787, -0.0856],\n",
      "        [-0.0674,  0.0442,  0.0768],\n",
      "        [ 0.1487,  0.0272,  0.1829],\n",
      "        [ 0.1124,  0.1315,  0.0859],\n",
      "        [ 0.1642, -0.1847,  0.1702],\n",
      "        [-0.0256, -0.0366,  0.1123],\n",
      "        [ 0.0566, -0.0583, -0.2113],\n",
      "        [ 0.1022, -0.0116, -0.0993],\n",
      "        [-0.1636, -0.2078,  0.1860],\n",
      "        [-0.0662,  0.0065,  0.2136],\n",
      "        [-0.0982, -0.1632, -0.1647],\n",
      "        [-0.0918,  0.1259,  0.1672],\n",
      "        [-0.1644, -0.0537,  0.1007],\n",
      "        [ 0.1797, -0.0751, -0.1927],\n",
      "        [ 0.0234, -0.1649,  0.0954],\n",
      "        [-0.1408, -0.1051,  0.1774],\n",
      "        [ 0.0604, -0.0076, -0.0197],\n",
      "        [ 0.1129,  0.0334, -0.0472],\n",
      "        [-0.0420, -0.0958,  0.1121],\n",
      "        [ 0.0095,  0.1675,  0.2033],\n",
      "        [ 0.1463, -0.0279,  0.0773],\n",
      "        [ 0.1255,  0.1006,  0.1052],\n",
      "        [ 0.2013,  0.2033, -0.1407],\n",
      "        [-0.1705,  0.2110,  0.0385],\n",
      "        [-0.2117,  0.0007,  0.1522],\n",
      "        [ 0.0505, -0.1026, -0.1550],\n",
      "        [-0.1005,  0.1437,  0.0411],\n",
      "        [ 0.0106,  0.0401, -0.0368],\n",
      "        [-0.0083, -0.0536, -0.1195],\n",
      "        [ 0.1368, -0.0549,  0.0317],\n",
      "        [ 0.0042, -0.1130, -0.0529],\n",
      "        [ 0.1315, -0.1801,  0.1651],\n",
      "        [ 0.0484,  0.1019, -0.1663],\n",
      "        [ 0.1359,  0.0051, -0.0036],\n",
      "        [-0.1447, -0.0751,  0.1071],\n",
      "        [ 0.0931, -0.1662,  0.1731],\n",
      "        [ 0.0969, -0.1629, -0.1159],\n",
      "        [ 0.0225, -0.2123,  0.0183],\n",
      "        [ 0.1193, -0.1861, -0.1977],\n",
      "        [-0.0776,  0.1843,  0.1403],\n",
      "        [ 0.1309, -0.0597, -0.1844],\n",
      "        [-0.1123,  0.1647, -0.1737],\n",
      "        [ 0.0219, -0.0586,  0.0630],\n",
      "        [ 0.0068, -0.1590, -0.2123],\n",
      "        [-0.1325, -0.0295,  0.0603],\n",
      "        [ 0.1451,  0.0092,  0.0728],\n",
      "        [-0.1060, -0.0913,  0.0197],\n",
      "        [-0.0978, -0.1022,  0.1511],\n",
      "        [-0.0463, -0.0215, -0.0140],\n",
      "        [-0.1890, -0.1059,  0.0023],\n",
      "        [-0.1222,  0.1779, -0.0164],\n",
      "        [ 0.1344, -0.1899, -0.0885],\n",
      "        [-0.0664,  0.1152,  0.1719],\n",
      "        [ 0.0757, -0.2002,  0.1210],\n",
      "        [ 0.2030,  0.0100, -0.1365],\n",
      "        [ 0.0117, -0.1225, -0.1747],\n",
      "        [-0.0801,  0.1426,  0.1823],\n",
      "        [ 0.0805,  0.0037, -0.0095],\n",
      "        [-0.1306, -0.1169,  0.1803],\n",
      "        [ 0.0936,  0.0439, -0.0011],\n",
      "        [-0.0107, -0.1802,  0.1312],\n",
      "        [ 0.1741, -0.1902, -0.1315],\n",
      "        [-0.0750, -0.0243, -0.0903],\n",
      "        [ 0.1839,  0.0162, -0.1599],\n",
      "        [-0.0682,  0.2081,  0.1075],\n",
      "        [ 0.0486, -0.1392,  0.0064],\n",
      "        [ 0.0472, -0.0360, -0.1814],\n",
      "        [ 0.2044,  0.1714, -0.0177],\n",
      "        [-0.0736,  0.1552, -0.1905],\n",
      "        [ 0.0880,  0.1697,  0.1687],\n",
      "        [-0.2111,  0.2015,  0.2028],\n",
      "        [ 0.1724,  0.0695, -0.1996],\n",
      "        [ 0.0920, -0.1924, -0.1967],\n",
      "        [-0.0648,  0.1855, -0.1777],\n",
      "        [-0.1403, -0.1366, -0.1494],\n",
      "        [-0.1647, -0.0017, -0.1945],\n",
      "        [ 0.1543,  0.1624, -0.2110],\n",
      "        [ 0.0991,  0.1443, -0.1342],\n",
      "        [-0.1636,  0.0547,  0.1487],\n",
      "        [-0.0473, -0.0784, -0.0579],\n",
      "        [ 0.0802,  0.0078, -0.1064],\n",
      "        [ 0.0946, -0.1853, -0.1268],\n",
      "        [-0.0855,  0.0816,  0.1339],\n",
      "        [-0.0243, -0.1846, -0.1814],\n",
      "        [ 0.0917,  0.0248, -0.1464],\n",
      "        [-0.1642,  0.2000, -0.1579],\n",
      "        [-0.0417,  0.2089, -0.0320],\n",
      "        [ 0.1516,  0.1372, -0.2000],\n",
      "        [ 0.1950, -0.1763,  0.0820],\n",
      "        [ 0.0004,  0.0363,  0.1334],\n",
      "        [-0.0756, -0.0722, -0.1305],\n",
      "        [ 0.1278,  0.0840,  0.1059],\n",
      "        [ 0.1186,  0.0004, -0.1456],\n",
      "        [-0.1771, -0.0795, -0.0905],\n",
      "        [-0.0870,  0.0365, -0.2058],\n",
      "        [-0.1650,  0.1321, -0.1537],\n",
      "        [-0.0079,  0.1268, -0.0709],\n",
      "        [ 0.0650,  0.0805,  0.0879],\n",
      "        [ 0.0307, -0.0729, -0.0988],\n",
      "        [ 0.1296, -0.1716,  0.2103],\n",
      "        [ 0.1345,  0.0516,  0.1738],\n",
      "        [-0.1529,  0.0578, -0.1075],\n",
      "        [ 0.1302, -0.0428,  0.1754],\n",
      "        [-0.1450, -0.1028,  0.1827],\n",
      "        [-0.0891,  0.0164,  0.0436],\n",
      "        [ 0.0833,  0.0677,  0.0708],\n",
      "        [-0.0274,  0.0104,  0.1648],\n",
      "        [-0.2087,  0.1497,  0.0446],\n",
      "        [-0.1804, -0.0471, -0.1718],\n",
      "        [ 0.1473, -0.2058, -0.0293],\n",
      "        [ 0.1667,  0.0508, -0.1904],\n",
      "        [ 0.0044,  0.2029,  0.1107],\n",
      "        [ 0.0171, -0.1621,  0.1366],\n",
      "        [ 0.1709,  0.2072,  0.1962],\n",
      "        [ 0.2102,  0.0271, -0.1191],\n",
      "        [ 0.1207, -0.0729, -0.0085],\n",
      "        [ 0.1240,  0.0897, -0.1060],\n",
      "        [-0.1294, -0.0928,  0.0453],\n",
      "        [-0.1707, -0.1755, -0.0115],\n",
      "        [-0.1943,  0.0765, -0.0450],\n",
      "        [ 0.0151,  0.0803, -0.1877],\n",
      "        [-0.0634,  0.0864,  0.1596],\n",
      "        [ 0.1820,  0.1654,  0.0609],\n",
      "        [-0.0467, -0.1257, -0.0017],\n",
      "        [ 0.0168,  0.0978, -0.0384],\n",
      "        [-0.0878, -0.0136,  0.1949]])), ('cheb_conv.lins.1.weight', tensor([[ 0.1595,  0.1971, -0.1285],\n",
      "        [-0.1014,  0.1363,  0.0315],\n",
      "        [-0.0980,  0.2062,  0.1035],\n",
      "        [-0.1014, -0.0306,  0.1732],\n",
      "        [ 0.0441,  0.1097,  0.1515],\n",
      "        [-0.1830,  0.0454,  0.0471],\n",
      "        [ 0.1867,  0.0698,  0.1542],\n",
      "        [-0.1254, -0.0549, -0.1098],\n",
      "        [-0.1876,  0.0750, -0.0605],\n",
      "        [-0.0273,  0.0046, -0.0774],\n",
      "        [-0.0151,  0.0867,  0.1314],\n",
      "        [-0.1071, -0.0834,  0.0853],\n",
      "        [ 0.1644, -0.1015,  0.1658],\n",
      "        [-0.0930, -0.0721, -0.0431],\n",
      "        [ 0.0896, -0.0112,  0.0783],\n",
      "        [ 0.1237, -0.1081,  0.0808],\n",
      "        [-0.0337, -0.0479, -0.0490],\n",
      "        [ 0.0443, -0.0800,  0.1982],\n",
      "        [ 0.0284,  0.1778,  0.0062],\n",
      "        [-0.0686, -0.0455, -0.1132],\n",
      "        [-0.0138,  0.1882, -0.0066],\n",
      "        [ 0.1648, -0.2056, -0.0462],\n",
      "        [ 0.1073,  0.0772,  0.0096],\n",
      "        [-0.1113, -0.0367, -0.0637],\n",
      "        [-0.0805, -0.0100, -0.0630],\n",
      "        [-0.0550, -0.0974, -0.0537],\n",
      "        [-0.0498,  0.0551, -0.0679],\n",
      "        [ 0.0644, -0.0309, -0.1878],\n",
      "        [ 0.0441, -0.1555,  0.1810],\n",
      "        [-0.0931,  0.0934, -0.0662],\n",
      "        [-0.0778, -0.1992, -0.1960],\n",
      "        [ 0.1543, -0.0348, -0.1946],\n",
      "        [-0.1760, -0.0621, -0.0363],\n",
      "        [ 0.0731, -0.0016, -0.0476],\n",
      "        [-0.1527, -0.1830,  0.0298],\n",
      "        [-0.0716,  0.0128, -0.1937],\n",
      "        [-0.0971, -0.0878,  0.0777],\n",
      "        [ 0.1735, -0.1351,  0.0039],\n",
      "        [-0.0313,  0.0225,  0.0561],\n",
      "        [-0.0060, -0.1233, -0.1576],\n",
      "        [ 0.1912, -0.0174,  0.1377],\n",
      "        [-0.1759,  0.0235, -0.1327],\n",
      "        [ 0.1347, -0.1229,  0.1749],\n",
      "        [ 0.0810, -0.1807,  0.1642],\n",
      "        [-0.0164,  0.1880, -0.0361],\n",
      "        [ 0.0155,  0.0093,  0.2042],\n",
      "        [-0.0959,  0.0923, -0.0457],\n",
      "        [-0.1633,  0.1274, -0.1709],\n",
      "        [-0.1241, -0.1515,  0.2109],\n",
      "        [ 0.1454, -0.0466, -0.1201],\n",
      "        [ 0.1080,  0.1537,  0.0210],\n",
      "        [-0.1792,  0.0003, -0.0257],\n",
      "        [ 0.1220,  0.1583,  0.0887],\n",
      "        [-0.0449,  0.0616,  0.0080],\n",
      "        [-0.1019,  0.2091,  0.1043],\n",
      "        [ 0.1014,  0.0321, -0.1440],\n",
      "        [-0.1976,  0.1457, -0.1353],\n",
      "        [ 0.0291,  0.1820, -0.1933],\n",
      "        [ 0.0796,  0.1008,  0.1342],\n",
      "        [-0.1517, -0.2060, -0.0942],\n",
      "        [-0.0895, -0.1962, -0.0630],\n",
      "        [-0.0795, -0.0269,  0.1325],\n",
      "        [-0.1358, -0.0892, -0.1928],\n",
      "        [ 0.0268, -0.2130, -0.1917],\n",
      "        [ 0.0254, -0.1956,  0.0626],\n",
      "        [-0.1211,  0.0835,  0.1391],\n",
      "        [ 0.0862,  0.0847, -0.1425],\n",
      "        [-0.1291,  0.2100,  0.0046],\n",
      "        [ 0.1440, -0.1723,  0.0708],\n",
      "        [-0.0404,  0.1012, -0.1506],\n",
      "        [ 0.0456, -0.1434,  0.0621],\n",
      "        [-0.1854,  0.0577,  0.2118],\n",
      "        [ 0.1097, -0.1023, -0.0602],\n",
      "        [-0.1585,  0.1460, -0.0288],\n",
      "        [ 0.0598, -0.1928,  0.1025],\n",
      "        [ 0.0428, -0.0747,  0.1321],\n",
      "        [ 0.1385, -0.1047,  0.0036],\n",
      "        [-0.1630,  0.0594, -0.1869],\n",
      "        [ 0.0228,  0.0974,  0.1289],\n",
      "        [-0.0191,  0.0782,  0.0927],\n",
      "        [ 0.1750,  0.2138,  0.1969],\n",
      "        [-0.1338,  0.0223, -0.2085],\n",
      "        [ 0.0999,  0.1248,  0.1080],\n",
      "        [ 0.0470, -0.1795, -0.0656],\n",
      "        [ 0.0736,  0.2107, -0.0808],\n",
      "        [-0.0270,  0.1083, -0.0542],\n",
      "        [ 0.0364, -0.0526, -0.2105],\n",
      "        [ 0.0943, -0.0162,  0.1696],\n",
      "        [ 0.0225, -0.0548,  0.0172],\n",
      "        [-0.1211,  0.0956,  0.1403],\n",
      "        [-0.0546, -0.2059, -0.1119],\n",
      "        [-0.0406,  0.1752, -0.0104],\n",
      "        [ 0.1356, -0.0316, -0.0276],\n",
      "        [ 0.1132, -0.1906, -0.0449],\n",
      "        [ 0.1986,  0.0537, -0.1250],\n",
      "        [ 0.1580,  0.0749, -0.1771],\n",
      "        [ 0.0869, -0.1927,  0.0097],\n",
      "        [-0.1053, -0.1603, -0.1234],\n",
      "        [ 0.0105,  0.1653,  0.1261],\n",
      "        [-0.0729, -0.2139, -0.0239],\n",
      "        [ 0.0839, -0.0162,  0.2044],\n",
      "        [-0.1403, -0.2123,  0.0327],\n",
      "        [-0.0513,  0.0207, -0.0039],\n",
      "        [ 0.0750,  0.1107,  0.1542],\n",
      "        [-0.0671, -0.0923, -0.1832],\n",
      "        [ 0.0662, -0.0427,  0.1945],\n",
      "        [ 0.0840,  0.1054,  0.1653],\n",
      "        [-0.0164, -0.1073,  0.1823],\n",
      "        [-0.0600,  0.2049, -0.1791],\n",
      "        [-0.1789,  0.1296,  0.0799],\n",
      "        [ 0.1148, -0.1045, -0.0935],\n",
      "        [ 0.1028, -0.0024, -0.2061],\n",
      "        [-0.1808, -0.0469, -0.0632],\n",
      "        [-0.1627, -0.0346, -0.0251],\n",
      "        [ 0.0639, -0.0867, -0.1173],\n",
      "        [-0.0200,  0.1547, -0.1138],\n",
      "        [ 0.1800,  0.1960, -0.0979],\n",
      "        [-0.0574, -0.1819,  0.0399],\n",
      "        [-0.0047, -0.1603,  0.1649],\n",
      "        [-0.0875, -0.1545,  0.0598],\n",
      "        [ 0.1614, -0.0008, -0.0382],\n",
      "        [-0.0253, -0.0904,  0.0939],\n",
      "        [-0.1955,  0.1036,  0.0933],\n",
      "        [ 0.0110,  0.0855,  0.0621],\n",
      "        [ 0.1303,  0.0313, -0.0055],\n",
      "        [-0.2138,  0.0953,  0.0744],\n",
      "        [ 0.0380,  0.0165,  0.1358],\n",
      "        [ 0.0100,  0.0500,  0.0442]])), ('cheb_conv.lins.2.weight', tensor([[ 0.0966, -0.1076,  0.1074],\n",
      "        [-0.2033, -0.0901,  0.1921],\n",
      "        [ 0.1321, -0.1361, -0.0561],\n",
      "        [ 0.1280,  0.1645,  0.1160],\n",
      "        [-0.1199,  0.0784,  0.0121],\n",
      "        [ 0.0041,  0.0817,  0.0140],\n",
      "        [-0.1397, -0.0499, -0.1797],\n",
      "        [ 0.1229, -0.1239, -0.1923],\n",
      "        [ 0.1543, -0.1967,  0.0562],\n",
      "        [ 0.2085,  0.1069, -0.1889],\n",
      "        [-0.0787,  0.1216, -0.1919],\n",
      "        [ 0.0982, -0.0200, -0.1916],\n",
      "        [-0.1876, -0.1423, -0.0966],\n",
      "        [-0.0696,  0.0236, -0.1062],\n",
      "        [-0.1239,  0.1397,  0.0160],\n",
      "        [-0.1963, -0.0021,  0.1350],\n",
      "        [-0.0317, -0.1231,  0.0793],\n",
      "        [ 0.0775,  0.0169, -0.1267],\n",
      "        [ 0.0638, -0.1310,  0.1959],\n",
      "        [-0.1649,  0.0170,  0.1390],\n",
      "        [ 0.1176, -0.1573, -0.1789],\n",
      "        [-0.1351, -0.1913,  0.1531],\n",
      "        [-0.1067, -0.1779, -0.0550],\n",
      "        [ 0.0466,  0.1766,  0.0671],\n",
      "        [-0.1478, -0.1931,  0.0466],\n",
      "        [ 0.0246,  0.2078, -0.0511],\n",
      "        [-0.1344, -0.0579,  0.1550],\n",
      "        [-0.1750,  0.0480,  0.1384],\n",
      "        [-0.0212,  0.0221,  0.1053],\n",
      "        [ 0.1734, -0.0793,  0.2113],\n",
      "        [-0.0833, -0.0318,  0.2033],\n",
      "        [-0.1571, -0.0369,  0.1050],\n",
      "        [-0.1565,  0.2062,  0.0805],\n",
      "        [-0.0992,  0.2055,  0.0727],\n",
      "        [-0.0530,  0.2123, -0.1259],\n",
      "        [ 0.1027, -0.2013,  0.0467],\n",
      "        [ 0.0644, -0.0618,  0.1399],\n",
      "        [ 0.1912, -0.1423, -0.1440],\n",
      "        [-0.1512,  0.0449,  0.1424],\n",
      "        [-0.1042,  0.1564, -0.1317],\n",
      "        [ 0.1502,  0.1446, -0.2109],\n",
      "        [-0.1688,  0.0888, -0.0985],\n",
      "        [ 0.1301, -0.1523, -0.0249],\n",
      "        [ 0.1387,  0.0306,  0.1545],\n",
      "        [-0.1960, -0.0383, -0.1273],\n",
      "        [ 0.1175,  0.0796, -0.1240],\n",
      "        [ 0.0296, -0.0431, -0.2028],\n",
      "        [ 0.0948,  0.1814, -0.1719],\n",
      "        [ 0.1356,  0.2021,  0.0612],\n",
      "        [ 0.1066, -0.1032,  0.0674],\n",
      "        [ 0.1839, -0.1654, -0.1068],\n",
      "        [-0.0232,  0.0982, -0.1260],\n",
      "        [ 0.1717,  0.0516, -0.2019],\n",
      "        [-0.1439,  0.0920,  0.1134],\n",
      "        [-0.1001,  0.0271,  0.0509],\n",
      "        [ 0.1910, -0.1313, -0.1389],\n",
      "        [ 0.1216,  0.0872,  0.0526],\n",
      "        [-0.1274, -0.1743, -0.1943],\n",
      "        [ 0.2076,  0.1376,  0.0797],\n",
      "        [-0.0752,  0.1238, -0.0390],\n",
      "        [-0.0218, -0.0680, -0.1122],\n",
      "        [ 0.0382, -0.1536,  0.0180],\n",
      "        [ 0.0441,  0.0302, -0.0289],\n",
      "        [ 0.1806,  0.1096, -0.0963],\n",
      "        [ 0.0561, -0.0293, -0.0983],\n",
      "        [ 0.2036, -0.0632, -0.0434],\n",
      "        [-0.0997, -0.1230,  0.1816],\n",
      "        [ 0.1247,  0.1520,  0.0682],\n",
      "        [-0.0460,  0.1965,  0.0031],\n",
      "        [-0.0913, -0.0769,  0.0373],\n",
      "        [ 0.1001,  0.1074, -0.0946],\n",
      "        [ 0.1902, -0.0783, -0.1648],\n",
      "        [ 0.1449, -0.0927, -0.1218],\n",
      "        [ 0.0725,  0.0077,  0.0432],\n",
      "        [ 0.0307, -0.1396,  0.0813],\n",
      "        [-0.0422, -0.1303,  0.1135],\n",
      "        [-0.1450,  0.1618,  0.0881],\n",
      "        [-0.0561, -0.2034,  0.0087],\n",
      "        [ 0.2130,  0.0862,  0.1589],\n",
      "        [-0.1699,  0.1233, -0.0925],\n",
      "        [-0.1647,  0.0848, -0.0680],\n",
      "        [ 0.1437,  0.1754,  0.0711],\n",
      "        [ 0.1833,  0.1370,  0.0627],\n",
      "        [-0.1479, -0.1071, -0.1730],\n",
      "        [-0.1824,  0.1690,  0.1803],\n",
      "        [-0.1106, -0.0034, -0.0876],\n",
      "        [-0.2125, -0.1795,  0.1393],\n",
      "        [-0.1491,  0.1301,  0.1066],\n",
      "        [ 0.1355,  0.0585, -0.1172],\n",
      "        [-0.1085,  0.2107, -0.0887],\n",
      "        [-0.1310, -0.0367,  0.0962],\n",
      "        [-0.1647,  0.1186,  0.0919],\n",
      "        [ 0.0287,  0.0609, -0.1715],\n",
      "        [ 0.1923,  0.1924, -0.0635],\n",
      "        [ 0.1336, -0.0150, -0.1556],\n",
      "        [ 0.0941,  0.1272,  0.1173],\n",
      "        [ 0.1535,  0.0725, -0.1790],\n",
      "        [-0.0422, -0.0955,  0.0914],\n",
      "        [-0.0558,  0.0419, -0.0099],\n",
      "        [ 0.1355, -0.0224,  0.1591],\n",
      "        [-0.0950,  0.1759,  0.1733],\n",
      "        [-0.0583, -0.0768, -0.1197],\n",
      "        [-0.1353, -0.0557, -0.0546],\n",
      "        [-0.0745, -0.0256, -0.0589],\n",
      "        [-0.1646, -0.1548, -0.0375],\n",
      "        [-0.1942,  0.0882,  0.0845],\n",
      "        [-0.0223,  0.1679, -0.0966],\n",
      "        [-0.0197, -0.0895,  0.1596],\n",
      "        [-0.0252, -0.1056,  0.1701],\n",
      "        [ 0.1084, -0.1382, -0.0556],\n",
      "        [ 0.1991, -0.1419, -0.1767],\n",
      "        [ 0.0659, -0.0639, -0.1196],\n",
      "        [ 0.0205, -0.1772, -0.1214],\n",
      "        [-0.0475, -0.0705,  0.0704],\n",
      "        [ 0.0402, -0.0391, -0.1327],\n",
      "        [ 0.1967,  0.1553,  0.0828],\n",
      "        [ 0.1331,  0.1566,  0.1478],\n",
      "        [-0.1153,  0.0528, -0.0611],\n",
      "        [ 0.1018,  0.0944, -0.0139],\n",
      "        [ 0.2117, -0.0114,  0.0311],\n",
      "        [-0.1100,  0.1771,  0.1296],\n",
      "        [ 0.0935,  0.1858,  0.0102],\n",
      "        [ 0.1133, -0.0984, -0.0419],\n",
      "        [ 0.0118,  0.1682,  0.1389],\n",
      "        [-0.1212, -0.1410,  0.1160],\n",
      "        [-0.1443,  0.2083,  0.2137],\n",
      "        [-0.1840, -0.1054,  0.1417],\n",
      "        [ 0.0008, -0.1598,  0.1732]])), ('cheb_conv.lins.3.weight', tensor([[-7.7763e-02, -1.6442e-01,  2.1273e-01],\n",
      "        [-1.8539e-01, -4.8145e-02,  7.7263e-02],\n",
      "        [-3.7985e-03, -2.0836e-01,  5.0807e-02],\n",
      "        [ 8.4475e-02, -7.3873e-02,  2.0268e-01],\n",
      "        [ 1.7299e-01,  1.2137e-01, -1.4363e-01],\n",
      "        [-1.4021e-01,  1.7863e-01,  1.3041e-01],\n",
      "        [-4.7545e-02,  1.9579e-01,  1.9792e-01],\n",
      "        [-1.0212e-02,  1.9785e-01, -5.2402e-02],\n",
      "        [ 9.8117e-02,  1.8216e-01,  6.3354e-02],\n",
      "        [ 2.3026e-03, -1.1675e-01, -4.8043e-02],\n",
      "        [-1.4593e-01, -1.7031e-01, -1.2353e-01],\n",
      "        [ 2.6148e-03, -1.3284e-01, -1.2775e-01],\n",
      "        [-1.1399e-01, -1.4004e-01, -1.6878e-01],\n",
      "        [ 2.4131e-02,  1.7574e-01,  2.0040e-01],\n",
      "        [ 2.0681e-01, -4.4577e-02, -2.0981e-01],\n",
      "        [-6.6689e-02, -4.4486e-02, -1.0088e-01],\n",
      "        [ 8.2515e-02,  2.0728e-01, -8.3226e-02],\n",
      "        [ 2.0232e-01, -2.1390e-01, -1.0742e-01],\n",
      "        [ 1.4779e-01,  6.3527e-02,  1.3169e-01],\n",
      "        [-1.5224e-01, -9.9143e-02, -4.3299e-02],\n",
      "        [ 1.9941e-01, -2.1224e-01,  6.7544e-02],\n",
      "        [ 1.4474e-01,  1.0437e-01,  1.2716e-01],\n",
      "        [-1.5005e-02,  4.4564e-02, -4.7471e-04],\n",
      "        [-1.1433e-01,  1.3444e-01, -2.0968e-01],\n",
      "        [-2.9566e-02,  1.7799e-01, -1.5847e-01],\n",
      "        [-7.7822e-02, -1.2335e-02,  2.1158e-01],\n",
      "        [ 1.7140e-01,  1.2100e-01,  7.8922e-02],\n",
      "        [-2.7029e-02,  1.8643e-01, -7.9830e-02],\n",
      "        [ 1.1549e-01, -1.3281e-01,  1.4829e-03],\n",
      "        [-1.2497e-01,  1.9044e-01, -9.9164e-02],\n",
      "        [-1.9307e-01,  1.4106e-01,  3.2968e-02],\n",
      "        [ 1.9933e-01, -2.8644e-02,  1.5166e-01],\n",
      "        [ 4.0224e-02,  1.7231e-01,  5.0534e-02],\n",
      "        [ 5.7162e-02,  1.1304e-01,  9.3875e-02],\n",
      "        [ 1.6868e-01, -9.4535e-02,  2.5883e-02],\n",
      "        [-1.8417e-01, -9.1038e-02, -1.3094e-02],\n",
      "        [-7.1166e-02,  1.2576e-01, -9.8962e-02],\n",
      "        [-2.7534e-02, -1.5667e-01, -2.0822e-01],\n",
      "        [-1.4564e-01, -1.9349e-01,  1.5452e-01],\n",
      "        [-4.7121e-02,  1.5634e-01,  1.9666e-02],\n",
      "        [-1.5543e-01, -1.4505e-01,  5.2740e-02],\n",
      "        [-1.9418e-01, -7.9953e-02,  6.2071e-02],\n",
      "        [ 6.0816e-02,  6.4229e-02, -7.3535e-02],\n",
      "        [-1.1613e-01,  6.5776e-02,  2.4028e-02],\n",
      "        [-9.9108e-02,  9.4827e-02, -5.8651e-02],\n",
      "        [ 2.0001e-01, -5.0790e-02, -1.0387e-01],\n",
      "        [-4.0629e-02, -1.0924e-01,  9.7826e-02],\n",
      "        [ 6.4543e-03,  1.2871e-01, -1.7798e-01],\n",
      "        [ 7.1618e-02,  2.0031e-01, -1.7821e-01],\n",
      "        [ 5.8658e-02, -6.7083e-02, -9.5049e-02],\n",
      "        [-1.6568e-01, -1.7620e-02,  3.7661e-02],\n",
      "        [ 1.6753e-01, -1.4547e-01,  9.3832e-02],\n",
      "        [ 9.3717e-02, -1.9659e-01, -9.9691e-02],\n",
      "        [ 1.8425e-01,  4.2885e-02, -1.8061e-01],\n",
      "        [-1.8326e-01, -1.2699e-01, -3.8158e-02],\n",
      "        [-1.5335e-01, -1.8135e-01,  1.4311e-01],\n",
      "        [ 5.5037e-02,  3.0830e-02, -1.3104e-01],\n",
      "        [-1.1080e-01,  1.8817e-02,  1.6205e-01],\n",
      "        [ 1.2116e-01, -1.6956e-01, -1.4256e-01],\n",
      "        [-1.8317e-01,  1.8621e-01,  1.2261e-01],\n",
      "        [ 1.9261e-01, -1.3437e-01,  4.4133e-02],\n",
      "        [-8.9091e-02, -1.1424e-01, -9.9379e-02],\n",
      "        [-2.0198e-01, -5.2510e-02,  3.7546e-02],\n",
      "        [ 6.2894e-02,  1.6609e-01, -2.8612e-02],\n",
      "        [ 1.5530e-01, -1.3272e-01, -1.4428e-01],\n",
      "        [ 2.7521e-02, -6.4609e-02,  1.4166e-01],\n",
      "        [ 3.9748e-02, -1.6352e-01,  6.6352e-02],\n",
      "        [ 2.4055e-02,  1.0149e-01, -1.9018e-01],\n",
      "        [-2.9535e-02,  1.8410e-01,  1.5285e-01],\n",
      "        [-2.0948e-01, -1.9179e-01, -1.0060e-02],\n",
      "        [ 2.0679e-01,  1.6802e-04,  2.0710e-01],\n",
      "        [-1.6669e-01, -1.4144e-01,  9.5574e-02],\n",
      "        [ 6.7816e-02, -1.5547e-01,  2.9265e-02],\n",
      "        [ 1.8158e-01,  5.0469e-02, -1.0159e-01],\n",
      "        [ 6.5869e-02, -1.7964e-01,  9.7731e-02],\n",
      "        [ 4.3816e-02,  4.8751e-02, -1.1398e-01],\n",
      "        [ 5.4005e-02, -3.4853e-02, -1.9732e-01],\n",
      "        [-1.8505e-01,  2.1388e-01,  1.0650e-01],\n",
      "        [ 1.4691e-01,  1.4556e-01,  1.2087e-01],\n",
      "        [ 8.9493e-02, -1.5842e-01, -1.9115e-01],\n",
      "        [ 5.5541e-02,  1.1446e-01, -3.4538e-03],\n",
      "        [ 1.0796e-01,  5.2512e-02, -7.9558e-02],\n",
      "        [ 3.6338e-03,  2.9656e-03, -1.7400e-02],\n",
      "        [ 1.9994e-01, -1.7331e-01, -2.1127e-01],\n",
      "        [ 4.4893e-03,  1.9204e-02, -1.3334e-01],\n",
      "        [ 8.7960e-02,  9.9342e-02,  1.2714e-01],\n",
      "        [ 1.3906e-01,  3.1411e-02,  1.7290e-01],\n",
      "        [ 1.3888e-01,  7.5239e-02,  7.7791e-02],\n",
      "        [ 1.8602e-02,  1.3762e-02,  3.8719e-02],\n",
      "        [-1.8601e-01,  1.7250e-01, -9.2197e-02],\n",
      "        [ 1.8380e-01, -5.0524e-03,  2.0445e-01],\n",
      "        [ 9.2963e-03,  1.2975e-01, -7.2469e-02],\n",
      "        [-4.5974e-02,  1.8728e-01, -4.1993e-02],\n",
      "        [-2.0125e-02, -1.9242e-01,  1.9404e-01],\n",
      "        [ 3.3286e-02,  1.8453e-01, -2.0607e-01],\n",
      "        [-1.5368e-01,  1.0318e-01,  1.1453e-02],\n",
      "        [-1.2097e-01, -6.2836e-02,  3.5075e-02],\n",
      "        [-4.6552e-02,  5.0736e-02, -6.2901e-02],\n",
      "        [ 3.8099e-02,  2.1220e-01,  1.8997e-01],\n",
      "        [-1.1315e-01, -8.6207e-02,  6.0098e-02],\n",
      "        [-1.6341e-01, -1.1047e-01, -1.1061e-01],\n",
      "        [-1.7257e-01,  1.3606e-01,  1.8348e-01],\n",
      "        [ 8.3282e-02,  4.9839e-02, -1.6861e-01],\n",
      "        [ 3.0429e-03, -1.5436e-01,  1.2570e-01],\n",
      "        [ 8.1010e-03, -1.2732e-02, -5.7480e-02],\n",
      "        [-1.6554e-02, -6.7148e-02,  5.3545e-02],\n",
      "        [ 1.7078e-02,  1.1827e-02,  6.9835e-02],\n",
      "        [-1.9960e-02, -1.3772e-01, -1.1393e-01],\n",
      "        [ 1.7486e-01, -1.0372e-01,  1.7789e-01],\n",
      "        [ 1.8808e-01, -2.1009e-01, -1.0289e-01],\n",
      "        [ 1.9621e-01, -1.4788e-01,  2.0526e-01],\n",
      "        [-3.0319e-02, -1.0271e-03,  1.8895e-01],\n",
      "        [ 1.0357e-02,  1.3370e-01,  2.0602e-01],\n",
      "        [ 6.4185e-03, -1.2081e-01, -1.7696e-01],\n",
      "        [ 1.2742e-02, -1.4322e-01, -1.1225e-01],\n",
      "        [ 1.0988e-02,  2.0334e-01, -1.7689e-02],\n",
      "        [ 2.4700e-03, -8.3526e-02,  1.3033e-01],\n",
      "        [-9.6853e-02, -8.4102e-02, -6.2547e-02],\n",
      "        [ 1.5245e-01,  1.7371e-01, -9.8657e-02],\n",
      "        [ 1.8854e-01, -1.3744e-01,  4.9751e-02],\n",
      "        [ 1.1473e-01,  1.5518e-01, -4.4899e-02],\n",
      "        [-2.3636e-02, -1.2803e-01,  1.3710e-01],\n",
      "        [-1.6578e-01,  6.0024e-02,  4.1072e-02],\n",
      "        [-2.0554e-01,  9.5991e-02,  1.1625e-01],\n",
      "        [ 1.7963e-02, -1.9381e-01, -7.9213e-02],\n",
      "        [-2.5447e-02,  7.4435e-02,  3.4902e-03],\n",
      "        [ 1.0755e-01, -2.1483e-02, -3.9283e-02],\n",
      "        [-2.1161e-01,  3.0891e-02, -3.9280e-02]])), ('cheb_conv.lins.4.weight', tensor([[ 6.2353e-02, -1.4693e-02,  2.8907e-02],\n",
      "        [-5.5095e-02, -7.9593e-02,  2.0712e-01],\n",
      "        [-8.3337e-02, -1.7143e-01,  1.0599e-01],\n",
      "        [-1.5418e-01,  2.0339e-01,  8.9871e-02],\n",
      "        [-1.0634e-01, -1.0964e-01,  1.2350e-01],\n",
      "        [ 1.1554e-01,  1.7888e-01, -1.4992e-02],\n",
      "        [ 1.2186e-01,  1.7601e-01, -2.5409e-02],\n",
      "        [-5.7073e-02, -2.1017e-01, -8.1592e-02],\n",
      "        [ 5.0621e-02, -5.2666e-02, -1.4136e-01],\n",
      "        [ 2.3016e-02,  1.1032e-01, -6.4230e-02],\n",
      "        [-1.2221e-01,  2.0793e-01,  1.0861e-01],\n",
      "        [-7.7543e-02,  7.5518e-02,  1.7020e-01],\n",
      "        [ 1.9234e-01, -1.1232e-01,  6.3435e-02],\n",
      "        [ 1.8622e-01,  1.4224e-01,  1.2238e-01],\n",
      "        [-3.6065e-03,  4.5083e-02, -1.8359e-01],\n",
      "        [-1.2169e-01,  1.6263e-01, -9.0611e-02],\n",
      "        [-7.9804e-02,  8.2417e-02, -1.8955e-01],\n",
      "        [ 2.9040e-02,  2.1224e-01,  1.4582e-01],\n",
      "        [ 9.7869e-02,  2.0193e-01,  1.5676e-01],\n",
      "        [-7.2959e-02,  1.6331e-01, -7.4147e-02],\n",
      "        [-4.3690e-03, -2.0282e-01,  7.3973e-02],\n",
      "        [ 1.3118e-01,  1.4050e-01,  7.4070e-02],\n",
      "        [-6.6089e-02,  3.2320e-02, -9.1568e-02],\n",
      "        [ 7.2468e-02, -1.9353e-01,  9.6522e-02],\n",
      "        [-1.9334e-01,  1.2280e-01,  2.2295e-03],\n",
      "        [-6.9764e-02,  1.1478e-01, -1.2336e-01],\n",
      "        [-9.8386e-02,  3.9488e-02, -3.3701e-02],\n",
      "        [-2.1024e-01, -9.9514e-02,  1.9830e-01],\n",
      "        [-1.3299e-02,  4.3926e-02, -3.7839e-02],\n",
      "        [ 1.6740e-01,  6.3885e-02,  1.6126e-01],\n",
      "        [-4.3784e-02, -6.6667e-02, -1.3383e-01],\n",
      "        [ 6.0674e-02,  1.1309e-01,  1.4685e-01],\n",
      "        [ 4.3832e-02, -1.5056e-01, -1.8402e-01],\n",
      "        [-2.7885e-02, -5.2257e-02, -1.0027e-01],\n",
      "        [-2.8703e-03,  1.5169e-01, -8.5992e-02],\n",
      "        [-9.9392e-02, -2.5665e-02,  3.0189e-02],\n",
      "        [-1.9855e-01, -2.0517e-01, -1.1109e-01],\n",
      "        [-1.4283e-01, -1.4329e-01, -4.7499e-02],\n",
      "        [ 1.0469e-01, -8.3024e-02, -1.1942e-01],\n",
      "        [ 1.4685e-02, -2.6861e-02,  2.1012e-02],\n",
      "        [ 2.0062e-01, -4.1062e-02,  1.1196e-01],\n",
      "        [ 4.8265e-02, -2.7661e-02,  1.2823e-01],\n",
      "        [-9.4553e-02, -1.4843e-01,  1.0250e-01],\n",
      "        [ 1.1285e-01, -4.8220e-02, -1.7295e-01],\n",
      "        [ 1.8365e-01, -5.7643e-02,  1.5323e-01],\n",
      "        [-2.1299e-01, -9.0326e-02,  4.1995e-02],\n",
      "        [ 2.0250e-01, -8.0751e-02,  1.5825e-01],\n",
      "        [-4.6572e-02,  1.4587e-01, -1.6649e-01],\n",
      "        [ 6.3753e-02,  6.3704e-03,  8.4775e-02],\n",
      "        [-2.1201e-01, -4.3808e-02,  1.7832e-01],\n",
      "        [-9.0414e-02,  1.6089e-01, -1.7145e-01],\n",
      "        [-1.0037e-01,  1.4195e-01,  9.5062e-02],\n",
      "        [ 1.8812e-01, -1.3223e-01,  8.4696e-02],\n",
      "        [-1.4788e-01,  2.0505e-02, -2.1204e-01],\n",
      "        [ 8.7359e-02, -2.1267e-01,  1.5705e-01],\n",
      "        [ 1.6605e-01, -1.8416e-01, -1.1607e-01],\n",
      "        [ 2.8328e-02, -9.1821e-02,  2.0785e-01],\n",
      "        [ 1.6264e-01, -1.4635e-01, -2.6424e-02],\n",
      "        [-1.6186e-01, -5.5187e-02,  6.4552e-02],\n",
      "        [ 2.1135e-01,  6.1541e-02,  1.6121e-01],\n",
      "        [ 1.4313e-01,  1.1661e-01,  4.2855e-02],\n",
      "        [ 9.8467e-02, -1.7638e-01, -1.9209e-01],\n",
      "        [-1.2514e-01, -6.1613e-02, -7.0146e-02],\n",
      "        [-8.8075e-02,  2.0089e-01, -1.8928e-02],\n",
      "        [-1.8332e-01,  7.0088e-02,  2.4475e-03],\n",
      "        [ 6.4288e-02, -7.0377e-02,  7.3001e-02],\n",
      "        [-1.0454e-02, -1.9369e-01,  4.8055e-02],\n",
      "        [-5.1750e-02,  7.9438e-02, -1.7728e-01],\n",
      "        [ 1.4544e-01, -3.2749e-02, -1.7479e-01],\n",
      "        [-1.4276e-01, -2.0406e-01,  7.1929e-02],\n",
      "        [ 1.7591e-01,  9.2181e-02,  2.0040e-01],\n",
      "        [-1.6349e-02,  6.9977e-02, -1.2033e-02],\n",
      "        [ 1.0601e-01,  1.7294e-01,  4.8384e-02],\n",
      "        [ 1.2351e-01, -2.0718e-01, -7.1514e-02],\n",
      "        [ 3.9904e-02, -1.5473e-01, -1.1098e-01],\n",
      "        [ 2.8590e-02,  2.0100e-01, -1.7860e-01],\n",
      "        [ 4.3533e-02,  2.0807e-01, -8.0735e-02],\n",
      "        [-1.7282e-01,  1.5899e-01, -9.7633e-02],\n",
      "        [-1.3341e-01, -9.0287e-02,  7.9795e-02],\n",
      "        [-1.6078e-02,  9.7587e-02, -1.2930e-01],\n",
      "        [ 1.3469e-02,  1.4239e-01, -5.9458e-02],\n",
      "        [-5.5428e-02, -2.1184e-01,  2.0075e-01],\n",
      "        [-1.1029e-01,  6.3412e-03, -1.4410e-01],\n",
      "        [-1.4049e-01,  1.6243e-01, -1.8657e-01],\n",
      "        [ 1.9534e-01, -2.1359e-01,  8.2244e-02],\n",
      "        [ 1.2076e-01,  4.6662e-04,  1.3299e-01],\n",
      "        [-1.2003e-01,  3.2794e-02,  3.6580e-02],\n",
      "        [ 1.8281e-03,  6.7931e-02,  1.3245e-01],\n",
      "        [-1.0236e-01,  4.9061e-02, -3.4389e-02],\n",
      "        [-2.1578e-02, -1.2315e-01, -1.4165e-01],\n",
      "        [ 1.6029e-01, -1.3822e-01,  2.6735e-03],\n",
      "        [ 2.1176e-01,  1.7918e-01, -1.9980e-01],\n",
      "        [-7.3391e-02,  9.3333e-02,  2.0806e-01],\n",
      "        [-1.4542e-02, -6.5194e-02, -1.7279e-01],\n",
      "        [ 6.5674e-02, -2.2825e-02, -1.1647e-01],\n",
      "        [-2.1177e-01,  1.6633e-02,  1.9043e-01],\n",
      "        [-5.4735e-02,  4.5852e-02,  2.0174e-01],\n",
      "        [ 7.7439e-02, -9.5631e-02, -4.5586e-02],\n",
      "        [ 1.3788e-01, -1.1385e-01,  1.1594e-01],\n",
      "        [ 1.5669e-01, -5.7890e-02,  8.2387e-02],\n",
      "        [ 1.7930e-01,  1.5740e-01,  1.7987e-01],\n",
      "        [-2.3054e-02,  1.8828e-01,  1.8680e-04],\n",
      "        [ 2.0980e-02,  7.1411e-02,  1.9858e-01],\n",
      "        [ 1.5293e-01, -1.3231e-02,  5.5168e-02],\n",
      "        [-1.8555e-01,  1.5772e-01, -9.6273e-02],\n",
      "        [-1.5641e-02,  1.2516e-02, -4.9142e-02],\n",
      "        [-8.5399e-02,  7.4644e-02,  1.6390e-01],\n",
      "        [-1.6872e-01,  4.9060e-02, -2.3048e-03],\n",
      "        [ 1.7334e-01, -1.8856e-01, -7.1270e-02],\n",
      "        [-1.1290e-01, -1.2408e-01,  1.4243e-01],\n",
      "        [ 1.9044e-01,  6.4823e-02, -9.6189e-02],\n",
      "        [-1.6406e-01,  2.0139e-01, -4.0740e-02],\n",
      "        [ 6.7569e-03,  2.0801e-01,  1.0851e-01],\n",
      "        [ 1.0046e-01, -3.8492e-02, -5.3802e-02],\n",
      "        [ 7.0866e-02, -1.7709e-02, -1.5647e-01],\n",
      "        [ 2.8359e-02,  1.5631e-01,  1.5299e-01],\n",
      "        [ 1.1645e-01, -6.6113e-02, -5.6521e-02],\n",
      "        [ 9.5851e-02, -1.7460e-01, -1.3329e-01],\n",
      "        [ 7.4811e-02, -1.8176e-01, -4.9601e-02],\n",
      "        [ 8.0092e-02, -1.6592e-01, -8.1848e-02],\n",
      "        [ 1.5288e-01, -1.0780e-01, -1.3378e-02],\n",
      "        [ 1.8099e-01, -5.6214e-02,  2.0316e-01],\n",
      "        [ 5.2854e-02,  1.3385e-01, -5.5777e-02],\n",
      "        [ 3.6129e-02,  1.1936e-01,  9.3356e-02],\n",
      "        [ 1.1937e-01, -1.8614e-01,  7.8283e-02],\n",
      "        [-2.0720e-01,  3.1348e-02,  5.6806e-02],\n",
      "        [-1.3565e-01,  1.3517e-01, -1.8610e-01],\n",
      "        [ 9.3910e-02,  1.6235e-01, -2.7415e-02]])), ('cheb_conv.lins.5.weight', tensor([[-0.2062, -0.1081, -0.1069],\n",
      "        [ 0.1742, -0.0523,  0.2011],\n",
      "        [-0.1400, -0.1690, -0.1284],\n",
      "        [ 0.2085, -0.0804, -0.1228],\n",
      "        [ 0.0590,  0.1675, -0.1949],\n",
      "        [ 0.0888, -0.0452, -0.0623],\n",
      "        [-0.1209,  0.0944,  0.0532],\n",
      "        [ 0.1668, -0.1376,  0.0925],\n",
      "        [ 0.0785, -0.2052,  0.0067],\n",
      "        [ 0.1918,  0.1463, -0.1693],\n",
      "        [-0.1876, -0.1226,  0.2082],\n",
      "        [-0.1191, -0.0858, -0.2057],\n",
      "        [ 0.0501, -0.0878,  0.2017],\n",
      "        [-0.1195, -0.0929, -0.1470],\n",
      "        [ 0.1130, -0.1645,  0.0591],\n",
      "        [ 0.1335,  0.1757,  0.0951],\n",
      "        [-0.1998,  0.1590, -0.1288],\n",
      "        [ 0.2107,  0.1406, -0.1530],\n",
      "        [-0.0860,  0.1317,  0.0499],\n",
      "        [-0.0647,  0.0522, -0.1699],\n",
      "        [ 0.0555, -0.0484, -0.0839],\n",
      "        [ 0.0316, -0.0178,  0.1900],\n",
      "        [ 0.0142, -0.0103,  0.0956],\n",
      "        [-0.1282,  0.0819,  0.1448],\n",
      "        [ 0.0316, -0.1187,  0.0314],\n",
      "        [-0.0017,  0.0125, -0.1276],\n",
      "        [-0.0513,  0.0195, -0.1639],\n",
      "        [ 0.0911,  0.1628,  0.0158],\n",
      "        [ 0.0671,  0.0642,  0.1303],\n",
      "        [ 0.1217, -0.0707,  0.0201],\n",
      "        [-0.0783, -0.0949, -0.2102],\n",
      "        [-0.0531, -0.0781,  0.2035],\n",
      "        [ 0.1816,  0.1809,  0.1045],\n",
      "        [-0.0991, -0.0892, -0.0557],\n",
      "        [-0.2125,  0.2042,  0.1648],\n",
      "        [ 0.1204,  0.2111, -0.1049],\n",
      "        [ 0.1730, -0.1692,  0.1210],\n",
      "        [ 0.0641,  0.1880,  0.1298],\n",
      "        [-0.1856, -0.1358, -0.0370],\n",
      "        [-0.0629,  0.1420, -0.0473],\n",
      "        [ 0.1616, -0.0181,  0.0546],\n",
      "        [ 0.0269, -0.1423, -0.0356],\n",
      "        [ 0.0129, -0.0456, -0.0868],\n",
      "        [-0.0400,  0.0350,  0.1216],\n",
      "        [-0.1150, -0.0359, -0.1978],\n",
      "        [ 0.1953, -0.1286,  0.0729],\n",
      "        [-0.0209, -0.0933,  0.0605],\n",
      "        [ 0.1968,  0.2069,  0.1134],\n",
      "        [ 0.1134,  0.0325,  0.1424],\n",
      "        [-0.1944, -0.0588, -0.0324],\n",
      "        [ 0.0477, -0.1466, -0.0062],\n",
      "        [ 0.0003,  0.1293,  0.0233],\n",
      "        [ 0.1971, -0.1930,  0.1363],\n",
      "        [-0.0095, -0.1534,  0.0155],\n",
      "        [ 0.1808,  0.1696, -0.1614],\n",
      "        [-0.0946, -0.1696,  0.2112],\n",
      "        [-0.1309,  0.1207,  0.0881],\n",
      "        [-0.1023,  0.2131,  0.0159],\n",
      "        [-0.2072,  0.0199,  0.0338],\n",
      "        [ 0.1212, -0.0675,  0.1444],\n",
      "        [-0.1772,  0.0737,  0.0837],\n",
      "        [ 0.1613, -0.0309, -0.1470],\n",
      "        [ 0.1887, -0.0943, -0.1872],\n",
      "        [ 0.0714, -0.0823,  0.0728],\n",
      "        [ 0.1999,  0.1006,  0.1753],\n",
      "        [ 0.0504,  0.0992, -0.2015],\n",
      "        [ 0.1337,  0.1574,  0.1067],\n",
      "        [-0.1808, -0.1644,  0.0441],\n",
      "        [ 0.0868, -0.1446,  0.0602],\n",
      "        [ 0.1340, -0.2042, -0.0086],\n",
      "        [-0.0393, -0.1795,  0.1027],\n",
      "        [-0.1575,  0.1884,  0.1775],\n",
      "        [-0.1591,  0.0961,  0.0244],\n",
      "        [-0.0980, -0.0823, -0.0516],\n",
      "        [ 0.0104, -0.0292, -0.0713],\n",
      "        [-0.1592,  0.1770, -0.1368],\n",
      "        [-0.0738, -0.1736,  0.2096],\n",
      "        [-0.1869,  0.1661, -0.0891],\n",
      "        [-0.0010,  0.1671, -0.2010],\n",
      "        [-0.0249,  0.1324, -0.0976],\n",
      "        [ 0.0276, -0.1116, -0.0236],\n",
      "        [ 0.1172,  0.0678,  0.0633],\n",
      "        [ 0.0258,  0.0570,  0.1557],\n",
      "        [-0.0653, -0.0591,  0.1433],\n",
      "        [-0.1649, -0.1826, -0.1329],\n",
      "        [ 0.0661,  0.0425,  0.0456],\n",
      "        [-0.1012,  0.2013,  0.0217],\n",
      "        [ 0.1221,  0.1132,  0.1973],\n",
      "        [ 0.1028, -0.1923, -0.1549],\n",
      "        [-0.1870,  0.0158, -0.0952],\n",
      "        [-0.1325, -0.1363, -0.0532],\n",
      "        [ 0.1106,  0.1958, -0.1957],\n",
      "        [-0.0843,  0.1775,  0.1401],\n",
      "        [-0.0327,  0.1710, -0.0358],\n",
      "        [-0.0247,  0.0712,  0.0180],\n",
      "        [ 0.0741,  0.1448,  0.1592],\n",
      "        [ 0.2042, -0.1188, -0.1678],\n",
      "        [ 0.0531, -0.0797, -0.1540],\n",
      "        [ 0.2073,  0.0100, -0.0205],\n",
      "        [-0.0846,  0.0409, -0.1603],\n",
      "        [ 0.0583, -0.1276, -0.1100],\n",
      "        [-0.1278, -0.0808, -0.1816],\n",
      "        [-0.0943, -0.1838, -0.0500],\n",
      "        [ 0.1845, -0.0394,  0.0479],\n",
      "        [-0.0423, -0.2105, -0.0893],\n",
      "        [-0.0707,  0.0598, -0.0462],\n",
      "        [ 0.0340,  0.0771,  0.1583],\n",
      "        [ 0.0065,  0.0163,  0.2118],\n",
      "        [ 0.2136, -0.0494, -0.1470],\n",
      "        [ 0.1809,  0.0155,  0.1611],\n",
      "        [ 0.0174,  0.0538,  0.0159],\n",
      "        [-0.1234,  0.1160, -0.1181],\n",
      "        [-0.0844,  0.0881,  0.1885],\n",
      "        [ 0.2002, -0.1071,  0.1469],\n",
      "        [ 0.1749, -0.1482, -0.1864],\n",
      "        [ 0.1715,  0.1667,  0.1854],\n",
      "        [ 0.1012,  0.1144,  0.1573],\n",
      "        [ 0.1294,  0.1960, -0.1261],\n",
      "        [ 0.1812, -0.0178,  0.0211],\n",
      "        [ 0.0872, -0.0704, -0.0048],\n",
      "        [-0.1159,  0.0125, -0.0423],\n",
      "        [ 0.0825,  0.2110,  0.1796],\n",
      "        [ 0.0145, -0.1948,  0.1964],\n",
      "        [ 0.0019, -0.0465,  0.1008],\n",
      "        [ 0.0589,  0.0892, -0.0643],\n",
      "        [ 0.1341,  0.0309, -0.1504],\n",
      "        [ 0.1582, -0.0759,  0.1722],\n",
      "        [ 0.0861,  0.0708,  0.0669]]))])\n"
     ]
    }
   ],
   "source": [
    "x = dataset[0].pos\n",
    "x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "get_graph = GetGraph()\n",
    "W = get_graph(x)\n",
    "edge_index, edge_weight = tgu.dense_to_sparse(W)\n",
    "conv1 = RGCNN_Conv(F_in=3, K=6, F_out=128)\n",
    "aux = conv1(x, W)\n",
    "#print(aux.shape)\n",
    "\n",
    "print(conv1.state_dict())   # This shows the Parameters of the Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the defined Convolutional Layer we can create our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNN_Model(nn.Module):\n",
    "    def __init__(self, points_number, F, K, M, in_features):\n",
    "\n",
    "        # Verify the consistency w.r.t. the number of layers.\n",
    "        assert len(F) == len(K)\n",
    "        \n",
    "        super(RGCNN_Model, self).__init__()\n",
    "        self.points_number = points_number\n",
    "        self.F = F\n",
    "        self.L = L\n",
    "        self.M = M\n",
    "        self.layers_number = len(F)\n",
    "        self.get_graph = GetGraph()\n",
    "        self.convolution_list = []\n",
    "        self.mlp_list = []\n",
    "        self.rloss = nn.MSELoss()\n",
    "        self.pool = nn.MaxPool1d(points_number)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        for i in range(self.layers_number):\n",
    "            if i == 0:\n",
    "                layer = RGCNN_Conv(in_features, K[i], F[i])\n",
    "            else:\n",
    "                layer = RGCNN_Conv(F[i-1], K[i], F[i])\n",
    "            setattr(self, 'gcn%d' % i, layer)\n",
    "\n",
    "        for i in range(len(M)):\n",
    "            if i == 0:\n",
    "                mlp = nn.Linear(F[-1], M[i])\n",
    "            else:\n",
    "                mlp = nn.Linear(M[i-1], M[i])\n",
    "            setattr(self, 'mlp%d' % i, mlp )\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        W = self.get_graph(x)\n",
    "        losses = []\n",
    "        labels = torch.zeros(40)\n",
    "        labels[label] = 1\n",
    "        labels = labels.to(device)\n",
    "        for i in range(self.layers_number):\n",
    "            x = getattr(self, 'gcn%d' % i)(x, W)\n",
    "        loss = self.rloss(x, labels)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.pool(x)\n",
    "        x.squeeze_(2)\n",
    "        for i in range(len(self.M)):\n",
    "            x = getattr(self, 'mlp%d' % i)(x)\n",
    "            x = self.relu(x)\n",
    "        return x, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on  cuda\n"
     ]
    }
   ],
   "source": [
    "F = [128, 512, 1024, 512, 128, 40]  # Number of graph convolutional filters.\n",
    "K = [6, 5, 3, 1, 1, 1]  # Polynomial orders.\n",
    "M = [512, 128, 40]  # Output dimensionality of fully connected layers.\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print(\"Training on \", device)\n",
    "\n",
    "model = RGCNN_Model(points_number=points_number, F=F, K=K, M=M, in_features=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 3])\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    \n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        X = data.pos\n",
    "        label = data.y\n",
    "        X = X.reshape([1, X.shape[0], X.shape[1]])\n",
    "        X = X.to(device)\n",
    "        label = label.to(torch.float)\n",
    "        label = label.to(device)\n",
    "        # Forward pass.\n",
    "        print(label.to(torch.int).item())\n",
    "        out, loss = model(X, label.to(torch.int).item())\n",
    "        # Calculate gradients.\n",
    "        loss.backward()\n",
    "        # Updates the models parameters\n",
    "        optimizer.step()\n",
    "\n",
    "print(dataset[0].pos.shape)\n",
    "train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        X = data.pos\n",
    "        labels = data.y\n",
    "        X, labels = X.to(device), labels.to(device)  \n",
    "        X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "        # Forward pass.\n",
    "        out, loss = model(X, labels)\n",
    "        # Take the index of the class with the highest probability.\n",
    "        pred = out.argmax(dim=1)\n",
    "        # Compare with ground-truth labels.\n",
    "        correct += int((pred == labels).sum()) \n",
    "        print(correct)\n",
    "        # print(len(loader))\n",
    "    return correct / len(loader)\n",
    "\n",
    "test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Epoch: 1, Train Acc: 0.0250\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Epoch: 2, Train Acc: 0.0000\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Epoch: 3, Train Acc: 0.0250\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-6c29cd0607c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch}, Train Acc: {train_acc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-bdd0e0f9b2b2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Calculate gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Alex_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-a53f6d8e43b2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, label)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gcn%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Alex_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-d31edbf58de1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, W)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_to_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheb_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Alex_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Alex_torch/lib/python3.7/site-packages/torch_geometric/nn/conv/cheb_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlambda_max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mlambda_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             lambda_max = torch.tensor(lambda_max, dtype=x.dtype,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    train(dataset)\n",
    "    train_acc = test(dataset)\n",
    "    print(f'Epoch: {epoch}, Train Acc: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c0fe59c60a9be49491cfed5af4355f9d7f0b1a43e9b3a8e9ef6dffb36976bea"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
