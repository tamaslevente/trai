{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa46ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14cd3f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: ModelNet10(3991)\n",
      "Test dataset shape:  ModelNet10(908)\n",
      "Data(pos=[1024, 3], y=[1], normal=[1024, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import ModelNet\n",
    "from torch_geometric.transforms import SamplePoints\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_geometric.transforms import LinearTransformation\n",
    "from torch_geometric.transforms import GenerateMeshNormals\n",
    "from torch_geometric.transforms import NormalizeScale\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from torch_scatter import scatter_mean\n",
    "import sys\n",
    "\n",
    "## NOTE:\n",
    "# Made it work with ModelNet10 (in folder \"data/ModelNet\") that has only 10 classes\n",
    "# Now I'll try to test it with ModelNet40 (\"data/ModelNet40\") with 40 classes\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Choosing device:\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Hyper parameters:\n",
    "num_points = 1024    # 1024 seems to be the limit...?\n",
    "batch_size = 32      # not yet used\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import ModelNet\n",
    "from torch_geometric.transforms import SamplePoints\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_geometric.transforms import LinearTransformation\n",
    "from torch_geometric.transforms import GenerateMeshNormals\n",
    "from torch_geometric.transforms import NormalizeScale\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from torch_scatter import scatter_mean\n",
    "import sys\n",
    "\n",
    "\n",
    "## NOTE:\n",
    "# Made it work with ModelNet10 (in folder \"data/ModelNet\") that has only 10 classes\n",
    "# Now I'll try to test it with ModelNet40 (\"data/ModelNet40\") with 40 classes\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Choosing device:\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "#                  NO LONGER USED but leave them here...\n",
    "F = [128, 512, 1024]  # Number of graph convolutional filters.\n",
    "K = [6, 5, 3]         # Polynomial orders.\n",
    "M = [512, 128, 10]    # Output dimensionality of fully connected layers.\n",
    "##########################################################################\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "## Data loading:\n",
    "# For ModelNet10 change root to \"data/ModelNet\"   -> 10 classes\n",
    "# For MpdelNet40 change root to \"data/ModelNet40\" -> 40 classes\n",
    "# Don't forget to change accordingly the output layer from the model...\n",
    "transforms = Compose([SamplePoints(num_points, include_normals=True), NormalizeScale()])\n",
    "\n",
    "modelnet_num = 10\n",
    "root = \"data/ModelNet\"+str(modelnet_num)\n",
    "dataset_train = ModelNet(root=root, name=str(modelnet_num), train=True, transform=transforms)\n",
    "dataset_test = ModelNet(root=root, name=str(modelnet_num), train=False, transform=transforms)\n",
    "\n",
    "# Shuffle Data\n",
    "dataset_train = dataset_train.shuffle()\n",
    "dataset_test = dataset_test.shuffle()\n",
    "\n",
    "# Verification...\n",
    "print(f\"Train dataset shape: {dataset_train}\")\n",
    "print(f\"Test dataset shape:  {dataset_test}\")\n",
    "\n",
    "print(dataset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982f90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric.utils as utils\n",
    "import torch_geometric.nn.conv as conv\n",
    "\n",
    "class GetGraph(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Creates the weighted adjacency matrix 'W'\n",
    "        Taked directly from RGCNN\n",
    "        \"\"\"\n",
    "        super(GetGraph, self).__init__()\n",
    "\n",
    "    def forward(self, point_cloud):\n",
    "        point_cloud_transpose = point_cloud.permute(0, 2, 1)\n",
    "        point_cloud_inner = torch.matmul(point_cloud, point_cloud_transpose)\n",
    "        point_cloud_inner = -2 * point_cloud_inner\n",
    "        point_cloud_square = torch.sum(torch.mul(point_cloud, point_cloud), dim=2, keepdim=True)\n",
    "        point_cloud_square_tranpose = point_cloud_square.permute(0, 2, 1)\n",
    "        adj_matrix = point_cloud_square + point_cloud_inner + point_cloud_square_tranpose\n",
    "        adj_matrix = torch.exp(-adj_matrix)\n",
    "        return adj_matrix\n",
    "\n",
    "\n",
    "class GetLaplacian(nn.Module):\n",
    "    def __init__(self, normalize=True):\n",
    "        \"\"\"\n",
    "        Computes the Graph Laplacian from a Weighted Graph\n",
    "        Taken directly from RGCNN - currently not used - might need to find alternatives in PyG for loss function\n",
    "        \"\"\"\n",
    "        super(GetLaplacian, self).__init__()\n",
    "        self.normalize = normalize\n",
    "\n",
    "        def diag(self, mat):\n",
    "        # input is batch x vertices\n",
    "            d = []\n",
    "            for vec in mat:\n",
    "                d.append(torch.diag(vec))\n",
    "            return torch.stack(d)\n",
    "\n",
    "    def forward(self, adj_matrix):\n",
    "        if self.normalize:\n",
    "            D = torch.sum(adj_matrix, dim=1)\n",
    "            eye = torch.ones_like(D)\n",
    "            eye = self.diag(eye)\n",
    "            D = 1 / torch.sqrt(D)\n",
    "            D = self.diag(D)\n",
    "            L = eye - torch.matmul(torch.matmul(D, adj_matrix), D)\n",
    "        else:\n",
    "            D = torch.sum(adj_matrix, dim=1)\n",
    "            D = torch.diag(D)\n",
    "            L = D - adj_matrix\n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5583d500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = RGCNN_model(num_points, F, K, M)\\n\\nprint(\"Model\\'s state_dict:\")\\nfor param_tensor in model.state_dict():\\n    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\\n\\n# Print optimizer\\'s state_dict\\nprint(\"Optimizer\\'s state_dict:\")\\nfor var_name in optimizer.state_dict():\\n    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric.utils as utils\n",
    "import torch_geometric.nn.conv as conv\n",
    "import torch\n",
    "\n",
    "class RGCNN_model(nn.Module):\n",
    "    def __init__(self, vertice, F, K, M, regularization = 0, dropout = 0):\n",
    "        # verify the consistency w.r.t. the number of layers\n",
    "        assert len(F) == len(K)\n",
    "        super(RGCNN_model, self).__init__()\n",
    "        '''\n",
    "        F := List of Convolutional Layers dimensions\n",
    "        K := List of Chebyshev polynomial degrees\n",
    "        M := List of Fully Connected Layers dimenstions\n",
    "        \n",
    "        Currently the dimensions are 'hardcoded'\n",
    "        '''\n",
    "        self.F = F\n",
    "        self.K = K\n",
    "        self.M = M\n",
    "\n",
    "        self.vertice = vertice\n",
    "        self.regularization = regularization    # gamma from the paper: 10^-9\n",
    "        self.dropout = dropout\n",
    "        self.regularizers = []\n",
    "\n",
    "        # initialize the model layers\n",
    "        self.get_graph = GetGraph()\n",
    "        # self.get_laplacian = GetLaplacian(normalize=True)\n",
    "        self.pool = nn.MaxPool1d(self.vertice)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=self.dropout)\n",
    "\n",
    "        ###################################################################\n",
    "        #                               CHANGE HERE\n",
    "        self.conv1 = conv.ChebConv(6, 128, 6)\n",
    "        self.conv2 = conv.ChebConv(128, 512, 5)\n",
    "        self.conv3 = conv.ChebConv(512, 1024, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, modelnet_num)\n",
    "        ###################################################################\n",
    "\n",
    "        '''\n",
    "        for i in range(len(F)):\n",
    "            if i == 0:\n",
    "                layer = ChebConv(Fin=3, K=K[i], Fout=F[i])\n",
    "            else:\n",
    "                layer = ChebConv(Fin=F[i-1], K=K[i], Fout=F[i])\n",
    "            setattr(self, 'gcn%d'%i, layer)\n",
    "        for i in range(len(M)):\n",
    "            if i==0:\n",
    "                layer = nn.Linear(F[-1], M[i])\n",
    "            else:\n",
    "                layer = nn.Linear(M[i-1], M[i])\n",
    "            setattr(self, 'fc%d'%i, layer)\n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.regularizers = []\n",
    "        # forward pass\n",
    "        W   = self.get_graph(x.detach())  # we don't want to compute gradients when building the graph\n",
    "        edge_index, edge_weight = utils.dense_to_sparse(W)\n",
    "        out = self.conv1(x, edge_index, edge_weight)\n",
    "        out = self.relu(out)\n",
    "        edge_index, edge_weight = utils.remove_self_loops(edge_index, edge_weight)\n",
    "        L_edge_index, L_edge_weight = torch_geometric.utils.get_laplacian(edge_index.detach(), edge_weight.detach(), normalization=\"sym\")\n",
    "        L = torch_geometric.utils.to_dense_adj(edge_index=L_edge_index, edge_attr=L_edge_weight)\n",
    "        self.regularizers.append(torch.linalg.norm(torch.matmul(torch.matmul(torch.Tensor.permute(out.detach(), [0, 2, 1]), L), out.detach())))\n",
    "\n",
    "        W   = self.get_graph(out.detach())\n",
    "        edge_index, edge_weight = utils.dense_to_sparse(W)\n",
    "        out = self.conv2(out, edge_index, edge_weight)\n",
    "        out = self.relu(out)\n",
    "        edge_index, edge_weight = utils.remove_self_loops(edge_index, edge_weight)\n",
    "        L_edge_index, L_edge_weight = torch_geometric.utils.get_laplacian(edge_index.detach(), edge_weight.detach(), normalization=\"sym\")\n",
    "        L = torch_geometric.utils.to_dense_adj(edge_index=L_edge_index, edge_attr=L_edge_weight)\n",
    "        self.regularizers.append(torch.linalg.norm(torch.matmul(torch.matmul(torch.Tensor.permute(out.detach(), [0, 2, 1]), L), out.detach())))\n",
    "\n",
    "        W   = self.get_graph(out.detach())\n",
    "        edge_index, edge_weight = utils.dense_to_sparse(W)\n",
    "        out = self.conv3(out, edge_index, edge_weight)\n",
    "        out = self.relu(out)\n",
    "        edge_index, edge_weight = utils.remove_self_loops(edge_index, edge_weight)\n",
    "        L_edge_index, L_edge_weight = torch_geometric.utils.get_laplacian(edge_index.detach(), edge_weight.detach(), normalization=\"sym\")\n",
    "        L = torch_geometric.utils.to_dense_adj(edge_index=L_edge_index, edge_attr=L_edge_weight)\n",
    "        self.regularizers.append(torch.linalg.norm(torch.matmul(torch.matmul(torch.Tensor.permute(out.detach(), [0, 2, 1]), L), out.detach())))\n",
    "\n",
    "        '''\n",
    "        for i in range(len(self.F)):\n",
    "            x = getattr(self, 'gcn%d'%i)(x, L)\n",
    "            print(x)\n",
    "            x = self.relu(x)\n",
    "        '''\n",
    "\n",
    "        out = out.permute(0, 2, 1) # Transpose\n",
    "        out = self.pool(out)\n",
    "        out.squeeze_(2)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        for param in self.fc1.parameters():\n",
    "            self.regularizers.append(torch.linalg.norm(param))\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        for param in self.fc1.parameters():\n",
    "            self.regularizers.append(torch.linalg.norm(param))\n",
    "        out = self.fc3(out)\n",
    "        for param in self.fc1.parameters():\n",
    "            self.regularizers.append(torch.linalg.norm(param))\n",
    "        '''\n",
    "        for i in range(len(self.M)):\n",
    "            x = getattr(self, \"fc%d\"%i)(x)\n",
    "        return x\n",
    "        '''\n",
    "\n",
    "        return out, self.regularizers\n",
    "'''\n",
    "model = RGCNN_model(num_points, F, K, M)\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5521070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Sample: 0, Loss:2.2764809131622314 - Predicted class vs Real Cass: 1 <-> 5\n",
      "Epoch: 0, Sample: 100, Loss:1.7029818296432495 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 0, Sample: 200, Loss:2.2355823516845703 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 0, Sample: 300, Loss:1.329619288444519 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 0, Sample: 400, Loss:2.031759023666382 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 0, Sample: 500, Loss:1.9137217998504639 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 0, Sample: 600, Loss:2.2404379844665527 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 0, Sample: 700, Loss:0.5447449684143066 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 800, Loss:1.5520204305648804 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 0, Sample: 900, Loss:1.3378716707229614 - Predicted class vs Real Cass: 1 <-> 6\n",
      "Epoch: 0, Sample: 1000, Loss:1.09655877622572e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 0, Sample: 1100, Loss:2.329083204269409 - Predicted class vs Real Cass: 7 <-> 8\n",
      "Epoch: 0, Sample: 1200, Loss:1.6535677909851074 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 1300, Loss:0.020356958732008934 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 0, Sample: 1400, Loss:1.8026987314224243 - Predicted class vs Real Cass: 8 <-> 7\n",
      "Epoch: 0, Sample: 1500, Loss:3.151916742324829 - Predicted class vs Real Cass: 5 <-> 9\n",
      "Epoch: 0, Sample: 1600, Loss:1.930788516998291 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 0, Sample: 1700, Loss:0.5053675174713135 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 0, Sample: 1800, Loss:0.0982256829738617 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 0, Sample: 1900, Loss:1.8223854303359985 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 0, Sample: 2000, Loss:2.318254232406616 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 0, Sample: 2100, Loss:2.720771551132202 - Predicted class vs Real Cass: 8 <-> 6\n",
      "Epoch: 0, Sample: 2200, Loss:1.7491658926010132 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 0, Sample: 2300, Loss:7.650880434084684e-05 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 0, Sample: 2400, Loss:0.13211876153945923 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 0, Sample: 2500, Loss:0.7764407992362976 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 2600, Loss:0.20782649517059326 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 2700, Loss:0.00016195532225538045 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 2800, Loss:0.4106055200099945 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 2900, Loss:1.9604239463806152 - Predicted class vs Real Cass: 1 <-> 8\n",
      "Epoch: 0, Sample: 3000, Loss:0.8727757930755615 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 0, Sample: 3100, Loss:1.7897825241088867 - Predicted class vs Real Cass: 9 <-> 6\n",
      "Epoch: 0, Sample: 3200, Loss:1.7542390823364258 - Predicted class vs Real Cass: 8 <-> 1\n",
      "Epoch: 0, Sample: 3300, Loss:1.2603388768184232e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 0, Sample: 3400, Loss:0.002794461790472269 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 3500, Loss:2.290253162384033 - Predicted class vs Real Cass: 6 <-> 3\n",
      "Epoch: 0, Sample: 3600, Loss:1.2259989976882935 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 0, Sample: 3700, Loss:2.502284288406372 - Predicted class vs Real Cass: 2 <-> 8\n",
      "Epoch: 0, Sample: 3800, Loss:0.49914735555648804 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 3900, Loss:1.6352863311767578 - Predicted class vs Real Cass: 8 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.527436732648459 ~~~~~~~~~~~\n",
      "Epoch: 1, Sample: 0, Loss:0.027183594182133675 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 1, Sample: 100, Loss:0.3283383250236511 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 1, Sample: 200, Loss:1.0708739757537842 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 1, Sample: 300, Loss:0.0368800163269043 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 400, Loss:0.32575833797454834 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 500, Loss:0.19700561463832855 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 1, Sample: 600, Loss:1.1116728782653809 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 1, Sample: 700, Loss:0.08500630408525467 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 800, Loss:0.0031591919250786304 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 900, Loss:0.6850500106811523 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 1, Sample: 1000, Loss:0.18201623857021332 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 1, Sample: 1100, Loss:0.7235019207000732 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 1, Sample: 1200, Loss:2.8038350137649104e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 1300, Loss:0.09377259016036987 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 1, Sample: 1400, Loss:0.042164672166109085 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 1500, Loss:2.365645408630371 - Predicted class vs Real Cass: 6 <-> 9\n",
      "Epoch: 1, Sample: 1600, Loss:0.155088409781456 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 1, Sample: 1700, Loss:1.0902159214019775 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 1800, Loss:0.0388362817466259 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 1900, Loss:2.1812074184417725 - Predicted class vs Real Cass: 8 <-> 1\n",
      "Epoch: 1, Sample: 2000, Loss:1.7423135042190552 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 1, Sample: 2100, Loss:0.3409355878829956 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 1, Sample: 2200, Loss:1.0011200904846191 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 1, Sample: 2300, Loss:1.7867831729745376e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 1, Sample: 2400, Loss:0.04016067832708359 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 1, Sample: 2500, Loss:0.007827116176486015 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 2600, Loss:0.0007040159543976188 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 2700, Loss:1.325678340435843e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 2800, Loss:0.03397532179951668 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 2900, Loss:0.0722711831331253 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 1, Sample: 3000, Loss:0.2854798436164856 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 1, Sample: 3100, Loss:1.2452012300491333 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 1, Sample: 3200, Loss:1.8431692123413086 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 1, Sample: 3300, Loss:0.01945250667631626 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 1, Sample: 3400, Loss:2.1294940779625904e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 3500, Loss:1.3375755548477173 - Predicted class vs Real Cass: 8 <-> 3\n",
      "Epoch: 1, Sample: 3600, Loss:0.6089924573898315 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 1, Sample: 3700, Loss:1.1351567506790161 - Predicted class vs Real Cass: 3 <-> 8\n",
      "Epoch: 1, Sample: 3800, Loss:2.309873104095459 - Predicted class vs Real Cass: 9 <-> 2\n",
      "Epoch: 1, Sample: 3900, Loss:2.620119333267212 - Predicted class vs Real Cass: 7 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.7080932097218742 ~~~~~~~~~~~\n",
      "Epoch: 2, Sample: 0, Loss:8.151071710926772e-07 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 2, Sample: 100, Loss:0.27637979388237 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 2, Sample: 200, Loss:0.20020198822021484 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 2, Sample: 300, Loss:1.015326976776123 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 2, Sample: 400, Loss:0.0012609906261786819 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 2, Sample: 500, Loss:0.3951454758644104 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 2, Sample: 600, Loss:2.6478452682495117 - Predicted class vs Real Cass: 4 <-> 9\n",
      "Epoch: 2, Sample: 700, Loss:1.8638567098605563e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 800, Loss:0.000782898860052228 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 2, Sample: 900, Loss:0.8048089742660522 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 2, Sample: 1000, Loss:1.7312237332589575e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 2, Sample: 1100, Loss:0.9309920072555542 - Predicted class vs Real Cass: 8 <-> 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Sample: 1200, Loss:0.2645889222621918 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 1300, Loss:0.03962254896759987 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 2, Sample: 1400, Loss:0.0019118915079161525 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 2, Sample: 1500, Loss:8.089229583740234 - Predicted class vs Real Cass: 4 <-> 9\n",
      "Epoch: 2, Sample: 1600, Loss:0.013005051761865616 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 2, Sample: 1700, Loss:0.049190495163202286 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 2, Sample: 1800, Loss:0.46017199754714966 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 2, Sample: 1900, Loss:2.473133087158203 - Predicted class vs Real Cass: 3 <-> 1\n",
      "Epoch: 2, Sample: 2000, Loss:1.1519232988357544 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 2, Sample: 2100, Loss:0.44350528717041016 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 2, Sample: 2200, Loss:0.00014864328841213137 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 2, Sample: 2300, Loss:2.3543018414784456e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 2, Sample: 2400, Loss:0.020129192620515823 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 2, Sample: 2500, Loss:1.4154383052300545e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 2600, Loss:0.182174414396286 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 2700, Loss:1.5169332527875667e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 2800, Loss:0.00010961118823615834 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 2900, Loss:0.6070845127105713 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 2, Sample: 3000, Loss:0.023827191442251205 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 2, Sample: 3100, Loss:0.6823300719261169 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 2, Sample: 3200, Loss:1.586195707321167 - Predicted class vs Real Cass: 8 <-> 1\n",
      "Epoch: 2, Sample: 3300, Loss:0.00024240560014732182 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 2, Sample: 3400, Loss:0.0328538678586483 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 3500, Loss:0.9456633925437927 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 2, Sample: 3600, Loss:0.03727295249700546 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 2, Sample: 3700, Loss:0.5615164041519165 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 2, Sample: 3800, Loss:1.3767364025115967 - Predicted class vs Real Cass: 9 <-> 2\n",
      "Epoch: 2, Sample: 3900, Loss:2.141916036605835 - Predicted class vs Real Cass: 7 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.7627161112503132 ~~~~~~~~~~~\n",
      "Epoch: 3, Sample: 0, Loss:1.204114596475847e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 3, Sample: 100, Loss:0.22345572710037231 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 3, Sample: 200, Loss:9.178426989819854e-05 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 3, Sample: 300, Loss:0.0301810335367918 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 3, Sample: 400, Loss:0.0037957357708364725 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 3, Sample: 500, Loss:0.08405289798974991 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 3, Sample: 600, Loss:2.624638795852661 - Predicted class vs Real Cass: 7 <-> 9\n",
      "Epoch: 3, Sample: 700, Loss:0.0004850211553275585 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 800, Loss:0.006017410196363926 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 3, Sample: 900, Loss:1.6506105661392212 - Predicted class vs Real Cass: 8 <-> 6\n",
      "Epoch: 3, Sample: 1000, Loss:2.2852445908938535e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 3, Sample: 1100, Loss:0.668907880783081 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 3, Sample: 1200, Loss:3.992441270384006e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 1300, Loss:0.010900022462010384 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 3, Sample: 1400, Loss:0.03711843863129616 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 3, Sample: 1500, Loss:4.296035289764404 - Predicted class vs Real Cass: 4 <-> 9\n",
      "Epoch: 3, Sample: 1600, Loss:3.722244218806736e-05 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 3, Sample: 1700, Loss:0.07203377783298492 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 3, Sample: 1800, Loss:1.468807339668274 - Predicted class vs Real Cass: 0 <-> 7\n",
      "Epoch: 3, Sample: 1900, Loss:2.8552534580230713 - Predicted class vs Real Cass: 4 <-> 1\n",
      "Epoch: 3, Sample: 2000, Loss:0.465959370136261 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 3, Sample: 2100, Loss:0.11975636333227158 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 3, Sample: 2200, Loss:0.3055438995361328 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 3, Sample: 2300, Loss:1.8682832205740851e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 3, Sample: 2400, Loss:0.10697667300701141 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 3, Sample: 2500, Loss:1.7506738458905602e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 2600, Loss:0.0003302361292298883 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 2700, Loss:1.763020918588154e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 2800, Loss:1.4295459985733032 - Predicted class vs Real Cass: 9 <-> 2\n",
      "Epoch: 3, Sample: 2900, Loss:0.0014549277257174253 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 3, Sample: 3000, Loss:0.037505388259887695 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 3, Sample: 3100, Loss:1.0884819030761719 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 3, Sample: 3200, Loss:1.856144905090332 - Predicted class vs Real Cass: 8 <-> 1\n",
      "Epoch: 3, Sample: 3300, Loss:1.6395786133216461e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 3, Sample: 3400, Loss:0.000486275675939396 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 3500, Loss:0.5911435484886169 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 3, Sample: 3600, Loss:5.026910781860352 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 3, Sample: 3700, Loss:3.1026384830474854 - Predicted class vs Real Cass: 3 <-> 8\n",
      "Epoch: 3, Sample: 3800, Loss:0.8285085558891296 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 3900, Loss:0.49453189969062805 - Predicted class vs Real Cass: 1 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.7754948634427462 ~~~~~~~~~~~\n",
      "Epoch: 4, Sample: 0, Loss:0.0038857171311974525 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 4, Sample: 100, Loss:0.012931282632052898 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 4, Sample: 200, Loss:0.0006975356373004615 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 4, Sample: 300, Loss:0.08875944465398788 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 400, Loss:0.00650844257324934 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 500, Loss:0.05599554255604744 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 4, Sample: 600, Loss:5.304385662078857 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 4, Sample: 700, Loss:0.000486765056848526 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 800, Loss:9.656015754444525e-05 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 900, Loss:1.3577747344970703 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 4, Sample: 1000, Loss:1.8771780787574244e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 4, Sample: 1100, Loss:0.9476944804191589 - Predicted class vs Real Cass: 3 <-> 8\n",
      "Epoch: 4, Sample: 1200, Loss:0.0016174253541976213 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 1300, Loss:0.00020874386245850474 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 4, Sample: 1400, Loss:0.40582045912742615 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 1500, Loss:5.27616024017334 - Predicted class vs Real Cass: 5 <-> 9\n",
      "Epoch: 4, Sample: 1600, Loss:0.828731119632721 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 4, Sample: 1700, Loss:0.0016144998371601105 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 1800, Loss:0.4005393087863922 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 1900, Loss:2.0776560306549072 - Predicted class vs Real Cass: 6 <-> 1\n",
      "Epoch: 4, Sample: 2000, Loss:1.5524569749832153 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 4, Sample: 2100, Loss:0.5408118367195129 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 4, Sample: 2200, Loss:0.008179773576557636 - Predicted class vs Real Cass: 9 <-> 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Sample: 2300, Loss:2.4650141767779132e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 4, Sample: 2400, Loss:0.006905227899551392 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 4, Sample: 2500, Loss:1.2678978009716957e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 2600, Loss:0.00021087522327434272 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 2700, Loss:1.7990123524214141e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 2800, Loss:2.0476029476412805e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 2900, Loss:0.28700685501098633 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 4, Sample: 3000, Loss:0.020634450018405914 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 4, Sample: 3100, Loss:0.9630770683288574 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 4, Sample: 3200, Loss:1.4033371210098267 - Predicted class vs Real Cass: 8 <-> 1\n",
      "Epoch: 4, Sample: 3300, Loss:2.251968226119061e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 4, Sample: 3400, Loss:0.00021173768618609756 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 3500, Loss:8.559144973754883 - Predicted class vs Real Cass: 8 <-> 3\n",
      "Epoch: 4, Sample: 3600, Loss:0.05992145836353302 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 4, Sample: 3700, Loss:0.8277527093887329 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 4, Sample: 3800, Loss:0.011287111788988113 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 3900, Loss:0.6266113519668579 - Predicted class vs Real Cass: 1 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.791029817088449 ~~~~~~~~~~~\n",
      "Epoch: 5, Sample: 0, Loss:1.368554308101011e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 5, Sample: 100, Loss:0.870719313621521 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 5, Sample: 200, Loss:0.0037828702479600906 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 5, Sample: 300, Loss:0.0005492166383191943 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 400, Loss:0.07595904916524887 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 500, Loss:0.006625957787036896 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 5, Sample: 600, Loss:0.045497700572013855 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 5, Sample: 700, Loss:0.07800687104463577 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 800, Loss:0.00375161599367857 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 900, Loss:1.4437466859817505 - Predicted class vs Real Cass: 3 <-> 6\n",
      "Epoch: 5, Sample: 1000, Loss:2.725402737269178e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 5, Sample: 1100, Loss:1.1263371706008911 - Predicted class vs Real Cass: 3 <-> 8\n",
      "Epoch: 5, Sample: 1200, Loss:0.0010058640036731958 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 1300, Loss:0.23491699993610382 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 5, Sample: 1400, Loss:0.007035079412162304 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 1500, Loss:0.6555689573287964 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 5, Sample: 1600, Loss:0.0012956609716638923 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 5, Sample: 1700, Loss:0.022300081327557564 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 1800, Loss:0.0005686567164957523 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 1900, Loss:3.5248374938964844 - Predicted class vs Real Cass: 4 <-> 1\n",
      "Epoch: 5, Sample: 2000, Loss:1.1789021492004395 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 5, Sample: 2100, Loss:0.9810364246368408 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 5, Sample: 2200, Loss:4.817898570763646e-06 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 5, Sample: 2300, Loss:2.4198861865443178e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 5, Sample: 2400, Loss:1.4842240716461674e-06 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 5, Sample: 2500, Loss:2.9422624720609747e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 2600, Loss:6.469746585935354e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 2700, Loss:0.00015274283941835165 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 2800, Loss:1.7452579186283401e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 2900, Loss:0.09407014399766922 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 5, Sample: 3000, Loss:0.22938419878482819 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 5, Sample: 3100, Loss:2.7102668285369873 - Predicted class vs Real Cass: 3 <-> 6\n",
      "Epoch: 5, Sample: 3200, Loss:0.8519584536552429 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 5, Sample: 3300, Loss:2.1291853045113385e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 5, Sample: 3400, Loss:0.2899978458881378 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 3500, Loss:1.0659387111663818 - Predicted class vs Real Cass: 8 <-> 3\n",
      "Epoch: 5, Sample: 3600, Loss:0.00019323766173329204 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 5, Sample: 3700, Loss:1.0045322179794312 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 5, Sample: 3800, Loss:0.05780927091836929 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 3900, Loss:0.26843366026878357 - Predicted class vs Real Cass: 1 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.7985467301428213 ~~~~~~~~~~~\n",
      "Epoch: 6, Sample: 0, Loss:1.8538861468186951e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 6, Sample: 100, Loss:0.0007115565240383148 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 6, Sample: 200, Loss:0.010296882130205631 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 6, Sample: 300, Loss:0.14230488240718842 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 6, Sample: 400, Loss:0.2562709152698517 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 6, Sample: 500, Loss:0.0032181711867451668 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 6, Sample: 600, Loss:1.371944546699524 - Predicted class vs Real Cass: 4 <-> 9\n",
      "Epoch: 6, Sample: 700, Loss:2.2652620828012004e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 800, Loss:2.782093361020088e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 6, Sample: 900, Loss:0.6781766414642334 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 6, Sample: 1000, Loss:2.9710893159062834e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 6, Sample: 1100, Loss:0.08477718383073807 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 6, Sample: 1200, Loss:1.0157699762203265e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 1300, Loss:0.019799623638391495 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 6, Sample: 1400, Loss:1.3539526462554932 - Predicted class vs Real Cass: 1 <-> 7\n",
      "Epoch: 6, Sample: 1500, Loss:1.0394058227539062 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 6, Sample: 1600, Loss:0.1305840015411377 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 6, Sample: 1700, Loss:1.318566773989005e-05 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 6, Sample: 1800, Loss:0.007174052298069 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 6, Sample: 1900, Loss:1.6405302286148071 - Predicted class vs Real Cass: 2 <-> 1\n",
      "Epoch: 6, Sample: 2000, Loss:0.5492222309112549 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 6, Sample: 2100, Loss:1.050188422203064 - Predicted class vs Real Cass: 8 <-> 6\n",
      "Epoch: 6, Sample: 2200, Loss:0.00046011857921257615 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 6, Sample: 2300, Loss:2.7866883556271205e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 6, Sample: 2400, Loss:5.0873732106992975e-06 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 6, Sample: 2500, Loss:1.8927737528429134e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 2600, Loss:1.9680180685099913e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 2700, Loss:1.7489028323325329e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 2800, Loss:0.0017067011212930083 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 2900, Loss:0.0992574617266655 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 6, Sample: 3000, Loss:0.3194480240345001 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 6, Sample: 3100, Loss:1.947092890739441 - Predicted class vs Real Cass: 8 <-> 6\n",
      "Epoch: 6, Sample: 3200, Loss:1.3381211757659912 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 6, Sample: 3300, Loss:2.518420387787046e-06 - Predicted class vs Real Cass: 5 <-> 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Sample: 3400, Loss:2.121440502378391e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 3500, Loss:1.5048843622207642 - Predicted class vs Real Cass: 8 <-> 3\n",
      "Epoch: 6, Sample: 3600, Loss:0.0120188994333148 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 6, Sample: 3700, Loss:1.91648530960083 - Predicted class vs Real Cass: 6 <-> 8\n",
      "Epoch: 6, Sample: 3800, Loss:0.04021243005990982 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 3900, Loss:1.548583984375 - Predicted class vs Real Cass: 7 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.8145828113254824 ~~~~~~~~~~~\n",
      "Epoch: 7, Sample: 0, Loss:1.7791719528759131e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 7, Sample: 100, Loss:0.02900434099137783 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 7, Sample: 200, Loss:0.015433147549629211 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 7, Sample: 300, Loss:0.00019401463214308023 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 7, Sample: 400, Loss:0.05376753211021423 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 7, Sample: 500, Loss:3.826248212135397e-05 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 7, Sample: 600, Loss:1.9998972415924072 - Predicted class vs Real Cass: 7 <-> 9\n",
      "Epoch: 7, Sample: 700, Loss:3.646504637799808e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 800, Loss:2.103296537825372e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 7, Sample: 900, Loss:0.604743242263794 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 7, Sample: 1000, Loss:2.2061913114157505e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 7, Sample: 1100, Loss:0.7589028477668762 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 7, Sample: 1200, Loss:0.0012108046794310212 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 1300, Loss:1.9622264062491013e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 7, Sample: 1400, Loss:2.119319200515747 - Predicted class vs Real Cass: 1 <-> 7\n",
      "Epoch: 7, Sample: 1500, Loss:5.046481609344482 - Predicted class vs Real Cass: 1 <-> 9\n",
      "Epoch: 7, Sample: 1600, Loss:0.08808588981628418 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 7, Sample: 1700, Loss:1.192773461341858 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 7, Sample: 1800, Loss:1.4626290067099035e-05 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 7, Sample: 1900, Loss:3.1411092281341553 - Predicted class vs Real Cass: 4 <-> 1\n",
      "Epoch: 7, Sample: 2000, Loss:0.3641453981399536 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 7, Sample: 2100, Loss:0.29158997535705566 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 7, Sample: 2200, Loss:0.06944667547941208 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 7, Sample: 2300, Loss:2.620899977046065e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 7, Sample: 2400, Loss:0.00021180704061407596 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 7, Sample: 2500, Loss:1.932461145770503e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 2600, Loss:2.074472604363109e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 2700, Loss:2.3475786292692646e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 2800, Loss:0.0007344296900555491 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 2900, Loss:0.3344259560108185 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 7, Sample: 3000, Loss:0.011611922644078732 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 7, Sample: 3100, Loss:0.8862037062644958 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 7, Sample: 3200, Loss:1.235964059829712 - Predicted class vs Real Cass: 8 <-> 1\n",
      "Epoch: 7, Sample: 3300, Loss:0.014666948467493057 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 7, Sample: 3400, Loss:3.1955132726579905e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 3500, Loss:1.0541011095046997 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 7, Sample: 3600, Loss:0.6448805332183838 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 7, Sample: 3700, Loss:2.4032766819000244 - Predicted class vs Real Cass: 6 <-> 8\n",
      "Epoch: 7, Sample: 3800, Loss:1.900285269584856e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 3900, Loss:0.005478693172335625 - Predicted class vs Real Cass: 1 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.8073164620395891 ~~~~~~~~~~~\n",
      "Epoch: 8, Sample: 0, Loss:1.9686444829858374e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 8, Sample: 100, Loss:0.0032591414637863636 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 8, Sample: 200, Loss:5.5576994782313704e-05 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 8, Sample: 300, Loss:0.48833173513412476 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 8, Sample: 400, Loss:0.000777760986238718 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 8, Sample: 500, Loss:0.6644622683525085 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 8, Sample: 600, Loss:0.8163222670555115 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 8, Sample: 700, Loss:3.4213576327601913e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 800, Loss:0.0020555590745061636 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 8, Sample: 900, Loss:0.6974347233772278 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 8, Sample: 1000, Loss:3.7551387777057244e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 8, Sample: 1100, Loss:0.5541377067565918 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 8, Sample: 1200, Loss:2.3467166556656593e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 1300, Loss:0.09604719281196594 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 8, Sample: 1400, Loss:0.1330547332763672 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 8, Sample: 1500, Loss:0.7237135767936707 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 8, Sample: 1600, Loss:0.4050293266773224 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 8, Sample: 1700, Loss:0.2196808159351349 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 8, Sample: 1800, Loss:7.649233339179773e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 8, Sample: 1900, Loss:2.668827533721924 - Predicted class vs Real Cass: 6 <-> 1\n",
      "Epoch: 8, Sample: 2000, Loss:0.5722115635871887 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 8, Sample: 2100, Loss:0.5696823000907898 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 8, Sample: 2200, Loss:0.00034111630520783365 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 8, Sample: 2300, Loss:2.8481758818088565e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 8, Sample: 2400, Loss:0.10963591933250427 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 8, Sample: 2500, Loss:2.4855473839124897e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 2600, Loss:0.025220688432455063 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 2700, Loss:2.7825890356325544e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 2800, Loss:0.0015892627416178584 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 2900, Loss:0.0013081878423690796 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 8, Sample: 3000, Loss:0.002821475500240922 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 8, Sample: 3100, Loss:1.500787377357483 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 8, Sample: 3200, Loss:0.5116745829582214 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 8, Sample: 3300, Loss:2.804552423185669e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 8, Sample: 3400, Loss:2.617777454361203e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 3500, Loss:1.132927417755127 - Predicted class vs Real Cass: 8 <-> 3\n",
      "Epoch: 8, Sample: 3600, Loss:0.011996539309620857 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 8, Sample: 3700, Loss:2.041062831878662 - Predicted class vs Real Cass: 6 <-> 8\n",
      "Epoch: 8, Sample: 3800, Loss:1.7009769678115845 - Predicted class vs Real Cass: 9 <-> 2\n",
      "Epoch: 8, Sample: 3900, Loss:0.9450167417526245 - Predicted class vs Real Cass: 1 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.7990478576797795 ~~~~~~~~~~~\n",
      "Epoch: 9, Sample: 0, Loss:2.4241619485110277e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 9, Sample: 100, Loss:0.00027215253794565797 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 9, Sample: 200, Loss:0.39689838886260986 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 9, Sample: 300, Loss:0.4534448981285095 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 9, Sample: 400, Loss:0.015433494001626968 - Predicted class vs Real Cass: 7 <-> 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Sample: 500, Loss:0.02198231965303421 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 9, Sample: 600, Loss:0.4828082025051117 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 9, Sample: 700, Loss:0.05066072195768356 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 800, Loss:0.004769247956573963 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 9, Sample: 900, Loss:1.4329628944396973 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 9, Sample: 1000, Loss:3.6185122098686406e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 9, Sample: 1100, Loss:0.04740089923143387 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 9, Sample: 1200, Loss:0.00016618947847746313 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 1300, Loss:2.4358332666452043e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 9, Sample: 1400, Loss:0.4450165331363678 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 9, Sample: 1500, Loss:0.5021941065788269 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 9, Sample: 1600, Loss:0.9285596609115601 - Predicted class vs Real Cass: 0 <-> 1\n",
      "Epoch: 9, Sample: 1700, Loss:0.9274483323097229 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 9, Sample: 1800, Loss:1.3826229405822232e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 9, Sample: 1900, Loss:4.700483322143555 - Predicted class vs Real Cass: 9 <-> 1\n",
      "Epoch: 9, Sample: 2000, Loss:0.7031461596488953 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 9, Sample: 2100, Loss:0.771675705909729 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 9, Sample: 2200, Loss:9.80438562692143e-06 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 9, Sample: 2300, Loss:3.7450770378200104e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 9, Sample: 2400, Loss:2.609277089504758e-06 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 9, Sample: 2500, Loss:1.95967618310533e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 2600, Loss:0.007949387654662132 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 2700, Loss:2.770056426015799e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 2800, Loss:3.478041890048189e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 2900, Loss:0.6002663969993591 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 9, Sample: 3000, Loss:0.5972551703453064 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 9, Sample: 3100, Loss:0.756388783454895 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 9, Sample: 3200, Loss:0.06774762272834778 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 9, Sample: 3300, Loss:3.4115328162442893e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 9, Sample: 3400, Loss:9.75280927377753e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 3500, Loss:0.748950719833374 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 9, Sample: 3600, Loss:9.921096352627501e-05 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 9, Sample: 3700, Loss:0.5950678586959839 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 9, Sample: 3800, Loss:0.001633040839806199 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 3900, Loss:0.39329999685287476 - Predicted class vs Real Cass: 1 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.8251064896016036 ~~~~~~~~~~~\n",
      "Epoch: 10, Sample: 0, Loss:2.488843392711715e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 10, Sample: 100, Loss:0.049801431596279144 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 10, Sample: 200, Loss:0.00023078978119883686 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 10, Sample: 300, Loss:0.8564745783805847 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 10, Sample: 400, Loss:1.5624134448444238e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 10, Sample: 500, Loss:0.0012650394346565008 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 10, Sample: 600, Loss:0.09434135258197784 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 10, Sample: 700, Loss:5.759767191193532e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 800, Loss:1.831293275245116e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 10, Sample: 900, Loss:0.9547092914581299 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 10, Sample: 1000, Loss:3.3370990877301665e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 10, Sample: 1100, Loss:1.5207867622375488 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 10, Sample: 1200, Loss:2.269808419441688e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 1300, Loss:0.0019597953651100397 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 10, Sample: 1400, Loss:1.6042983531951904 - Predicted class vs Real Cass: 1 <-> 7\n",
      "Epoch: 10, Sample: 1500, Loss:0.13405922055244446 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 10, Sample: 1600, Loss:0.004312497563660145 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 10, Sample: 1700, Loss:0.02198690176010132 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 10, Sample: 1800, Loss:1.4880241678838502e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 10, Sample: 1900, Loss:2.1671550273895264 - Predicted class vs Real Cass: 4 <-> 1\n",
      "Epoch: 10, Sample: 2000, Loss:2.632875680923462 - Predicted class vs Real Cass: 2 <-> 6\n",
      "Epoch: 10, Sample: 2100, Loss:1.099068284034729 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 10, Sample: 2200, Loss:3.0309188332466874e-06 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 10, Sample: 2300, Loss:3.7490285649255384e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 10, Sample: 2400, Loss:9.308577318734024e-06 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 10, Sample: 2500, Loss:3.145893424516544e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 2600, Loss:2.0980364752176683e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 2700, Loss:2.8967201615159865e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 2800, Loss:4.4077864913560916e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 2900, Loss:0.13682590425014496 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 10, Sample: 3000, Loss:0.6042121648788452 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 10, Sample: 3100, Loss:0.2593736946582794 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 10, Sample: 3200, Loss:0.00047993092448450625 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 10, Sample: 3300, Loss:2.797667548293248e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 10, Sample: 3400, Loss:4.3606574763543904e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 3500, Loss:1.3645715713500977 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 10, Sample: 3600, Loss:0.24054701626300812 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 10, Sample: 3700, Loss:3.5405426025390625 - Predicted class vs Real Cass: 4 <-> 8\n",
      "Epoch: 10, Sample: 3800, Loss:2.2362380605045473e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 3900, Loss:2.947804432551493e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.820095214232022 ~~~~~~~~~~~\n",
      "Epoch: 11, Sample: 0, Loss:2.66234451373748e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 11, Sample: 100, Loss:0.12458433955907822 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 11, Sample: 200, Loss:0.053335484117269516 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 11, Sample: 300, Loss:1.0834560271177907e-05 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 11, Sample: 400, Loss:1.8808085542332265e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 11, Sample: 500, Loss:0.11322750151157379 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 11, Sample: 600, Loss:0.5671943426132202 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 11, Sample: 700, Loss:4.085949967702618e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 800, Loss:1.8302189346286468e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 11, Sample: 900, Loss:1.2089952230453491 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 11, Sample: 1000, Loss:4.011222245026147e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 11, Sample: 1100, Loss:0.7171931266784668 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 11, Sample: 1200, Loss:4.496060682868119e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 1300, Loss:0.3224804401397705 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 11, Sample: 1400, Loss:0.03251836448907852 - Predicted class vs Real Cass: 7 <-> 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Sample: 1500, Loss:0.009936737827956676 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 11, Sample: 1600, Loss:0.00011942486162297428 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 11, Sample: 1700, Loss:0.0086568184196949 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 11, Sample: 1800, Loss:2.3878374122432433e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 11, Sample: 1900, Loss:1.8567322492599487 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 11, Sample: 2000, Loss:0.9740878343582153 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 11, Sample: 2100, Loss:0.05549755319952965 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 11, Sample: 2200, Loss:3.235589474570588e-06 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 11, Sample: 2300, Loss:3.1823385597817833e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 11, Sample: 2400, Loss:0.0002959584235213697 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 11, Sample: 2500, Loss:3.1568574740958866e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 2600, Loss:2.3146742478274973e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 2700, Loss:4.932873707730323e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 2800, Loss:3.462900394879398e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 2900, Loss:3.3674402236938477 - Predicted class vs Real Cass: 1 <-> 8\n",
      "Epoch: 11, Sample: 3000, Loss:0.04586077481508255 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 11, Sample: 3100, Loss:2.0027825832366943 - Predicted class vs Real Cass: 3 <-> 6\n",
      "Epoch: 11, Sample: 3200, Loss:0.30891528725624084 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 11, Sample: 3300, Loss:3.148212272208184e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 11, Sample: 3400, Loss:0.05016909912228584 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 3500, Loss:6.684744834899902 - Predicted class vs Real Cass: 4 <-> 3\n",
      "Epoch: 11, Sample: 3600, Loss:0.5169690251350403 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 11, Sample: 3700, Loss:6.252466678619385 - Predicted class vs Real Cass: 6 <-> 8\n",
      "Epoch: 11, Sample: 3800, Loss:0.11241213977336884 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 3900, Loss:0.035695888102054596 - Predicted class vs Real Cass: 1 <-> 1\n",
      "~~~~~~~~~ CORRECT: 0.8175895765472313 ~~~~~~~~~~~\n",
      "Epoch: 12, Sample: 0, Loss:2.6387767775304383e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 12, Sample: 100, Loss:2.3062217235565186 - Predicted class vs Real Cass: 0 <-> 9\n",
      "Epoch: 12, Sample: 200, Loss:0.06778091192245483 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 12, Sample: 300, Loss:0.5974776148796082 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 12, Sample: 400, Loss:0.00017809405107982457 - Predicted class vs Real Cass: 7 <-> 7\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model = RGCNN_model(num_points, F, K, M, dropout=0.6)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "def get_loss(y, labels, regularization, regularizers):\n",
    "    cross_entropy_loss = loss(y, labels)\n",
    "    s = torch.sum(torch.as_tensor(regularizers))\n",
    "    regularization *= s\n",
    "    l = cross_entropy_loss + regularization\n",
    "    return l\n",
    "    \n",
    "correct_percentage_list = []\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    #dataset_train = dataset_train.shuffle()\n",
    "    correct = 0\n",
    "    for i, data in enumerate(dataset_train):\n",
    "        # make sure the gradients are empty\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Data preparation \n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred, regularizers = model(x)     # (1 * 40)\n",
    "        \n",
    "        class_pred = torch.argmax(y_pred.squeeze(0))  # (1)  \n",
    "        correct += int((class_pred == y).sum())       # to compute the accuracy for each epoch\n",
    "        \n",
    "\n",
    "        # loss and backward\n",
    "        ###################################################################################\n",
    "        #                           CrossEntropyLoss\n",
    "        # This WORKS but I am testing the other way...\n",
    "        # l = loss(y_pred, y)   # one value\n",
    "        # l.backward()          # update gradients\n",
    "        ###################################################################################\n",
    "       \n",
    "        l = get_loss(y_pred, y, regularization=1e-9, regularizers=regularizers)\n",
    "        l.backward()\n",
    "\n",
    "        # optimisation\n",
    "        optimizer.step()\n",
    "    \n",
    "        if i%100==0:\n",
    "            print(f\"Epoch: {epoch}, Sample: {i}, Loss:{l} - Predicted class vs Real Cass: {class_pred} <-> {y.item()}\")\n",
    "            # print(torch.sum(torch.as_tensor(regularizers)))\n",
    "    print(f\"~~~~~~~~~ CORRECT: {correct / len(dataset_train)} ~~~~~~~~~~~\")\n",
    "    correct_percentage_list.append(correct / len(dataset_train))\n",
    "print(correct_percentage_list)\n",
    "\n",
    "# torch.save(model.state_dict(), \"/home/alex/Alex_pyt_geom/models\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in dataset_test:\n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred, _ = model(x)     # (1 * 40)\n",
    "\n",
    "        class_pred = torch.argmax(y_pred)\n",
    "        correct += int((class_pred == y).sum())\n",
    "\n",
    "    print(f\"Correct percentage : {correct / len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_percentage_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85919859",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in dataset_test:\n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred = model(x)     # (1 * 40)\n",
    "\n",
    "        class_pred = torch.argmax(y_pred)\n",
    "        # print(\"Pred: \", class_pred.item(), \"Real: \" , y.item())\n",
    "        correct += int((class_pred == y).sum())\n",
    "\n",
    "    print(f\"Correct percentage : {correct / len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f9783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in dataset_test:\n",
    "        \n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred, _ = model(x)     # (1 * 40)\n",
    "\n",
    "        class_pred = torch.argmax(y_pred)\n",
    "        print(\"Pred: \", class_pred.item(), \"Real: \" , y.item())\n",
    "        correct += int((class_pred == y_pred).sum())\n",
    "\n",
    "    print(f\"Correct percentage : {correct / len(dataset_test)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.rand([1, 1024, 6])*5+3\n",
    "    x = x.to(device)\n",
    "    y = model(x)\n",
    "    y_class = torch.argmax(y)\n",
    "    print(y)\n",
    "    print(y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c348f533",
   "metadata": {},
   "source": [
    "WORK IN PROGRESS!!! \n",
    "Trying to create batches from data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e229a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "length = len(dataset_train)\n",
    "batch_size = 32\n",
    "iterations = np.ceil(length/batch_size)\n",
    "iterations = iterations.astype(int)\n",
    "batched_data = torch.empty([125, 1024, 6])\n",
    "print(dataset_train)\n",
    "print(dataset_train[0])\n",
    "aux = Data()\n",
    "for i in range(iterations):\n",
    "    ob = dataset_train[i:i+batch_size]\n",
    "    pos=torch.empty([0, 3])\n",
    "    y = torch.empty([0])\n",
    "    normal = torch.empty([0, 3])\n",
    "    for data in ob:\n",
    "        pos = torch.cat([pos, data.pos])\n",
    "        y = torch.cat([y, data.y])\n",
    "        normal = torch.cat([normal, data.normal])\n",
    "    batch_data[i] = Data(pos=pos, y=y, normal=normal)\n",
    "print(pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pos.shape)\n",
    "#print(pos)\n",
    "print(len(batch_data))\n",
    "Batched_data = torch.empty([125, 1024, 6])\n",
    "BATCHED_DATA = []\n",
    "for i in range(125):\n",
    "    # print(batch_data[i].pos)\n",
    "    pos = torch.empty([32, 1024, 3])\n",
    "    y = torch.empty([32, 1])\n",
    "    normal = torch.empty([32, 1024, 3])\n",
    "    for i in range(batch_size):\n",
    "        pos[i] = batch_data[i].pos[num_points*i:num_points*i+1024]\n",
    "        y[i] = batch_data[i].y[i]\n",
    "        normal[i] = batch_data[i].normal[num_points*i:num_points*i+1024]\n",
    "    BATCH = Data(pos=pos, y=y, normal=normal)\n",
    "    BATCHED_DATA.append(BATCH)\n",
    "    # Batched_data[i] = Data(pos=pos, y=y, normal=normal)\n",
    "print(pos.shape)\n",
    "print(normal.shape)\n",
    "print(y.shape)\n",
    "print(len(BATCHED_DATA))\n",
    "for data in BATCHED_DATA:\n",
    "    print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
