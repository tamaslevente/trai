{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 26 18:22:21 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.38       Driver Version: 455.38       CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 3080    Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 53%   31C    P8    31W / 340W |   3049MiB / 10018MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1650      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      1798      G   /usr/bin/gnome-shell               54MiB |\r\n",
      "|    0   N/A  N/A      2565      G   /usr/lib/xorg/Xorg                103MiB |\r\n",
      "|    0   N/A  N/A      2723      G   ...mviewer/tv_bin/TeamViewer       15MiB |\r\n",
      "|    0   N/A  N/A     10930      G   /usr/lib/firefox/firefox            4MiB |\r\n",
      "|    0   N/A  N/A     11195      G   /usr/lib/firefox/firefox            4MiB |\r\n",
      "|    0   N/A  N/A     12563      G   /usr/lib/firefox/firefox            4MiB |\r\n",
      "|    0   N/A  N/A     16582      G   /usr/bin/gnome-shell               34MiB |\r\n",
      "|    0   N/A  N/A     21819      C   ...nvs/Alex_torch/bin/python     2797MiB |\r\n",
      "|    0   N/A  N/A     31058      G   gnome-control-center                4MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in Progress\n",
    "\n",
    "This is an implementation of RGCNN from the paper https://github.com/tegusi/RGCNN\n",
    "\n",
    "Initial testing will be done on the GeometricShapes dataset from PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole dataset:       \t ModelNet10(3991)\n",
      "Example from the dataset:\t Data(pos=[1777, 3], face=[3, 2509], y=[1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "'''\n",
    "from torch_geometric.datasets import GeometricShapes\n",
    "dataset = GeometricShapes(rood='data/GeometricShapes')\n",
    "'''\n",
    "from torch_geometric.datasets import ModelNet\n",
    "\n",
    "dataset = ModelNet(root='data/ModelNet', train=True)\n",
    "dataset_test = ModelNet(root='data/ModelNet', train=False)\n",
    "print(\"The whole dataset:       \\t\", dataset)\n",
    "print(\"Example from the dataset:\\t\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the Meshes from the dataset to a PointCloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of Train Point Cloud: \t Data(pos=[300, 3], y=[1])\n",
      "Example of Test Point Cloud: \t Data(pos=[300, 3], y=[1])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import SamplePoints\n",
    "from torch_geometric.transforms import NormalizeScale\n",
    "from torch_geometric.transforms import Compose\n",
    "\n",
    "# For reproductibility\n",
    "torch.manual_seed(42)\n",
    "points_number = 300  #For quicker test. Default: 1024\n",
    "dataset.transform = Compose([SamplePoints(num=points_number), NormalizeScale()])\n",
    "dataset_test.transform = Compose([SamplePoints(num=points_number), NormalizeScale()])\n",
    "#dataset.transform = NormalizeScale()\n",
    "#dataset_test.transform = NormalizeScale()\n",
    "print(\"Example of Train Point Cloud: \\t\", dataset[0])\n",
    "print(\"Example of Test Point Cloud: \\t\", dataset_test[0])\n",
    "# print(\"Example of Test Point CloudValues : \\t\", dataset_test[0].pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following classes are defined as in the RGCNN github:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GetGraph(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GetGraph, self).__init__()\n",
    "\n",
    "    def forward(self, point_cloud):\n",
    "        point_cloud_transpose = point_cloud.permute(0, 2, 1)\n",
    "        point_cloud_inner = torch.matmul(point_cloud, point_cloud_transpose)\n",
    "        point_cloud_inner = -2 * point_cloud_inner\n",
    "        point_cloud_square = torch.sum(torch.mul(point_cloud, point_cloud), dim=2, keepdim=True)\n",
    "        point_cloud_square_tranpose = point_cloud_square.permute(0, 2, 1)\n",
    "        adj_matrix = point_cloud_square + point_cloud_inner + point_cloud_square_tranpose\n",
    "        adj_matrix = torch.exp(-adj_matrix)\n",
    "        return adj_matrix\n",
    "\n",
    "\n",
    "class GetLaplacian(nn.Module):\n",
    "    def __init__(self, normalize=True):\n",
    "        super(GetLaplacian, self).__init__()\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def diag(self, mat):\n",
    "        # input is batch x vertices\n",
    "        d = []\n",
    "        for vec in mat:\n",
    "            d.append(torch.diag(vec))\n",
    "        return torch.stack(d)\n",
    "\n",
    "    def forward(self, adj_matrix):\n",
    "        if self.normalize:\n",
    "            D = torch.sum(adj_matrix, dim=2)\n",
    "            eye = torch.ones_like(D)\n",
    "            eye = self.diag(eye)\n",
    "            D = 1 / torch.sqrt(D)\n",
    "            D = self.diag(D)\n",
    "            L = eye - torch.matmul(torch.matmul(D, adj_matrix), D)\n",
    "        else:\n",
    "            D = torch.sum(adj_matrix, dim=1)\n",
    "            D = torch.matrix_diag(D)\n",
    "            L = D - adj_matrix\n",
    "        return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_graph = GetGraph()\n",
    "print(\"Shape of the dataset points: \\t\", dataset[0].pos.shape)\n",
    "data=dataset[0].pos\n",
    "data=data.reshape([1,data.shape[0], data.shape[1]])\n",
    "print(\"New shape:                   \\t\", data.shape)\n",
    "x=data\n",
    "W = get_graph(data)\n",
    "\n",
    "W_torch = W\n",
    "print(\"Graph shape:                 \\t\", W_torch.shape)\n",
    "W=torch.squeeze(W)\n",
    "print(\"Reduction of the data dimension:\\t\", W.shape)\n",
    "print(\"Graph:                       \\t\", W)\n",
    "\n",
    "\n",
    "getter_laplacian = GetLaplacian()\n",
    "L_torch = getter_laplacian(W_torch)\n",
    "L = torch.squeeze(L_torch)\n",
    "print(\"Laplacian shape:             \\t\", L_torch.shape)\n",
    "print(\"Squeezed Laplacian shape     \\t\", L.shape)\n",
    "print(\"Laplacian                    \\t\", L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Chebyshev approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def find_eigmax(L):\n",
    "    with torch.no_grad():\n",
    "        e1, _ = torch.eig(L, eigenvectors=False)\n",
    "        return torch.max(e1[:, 0]).item()\n",
    "\n",
    "def chebyshev_Lapl(X, Lapl, thetas, order):\n",
    "    list_powers = []\n",
    "    nodes = Lapl.shape[0]\n",
    "\n",
    "    T0 = X.float()\n",
    "\n",
    "    eigmax = find_eigmax(Lapl)\n",
    "    L_rescaled = (2 * Lapl / eigmax) - torch.eye(1024)\n",
    "\n",
    "    y = T0 * thetas[0]\n",
    "    list_powers.append(y)\n",
    "    T1 = torch.matmul(L_rescaled, T0)\n",
    "    list_powers.append(T1 * thetas[1])\n",
    "\n",
    "    # Computation of: T_k = 2*L_rescaled*T_k-1  -  T_k-2\n",
    "    for k in range(2, order):\n",
    "        T2 = 2 * torch.matmul(L_rescaled, T1) - T0\n",
    "        list_powers.append((T2 * thetas[k]))\n",
    "        T0, T1 = T1, T2\n",
    "    y_out = torch.stack(list_powers, dim=-1)\n",
    "    # the powers may be summed or concatenated. i use concatenation here\n",
    "    y_out = y_out.view(nodes, -1) # -1 = order* features_of_signal\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Chebyshev approx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = 3          # input features number for the 'model'\n",
    "out_features_1 = 128    # output features number from the first convolutional layer\n",
    "K1 = 6                  # order of the Chebyshev Polynomial\n",
    "thetas_1 = nn.Parameter(torch.rand(points_number))  # initialization of the parameters of the model for the first conv layer\n",
    "out = chebyshev_Lapl(x,L,thetas_1,K1)           # computing the approximate polynomial\n",
    "print('cheb approx out powers concatenated:', out.shape)    \n",
    "linear_1 = nn.Linear(K1*features_1, out_features_1)     # MLP == Linear\n",
    "layer_out_1 = linear_1(out)\n",
    "print('Layers output:', layer_out_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will try to define a convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn.conv as cnv\n",
    "import torch_geometric.utils as tgu\n",
    "\n",
    "class RGCNN_Conv(nn.Module):\n",
    "    def __init__(self, F_in, K, F_out):\n",
    "        super(RGCNN_Conv, self).__init__()\n",
    "        self.F_in = F_in\n",
    "        self.K = K\n",
    "        self.F_out = F_out\n",
    "        '''\n",
    "        self.W = nn.Parameter(torch.Tensor(self.K * self.F_in, self.F_out))\n",
    "        nn.init.normal_(self.W, mean=0, std=0.2)\n",
    "\n",
    "        self.B = nn.Parameter(torch.Tensor(self.F_out))\n",
    "        nn.init.normal_(self.B, mean=0, std=0.2)\n",
    "        '''\n",
    "        self.cheb_conv = cnv.ChebConv(in_channels=F_in, out_channels=F_out, K=K, normalization=\"sym\", bias=True)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, W):\n",
    "        N, M, F_in = list(x.size())\n",
    "        edge_index, edge_weight = tgu.dense_to_sparse(W)\n",
    "        x = self.cheb_conv(x=x, edge_index=edge_index, edge_weight=edge_weight)\n",
    "        x = self.relu(x)\n",
    "        return x.reshape(N, M, self.F_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[0].pos\n",
    "x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "get_graph = GetGraph()\n",
    "W = get_graph(x)\n",
    "edge_index, edge_weight = tgu.dense_to_sparse(W)\n",
    "conv1 = RGCNN_Conv(F_in=3, K=6, F_out=128)\n",
    "aux = conv1(x, W)\n",
    "#print(aux.shape)\n",
    "\n",
    "print(conv1.state_dict())   # This shows the Parameters of the Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the defined Convolutional Layer we can create our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNN_Model(nn.Module):\n",
    "    def __init__(self, points_number, F, K, M, in_features):\n",
    "\n",
    "        # Verify the consistency w.r.t. the number of layers.\n",
    "        assert len(F) == len(K)\n",
    "        \n",
    "        super(RGCNN_Model, self).__init__()\n",
    "        self.points_number = points_number\n",
    "        self.F = F\n",
    "        self.K = K\n",
    "        self.M = M\n",
    "        self.layers_number = len(F)\n",
    "        self.get_graph = GetGraph()\n",
    "        self.convolution_list = []\n",
    "        self.mlp_list = []\n",
    "        self.rloss = nn.MSELoss()\n",
    "        self.pool = nn.MaxPool1d(self.points_number)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        for i in range(self.layers_number):\n",
    "            if i == 0:\n",
    "                layer = RGCNN_Conv(in_features, K[i], F[i])\n",
    "            else:\n",
    "                layer = RGCNN_Conv(F[i-1], K[i], F[i])\n",
    "            setattr(self, 'gcn%d' % i, layer)\n",
    "\n",
    "        for i in range(len(M)):\n",
    "            if i == 0:\n",
    "                mlp = nn.Linear(F[-1], M[i])\n",
    "            else:\n",
    "                mlp = nn.Linear(M[i-1], M[i])\n",
    "            setattr(self, 'mlp%d' % i, mlp )\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        # W = self.get_graph(x)\n",
    "        losses = []\n",
    "        #labels = torch.zeros(40)\n",
    "        #labels[label] = 1\n",
    "        #labels = labels.to(device)\n",
    "        for i in range(self.layers_number):\n",
    "            W = self.get_graph(x)\n",
    "            x = getattr(self, 'gcn%d' % i)(x, W)\n",
    "        # loss = self.rloss(x, labels)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.pool(x)\n",
    "        x.squeeze_(2)\n",
    "        for i in range(len(self.M)):\n",
    "            x = getattr(self, 'mlp%d' % i)(x)\n",
    "            x = self.relu(x)\n",
    "        labels = torch.zeros(x.shape[-1])\n",
    "        labels[label] = 1\n",
    "        labels = labels.reshape(shape=list(x.shape))\n",
    "        labels = labels.to(device)\n",
    "        loss = self.rloss(x, labels)\n",
    "        return x, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on  cuda\n"
     ]
    }
   ],
   "source": [
    "F = [128, 512, 1024, 512, 128, 40]  # Number of graph convolutional filters.\n",
    "K = [6, 5, 3, 1, 1, 1]  # Polynomial orders.\n",
    "M = [512, 128, 10]  # Output dimensionality of fully connected layers.\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print(\"Training on \", device)\n",
    "model = RGCNN_Model(points_number=points_number, F=F, K=K, M=M, in_features=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 3]\n"
     ]
    }
   ],
   "source": [
    "rloss = nn.MSELoss()\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "    \n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        X = data.pos\n",
    "        label = data.y\n",
    "        X = X.reshape([1, X.shape[0], X.shape[1]])\n",
    "        X = X.to(device)\n",
    "        label = label.to(torch.float)\n",
    "        label = label.to(device)\n",
    "        # Forward pass.\n",
    "        # print(label.to(torch.int).item())\n",
    "        out, _ = model(X, label.to(torch.int).item())\n",
    "        pred = out.argmax(dim=-1)\n",
    "        loss = rloss(pred, label)\n",
    "        # Calculate gradients.\n",
    "        # loss.backward()\n",
    "        # Updates the models parameters\n",
    "        optimizer.step()\n",
    "\n",
    "print(list(dataset[0].pos.size()))\n",
    "\n",
    "#train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        X = data.pos\n",
    "        labels = data.y\n",
    "        X, labels = X.to(device), labels.to(device)  \n",
    "        X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "        # Forward pass.\n",
    "        out, loss = model(X, labels)\n",
    "        # Take the index of the class with the highest probability.\n",
    "        pred = out.argmax(dim=1)\n",
    "        # Compare with ground-truth labels.\n",
    "        correct += int((pred == labels).sum()) \n",
    "    return correct / len(loader)\n",
    "\n",
    "# test(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Acc: 0.0501\n",
      "Epoch: 2, Train Acc: 0.0501\n",
      "Epoch: 3, Train Acc: 0.0501\n",
      "Epoch: 4, Train Acc: 0.0501\n",
      "Epoch: 5, Train Acc: 0.0501\n",
      "Epoch: 6, Train Acc: 0.0501\n",
      "Epoch: 7, Train Acc: 0.0501\n",
      "Epoch: 8, Train Acc: 0.0501\n",
      "Epoch: 9, Train Acc: 0.0501\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6c29cd0607c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch}, Train Acc: {train_acc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-54d560bef1c7>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Alex_torch/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Alex_torch/lib/python3.7/site-packages/torch_geometric/transforms/compose.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Alex_torch/lib/python3.7/site-packages/torch_geometric/transforms/sample_points.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marea\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Alex_torch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Alex_torch/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    train(dataset)\n",
    "    train_acc = test(dataset)\n",
    "    print(f'Epoch: {epoch}, Train Acc: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = dataset[0].pos\n",
    "labels = dataset[0].y\n",
    "X, labels = X.to(device), labels.to(device)  \n",
    "X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "out, loss = model(X, labels)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c0fe59c60a9be49491cfed5af4355f9d7f0b1a43e9b3a8e9ef6dffb36976bea"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
